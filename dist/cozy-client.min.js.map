{"version":3,"sources":["webpack:///webpack/universalModuleDefinition","webpack:///cozy-client.min.js","webpack:///webpack/bootstrap 55c3d57ab06a4462218d","webpack:///./src/fetch.js","webpack:///./~/pouchdb-find/lib/utils.js","webpack:///./src/utils.js","webpack:///./~/pouchdb-find/lib/adapters/local/utils.js","webpack:///./~/process/browser.js","webpack:///./src/doctypes.js","webpack:///./~/core-js/modules/_global.js","webpack:///./~/pouchdb-collate/lib/index.js","webpack:///./src/auth_v3.js","webpack:///./~/core-js/modules/_descriptors.js","webpack:///./~/core-js/modules/_fails.js","webpack:///./~/core-js/modules/_is-object.js","webpack:///./~/immediate/lib/browser.js","webpack:///./~/inherits/inherits_browser.js","webpack:///./~/pouchdb-find/lib/abstract-mapreduce/utils.js","webpack:///./~/pouchdb-find/lib/adapters/local/abstract-mapper.js","webpack:///./~/argsarray/index.js","webpack:///./src/jsonapi.js","webpack:///./~/core-js/modules/_core.js","webpack:///./~/core-js/modules/_defined.js","webpack:///./~/core-js/modules/_has.js","webpack:///./~/core-js/modules/_hide.js","webpack:///./~/core-js/modules/_iobject.js","webpack:///./~/core-js/modules/_to-integer.js","webpack:///./~/core-js/modules/_to-iobject.js","webpack:///./~/core-js/modules/_uid.js","webpack:///./~/debug/src/browser.js","webpack:///./~/lie/lib/index.js","webpack:///./~/pouchdb-extend/index.js","webpack:///./~/pouchdb-find/lib/abstract-mapreduce/upsert.js","webpack:///./~/pouchdb-find/lib/adapters/local/get-indexes/index.js","webpack:///./~/pouchdb-find/lib/massageCreateIndexRequest.js","webpack:///./~/pouchdb-find/~/pouchdb-promise/lib/index.js","webpack:///./~/pouchdb-find/~/spark-md5/spark-md5.js","webpack:///./~/pouchdb-upsert/index.js","webpack:///./src/auth_storage.js","webpack:///./src/auth_v2.js","webpack:///./src/data.js","webpack:///./src/files.js","webpack:///./src/index.js","webpack:///./src/intents.js","webpack:///./src/jobs.js","webpack:///./src/mango.js","webpack:///./src/offline.js","webpack:///./src/relations.js","webpack:///./src/settings.js","webpack:///./~/babel-runtime/regenerator/index.js","webpack:///./~/core-js/modules/_a-function.js","webpack:///./~/core-js/modules/_an-object.js","webpack:///./~/core-js/modules/_array-includes.js","webpack:///./~/core-js/modules/_cof.js","webpack:///./~/core-js/modules/_ctx.js","webpack:///./~/core-js/modules/_dom-create.js","webpack:///./~/core-js/modules/_enum-bug-keys.js","webpack:///./~/core-js/modules/_export.js","webpack:///./~/core-js/modules/_ie8-dom-define.js","webpack:///./~/core-js/modules/_object-assign.js","webpack:///./~/core-js/modules/_object-dp.js","webpack:///./~/core-js/modules/_object-gops.js","webpack:///./~/core-js/modules/_object-keys-internal.js","webpack:///./~/core-js/modules/_object-keys.js","webpack:///./~/core-js/modules/_object-pie.js","webpack:///./~/core-js/modules/_property-desc.js","webpack:///./~/core-js/modules/_redefine.js","webpack:///./~/core-js/modules/_shared-key.js","webpack:///./~/core-js/modules/_shared.js","webpack:///./~/core-js/modules/_to-absolute-index.js","webpack:///./~/core-js/modules/_to-length.js","webpack:///./~/core-js/modules/_to-object.js","webpack:///./~/core-js/modules/_to-primitive.js","webpack:///./~/core-js/modules/es6.object.assign.js","webpack:///./~/debug/~/ms/index.js","webpack:///./~/debug/src/debug.js","webpack:///./~/events/events.js","webpack:///./~/is-array/index.js","webpack:///./~/isomorphic-fetch/fetch-npm-browserify.js","webpack:///./~/pouchdb-collate/lib/utils.js","webpack:///./~/pouchdb-find/lib/abstract-mapreduce/create-view.js","webpack:///./~/pouchdb-find/lib/abstract-mapreduce/index.js","webpack:///./~/pouchdb-find/lib/abstract-mapreduce/taskqueue.js","webpack:///./~/pouchdb-find/lib/adapters/http/index.js","webpack:///./~/pouchdb-find/lib/adapters/local/create-index/index.js","webpack:///./~/pouchdb-find/lib/adapters/local/delete-index/index.js","webpack:///./~/pouchdb-find/lib/adapters/local/find/in-memory-filter.js","webpack:///./~/pouchdb-find/lib/adapters/local/find/index.js","webpack:///./~/pouchdb-find/lib/adapters/local/find/query-planner.js","webpack:///./~/pouchdb-find/lib/adapters/local/index.js","webpack:///./~/pouchdb-find/lib/index.js","webpack:///./~/pouchdb/lib/index-browser.js","webpack:///./~/pouchdb/~/lie/lib/browser.js","webpack:///./~/regenerator-runtime/runtime-module.js","webpack:///./~/regenerator-runtime/runtime.js","webpack:///./~/scope-eval/scope_eval.js","webpack:///./~/spark-md5/spark-md5.js","webpack:///./~/vuvuzela/index.js","webpack:///./~/whatwg-fetch/fetch.js"],"names":["root","factory","exports","module","define","amd","this","modules","__webpack_require__","moduleId","installedModules","id","loaded","call","m","c","p","i","Object","prototype","hasOwnProperty","_m","args","slice","fn","a","b","apply","concat","_interopRequireDefault","obj","__esModule","default","_classCallCheck","instance","Constructor","TypeError","_possibleConstructorReturn","self","ReferenceError","_inherits","subClass","superClass","create","constructor","value","enumerable","writable","configurable","setPrototypeOf","__proto__","cozyFetch","cozy","path","options","arguments","length","undefined","fullpath","then","resp","disableAuth","fetch","manualAuthCredentials","cozyFetchWithAuth","authorize","credentials","res","handleResponse","_invalidTokenErrorHandler","headers","token","toAuthHeader","Promise","all","isV2","_ref","_ref2","_slicedToArray","status","dontRetry","client","_utils","retry","_auth_v","refreshToken","newToken","saveCredentials","cozyFetchJSON","method","body","processJSONAPI","fetchJSON","response","handleJSONResponse","cozyFetchRawJSON","JSON","stringify","invalidTokenErrorHandler","ok","data","contentType","get","indexOf","json","text","err","error","FetchError","isInvalidToken","Error","_jsonapi2","handleInvalidTokenError","currentOrigin","window","location","origin","requestUrl","url","replace","redirectURL","encodeQuery","disconnect","e","console","warn","defineProperty","sliceIterator","arr","_arr","_n","_d","_e","_s","_i","Symbol","iterator","next","done","push","Array","isArray","_jsonapi","_Error","reason","_this","getPrototypeOf","captureStackTrace","name","message","isUnauthorized","isNotFound","process","once","fun","called","getArguments","trace","len","toPromise","func","usedCB","tempCB","pop","nextTick","promise","fulfill","reject","callback","mesg","result","cancel","inherits","clone","extend","callbackify","cb","promisedCallback","crypto","Md5","MD5","string","browser","hash","createHash","update","digest","flatten","subArr","mergeObjects","getFieldFromDoc","doc","parsedField","key","setFieldInDoc","elem","parseField","fieldName","fields","current","ch","substring","pick","oneArrayIsSubArrayOfOther","left","right","Math","min","oneArrayIsStrictSubArrayOfOther","oneSetIsSubArrayOfOther","field","leftIdx","splice","compare","arrayToObject","max","maxScore","element","score","arrayEquals","arr1","arr2","uniq","keys","map","log","unpromiser","_len","_key","isPromise","l","isOnline","navigator","onLine","isOffline","sleep","time","resolve","setTimeout","count","delay","doTry","_len2","_key2","catch","getBackedoffDelay","getFuzzedDelay","retryDelay","fuzzingFactor","random","FuzzFactor","retryCount","pow","createPath","doctype","query","route","encodeURIComponent","q","qname","decodeQuery","queryIndex","queries","fragIndex","queryStr","parts","split","pair","decodeURIComponent","warned","getKey","getValue","massageSort","sort","sorting","isCombinationalField","combinationFields","mergeGtGte","operator","fieldMatchers","$eq","$gte","$gt","mergeLtLte","$lte","$lt","mergeNe","$ne","mergeEq","mergeAndedSelectors","selectors","forEach","selector","matcher","massageSelector","input","utils","wasAnded","massageIndexDef","indexDef","getKeyFromDoc","index","def","filterInclusiveStart","rows","targetValue","indexFields","row","docKey","abs","collate","reverseOptions","opts","newOpts","startkey","endkey","inclusive_start","inclusive_end","validateIndex","ascFields","filter","validateSort","requestDef","defaultUsed","noneIdSorts","sortItem","join","validateFindRequest","getUserFields","userFields","selectorFields","sortFields","Number","MAX_VALUE","rightIdx","sortOrder","defaultSetTimout","defaultClearTimeout","runTimeout","cachedSetTimeout","runClearTimeout","marker","cachedClearTimeout","clearTimeout","cleanUpNextTick","draining","currentQueue","queue","queueIndex","drainQueue","timeout","run","Item","array","noop","title","env","argv","version","versions","on","addListener","off","removeListener","removeAllListeners","emit","binding","cwd","chdir","dir","umask","normalizeDoctype","isQualified","known","REVERSE_KNOWN","KNOWN_DOCTYPES","DOCTYPE_FILES","files","folder","contact","event","track","playlist","k","global","Function","__g","indexify","numToIndexableString","toIndexableString","objKey","parseNumber","str","num","originalIdx","zero","neg","numAsString","magAsString","MAGNITUDE_DIGITS","magnitude","parseInt","MIN_MAGNITUDE","parseFloat","stack","metaStack","lastMetaElement","lastElementIndex","arrayCollate","stringCollate","objectCollate","ak","bk","collationIndex","x","idx","expFormat","toExponential","magForComparison","magString","padLeft","toString","SEP","factor","factorStr","toFixed","normalizeKey","ai","bi","Infinity","isNaN","origKey","Date","toJSON","val","parseIndexableString","parsedNum","parsedStr","arrayElement","objElement","clientParams","_clientParams","Client","registerClient","cli","isRegistered","_fetch","toRegisterJSON","updateClient","resetSecret","client_id","clientID","client_secret","clientSecret","createClient","unregisterClient","getClient","oldClient","newClient","shouldPassRegistration","registrationAccessToken","getAuthCodeURL","scopes","state","generateRandomState","redirect_uri","redirectURI","response_type","scope","_url","getAccessToken","pageURL","grantQueries","getGrantCodeFromPageURL","retrieveToken","grant_type","code","refresh_token","oauthFlow","storage","onRegistered","clearAndRetry","tryCount","clear","registerNewClient","_getAuthCodeURL","save","StateKey","ignoreCachedCredentials","load","CredsKey","storedState","AccessToken","statePromise","t","delete","creds","assign","Content-Type","href","buffer","getRandomValues","Uint8Array","StateSize","randomBytes","floor","btoa","String","fromCharCode","AppToken","_createClass","defineProperties","target","props","descriptor","protoProps","staticProps","registration_access_token","redirect_uris","softwareID","software_id","softwareVersion","software_version","clientName","client_name","clientKind","client_kind","clientURI","client_uri","logoURI","logo_uri","policyURI","policy_uri","notificationPlatform","notification_platform","notificationDeviceToken","notification_device_token","tokenType","token_type","accessToken","access_token","exec","it","oldQueue","immediate","task","scheduleDrain","Mutation","MutationObserver","WebKitMutationObserver","observer","document","createTextNode","observe","characterData","setImmediate","MessageChannel","createElement","scriptEl","onreadystatechange","parentNode","removeChild","documentElement","appendChild","channel","port1","onmessage","port2","postMessage","ctor","superCtor","super_","TempCtor","argsarray","fin","promise2","sequentialize","promiseFactory","that","add","arrs","output","createDeepMultiMapper","toEmit","iLen","j","jLen","createDeepSingleMapper","createShallowSingleMapper","createShallowMultiMapper","checkShallow","createMapper","isShallow","isSingle","mapper","mapFunDef","reducer","ddocValidator","ddoc","viewName","view","views","_id","localUtils","abstractMapReduce","abstractMapper","argsArray","indexKey","type","findByRef","resources","ref","handleResource","rawResource","links","resource","_type","_rev","meta","rev","attributes","relations","rels","relationships","handleTopLevel","included","r","core","__e","dP","createDesc","object","f","cof","propertyIsEnumerable","ceil","IObject","defined","px","useColors","style","firebug","exception","table","userAgent","toLowerCase","match","RegExp","$1","formatArgs","namespace","humanize","diff","color","lastC","namespaces","removeItem","debug","DEBUG","localstorage","localStorage","chrome","local","colors","formatters","v","enable","INTERNAL","resolver","PENDING","outcome","handled","UNHANDLED","safelyResolveThenable","QueueItem","onFulfilled","onRejected","callFulfilled","otherCallFulfilled","callRejected","otherCallRejected","unwrap","returnValue","handlers","getThen","thenable","onError","onSuccess","tryToUnwrap","tryCatch","out","iterable","allResolver","resolveFromAll","outValue","values","resolved","race","REJECTED","FULFILLED","class2type","core_toString","isWindow","isPlainObject","nodeType","core_hasOwn","isFunction","container","extendInner","src","copy","copyIsArray","optionsIsArray","deep","numericStringRegex","test","types","typename","upsert","db","diffFun","getIndexes","allDocs","include_docs","allDocsRes","indexes","language","viewNames","total_rows","_interopDefault","ex","lie","PouchPromise","add32","cmn","s","ff","d","gg","hh","ii","md5cycle","md5blk","md5blks","charCodeAt","md5blk_array","md51","tail","tmp","lo","hi","n","md51_array","subarray","hex_chr","rhex","hex","md5","SparkMD5","reset","y","lsw","msw","append","unescape","appendBinary","contents","_buff","_length","_state","substr","end","raw","ret","buff","_finish","destroy","hashBinary","content","ArrayBuffer","_concatArrayBuffer","byteLength","first","second","firstLength","set","upsertInner","docId","docRev","newDoc","tryAndPut","updated","put","putIfNotExists","existingDoc","PouchDB","plugin","LocalStorage","prefix","setItem","_this2","item","getItem","parse","_this3","_this4","MemoryStorage","deleted","getAppToken","parent","intent","action","receiver","appName","removeEventListener","addEventListener","V2TOKEN_ABORT_TIMEOUT","_doctypes","docType","httpVerb","find","NOREV","findMany","ids","docs","_iteratorNormalCompletion","_didIteratorError","_iteratorError","_step","_iterator","return","_iteratorNormalCompletion2","_didIteratorError2","_iteratorError2","_step2","_iterator2","findAll","_iteratorNormalCompletion3","_didIteratorError3","_iteratorError3","_step3","_iterator3","changesFeed","changes","updateAttributes","tries","_delete","sanitizeFileName","trim","getFileTypeFromName","doUpload","isBuffer","isFile","File","isBlob","Blob","isStream","readable","pipe","isString","contentLength","checksum","lastModifiedDate","ifMatch","contentTypeOctetStream","toGMTString","dirID","executable","createDirectory","_ref3","getDirectoryOrCreate","parentDirectory","ROOT_DIR_ID","statByPath","parsedError","errors","createDirectoryByPath","offline","part","rootDirectoryPromise","statById","reduce","parentDirectoryPromise","updateById","doUpdateAttributes","attrs","_typeof","_ref4","If-Match","updateAttributesById","updateAttributesByPath","trashById","_ref5","hasDatabase","getDatabase","dir_id","_ref6","_ref7","children","TRASH_DIR_ID","sortFiles","addIsDir","toJsonApi","encodePageOptions","downloadById","downloadByPath","extractResponseLinkRelated","related","getDownloadLinkByPath","getDownloadLinkById","getFilePath","file","folderPath","endsWith","getCollectionShareLink","collectionType","permissions","verbs","collection","sharecode","codes","email","getArchiveLinkByPaths","paths","archive","getArchiveLinkByIds","listTrash","clearTrash","restoreById","destroyById","_ref8","isDir","allFiles","folders","localeCompare","_interopRequireWildcard","newObj","nopOnRegistered","protoify","context","addToProto","ctx","proto","disablePromises","attr","_auth_storage","_auth_v2","auth","_data","_mango","mango","_files","_intents","intents","_jobs","jobs","_offline","_settings","settings","_relations","AppTokenV3","AccessTokenV3","ClientV3","AuthNone","AuthRunning","AuthError","AuthOK","defaultClientParams","dataProto","defineIndex","addReferencedFiles","removeReferencedFiles","listReferencedFiles","fetchReferencedFiles","authProto","filesProto","getDownloadLink","getArchiveLink","queryFiles","intentsProto","createService","getRedirectionURL","redirect","jobsProto","queued","offlineProto","init","getDoctypes","createDatabase","destroyDatabase","destroyAllDatabase","hasReplication","replicateFromCozy","stopReplication","stopAllReplication","hasRepeatedReplication","startRepeatedReplication","stopRepeatedReplication","stopAllRepeatedReplication","settingsProto","diskUsage","changePassphrase","getInstance","updateInstance","getClients","deleteClientById","updateLastSync","ensureHasReconnectParam","URL","searchParams","has","search","AppTokenV2","_inited","_oauth","_token","_authstate","_authcreds","_storage","_version","oauth","_onRegistered","cozyURL","onInvalidTokenError","forceTokenRefresh","pathprefix","datasystem","_asyncToGenerator","gen","step","arg","info","injectService","onReadyCallback","ownerDocument","defaultView","iframe","onload","setAttribute","classList","intentClass","focus","serviceOrigin","handshaken","messageHandler","eventType","source","prop","transition","dimensions","removeIntentFrame","errorSerializer","deserialize","pickService","filterServices","services","filteredServices","createPromise","start","service","restData","listenClientData","messageEventListener","intentId","serviceWindow","terminated","terminate","resizeClient","transitionProperty","maxHeight","clientHeight","maxWidth","clientWidth","getData","getIntent","eventName","exposeIntentFrameRemoval","throw","serialize","isSerializable","includes","buildRedirectionURL","parameterStrings","_regenerator","_regenerator2","mark","_callee","baseURL","sanitizedURL","wrap","_context","prev","sent","abrupt","stop","_x3","_x4","_x5","_callee2","redirectionURL","_context2","_x6","_x7","_x8","mapErrorProperties","from","to","nativeProperties","property","workerType","_defineProperty","defineIndexV2","defineIndexV3","indexRef","queryV2","queryV3","getV3Options","wholeResponse","indexName","capitalize","indexDefinition","makeMapFunction","indexResult","makeMapReduceQuery","use_index","limit","skip","since","descending","charAt","toUpperCase","MAP_TEMPLATE","parseSelector","acc","LOGICOPERATORS","VALUEOPERATORS","normalizeSelector","filters","_filter","op","applySelector","lower","COUCHDB_LOWEST","upper","COUCHDB_INFINITY","inclusiveEnd","mrquery","firstFreeValueField","normalizedSelector","used","isFreeValue","FIELDSPLACEHOLDER","ï¿¿","_ref$options","_ref$doctypes","doctypes","getInfo","database","setDatabase","pluginLoaded","_pouchdb2","_pouchdbFind2","pouchdbAdapterCordovaSqlite","createIndexes","createIndex","getReplication","replication","setReplication","getReplicationUrl","basic","toBasicAuth","getReplicationPromise","replicationPromise","setReplicationPromise","live","replicationOfflineError","replicate","onComplete","getRepeatedReplication","interval","setRepeatedReplication","timer","setInterval","clearInterval","_pouchdb","_pouchdbFind","updateRelations","verb","refs","makeReferencesPath","params","currentPassPhrase","newPassPhrase","current_passphrase","new_passphrase","isObject","toIObject","toLength","toAbsoluteIndex","IS_INCLUDES","$this","el","fromIndex","O","aFunction","is","hide","redefine","PROTOTYPE","$export","own","exp","IS_FORCED","F","IS_GLOBAL","G","IS_STATIC","S","IS_PROTO","P","IS_BIND","B","expProto","U","W","R","getKeys","gOPS","pIE","toObject","$assign","A","K","T","aLen","getSymbols","isEnum","anObject","IE8_DOM_DEFINE","toPrimitive","Attributes","getOwnPropertySymbols","arrayIndexOf","IE_PROTO","names","$keys","enumBugKeys","bitmap","SRC","TO_STRING","$toString","TPL","inspectSource","safe","shared","uid","SHARED","store","toInteger","valueOf","h","fmtShort","ms","round","fmtLong","plural","long","selectColor","createDebug","enabled","curr","prevTime","coerce","unshift","format","formatter","logFn","bind","skips","disable","EventEmitter","_events","_maxListeners","isNumber","isUndefined","defaultMaxListeners","setMaxListeners","er","handler","listeners","listener","newListener","g","fired","list","position","listenerCount","evlistener","emitter","pad","padWith","upToLength","padding","targetLength","padRight","stringLexCompare","bLen","aChar","bChar","intToDecimalForm","int","isNeg","remainder","sourceDB","mapFun","reduceFun","temporary","pluginName","viewSignature","_cachedViews","cachedView","diffFunction","fullViewName","depDbs","depDbName","db_name","registerDependentDatabase","auto_compaction","adapter","lastSeqDoc","seq","QueryParseError","NotFoundError","parseViewName","isGenOne","sortByKeyThenValue","keyCompare","sliceResults","results","rowToDocId","emitError","tryCode","checkQueryParseError","startkeyName","endkeyName","group","group_level","defaultsTo","createIndexer","getDocsToPersist","docIdsToChangesAndEmits","getMetaDoc","defaultMetaDoc","metaDocId","getKeyValueDocs","metaDoc","processKvDocs","kvDocsRes","kvDocs","oldKeysMap","_deleted","indexableKeysToKeyValues","keyValue","newKeys","kvDoc","docData","saveKeyValues","seqDocId","docIds","listOfDocsToPersist","docsToPersist","bulkDocs","getQueue","persistentQueues","TaskQueue","updateView","updateViewInQueue","mapResults","processChange","currentSeq","complete","finish","processNextBatch","conflicts","CHANGES_BATCH_SIZE","change","lastKey","jl","complexKey","indexableKey","reduceView","shouldGroup","groups","lvl","last","reduceTry","queryView","queryViewInQueue","fetchFromView","viewOpts","totalRows","expectedKeys","parsedKeyAndDocId","pouchCollate","onMapResultsReady","finalResults","shouldReduce","offset","attachments","binary","docIdsToDocs","cur","fetchPromises","keyStart","keyEnd","localViewCleanup","docsToViews","designDocName","viewsToStatus","ddocName","viewDBNames","statusIsGood","viewDBName","dbsToDelete","destroyPromises","__opts","queryPromised","createViewOpts","tempViewQueue","createView","cleanup","stale","viewCleanup","massageCreateIndexRequest","request","deleteIndex","pouchUpsert","updateDdoc","hasInvalidLanguage","viewExists","originalIndexDef","ddocId","signature","deltaFun","createFieldSorter","getFieldValuesAsArray","docFieldValue","aRow","bRow","aFieldValues","bFieldValues","collation","filterInMemoryFields","inMemoryFields","rowFilter","fieldSorter","reverse","every","matchCominationalSelector","matchSelector","userOperator","userValue","some","orMatchers","matchers","fieldExists","fieldIsNotUndefined","modField","divisor","mod","arrayContainsValue","arrayContainsAllValues","arraySize","regexMatch","re","typeMatch","$elemMatch","$exists","$mod","neValue","$in","$nin","$size","$all","$regex","$type","indexToSignature","doAllDocs","originalOpts","getIndexesRes","queryPlan","planQuery","indexToUse","queryOpts","isDescending","warning","checkFieldInIndex","indexField","userOperatorLosesPrecision","sortFieldsByIndex","aIdx","bIdx","getBasicInMemoryFields","needToFilterInMemory","getInMemoryFieldsFromNe","getInMemoryFields","coreInMemoryFields","checkIndexFieldsMatch","sortMatches","selectorMatches","isNonLogicalMatcher","logicalMatchers","checkFieldsLogicallySound","firstField","hasLogicalOperator","matcherKey","isInvalidNe","checkIndexMatches","fieldsMatch","findMatchingIndexes","indexMatches","findBestMatchingIndex","scoreIndex","userFieldsMap","matchingIndexes","defaultIndex","getSingleFieldQueryOptsFor","getSingleFieldCoreQueryPlan","combinedOpts","userOperators","newQueryOpts","getMultiFieldCoreQueryPlan","getMultiFieldQueryOpts","inclusiveStart","COLLATE_LO","COLLATE_HI","usingGtlt","previousKeys","previousWasEq","previousWasSame","gtltLostSpecificity","getDefaultQueryPlan","getCoreQueryPlan","userFieldsRes","coreQueryPlan","httpIndexes","localIndexes","isBinaryObject","cloneArrayBuffer","targetArray","sourceArray","cloneBinaryObject","size","webkitSlice","Ctor","funcToString","objectCtorString","newObject","toISOString","PouchPromise$1","adapterFun","logApiCall","logArgs","origCallback","responseArgs","_closed","_destroyed","taskqueue","isReady","addTask","failed","mangle","unmangle","Map$1","_store","Set$1","supportsMapAndSet","Map","Set","getOwnPropertyDescriptor","species","identityFunction","formatResultForOpenRevsGet","bulkGet","collapseResultsAndFinish","perDocResults","checkDone","numDone","numDocs","gotResult","docIndex","nextBatch","allRequests","upTo","MAX_NUM_CONCURRENT_REQUESTS","batch","processBatch","docIdx","docRequests","requestsById","docOpts","open_revs","formatResult","param","requests","ExportedMap","isChromeApp","hasLocalStorage","hasLocal","attachBrowserEvents","onChanged","dbName","newValue","attachEvent","Changes","events","_listeners","guardedConsole","randomNumber","maxTimeout","ratio","range","defaultBackOff","explainError","PouchError","createError","CustomPouchError","generateErrorFromResponse","UNKNOWN_ERROR","tryFilter","req","msg","BAD_REQUEST","filterChange","hasFilter","query_params","filterReturn","att","_attachments","stub","invalidIdError","INVALID_ID","RESERVED_ID","MISSING_ID","ee","parseDesignDocFunctionName","normalizeDesignDocFunctionName","normalized","parseUri","parser","uri","encoded","qName","qParser","$0","$2","radix","uuid","chars","winningRev","metadata","winningId","winningPos","winningDeleted","node","toVisit","rev_tree","tree","branches","pos","traverseRevTree","revs","newCtx","sortByPos","collectLeaves","leaves","isLeaf","collectConflicts","win","leaf","compactTree","revHash","rootToLeaf","history","sortByPos$1","binarySearch","comparator","mid","low","high","insertSorted","pathToTree","numStemmed","currentLeaf","compareTree","mergeTree","in_tree1","in_tree2","tree1","tree2","merged","doMerge","dontExpand","restree","branch","t1","t2","candidateParents","trees","parentIdx","elements","elementsLen","stem","depth","maybeStem","stemmed","stemmedNode","merge","newTree","stemmedRevs","revExists","splitRev","targetPos","targetId","getTrees","isDeleted","isLocalId","latest","historyNode","historyRev","evalFilter","scopedEval","evalView","tryCatchInChangeListener","Changes$2","onDestroy","onChange","isCancelled","doChanges","changeList","_conflicts","yankError","cleanDocs","atts","compareByIdThenRev","idCompare","aStart","_revisions","bStart","computeHeight","height","edges","prnt","edge","allDocsKeysQuery","api","_allDocs","subOpts","assign$1","optKey","doNextCompaction","_compactionQueue","last_seq","_compact","shift","attachmentNameError","AbstractPouchDB","TaskQueue$1","parseAdapter","adapters","PouchDB$5","preferredAdapters","adapterName","usePrefix","use_prefix","prepareForDestruction","onDestroyed","onClosed","onConstructorDestroyed","destructionListeners","_destructionListeners","prefixedName","backend","_adapter","valid","fail","ready","setUpEventEmitter","Pouch","eventEmitter","destructListeners","parseRevisionInfo","INVALID_REV","makeRevTreeFromRevisions","revisions","revisionIds","parseDoc","newEdits","nRevNum","newRevId","revInfo","_rev_tree","specialKey","reservedWords","DOC_VALIDATION","dataWords","createBlob","properties","Builder","BlobBuilder","MSBlobBuilder","MozBlobBuilder","WebKitBlobBuilder","builder","getBlob","binaryStringToArrayBuffer","bin","buf","binStringToBluffer","binString","b64ToBluffer","b64","thisAtob","arrayBufferToBinaryString","bytes","readAsBinaryString","blob","FileReader","FileReaderSync","readAsArrayBuffer","reader","hasBinaryString","onloadend","blobToBinaryString","blobOrBuffer","blobToBase64","base64","thisBtoa","rawToBase64","sliceBlob","blob$$1","appendBlob","arrayBuffer","appendString","binaryMd5","setImmediateShim","loadNextChunk","currentChunk","chunkSize","chunks","inputIsString","MD5_CHUNK_SIZE","stringMd5","parseBase64","BAD_ARG","preprocessString","blobType","asBinary","content_type","preprocessBlob","preprocessAttachment","preprocessAttachments","docInfos","docv","overallErr","docInfo","processedAttachment","recv","updateDoc","revLimit","writeDoc","previousWinningRev","previouslyDeleted","isRoot","inConflict","REV_CONFLICT","newRev","rev_map","newRevIsDeleted","winningRev$$1","winningRevIsDeleted","delta","rootIsMissing","processDocs","fetchedDocs","tx","overallCallback","insertDoc","resultsIdx","MISSING_DOC","checkAllDocsDone","docsDone","docsToDo","new_edits","idsToDocs","currentDoc","docWritten","nextDoc","safeJsonParse","vuvuzela","safeJsonStringify","idbError","evt","IDB_ERROR","encodeMetadata","deletedOrLocal","decodeMetadata","storedObject","decodeDoc","_doc_id_rev","lastIndexOf","readBlobData","asBlob","fetchAttachmentsIfNecessary","txn","fetchAttachment","attObj","objectStore","ATTACH_STORE","onsuccess","postProcessAttachments","attNames","compactRevs","deleteOrphanedAttachments","possiblyOrphanedDigests","countReq","attAndSeqStore","IDBKeyRange","bound","attStore","seqStore","BY_SEQ_STORE","ATTACH_AND_SEQ_STORE","cursor","openCursor","only","digestSeq","primaryKey","continue","openTransactionSafely","idb","stores","mode","transaction","idbBulkDocs","dbOpts","startTransaction","DOC_STORE","LOCAL_STORE","META_STORE","txnResult","onabort","ontimeout","oncomplete","docStore","bySeqStore","attachStore","attachAndSeqStore","metaStore","updateDocCountIfReady","verifyAttachments","preconditionErrored","fetchExistingDocs","onAllDocsProcessed","allDocsProcessed","idbProcessDocs","revs_limit","docCount","docCountDelta","numFetched","readMetadata","changesHandler$$1","notify","_meta","verifyAttachment","MISSING_STUB","digests","filename","attErr","isUpdate","hasAttachments","writeAttachments","finishDoc","afterPutDoc","revsToDelete","metadataToStore","metaDataReq","afterPutMetadata","afterPutDocError","preventDefault","stopPropagation","getKeyReq","putReq","insertAttachmentMappings","onerror","collectResults","attachmentSaved","revpos","saveAttachment","attsAdded","attsToAdd","newAtt","docInfoError","blobSupport","runBatchedCursor","keyRange","batchSize","onBatch","onGetAll","valuesBatch","keysBatch","pseudoCursor","onGetAllKeys","continuePseudoCursor","newKeyRange","upperOpen","lowerBound","getAll","getAllKeys","onCursor","useGetAll","createKeyRange","upperBound","idbAllDocs","fetchDocAsynchronously","docIdRevIndex","allDocsInner","batchValues","batchValue","batchKeys","onResultsReady","onTxnComplete","keyRangeError","checkBlobSupport","DETECT_BLOB_SUPPORT_STORE","matchedChrome","matchedEdge","countDocs","applyNext","running","enqueueTask","processMetadataAndWinningDoc","winningDoc","lastSeq","filtered","numResults","returnDocs","onBatchDone","winningDocs","metadatas","fetchWinningDocAndMetadata","onGetMetadata","docIdRev","docIdsToMetadata","continuous","doc_ids","ExportedSet","return_docs","objectStores","IdbPouch","thisCallback","createSchema","createObjectStore","keyPath","autoIncrement","unique","addDeletedOrLocalIndex","createLocalStoreSchema","migrateLocalStore","localStore","seqCursor","addAttachAndSeqStore","migrateAttsAndSeqs","digestMap","migrateMetadata","decodeMetadataCompat","fetchMetadataSeq","metadataSeq","onGetMetadataSeq","instanceId","_bulkDocs","reqOpts","_get","_getAttachment","attachId","attachment","blobData","_info","updateSeq","doc_count","update_seq","idb_attachment_format","_changes","_close","close","cachedDBs","_getRevisionTree","_doCompaction","_getLocal","_putLocal","oldRev","oStore","oldDoc","_removeLocal","_destroy","openReq","openReqList","indexedDB","deleteDatabase","cached","tryStorageOption","open","ADAPTER_VERSION","onupgradeneeded","migration","migrations","oldVersion","currentTarget","completeSetup","storedMetaDoc","storeMetaDocIfReady","instanceKey","onversionchange","blobSupportPromise","decodeUtf8","escape","hexToInt","charCode","parseHexUtf8","parseHexUtf16","parseHexString","encoding","quote","escapeBlob","unescapeBlob","stringifyDoc","unstringifyDoc","qMarks","select","joiner","where","orderBy","compactRevs$1","deleteOrphans","seqs","sql","ATTACH_AND_SEQ_STORE$1","executeSql","digestsToCheck","nonOrphanedDigests","ATTACH_STORE$1","BY_SEQ_STORE$1","websqlError","errorNameMatch","errorName","errorReason","WSQ_ERROR","getSize","isAndroid","websqlBulkDocs","websqlChanges","_name","cnt","sqlArgs","deletedInt","insertId","dataWritten","fetchSql","attachmentErr","revsToCompact","DOC_STORE$1","metadataStr","websqlProcessDocs","userDocs","docInfoErrors","openDatabaseWithOpts","websql","description","openDBSafely","openDB$1","cachedResult","cachedDatabases","fetchAttachmentsIfNecessary$1","attOpts","_","WebSqlPouch$1","dbCreated","runMigration2","DOC_STORE_WINNINGSEQ_INDEX_SQL","BY_SEQ_STORE_DELETED_INDEX_SQL","runMigration3","LOCAL_STORE$1","doNext","runMigration4","updateRows","doc_id_rev","doc_id","BY_SEQ_STORE_DOC_ID_REV_INDEX_SQL","runMigration5","nextPage","SELECT_DOCS","DOC_STORE_AND_BY_SEQ_JOINER","pageSize","addDigestSeq","digestSeqs","digestSeqPairs","attachAndRev","ATTACH_AND_SEQ_STORE_ATTACH_INDEX_SQL","ATTACH_AND_SEQ_STORE_SEQ_INDEX_SQL","runMigration6","runMigration7","checkEncoding","onGetInstanceId","idRequests","idCallback","onGetVersion","dbVersion","META_STORE$1","attach","initSeq","initSeqArgs","ADAPTER_VERSION$1","setupDone","migrated","dbid","tasks","nextMigration","setup","fetchVersion","db_version","getMaxSeq","latest$$1","websqlOpts","POUCH_VERSION","openDBResult","readTransaction","theSeq","theDocCount","websql_encoding","latestRev","missingErr","deletedErr","criteria","fetchChanges","selectStmt","reportChange","maxSeq","escaped","putLocal","rowsAffected","removeLocal","canOpenTestDB","openDatabase","isValidWebSQL","hasLS","localStorageKey","openedTestDB","openDB","WebSQLPouch","_opts","wrappedFetch","wrappedPromise","fetchRequest","Headers","fetchOptions","processData","fetchResponse","statusCode","abort","xhRequest","xhr","timedout","abortReq","cleanUp","timeoutReq","onprogress","upload","XMLHttpRequest","withCredentials","Accept","responseType","setRequestHeader","readyState","getResponseHeader","responseText","send","testXhr","ajax$1","hasXhr","defaultBody","ajaxCore$1","missing","res$2","defaultOptions","cache","ajax","ua","isSafari","isIE","isEdge","shouldCacheBust","isBlobUrl","hasArgs","now","pool","promiseFactories","runNext","runNextBatch","thisErr","readAttachmentsAsBlobOrBuffer","encodeDocId","preprocessAttachments$2","hasUrlPrefix","protocol","getHost","user","password","username","genDBUrl","genUrl","pathDel","host","port","paramsToStr","HttpPouch","ajax$$1","userOpts","reqAjax","ajaxOpts","log$1","_ajax","ajaxPromise","adapterFun$$1","skipSetup","skip_setup","setupPromise","checkExists","dbUrl","encodeAttachmentId","attachmentId","nAuth","Authorization","uuid$$1","compact","ping","compact_running","doBulkGet","doBulkGetShim","onResult","batchNum","numBatches","MAX_SIMULTANEOUS_REVS","supportsBulkGet","supportsBulkGetMap","fetchAttachments","filenames","fetchAllAttachments","docOrDocs","revs_info","remove","docOrId","optsOrRev","getAttachment","removeAttachment","putAttachment","_put","start_key","end_key","paramStr","batch_size","leftToFetch","feed","heartbeat","param_name","lastFetchedSeq","aborted","xhrOpts","fetched","raw_results_length","finished","revsDiff","TaskQueue$2","cachedViews","promiseForView","BuiltInError","createBuiltInError","sum","jNum","evalFunctionWithEval","log$2","finalPromiseFactory","theSet","mapToKeysArray","tryMap","tryReduce","rereduce","readAttachmentsAsBlobOrBuffer$1","postprocessAttachments","addHttpParam","paramName","asJson","coerceInteger","integerCandidate","asNumber","coerceOptions","checkPositiveInteger","number","optionName","httpQuery","MAX_URL_LENGTH","keysAsString","customQuery","_query","customViewCleanup","_viewCleanup","processKeyValueDocs","oldKeys","CHANGES_BATCH_SIZE$1","createDocIdsToChangesAndEmits","createIndexableKeysToKeyValues","emittedKeyValue","origMap","builtInReduce","POSITIVE_INFINITY","groupKey","httpViewCleanup","isGenOne$1","fileHasChanged","localDoc","remoteDoc","getDocAttachments","getDocAttachmentsFromTargetOrSource","doCheckForLocalAttachments","createBulkGetOpts","diffs","missingRevs","missingRev","getDocs","getAllDocs","bulkGetOpts","bulkGetResponse","cancelled","bulkGetInfo","resultDocs","Boolean","hasConflicts","fetchRevisionOneDocs","getRevisionOneDocs","returnResult","updateCheckpoint","checkpoint","session","session_id","replicator","REPLICATOR","CHECKPOINT_VERSION","CHECKPOINT_HISTORY_SIZE","Checkpointer","compareReplicationLogs","srcDoc","tgtDoc","compareReplicationHistory","sourceHistory","targetHistory","sourceRest","targetRest","LOWEST_SEQ","sourceId","hasSessionId","sessionId","rest","isForbiddenError","backOff","back_off_function","backOffSet","current_back_off","STARTING_BACK_OFF","removeBackOffSetter","sortObjectPropertiesByKey","queryParams","generateReplicationId","filterFun","filterViewName","queryData","md5sum","initCheckpointer","checkpointer","repId","writeDocs","changedDocs","currentBatch","bulkOpts","completeReplication","errorsById","errorsNo","doc_write_failures","docs_written","finishBatch","outResult","writingCheckpoint","writeCheckpoint","getChanges","onCheckpointError","getDiffs","getBatchDocs","got","docs_read","startNextBatch","batches","processPendingBatch","abortReplication","pendingBatch","changesOpts","changesCompleted","replicationCompleted","fatalError","end_time","onChangesComplete","changesPending","onChangesError","abortChanges","batches_limit","_abortChanges","startChanges","getCheckpoint","start_time","_addedListeners","Replication","toPouch","PouchConstructor","replicateWrapper","replicateRet","srcPouch","targetPouch","sync$1","Sync","pullChange","direction","pushChange","pushDenied","pullDenied","pushPaused","pullPaused","pushActive","pullActive","removeAll","isChange","isDenied","isPaused","isActive","removed","addOneListener","canceled","optsPush","optsPull","pull","success","sync","other","mangled","eventFunction","inprogress","notifyLocalWindows","nextSource","nextKey","MISSING_BULK_DOCS","QUERY_PARSE_ERROR","NOT_AN_OBJECT","hasName","filterChanges","newPromise","filterName","post","createAttachment","prevrevpos","was_delete","addToMissing","revId","processDoc","missingForId","missingObj","compactDocument","revTree","candidates","promises","finishOpenRevs","existing","splittedRev","revNo","currentPath","hashIndex","hashFoundAtRevPos","indexOfRev","howMany","_revs_info","incompatibleOpt","attachmentError","dependentDb","dependentDbs","depDB","destroyDb","deletedMap","trueName","execute","addToPreferredAdapters","defaults","defaultOpts","PouchAlt","__defaults","atob","platform","IDBPouch","WebSqlPouch","HttpPouch$1","_sum","_count","_stats","sumsqr","_sumsqr","mapreduce","updateTarget","updateSource","readOnlySource","comparisons","targetDoc","sourceDoc","1","_readyCalled","hadRuntime","regeneratorRuntime","getOwnPropertyNames","oldRuntime","innerFn","outerFn","tryLocsList","protoGenerator","Generator","generator","Context","_invoke","makeInvokeMethod","GeneratorFunction","GeneratorFunctionPrototype","defineIteratorMethods","AsyncIterator","invoke","record","hasOwn","__await","unwrapped","enqueue","callInvokeWithMethodAndArg","previousPromise","domain","GenStateSuspendedStart","GenStateExecuting","GenStateCompleted","doneResult","delegate","delegateResult","maybeInvokeDelegate","ContinueSentinel","_sent","dispatchException","GenStateSuspendedYield","resultName","nextLoc","pushTryEntry","locs","entry","tryLoc","catchLoc","finallyLoc","afterLoc","tryEntries","resetTryEntry","completion","iteratorMethod","iteratorSymbol","Op","$Symbol","toStringTagSymbol","toStringTag","inModule","runtime","IteratorPrototype","getProto","NativeIteratorPrototype","Gp","displayName","isGeneratorFunction","genFun","awrap","async","iter","skipTempReset","rootEntry","rootRecord","rval","handle","loc","caught","hasCatch","hasFinally","finallyEntry","thrown","delegateYield","hasProp","toUtf8","utf8Str2ArrayBuffer","returnUInt8Array","arrayBuffer2Utf8Str","concatenateArrayBuffers","hexToBinaryString","clamp","begin","_hash","getState","setState","arrayPrefix","objPrefix","numChar","parsedString","lastCh","numConsecutiveSlashes","normalizeName","normalizeValue","iteratorFor","items","support","header","consumed","bodyUsed","fileReaderReady","readBlobAsArrayBuffer","readBlobAsText","readAsText","readArrayBufferAsText","bufferClone","Body","_initBody","_bodyInit","_bodyText","isPrototypeOf","_bodyBlob","formData","FormData","_bodyFormData","URLSearchParams","isDataView","_bodyArrayBuffer","isArrayBufferView","rejected","decode","normalizeMethod","upcased","methods","Request","referrer","form","parseHeaders","rawHeaders","line","Response","bodyInit","statusText","viewClasses","DataView","isView","oldValue","thisArg","entries","redirectStatuses","RangeError","getAllResponseHeaders","responseURL","polyfill"],"mappings":"CAAA,SAAAA,EAAAC,GACA,gBAAAC,UAAA,gBAAAC,QACAA,OAAAD,QAAAD,IACA,kBAAAG,gBAAAC,IACAD,OAAA,YAAAH,GACA,gBAAAC,SACAA,QAAA,OAAAD,KAEAD,EAAA,KAAAA,EAAA,SAAmCA,EAAA,YAAAC,MAClCK,KAAA,WACD,MCAgB,UAAUC,GCN1B,QAAAC,GAAAC,GAGA,GAAAC,EAAAD,GACA,MAAAC,GAAAD,GAAAP,OAGA,IAAAC,GAAAO,EAAAD,IACAP,WACAS,GAAAF,EACAG,QAAA,EAUA,OANAL,GAAAE,GAAAI,KAAAV,EAAAD,QAAAC,IAAAD,QAAAM,GAGAL,EAAAS,QAAA,EAGAT,EAAAD,QAvBA,GAAAQ,KAqCA,OATAF,GAAAM,EAAAP,EAGAC,EAAAO,EAAAL,EAGAF,EAAAQ,EAAA,GAGAR,EAAA,IDcW,SAASD,GAEnB,IAAI,GAAIU,KAAKV,GACZ,GAAGW,OAAOC,UAAUC,eAAeP,KAAKN,EAASU,GAChD,aAAcV,GAAQU,IACtB,IAAK,WAAY,KACjB,KAAK,SAEJV,EAAQU,GAAM,SAASI,GACtB,GAAIC,GAAOD,EAAGE,MAAM,GAAIC,EAAKjB,EAAQc,EAAG,GACxC,OAAO,UAAUI,EAAEC,EAAEX,GACpBS,EAAGG,MAAMrB,MAAOmB,EAAEC,EAAEX,GAAGa,OAAON,MAE9Bf,EAAQU,GACV,MACD,SAECV,EAAQU,GAAKV,EAAQA,EAAQU,IAKhC,MAAOV,KAGF,SAASJ,EAAQD,EAASM,GAE/BA,EAAoB,IACpBL,EAAOD,QAAUM,EAAoB,KAKhC,SAASL,EAAQD,EAASM,GAE/B,YAuBA,SAASqB,GAAuBC,GAAO,MAAOA,IAAOA,EAAIC,WAAaD,GAAQE,QAASF,GAEvF,QAASG,GAAgBC,EAAUC,GAAe,KAAMD,YAAoBC,IAAgB,KAAM,IAAIC,WAAU,qCAEhH,QAASC,GAA2BC,EAAMzB,GAAQ,IAAKyB,EAAQ,KAAM,IAAIC,gBAAe,4DAAgE,QAAO1B,GAAyB,gBAATA,IAAqC,kBAATA,GAA8ByB,EAAPzB,EAElO,QAAS2B,GAAUC,EAAUC,GAAc,GAA0B,kBAAfA,IAA4C,OAAfA,EAAuB,KAAM,IAAIN,WAAU,iEAAoEM,GAAeD,GAAStB,UAAYD,OAAOyB,OAAOD,GAAcA,EAAWvB,WAAayB,aAAeC,MAAOJ,EAAUK,YAAY,EAAOC,UAAU,EAAMC,cAAc,KAAeN,IAAYxB,OAAO+B,eAAiB/B,OAAO+B,eAAeR,EAAUC,GAAcD,EAASS,UAAYR,GE/G3d,QAASS,GAAWC,EAAMC,GAAoB,GAAdC,GAAcC,UAAAC,OAAA,GAAAC,SAAAF,UAAA,GAAAA,UAAA,KACnD,OAAOH,GAAKM,SAASL,GAAMM,KAAK,SAACD,GAC/B,GAAIE,SASJ,OAPEA,GADEN,EAAQO,YACHC,MAAMJ,EAAUJ,GACdA,EAAQS,sBACVC,EAAkBZ,EAAMM,EAAUJ,EAASA,EAAQS,uBAEnDX,EAAKa,YAAYN,KAAK,SAACO,GAAD,MAC3BF,GAAkBZ,EAAMM,EAAUJ,EAASY,KAExCN,EAAKD,KAAK,SAAAQ,GAAA,MAAOC,GAAeD,EAAKf,EAAKiB,+BAIrD,QAASL,GAAmBZ,EAAMM,EAAUJ,EAASY,GAUnD,MATIA,KACFZ,EAAQgB,QAAUhB,EAAQgB,YAC1BhB,EAAQgB,QAAR,cAAmCJ,EAAYK,MAAMC,gBAKvDlB,EAAQY,YAAc,UAEfO,QAAQC,KACbtB,EAAKuB,OACLb,MAAMJ,EAAUJ,KACfK,KAAK,SAAAiB,GAAiB,GAAAC,GAAAC,EAAAF,EAAA,GAAfD,EAAeE,EAAA,GAATV,EAASU,EAAA,EACvB,IAAoB,MAAfV,EAAIY,QAAiC,MAAfZ,EAAIY,QAAmBJ,IAAST,GAAeZ,EAAQ0B,UAChF,MAAOb,EAFc,IAMfc,GAAkBf,EAAlBe,OAAQV,EAAUL,EAAVK,KAChB,OAAKU,IAAYV,4BAGjBjB,EAAQ0B,WAAY,GACb,EAAAE,EAAAC,OAAM,kBAAM,EAAAC,EAAAC,cAAajC,EAAM6B,EAAQV,IAAQ,KACnDZ,KAAK,SAAC2B,GAAD,MAAclC,GAAKmC,gBAAgBN,EAAQK,KAChD3B,KAAK,SAACO,GAAD,MAAiBF,GAAkBZ,EAAMM,EAAUJ,EAASY,MAL3DC,IASN,QAASqB,GAAepC,EAAMqC,EAAQpC,EAAMqC,GAAoB,GAAdpC,GAAcC,UAAAC,OAAA,GAAAC,SAAAF,UAAA,GAAAA,UAAA,MAC/DoC,EAAmD,mBAA3BrC,GAAQqC,gBAAkCrC,EAAQqC,cAChF,OAAOC,GAAUxC,EAAMqC,EAAQpC,EAAMqC,EAAMpC,GACxCK,KAAK,SAAAkC,GAAA,MAAYC,GAAmBD,EAAUF,KAG5C,QAASI,GAAkB3C,EAAMqC,EAAQpC,EAAMqC,GAAoB,GAAdpC,GAAcC,UAAAC,OAAA,GAAAC,SAAAF,UAAA,GAAAA,UAAA,KACxE,OAAOqC,GAAUxC,EAAMqC,EAAQpC,EAAMqC,EAAMpC,GACxCK,KAAK,SAAAkC,GAAA,MAAYC,GAAmBD,GAAU,KAGnD,QAASD,GAAWxC,EAAMqC,EAAQpC,EAAMqC,GAAoB,GAAdpC,GAAcC,UAAAC,OAAA,GAAAC,SAAAF,UAAA,GAAAA,UAAA,KAC1DD,GAAQmC,OAASA,CAEjB,IAAMnB,GAAUhB,EAAQgB,QAAUhB,EAAQgB,WAa1C,OAXAA,GAAA,OAAoB,mBAEL,QAAXmB,GAA+B,SAAXA,GAA8BhC,SAATiC,IACvCpB,EAAQ,gBACVhB,EAAQoC,KAAOA,GAEfpB,EAAQ,gBAAkB,mBAC1BhB,EAAQoC,KAAOM,KAAKC,UAAUP,KAI3BvC,EAAUC,EAAMC,EAAMC,GAG/B,QAASc,GAAgBD,EAAK+B,GAC5B,GAAI/B,EAAIgC,GACN,MAAOhC,EAET,IAAIiC,UACEC,EAAclC,EAAIG,QAAQgC,IAAI,eAMpC,OAJEF,GADEC,GAAeA,EAAYE,QAAQ,SAAW,EACzCpC,EAAIqC,OAEJrC,EAAIsC,OAENL,EAAKzC,KAAK,SAAA+C,GACf,GAAMC,GAAQ,GAAIC,GAAWzC,EAAKuC,EAIlC,MAHIE,GAAWC,eAAeF,IAAUT,GACtCA,EAAyBS,GAErBA,IAIV,QAASb,GAAoB3B,GAA4B,GAAvBwB,KAAuBpC,UAAAC,OAAA,GAAAC,SAAAF,UAAA,KAAAA,UAAA,GACjD8C,EAAclC,EAAIG,QAAQgC,IAAI,eACpC,KAAKD,GAAeA,EAAYE,QAAQ,QAAU,EAChD,MAAOpC,GAAIsC,KAAK,SAACL,GACf,KAAM,IAAIQ,GAAWzC,EAAK,GAAI2C,OAAM,yBAA2BV,KAInE,IAAMI,GAAOrC,EAAIqC,MACjB,OAAwD,KAApDH,EAAYE,QAAQ,6BAAqCZ,EACpDa,EAAK7C,KAALoD,EAAA/E,SAEAwE,EAIJ,QAASQ,GAAyBL,GACvC,IACE,GAAMM,GAAgBC,OAAOC,SAASC,OAChCC,EAAaV,EAAMW,GAEzB,IAAoF,IAAhFD,EAAWd,QAAQU,EAAcM,QAAQ,0BAA2B,QAAe,CACrF,GAAMC,GAAiBP,EAAjB,KAAkC,EAAA/B,EAAAuC,cAAcC,WAAc,GACpER,QAAOC,SAAWK,GAEpB,MAAOG,GACPC,QAAQC,KAAK,uCAAwCF,EAAGhB,IFrC3DzF,OAAO4G,eAAe5H,EAAS,cAC7B2C,OAAO,IAET3C,EAAQ0G,WAAanD,MAErB,IAAIqB,GAAiB,WAAc,QAASiD,GAAcC,EAAK/G,GAAK,GAAIgH,MAAeC,GAAK,EAAUC,GAAK,EAAWC,EAAK3E,MAAW,KAAM,IAAK,GAAiC4E,GAA7BC,EAAKN,EAAIO,OAAOC,cAAmBN,GAAMG,EAAKC,EAAGG,QAAQC,QAAoBT,EAAKU,KAAKN,EAAGxF,QAAY5B,GAAKgH,EAAKzE,SAAWvC,GAA3DiH,GAAK,IAAoE,MAAOxB,GAAOyB,GAAK,EAAMC,EAAK1B,EAAO,QAAU,KAAWwB,GAAMI,EAAW,QAAGA,EAAW,SAAO,QAAU,GAAIH,EAAI,KAAMC,IAAQ,MAAOH,GAAQ,MAAO,UAAUD,EAAK/G,GAAK,GAAI2H,MAAMC,QAAQb,GAAQ,MAAOA,EAAY,IAAIO,OAAOC,WAAYtH,QAAO8G,GAAQ,MAAOD,GAAcC,EAAK/G,EAAa,MAAM,IAAImB,WAAU,2DAGtlBlC,GE5FeiD,YF6FfjD,EEhDesF,gBFiDftF,EE3Ce6F,mBF4Cf7F,EEgBe8G,yBAnHhB,IAAA5B,GAAA5E,EAAA,GACA0E,EAAA1E,EAAA,GACAsI,EAAAtI,EAAA,IFyGKuG,EAAYlF,EAAuBiH,GEsB3BlC,EFuIK1G,EEvIL0G,WFuI0B,SAAUmC,GEtI/C,QAAAnC,GAAazC,EAAK6E,GAAQ/G,EAAA3B,KAAAsG,EAAA,IAAAqC,GAAA5G,EAAA/B,MAAAsG,EAAA1D,WAAAhC,OAAAgI,eAAAtC,IAAA/F,KAAAP,MAAA,OAEpBwG,OAAMqC,mBACRrC,MAAMqC,kBAANF,EAA8BA,EAAKrG,aAGrCqG,EAAKG,KAAO,aACZH,EAAKpD,SAAW1B,EAChB8E,EAAK3B,IAAMnD,EAAImD,IACf2B,EAAKlE,OAASZ,EAAIY,OAClBkE,EAAKD,OAASA,EAEd9H,OAAO4G,eAAPmB,EAA4B,WAC1BpG,MAAOmG,EAAOK,UACO,gBAAXL,GAAsBA,EAAShD,KAAKC,UAAU+C,MAdlCC,EF8JzB,MAvBAzG,GAAUoE,EAAYmC,GAuBfnC,GE/JsBE,MAoBhCF,GAAW0C,eAAiB,SAAU5C,GAEpC,MAAoB,eAAbA,EAAI0C,MAAwC,MAAf1C,EAAI3B,QAG1C6B,EAAW2C,WAAa,SAAU7C,GAEhC,MAAoB,eAAbA,EAAI0C,MAAwC,MAAf1C,EAAI3B,QAG1C6B,EAAWC,eAAiB,SAAUH,GAEpC,MAAoB,eAAbA,EAAI0C,MAAwC,MAAf1C,EAAI3B,QAAkB2B,EAAIsC,SAAgC,sBAArBtC,EAAIsC,OAAOrC,OAAsD,kBAArBD,EAAIsC,OAAOrC,SFmJ5H,SAASxG,EAAQD,EAASM,IGrThC,SAAAgJ,GAAA,YAEA,IAAA/E,GAAAjE,EAAA,GAGAN,GAAAuJ,KAAA,SAAAC,GACA,GAAAC,IAAA,CACA,OAAAzJ,GAAA0J,aAAA,SAAAtI,GACA,GAAAqI,EAEA,KADA/B,SAAAiC,QACA,GAAA/C,OAAA,8BAEA6C,IAAA,EACAD,EAAA/H,MAAArB,KAAAgB,MAKApB,EAAA0J,aAAA,SAAAF,GACA,kBAIA,IAHA,GAAAI,GAAAvG,UAAAC,OACAlC,EAAA,GAAAsH,OAAAkB,GACA7I,GAAA,IACAA,EAAA6I,GACAxI,EAAAL,GAAAsC,UAAAtC,EAEA,OAAAyI,GAAA7I,KAAAP,KAAAgB,KAIApB,EAAA6J,UAAA,SAAAC,GAEA,MAAA9J,GAAA0J,aAAA,SAAAtI,GACA,GAGA2I,GAHA3H,EAAAhC,KACA4J,EAAA,kBAAA5I,KAAAkC,OAAA,IAAAlC,EAAA6I,KAGAD,KAGAD,EAAA,SAAAvD,EAAA9C,GACA4F,EAAAY,SAAA,WACAF,EAAAxD,EAAA9C,MAIA,IAAAyG,GAAA,GAAA5F,GAAA,SAAA6F,EAAAC,GACA,IACA,GAAAC,GAAAtK,EAAAuJ,KAAA,SAAA/C,EAAA+D,GACA/D,EACA6D,EAAA7D,GAEA4D,EAAAG,IAKAnJ,GAAAqH,KAAA6B,GACAR,EAAArI,MAAAW,EAAAhB,GACO,MAAAqG,GACP4C,EAAA5C,KAYA,OARAsC,IACAI,EAAA1G,KAAA,SAAA+G,GACAT,EAAA,KAAAS,IACOT,GAEPI,EAAAM,OAAA,WACA,MAAArK,OAEA+J,KAIAnK,EAAA0K,SAAApK,EAAA,IACAN,EAAAuE,UAEAvE,EAAA2K,MAAA,SAAA/I,GACA,MAAA5B,GAAA4K,QAAA,KAAgChJ,IAGhC5B,EAAA4K,OAAAtK,EAAA,IAEAN,EAAA6K,YAAA,SAAArB,GACA,MAAAxJ,GAAA0J,aAAA,SAAAtI,GACA,GAAA0J,GAAA1J,EAAA6I,MACAE,EAAAX,EAAA/H,MAAArB,KAAAgB,EAEA,OADApB,GAAA+K,iBAAAZ,EAAAW,GACAX,KAIAnK,EAAA+K,iBAAA,SAAAZ,EAAAG,GAUA,MATAH,GAAA1G,KAAA,SAAAQ,GACAqF,EAAAY,SAAA,WACAI,EAAA,KAAArG,MAEG,SAAA6E,GACHQ,EAAAY,SAAA,WACAI,EAAAxB,OAGAqB,EAGA,IAAAa,GAAA1K,EAAA,IACA2K,EAAA3K,EAAA,GAEAN,GAAAkL,IAAA,SAAAC,GAEA,MAAA7B,GAAA8B,QAGAH,EAAAI,KAAAF,GAFAH,EAAAM,WAAA,OAAAC,OAAAJ,GAAAK,OAAA,QAMAxL,EAAAyL,QAAAzL,EAAA0J,aAAA,SAAAtI,GAEA,OADA6C,MACAlD,EAAA,EAAA6I,EAAAxI,EAAAkC,OAAoCvC,EAAA6I,EAAS7I,IAAA,CAC7C,GAAA2K,GAAAtK,EAAAL,EACA2H,OAAAC,QAAA+C,GACAzH,IAAAvC,OAAA1B,EAAAyL,QAAAhK,MAAA,KAAAiK,IAEAzH,EAAAwE,KAAAiD,GAGA,MAAAzH,KAGAjE,EAAA2L,aAAA,SAAA7D,GAEA,OADA7D,MACAlD,EAAA,EAAA6I,EAAA9B,EAAAxE,OAAmCvC,EAAA6I,EAAS7I,IAC5CkD,EAAAjE,EAAA4K,QAAA,EAAA3G,EAAA6D,EAAA/G,GAEA,OAAAkD,IAKAjE,EAAA4L,gBAAA,SAAAC,EAAAC,GAEA,OADAnJ,GAAAkJ,EACA9K,EAAA,EAAA6I,EAAAkC,EAAAxI,OAA2CvC,EAAA6I,EAAS7I,IAAA,CACpD,GAAAgL,GAAAD,EAAA/K,EAEA,IADA4B,IAAAoJ,IACApJ,EACA,MAGA,MAAAA,IAGA3C,EAAAgM,cAAA,SAAAH,EAAAC,EAAAnJ,GACA,OAAA5B,GAAA,EAAA6I,EAAAkC,EAAAxI,OAA2CvC,EAAA6I,EAAA,EAAW7I,IAAA,CACtD,GAAAkL,GAAAH,EAAA/K,EACA8K,KAAAI,MAEAJ,EAAAC,EAAAlC,EAAA,IAAAjH,GAIA3C,EAAAkM,WAAA,SAAAC,GAIA,OAFAC,MACAC,EAAA,GACAtL,EAAA,EAAA6I,EAAAuC,EAAA7I,OAAyCvC,EAAA6I,EAAS7I,IAAA,CAClD,GAAAuL,GAAAH,EAAApL,EACA,OAAAuL,EACAvL,EAAA,UAAAoL,EAAApL,EAAA,GACAsL,IAAAE,UAAA,EAAAF,EAAA/I,OAAA,QAEA8I,EAAA3D,KAAA4D,GACAA,EAAA,IAGAA,GAAAC,EAIA,MADAF,GAAA3D,KAAA4D,GACAD,GAKApM,EAAAwM,KAAA,SAAA5K,EAAAkG,GAEA,OADA7D,MACAlD,EAAA,EAAA6I,EAAA9B,EAAAxE,OAAmCvC,EAAA6I,EAAS7I,IAAA,CAC5C,GAAA+K,GAAA9L,EAAAkM,WAAApE,EAAA/G,IACA4B,EAAA3C,EAAA4L,gBAAAhK,EAAAkK,EACA,oBAAAnJ,IACA3C,EAAAgM,cAAA/H,EAAA6H,EAAAnJ,GAGA,MAAAsB,IAIAjE,EAAAyM,0BAAA,SAAAC,EAAAC,GAEA,OAAA5L,GAAA,EAAA6I,EAAAgD,KAAAC,IAAAH,EAAApJ,OAAAqJ,EAAArJ,QAA4DvC,EAAA6I,EAAS7I,IACrE,GAAA2L,EAAA3L,KAAA4L,EAAA5L,GACA,QAGA,WAIAf,EAAA8M,gCAAA,SAAAJ,EAAAC,GAEA,QAAAD,EAAApJ,OAAAqJ,EAAArJ,SAIAtD,EAAAyM,0BAAAC,EAAAC,IAKA3M,EAAA+M,wBAAA,SAAAL,EAAAC,GACAD,IAAArL,OACA,QAAAN,GAAA,EAAA6I,EAAA+C,EAAArJ,OAAqCvC,EAAA6I,EAAS7I,IAAA,CAC9C,GAAAiM,GAAAL,EAAA5L,EACA,KAAA2L,EAAApJ,OACA,KAEA,IAAA2J,GAAAP,EAAArG,QAAA2G,EACA,IAAAC,KAAA,EACA,QAEAP,GAAAQ,OAAAD,EAAA,GAGA,UAGAjN,EAAAmN,QAAA,SAAAT,EAAAC,GACA,MAAAD,GAAAC,GAAA,EAAAD,EAAAC,EAAA,KAGA3M,EAAAoN,cAAA,SAAAtF,GAEA,OADA7D,MACAlD,EAAA,EAAA6I,EAAA9B,EAAAxE,OAAmCvC,EAAA6I,EAAS7I,IAC5CkD,EAAA6D,EAAA/G,KAAA,CAEA,OAAAkD,IAGAjE,EAAAqN,IAAA,SAAAvF,EAAA0B,GAGA,OAFA6D,GAAA,KACAC,GAAA,EACAvM,EAAA,EAAA6I,EAAA9B,EAAAxE,OAAmCvC,EAAA6I,EAAS7I,IAAA,CAC5C,GAAAwM,GAAAzF,EAAA/G,GACAyM,EAAAhE,EAAA+D,EACAC,GAAAF,IACAA,EAAAE,EACAH,EAAAE,GAGA,MAAAF,IAGArN,EAAAyN,YAAA,SAAAC,EAAAC,GACA,GAAAD,EAAApK,SAAAqK,EAAArK,OACA,QAEA,QAAAvC,GAAA,EAAA6I,EAAA8D,EAAApK,OAAoCvC,EAAA6I,EAAS7I,IAC7C,GAAA2M,EAAA3M,KAAA4M,EAAA5M,GACA,QAGA,WAGAf,EAAA4N,KAAA,SAAA9F,GAEA,OADAlG,MACAb,EAAA,EAAiBA,EAAA+G,EAAAxE,OAAgBvC,IACjCa,EAAA,IAAAkG,EAAA/G,KAAA,CAEA,OAAAC,QAAA6M,KAAAjM,GAAAkM,IAAA,SAAA/B,GACA,MAAAA,GAAAQ,UAAA,MAIAvM,EAAA+N,IAAAzN,EAAA,sBHyT8BK,KAAKX,EAASM,EAAoB,KAI1D,SAASL,EAAQD,GAEtB,YI1lBM,SAASgO,GAAY1M,GAC1B,MAAO,YAAmB,OAAA2M,GAAA5K,UAAAC,OAANlC,EAAMsH,MAAAuF,GAAAC,EAAA,EAAAA,EAAAD,EAAAC,IAAN9M,EAAM8M,GAAA7K,UAAA6K,EACxB,IAAMvL,GAAQrB,EAAGG,MAAMrB,KAAMgB,EAC7B,KAAK+M,EAAUxL,GACb,MAAOA,EAET,IAAMyL,GAAIhN,EAAKkC,MACf,IAAU,IAAN8K,GAAkC,kBAAhBhN,GAAKgN,EAAI,GAA/B,CAGA,GAAMtD,GAAK1J,EAAKgN,EAAI,EACpBzL,GAAMc,KACJ,SAACQ,GAAD,MAAS6G,GAAG,KAAM7G,IAClB,SAACuC,GAAD,MAASsE,GAAGtE,EAAK,UAKhB,QAAS2H,GAAWxL,GACzB,QAASA,GAA+B,kBAAfA,GAAMc,KAG1B,QAAS4K,KACd,MAA4B,mBAAdC,YAA4BA,UAAUC,OAG/C,QAASC,KACd,OAAQH,IAGH,QAASI,GAAOC,EAAMtN,GAC3B,MAAO,IAAImD,SAAQ,SAACoK,GAClBC,WAAWD,EAASD,EAAMtN,KAIvB,QAAS6D,GAAO3D,EAAIuN,GAAoB,GAAbC,GAAazL,UAAAC,OAAA,GAAAC,SAAAF,UAAA,GAAAA,UAAA,GAAL,GACxC,OAAO,SAAS0L,KAAgB,OAAAC,GAAA3L,UAAAC,OAANlC,EAAMsH,MAAAsG,GAAAC,EAAA,EAAAA,EAAAD,EAAAC,IAAN7N,EAAM6N,GAAA5L,UAAA4L,EAC9B,OAAO3N,gBAAMF,GAAM8N,MAAM,SAAC1I,GACxB,KAAMqI,EAAQ,EACZ,KAAMrI,EAER,OAAOiI,GAAMU,EAAkBL,EAAOD,IACnCpL,KAAK,iBAAMsL,gBAAS3N,QAKtB,QAASgO,GAAgBC,GAC9B,GAAMC,IAAkC,EAAhB1C,KAAK2C,SAAgB,GAAKC,CAClD,OAAOH,IAAc,EAAMC,GAGtB,QAASH,GAAmBE,GAA4B,GAAhBI,GAAgBpM,UAAAC,OAAA,GAAAC,SAAAF,UAAA,GAAAA,UAAA,GAAH,CAC1D,OAAO+L,GAAeC,EAAazC,KAAK8C,IAAI,EAAGD,EAAa,IAGvD,QAASE,GAAYzM,EAAMuB,EAAMmL,GAAgC,GAAvBnP,GAAuB4C,UAAAC,OAAA,GAAAC,SAAAF,UAAA,GAAAA,UAAA,GAAlB,GAAIwM,EAAcxM,UAAAC,OAAA,GAAAC,SAAAF,UAAA,GAAAA,UAAA,GAAN,KAC5DyM,EAAQ,QACPrL,KACHqL,GAAYC,mBAAmBH,GAA/B,KAES,KAAPnP,IACFqP,GAASC,mBAAmBtP,GAE9B,IAAMuP,GAAIzI,EAAYsI,EAItB,OAHU,KAANG,IACFF,GAAS,IAAME,GAEVF,EAGF,QAASvI,GAAasI,GAC3B,IAAKA,EACH,MAAO,EAET,IAAIG,GAAI,EACR,KAAK,GAAMC,KAASJ,GACR,KAANG,IACFA,GAAK,KAEPA,GAAQD,mBAAmBE,GAA3B,IAAqCF,mBAAmBF,EAAMI,GAEhE,OAAOD,GAGF,QAASE,GAAa9I,GAC3B,GAAI+I,GAAa/I,EAAIf,QAAQ,IACzB8J,GAAa,IACfA,EAAa/I,EAAI9D,OAEnB,IAAM8M,MACFC,EAAYjJ,EAAIf,QAAQ,IAI5B,IAHIgK,EAAY,IACdA,EAAYjJ,EAAI9D,QAEd+M,EAAYF,EACd,MAAOC,EAET,IAAME,GAAWlJ,EAAI/F,MAAM8O,EAAa,EAAGE,EAC3C,IAAiB,KAAbC,EACF,MAAOF,EAGT,KAAK,GADCG,GAAQD,EAASE,MAAM,KACpBzP,EAAI,EAAGA,EAAIwP,EAAMjN,OAAQvC,IAAK,CACrC,GAAI0P,GAAOF,EAAMxP,GAAGyP,MAAM,IAC1B,IAAoB,IAAhBC,EAAKnN,QAA4B,KAAZmN,EAAK,GAA9B,CAGA,GAAMR,GAAQS,mBAAmBD,EAAK,GACtC,KAAIL,EAAQlP,eAAe+O,GAG3B,GAAoB,IAAhBQ,EAAKnN,OACP8M,EAAQH,IAAS,MACZ,IAAoB,IAAhBQ,EAAKnN,OAGd,KAAM,IAAIsD,OAAM,gBAFhBwJ,GAAQH,GAASS,mBAAmBD,EAAK,MAK7C,MAAOL,GAIF,QAASzI,GAAMpB,GAChBoK,EAAOtK,QAAQE,MAAU,IAC3BoK,EAAOlI,KAAKlC,GACZmB,QAAQC,KAAK,iBAAkBpB,IJ4dlCvF,OAAO4G,eAAe5H,EAAS,cAC7B2C,OAAO,IAET3C,EI/lBegO,aJgmBfhO,EI9kBemO,YJ+kBfnO,EI3kBeqO,WJ4kBfrO,EIxkBewO,YJykBfxO,EIrkBeyO,QJskBfzO,EIhkBeiF,QJikBfjF,EIrjBeoP,iBJsjBfpP,EIjjBemP,oBJkjBfnP,EI9iBe2P,aJ+iBf3P,EIhiBeuH,cJiiBfvH,EInhBekQ,cJohBflQ,EI7ee2H,MA/HhB,IAAM6H,GAAa,GA8HbmB,MJyoBA,SAAS1Q,EAAQD,EAASM,GKxwBhC,YAKA,SAAAsQ,GAAAhP,GACA,MAAAZ,QAAA6M,KAAAjM,GAAA,GAGA,QAAAiP,GAAAjP,GACA,MAAAA,GAAAgP,EAAAhP,IAIA,QAAAkP,GAAAC,GACA,IAAArI,MAAAC,QAAAoI,GACA,SAAAnK,OAAA,yCAEA,OAAAmK,GAAAjD,IAAA,SAAAkD,GACA,mBAAAA,GAAA,CACA,GAAApP,KAEA,OADAA,GAAAoP,GAAA,MACApP,EAEA,MAAAoP,KAMA,QAAAC,GAAAjE,GACA,MAAAkE,GAAA7K,QAAA2G,IAAA,EAIA,QAAAmE,GAAAC,EAAAzO,EAAA0O,GACA,mBAAAA,GAAAC,MAGA,mBAAAD,GAAAE,KACA,SAAAH,EACAzO,EAAA0O,EAAAE,OACAF,EAAAE,KAAA5O,GAGAA,GAAA0O,EAAAE,aACAF,GAAAE,KACAF,EAAAG,IAAA7O,GAGG,mBAAA0O,GAAAG,IACH,SAAAJ,EACAzO,EAAA0O,EAAAG,YACAH,GAAAG,IACAH,EAAAE,KAAA5O,GAGAA,EAAA0O,EAAAG,MACAH,EAAAG,IAAA7O,GAIA0O,EAAAD,GAAAzO,GAKA,QAAA8O,GAAAL,EAAAzO,EAAA0O,GACA,mBAAAA,GAAAC,MAGA,mBAAAD,GAAAK,KACA,SAAAN,EACAzO,EAAA0O,EAAAK,OACAL,EAAAK,KAAA/O,GAGAA,GAAA0O,EAAAK,aACAL,GAAAK,KACAL,EAAAM,IAAAhP,GAGG,mBAAA0O,GAAAM,IACH,SAAAP,EACAzO,EAAA0O,EAAAM,YACAN,GAAAM,IACAN,EAAAK,KAAA/O,GAGAA,EAAA0O,EAAAM,MACAN,EAAAM,IAAAhP,GAIA0O,EAAAD,GAAAzO,GAKA,QAAAiP,GAAAjP,EAAA0O,GACA,OAAAA,GAEAA,EAAAQ,IAAApJ,KAAA9F,GAEA0O,EAAAQ,KAAAlP,GAKA,QAAAmP,GAAAnP,EAAA0O,SAGAA,GAAAG,UACAH,GAAAE,WACAF,GAAAM,UACAN,GAAAK,WACAL,GAAAQ,IACAR,EAAAC,IAAA3O,EAIA,QAAAoP,GAAAC,GAKA,GAAA/N,KAqCA,OAnCA+N,GAAAC,QAAA,SAAAC,GACAlR,OAAA6M,KAAAqE,GAAAD,QAAA,SAAAjF,GACA,GAAAmF,GAAAD,EAAAlF,EAKA,IAJA,gBAAAmF,KACAA,GAAmBb,IAAAa,IAGnBlB,EAAAjE,GACAmF,YAAAzJ,OACAzE,EAAA+I,GAAAmF,EAAArE,IAAA,SAAAlN,GACA,MAAAmR,IAAAnR,MAGAqD,EAAA+I,GAAA+E,GAAAI,QAEO,CACP,GAAAd,GAAApN,EAAA+I,GAAA/I,EAAA+I,MACAhM,QAAA6M,KAAAsE,GAAAF,QAAA,SAAAb,GACA,GAAAzO,GAAAwP,EAAAf,EAEA,eAAAA,GAAA,SAAAA,EACAD,EAAAC,EAAAzO,EAAA0O,GACW,QAAAD,GAAA,SAAAA,EACXK,EAAAL,EAAAzO,EAAA0O,GACW,QAAAD,EACXQ,EAAAjP,EAAA0O,GACW,QAAAD,EACXU,EAAAnP,EAAA0O,QAEAA,EAAAD,GAAAzO,UAMAsB,EAMA,QAAAmO,GAAAC,GACA,GAAA7H,GAAA8H,EAAA3H,MAAA0H,GACAE,GAAA,CACA,SAAA/H,KACAA,EAAAuH,EAAAvH,EAAA,MACA+H,GAAA,GAGA,QAAA/H,KAGAA,EAAA,KAAAuH,GAAAvH,EAAA,OAKA,QAFA4B,GAAApL,OAAA6M,KAAArD,GAEAzJ,EAAA,EAAiBA,EAAAqL,EAAA9I,OAAmBvC,IAAA,CACpC,GAAAiM,GAAAZ,EAAArL,GACAoR,EAAA3H,EAAAwC,EAEA,iBAAAmF,IAAA,OAAAA,EACAA,GAAiBb,IAAAa,GACZ,OAAAA,KAAAI,IAGLJ,EAAAN,KAAAM,EAAAN,MAEArH,EAAAwC,GAAAmF,EAGA,MAAA3H,GAIA,QAAAgI,GAAAC,GASA,MARAA,GAAArG,OAAAqG,EAAArG,OAAA0B,IAAA,SAAAd,GACA,mBAAAA,GAAA,CACA,GAAApL,KAEA,OADAA,GAAAoL,GAAA,MACApL,EAEA,MAAAoL,KAEAyF,EAGA,QAAAC,GAAA7G,EAAA8G,GAEA,OADA1O,MACAlD,EAAA,EAAiBA,EAAA4R,EAAAC,IAAAxG,OAAA9I,OAA6BvC,IAAA,CAC9C,GAAAiM,GAAA4D,EAAA+B,EAAAC,IAAAxG,OAAArL,GACAkD,GAAAwE,KAAAoD,EAAAmB,IAEA,MAAA/I,GAKA,QAAA4O,GAAAC,EAAAC,EAAAJ,GAEA,OADAK,GAAAL,EAAAC,IAAAxG,OACArL,EAAA,EAAA6I,EAAAkJ,EAAAxP,OAAoCvC,EAAA6I,EAAS7I,IAAA,CAC7C,GAAAkS,GAAAH,EAAA/R,GAKAmS,EAAAR,EAAAO,EAAApH,IAAA8G,EACA,QAAAK,EAAA1P,OACA4P,IAAA,OAIA,MAAAA,EAAA5P,OAAAyP,EAAAzP,QACA4P,EAAAjJ,KAIA,IAAA2C,KAAAuG,IAAAC,UAAAF,EAAAH,IAAA,EAEA,MAGA,MAAAhS,GAAA,EAAA+R,EAAAzR,MAAAN,GAAA+R,EAGA,QAAAO,GAAAC,GACA,GAAAC,GAAAjB,EAAA3H,MAAA2I,EAkBA,cAjBAC,GAAAC,eACAD,GAAAE,aACAF,GAAAG,sBACAH,GAAAI,cAEA,UAAAL,KACAC,EAAAC,SAAAF,EAAAG,QAEA,YAAAH,KACAC,EAAAE,OAAAH,EAAAE,UAEA,mBAAAF,KACAC,EAAAI,cAAAL,EAAAI,iBAEA,iBAAAJ,KACAC,EAAAG,gBAAAJ,EAAAK,eAEAJ,EAGA,QAAAK,GAAAjB,GACA,GAAAkB,GAAAlB,EAAAvG,OAAA0H,OAAA,SAAA9G,GACA,cAAA6D,EAAA7D,IAEA,QAAA6G,EAAAvQ,QAAAuQ,EAAAvQ,SAAAqP,EAAAvG,OAAA9I,OACA,SAAAsD,OAAA,6BAIA,QAAAmN,GAAAC,EAAArB,GACA,GAAAA,EAAAsB,aAAAD,EAAAjD,KAAA,CACA,GAAAmD,GAAAF,EAAAjD,KAAA+C,OAAA,SAAAK,GACA,cAAAnT,OAAA6M,KAAAsG,GAAA,KACKrG,IAAA,SAAAqG,GACL,MAAAnT,QAAA6M,KAAAsG,GAAA,IAGA,IAAAD,EAAA5Q,OAAA,EACA,SAAAsD,OAAA,4BAAAsN,EAAAE,KAAA,KACA,kCAIAzB,EAAAsB,YAKA,QAAAI,GAAAL,GACA,mBAAAA,GAAA9B,SACA,SAAAtL,OAAA,+CAsBA,QAAA0N,GAAApC,EAAAnB,GACA,GAEAwD,GAFAC,EAAAxT,OAAA6M,KAAAqE,GACAuC,EAAA1D,IAAAjD,IAAA8C,KAQA,OALA2D,GADAC,EAAAlR,QAAAmR,EAAAnR,OACAkR,EAEAC,EAGA,IAAAA,EAAAnR,QAEA8I,OAAAmI,IAKAA,IAAAxD,KAAA,SAAArE,EAAAC,GACA,GAAAM,GAAAwH,EAAApO,QAAAqG,EACAO,MAAA,IACAA,EAAAyH,OAAAC,UAEA,IAAAC,GAAAH,EAAApO,QAAAsG,EAIA,OAHAiI,MAAA,IACAA,EAAAF,OAAAC,WAEA1H,EAAA2H,GAAA,EAAA3H,EAAA2H,EAAA,OAIAxI,OAAAmI,EACAM,UAAA9D,EAAAjD,IAAA8C,KApWA,GAAA0B,GAAAhS,EAAA,GACA8S,EAAA9S,EAAA,GA0BA4Q,GAAA,oBA6UAjR,GAAAD,SACA4Q,SACAC,WACAC,cACAsB,kBACAwB,gBACAS,sBACAN,eACAV,iBACAR,uBACAL,kBACAtG,WAAAoG,EAAApG,WACAoI,gBACArD,yBLgxBM,SAAShR,EAAQD,GM5nCvB,QAAA8U,KACA,SAAAlO,OAAA,mCAEA,QAAAmO,KACA,SAAAnO,OAAA,qCAsBA,QAAAoO,GAAAxL,GACA,GAAAyL,IAAArG,WAEA,MAAAA,YAAApF,EAAA,EAGA,KAAAyL,IAAAH,IAAAG,IAAArG,WAEA,MADAqG,GAAArG,WACAA,WAAApF,EAAA,EAEA,KAEA,MAAAyL,GAAAzL,EAAA,GACK,MAAA/B,GACL,IAEA,MAAAwN,GAAAtU,KAAA,KAAA6I,EAAA,GACS,MAAA/B,GAET,MAAAwN,GAAAtU,KAAAP,KAAAoJ,EAAA,KAMA,QAAA0L,GAAAC,GACA,GAAAC,IAAAC,aAEA,MAAAA,cAAAF,EAGA,KAAAC,IAAAL,IAAAK,IAAAC,aAEA,MADAD,GAAAC,aACAA,aAAAF,EAEA,KAEA,MAAAC,GAAAD,GACK,MAAA1N,GACL,IAEA,MAAA2N,GAAAzU,KAAA,KAAAwU,GACS,MAAA1N,GAGT,MAAA2N,GAAAzU,KAAAP,KAAA+U,KAYA,QAAAG,KACAC,GAAAC,IAGAD,GAAA,EACAC,EAAAlS,OACAmS,EAAAD,EAAA9T,OAAA+T,GAEAC,GAAA,EAEAD,EAAAnS,QACAqS,KAIA,QAAAA,KACA,IAAAJ,EAAA,CAGA,GAAAK,GAAAZ,EAAAM,EACAC,IAAA,CAGA,KADA,GAAA3L,GAAA6L,EAAAnS,OACAsG,GAAA,CAGA,IAFA4L,EAAAC,EACAA,OACAC,EAAA9L,GACA4L,GACAA,EAAAE,GAAAG,KAGAH,IAAA,EACA9L,EAAA6L,EAAAnS,OAEAkS,EAAA,KACAD,GAAA,EACAL,EAAAU,IAiBA,QAAAE,GAAAtM,EAAAuM,GACA3V,KAAAoJ,MACApJ,KAAA2V,QAYA,QAAAC,MAhKA,GAOAf,GACAG,EARA9L,EAAArJ,EAAAD,YAgBA,WACA,IAEAiV,EADA,kBAAArG,YACAA,WAEAkG,EAEK,MAAArN,GACLwN,EAAAH,EAEA,IAEAM,EADA,kBAAAC,cACAA,aAEAN,EAEK,MAAAtN,GACL2N,EAAAL,KAuDA,IAEAS,GAFAC,KACAF,GAAA,EAEAG,GAAA,CAyCApM,GAAAY,SAAA,SAAAV,GACA,GAAApI,GAAA,GAAAsH,OAAArF,UAAAC,OAAA,EACA,IAAAD,UAAAC,OAAA,EACA,OAAAvC,GAAA,EAAuBA,EAAAsC,UAAAC,OAAsBvC,IAC7CK,EAAAL,EAAA,GAAAsC,UAAAtC,EAGA0U,GAAAhN,KAAA,GAAAqN,GAAAtM,EAAApI,IACA,IAAAqU,EAAAnS,QAAAiS,GACAP,EAAAW,IASAG,EAAA7U,UAAA4U,IAAA,WACAzV,KAAAoJ,IAAA/H,MAAA,KAAArB,KAAA2V,QAEAzM,EAAA2M,MAAA,UACA3M,EAAA8B,SAAA,EACA9B,EAAA4M,OACA5M,EAAA6M,QACA7M,EAAA8M,QAAA,GACA9M,EAAA+M,YAIA/M,EAAAgN,GAAAN,EACA1M,EAAAiN,YAAAP,EACA1M,EAAAC,KAAAyM,EACA1M,EAAAkN,IAAAR,EACA1M,EAAAmN,eAAAT,EACA1M,EAAAoN,mBAAAV,EACA1M,EAAAqN,KAAAX,EAEA1M,EAAAsN,QAAA,SAAA1N,GACA,SAAAtC,OAAA,qCAGA0C,EAAAuN,IAAA,WAA2B,WAC3BvN,EAAAwN,MAAA,SAAAC,GACA,SAAAnQ,OAAA,mCAEA0C,EAAA0N,MAAA,WAA4B,WN8oCtB,SAAS/W,EAAQD,EAASM,GAE/B,YOjzCM,SAAS2W,GAAkB/T,EAAMuB,EAAMmL,GAC5C,GAAIsH,GAActH,EAAQvJ,QAAQ,QAAS,CAC3C,IAAI5B,GAAQyS,EAAa,CACvB,GAAIC,GAAQC,EAAcxH,EAC1B,OAAIuH,GAAcA,EACXvH,EAAQvI,QAAQ,MAAO,KAEhC,IAAK5C,IAASyS,EAAa,CACzB,GAAIC,GAAQE,EAAezH,EAC3B,IAAIuH,EAEF,OADA,EAAAnS,EAAA2C,MAAK,yCAA2CiI,EAAU,kBAAoBuH,GACvEA,CAET,MAAM,IAAIvQ,OAAM,WAAagJ,EAAU,yBAEzC,MAAOA,GPoyCR5O,OAAO4G,eAAe5H,EAAS,cAC7B2C,OAAO,IAET3C,EAAQsX,cAAgB/T,OACxBvD,EOvzCeiX,kBAlBhB,IAAAjS,GAAA1E,EAAA,GAEagX,kBAAgB,gBAEvBD,GACJE,MAASD,EACTE,OAAUF,EACVG,QAAW,mBACXC,MAAS,iBACTC,MAAS,2BACTC,SAAY,+BAGRR,IACNpW,QAAO6M,KAAKwJ,GAAgBpF,QAAQ,SAAA4F,GAClCT,EAAcC,EAAeQ,IAAMA,KPk2C/B,SAAS5X,EAAQD,GQh3CvB,GAAA8X,GAAA7X,EAAAD,QAAA,mBAAAgH,gBAAA4F,WACA5F,OAAA,mBAAA5E,YAAAwK,WAAAxK,KAEA2V,SAAA,gBACA,iBAAAC,WAAAF,IRw3CM,SAAS7X,EAAQD,EAASM,GS73ChC,YAwEA,SAAA2X,GAAAlM,GACA,UAAAA,EACA,aAAAA,IACA,cACA,MAAAA,GAAA,GACA,cACA,MAAAmM,GAAAnM,EACA,cAMA,MAAAA,GACA1E,QAAA,gBACAA,QAAA,gBACAA,QAAA,eACA,cACA,GAAAsB,GAAAD,MAAAC,QAAAoD,GACAjE,EAAAa,EAAAoD,EAAA/K,OAAA6M,KAAA9B,GACAhL,GAAA,EACA6I,EAAA9B,EAAAxE,OACAkH,EAAA,EACA,IAAA7B,EACA,OAAA5H,EAAA6I,GACAY,GAAAxK,EAAAmY,kBAAArQ,EAAA/G,QAGA,QAAAA,EAAA6I,GAAA,CACA,GAAAwO,GAAAtQ,EAAA/G,EACAyJ,IAAAxK,EAAAmY,kBAAAC,GACApY,EAAAmY,kBAAApM,EAAAqM,IAGA,MAAA5N,GAGA,SAYA,QAAA6N,GAAAC,EAAAvX,GACA,GACAwX,GADAC,EAAAzX,EAEA0X,EAAA,MAAAH,EAAAvX,EACA,IAAA0X,EACAF,EAAA,EACAxX,QACG,CACH,GAAA2X,GAAA,MAAAJ,EAAAvX,EACAA,IACA,IAAA4X,GAAA,GACAC,EAAAN,EAAA/L,UAAAxL,IAAA8X,GACAC,EAAAC,SAAAH,EAAA,IAAAI,CAKA,KAJAN,IACAI,MAEA/X,GAAA8X,IACA,CACA,GAAAvM,GAAAgM,EAAAvX,EACA,WAAAuL,EACA,KAEAqM,IAAArM,EAEAvL,IAEA4X,IAAAnI,MAAA,KAEA+H,EADA,IAAAI,EAAArV,OACAyV,SAAAJ,EAAA,IAEAM,WAAAN,EAAA,OAAAA,EAAA,IAEAD,IACAH,GAAA,IAEA,IAAAO,IAIAP,EAAAU,WAAAV,EAAA,IAAAO,IAGA,OAAUP,MAAAjV,OAAAvC,EAAAyX,GAKV,QAAAvO,GAAAiP,EAAAC,GACA,GAAAvX,GAAAsX,EAAAjP,KAEA,IAAAkP,EAAA7V,OAAA,CACA,GAAA8V,GAAAD,IAAA7V,OAAA,EACA1B,KAAAwX,EAAA7L,UAEA4L,EAAAlP,MACAmP,EAAAD,IAAA7V,OAAA,GAEA,IAAAiK,GAAA6L,EAAA7L,QACA8L,EAAAD,EAAAzG,KACA,IAAAjK,MAAAC,QAAA4E,GACAA,EAAA9E,KAAA7G,OACK,IAAAyX,IAAAH,EAAA5V,OAAA,GACL,GAAAyI,GAAAmN,EAAAjP,KACAsD,GAAAxB,GAAAnK,MAEAsX,GAAAzQ,KAAA7G,IAmEA,QAAA0X,GAAA/X,EAAAC,GAEA,OADAoI,GAAAgD,KAAAC,IAAAtL,EAAA+B,OAAA9B,EAAA8B,QACAvC,EAAA,EAAiBA,EAAA6I,EAAS7I,IAAA,CAC1B,GAAAgQ,GAAA/Q,EAAAoT,QAAA7R,EAAAR,GAAAS,EAAAT,GACA,QAAAgQ,EACA,MAAAA,GAGA,MAAAxP,GAAA+B,SAAA9B,EAAA8B,OAAA,EACA/B,EAAA+B,OAAA9B,EAAA8B,OAAA,KAEA,QAAAiW,GAAAhY,EAAAC,GAIA,MAAAD,KAAAC,EAAA,EAAAD,EAAAC,EAAA,KAEA,QAAAgY,GAAAjY,EAAAC,GAGA,OAFAiY,GAAAzY,OAAA6M,KAAAtM,GAAAmY,EAAA1Y,OAAA6M,KAAArM,GACAoI,EAAAgD,KAAAC,IAAA4M,EAAAnW,OAAAoW,EAAApW,QACAvC,EAAA,EAAiBA,EAAA6I,EAAS7I,IAAA,CAE1B,GAAAgQ,GAAA/Q,EAAAoT,QAAAqG,EAAA1Y,GAAA2Y,EAAA3Y,GACA,QAAAgQ,EACA,MAAAA,EAIA,IADAA,EAAA/Q,EAAAoT,QAAA7R,EAAAkY,EAAA1Y,IAAAS,EAAAkY,EAAA3Y,KACA,IAAAgQ,EACA,MAAAA,GAIA,MAAA0I,GAAAnW,SAAAoW,EAAApW,OAAA,EACAmW,EAAAnW,OAAAoW,EAAApW,OAAA,KAMA,QAAAqW,GAAAC,GACA,GAAAnZ,IAAA,sCACAoZ,EAAApZ,EAAA4F,cAAAuT,GAEA,QAAAC,EACA,OAAAD,EACA,EAEAlR,MAAAC,QAAAiR,GACA,EAEAC,EAAA,EAAAA,EAAA,EAAAA,EAAA,EAEAnR,MAAAC,QAAAiR,GACA,EADA,OAUA,QAAA1B,GAAAK,GAEA,OAAAA,EACA,SAKA,IAAAuB,GAAAvB,EAAAwB,gBAAAvJ,MAAA,QACAsI,EAAAC,SAAAe,EAAA,OAEApB,EAAAH,EAAA,EAEA/N,EAAAkO,EAAA,QAIAsB,GAAAtB,GAAAI,KAAAE,EACAiB,EAAA3H,EAAA4H,QAAA,EAAAC,WAAA,IAAAtB,EAEArO,IAAA4P,EAAAH,CAGA,IAAAI,GAAAzN,KAAAuG,IAAA8F,WAAAa,EAAA,IACApB,KACA2B,EAAA,GAAAA,EAGA,IAAAC,GAAAD,EAAAE,QAAA,GAOA,OAJAD,KAAAjT,QAAA,aAEAmD,GAAA4P,EAAAE,EA3VA,GAAAtB,IAAA,IACAH,EAAA,EACAuB,EAAA,GAEA9H,EAAAhS,EAAA,GAEAN,GAAAoT,QAAA,SAAA7R,EAAAC,GAEA,GAAAD,IAAAC,EACA,QAGAD,GAAAvB,EAAAwa,aAAAjZ,GACAC,EAAAxB,EAAAwa,aAAAhZ,EAEA,IAAAiZ,GAAAd,EAAApY,GACAmZ,EAAAf,EAAAnY,EACA,IAAAiZ,EAAAC,IAAA,EACA,MAAAD,GAAAC,CAEA,WAAAnZ,EACA,QAEA,cAAAA,IACA,aACA,MAAAA,GAAAC,CACA,eACA,MAAAD,KAAAC,EAAA,EAAAD,EAAAC,GAAA,GACA,cACA,MAAA+X,GAAAhY,EAAAC,GAEA,MAAAkH,OAAAC,QAAApH,GAAA+X,EAAA/X,EAAAC,GAAAgY,EAAAjY,EAAAC,IAKAxB,EAAAwa,aAAA,SAAAzO,GACA,aAAAA,IACA,gBACA,WACA,cACA,MAAAA,KAAA4O,KAAA5O,MAAA4O,MAAAC,MAAA7O,GACA,KAEAA,CACA,cACA,GAAA8O,GAAA9O,CACA,IAAArD,MAAAC,QAAAoD,GAAA,CACA,GAAAnC,GAAAmC,EAAAzI,MACAyI,GAAA,GAAArD,OAAAkB,EACA,QAAA7I,GAAA,EAAuBA,EAAA6I,EAAS7I,IAChCgL,EAAAhL,GAAAf,EAAAwa,aAAAK,EAAA9Z,QAEO,IAAAgL,YAAA+O,MACP,MAAA/O,GAAAgP,QACO,WAAAhP,EAAA,CACPA,IACA,QAAA8L,KAAAgD,GACA,GAAAA,EAAA3Z,eAAA2W,GAAA,CACA,GAAAmD,GAAAH,EAAAhD,EACA,oBAAAmD,KACAjP,EAAA8L,GAAA7X,EAAAwa,aAAAQ,OAMA,MAAAjP,IA8CA/L,EAAAmY,kBAAA,SAAApM,GACA,GAAA0M,GAAA,IAEA,OADA1M,GAAA/L,EAAAwa,aAAAzO,GACA4N,EAAA5N,GAAAqO,EAAAnC,EAAAlM,GAAA0M,GAyEAzY,EAAAib,qBAAA,SAAA3C,GAKA,IAJA,GAAAY,MACAC,KACApY,EAAA,IAEA,CACA,GAAA4Y,GAAArB,EAAAvX,IACA,WAAA4Y,EAQA,OAAAA,GACA,QACAT,EAAAzQ,KAAA,KACA,MACA,SACAyQ,EAAAzQ,KAAA,MAAA6P,EAAAvX,IACAA,GACA,MACA,SACA,GAAAma,GAAA7C,EAAAC,EAAAvX,EACAmY,GAAAzQ,KAAAyS,EAAA3C,KACAxX,GAAAma,EAAA5X,MACA,MACA,SAEA,IADA,GAAA6X,GAAA,KACA,CACA,GAAA7O,GAAAgM,EAAAvX,EACA,WAAAuL,EACA,KAEA6O,IAAA7O,EACAvL,IAIAoa,IAAA9T,QAAA,sBACAA,QAAA,qBACAA,QAAA,qBACA6R,EAAAzQ,KAAA0S,EACA,MACA,SACA,GAAAC,IAA4B7N,WAAAoF,MAAAuG,EAAA5V,OAC5B4V,GAAAzQ,KAAA2S,EAAA7N,SACA4L,EAAA1Q,KAAA2S,EACA,MACA,SACA,GAAAC,IAA0B9N,WAAYoF,MAAAuG,EAAA5V,OACtC4V,GAAAzQ,KAAA4S,EAAA9N,SACA4L,EAAA1Q,KAAA4S,EACA,MACA,SACA,SAAAzU,OACA,4DAAA+S,OAlDA,CACA,OAAAT,EAAA5V,OACA,MAAA4V,GAAAjP,KAEAA,GAAAiP,EAAAC,OT0hDM,SAASlZ,EAAQD,EAASM,GAE/B,YA0BA,SAASyB,GAAgBC,EAAUC,GAAe,KAAMD,YAAoBC,IAAgB,KAAM,IAAIC,WAAU,qCU3pD1G,QAAS6C,GAAQ7B,EAAMoY,GAI5B,MAHKA,KACHA,EAAepY,EAAKqY,eAElBD,YAAwBE,GACnBF,EAEF,GAAIE,GAAOF,GAGb,QAASG,GAAgBvY,EAAMoY,GACpC,GAAMI,GAAM3W,EAAO7B,EAAMoY,EACzB,OAAII,GAAIC,eACCpX,QAAQ8F,OAAO,GAAIzD,OAAM,+BAE3B,EAAAgV,EAAAtW,eAAcpC,EAAM,OAAQ,iBAAkBwY,EAAIG,kBACvDlY,aAAa,IAEZF,KAAK,SAACyC,GAAD,MAAU,IAAIsV,GAAOtV,KAGxB,QAAS4V,GAAc5Y,EAAMoY,GAAmC,GAArBS,GAAqB1Y,UAAAC,OAAA,GAAAC,SAAAF,UAAA,IAAAA,UAAA,GAC/DqY,EAAM3W,EAAO7B,EAAMoY,EACzB,KAAKI,EAAIC,eACP,MAAOpX,SAAQ8F,OAAO,GAAIzD,OAAM,yBAElC,IAAIV,GAAOwV,EAAIG,gBAIf,OAHA3V,GAAK8V,UAAYN,EAAIO,SACjBF,IAAa7V,EAAKgW,cAAgBR,EAAIS,eAEnC,EAAAP,EAAAtW,eAAcpC,EAAM,MAApB,kBAA6CwY,EAAIO,SAAY/V,GAClErC,uBACEQ,MAAOqX,KAERjY,KAAK,SAACyC,GAAD,MAAUkW,GAAalW,EAAMwV,KAGhC,QAASW,GAAkBnZ,EAAMoY,GACtC,GAAMI,GAAM3W,EAAO7B,EAAMoY,EACzB,OAAKI,GAAIC,gBAGF,EAAAC,EAAAtW,eAAcpC,EAAM,SAApB,kBAAgDwY,EAAIO,SAAY,MACrEpY,uBACEQ,MAAOqX,KAJFnX,QAAQ8F,OAAO,GAAIzD,OAAM,0BAU7B,QAAS0V,GAAWpZ,EAAMoY,GAC/B,GAAMI,GAAM3W,EAAO7B,EAAMoY,EACzB,OAAKI,GAAIC,gBAGL,EAAA3W,EAAAwJ,aACKjK,QAAQoK,QAAQ+M,IAElB,EAAAE,EAAAtW,eAAcpC,EAAM,MAApB,kBAA6CwY,EAAIO,SAAY,MAEhEpY,uBACEQ,MAAOqX,KAGVjY,KAAK,SAACyC,GAAD,MAAUkW,GAAalW,EAAMwV,KAClCxM,MAAM,SAAC1I,GAQN,GAAIoV,EAAAlV,WAAW0C,eAAe5C,IAAQoV,EAAAlV,WAAW2C,WAAW7C,GAC1D,KAAM,IAAII,OAAM,0BAElB,MAAMJ,KAvBDjC,QAAQ8F,OAAO,GAAIzD,OAAM,0BA6BpC,QAASwV,GAAclW,EAAMqW,GAC3B,GAAMC,GAAY,GAAIhB,GAAOtV,GAIvBuW,IACFF,GACoC,KAAtCA,EAAUG,yBAC4B,KAAtCF,EAAUE,uBAKZ,OAHID,KACFD,EAAUE,wBAA0BH,EAAUG,yBAEzCF,EAMF,QAASG,GAAgBzZ,EAAM6B,GAAqB,GAAb6X,GAAavZ,UAAAC,OAAA,GAAAC,SAAAF,UAAA,GAAAA,UAAA,KAIzD,IAHM0B,YAAkByW,KACtBzW,EAAS,GAAIyW,GAAOzW,KAEjBA,EAAO4W,eACV,KAAM,IAAI/U,OAAM,wBAElB,IAAMiW,GAAQC,IACRjN,GACJmM,UAAajX,EAAOkX,SACpBc,aAAgBhY,EAAOiY,YACvBH,MAASA,EACTI,cAAiB,OACjBC,MAASN,EAAOxI,KAAK,KAEvB,QACEhN,IAAKlE,EAAKia,MAAL,oBAA+B,EAAAnY,EAAAuC,aAAYsI,IAChDgN,MAAOA,GAWJ,QAASO,GAAgBla,EAAM6B,EAAQ8X,GAAqB,GAAdQ,GAAcha,UAAAC,OAAA,GAAAC,SAAAF,UAAA,GAAAA,UAAA,GAAJ,EAC7D,KAAKwZ,EACH,MAAOtY,SAAQ8F,OAAO,GAAIzD,OAAM,uBAElC,IAAM0W,GAAeC,EAAwBF,EAC7C,OAAqB,QAAjBC,EACK/Y,QAAQ8F,OAAO,GAAIzD,OAAM,oCAE9BiW,IAAUS,EAAaT,MAClBtY,QAAQ8F,OAAO,GAAIzD,OAAM,+CAE3B4W,EAActa,EAAM6B,EAAQ,MACjC0Y,WAAc,qBACdC,KAAQJ,EAAaI,OAMlB,QAASvY,GAAcjC,EAAM6B,EAAQV,GAC1C,MAAOmZ,GAActa,EAAM6B,EAAQV,GACjCoZ,WAAc,gBACdE,cAAiBtZ,EAAMc,eAMpB,QAASyY,GAAW1a,EAAM2a,EAASvC,EAAcwC,GAOtD,QAASC,GAAevX,GACtB,GAAIwX,IAAa,EACf,KAAMxX,EAER,OAAOqX,GAAQI,QAAQxa,KAAK,iBAC1Bma,GAAU1a,EAAM2a,EAASvC,EAAcwC,KAG3C,QAASI,KACP,MAAOL,GAAQI,QACZxa,KAAK,iBAAMgY,GAAevY,EAAMoY,KAChC7X,KAAK,SAACsB,GAAW,GAAAoZ,GACKxB,EAAezZ,EAAM6B,EAAQuW,EAAasB,QAAxDxV,EADS+W,EACT/W,IAAKyV,EADIsB,EACJtB,KACZ,OAAOgB,GAAQO,KAAKC,GAAWtZ,SAAQqC,MAAKyV,YApBmD,GAAjCyB,GAAiCjb,UAAAC,OAAA,GAAAC,SAAAF,UAAA,IAAAA,UAAA,EACrG,IAAIib,EACF,MAAOT,GAAQI,QAAQxa,KAAK,iBAAMma,GAAU1a,EAAM2a,EAASvC,EAAcwC,GAAc,IAGzF,IAAIE,GAAW,CAmBf,OAAOzZ,SAAQC,KACbqZ,EAAQU,KAAKC,GACbX,EAAQU,KAAKF,KACZ5a,KAAK,SAAAiB,GAAgC,GAAAC,GAAAC,EAAAF,EAAA,GAA9BV,EAA8BW,EAAA,GAAjB8Z,EAAiB9Z,EAAA,EAItC,IAAIX,EAAa,CACf,GAAIuY,UAAWlY,QACf,KACEkY,EAAY,GAAIf,GAAOxX,EAAYe,QACnCV,EAAQ,GAAIqa,GAAY1a,EAAYK,OACpC,MAAOmC,GAEP,MAAOuX,GAAcvX,GAEvB,MAAO8V,GAAUpZ,EAAMqZ,GACpB9Y,KAAK,SAACsB,GAAD,OAAcA,SAAQV,WAC3B6K,MAAM,SAAC1I,GAQN,GAAIoV,EAAAlV,WAAW0C,eAAe5C,IAAQoV,EAAAlV,WAAW2C,WAAW7C,GAC1D,KAAM,IAAII,OAAM,0BAElB,QAAS7B,OAAQwX,EAAWlY,WAOlC,GAAIsa,SAIFA,GAHGF,EAGYla,QAAQoK,QAAQ8P,GAFhBP,GAKjB,IAAInZ,UAAQ8X,SAAOxY,QACnB,OAAOsa,GACJlb,KAAK,SAACyC,GAGL,MAFAnB,GAASmB,EAAKnB,OACd8X,EAAQ3W,EAAK2W,MACNtY,QAAQoK,QAAQmP,EAAa/Y,EAAQmB,EAAKkB,QAElD3D,KAAK,SAAC4Z,GAAD,MAAaD,GAAela,EAAM6B,EAAQ8X,EAAOQ,KACtD5Z,KAAK,SAACmb,GAAQva,EAAQua,IACtBnb,KAAK,iBAAMoa,GAAQgB,OAAOR,KAC1B5a,KAAK,kBAAQsB,SAAQV,aAEzBZ,KACC,SAACqb,GAAD,MAAWjB,GAAQO,KAAKI,EAAUM,IAClC,SAACtY,GACC,GAAIoV,EAAAlV,WAAW0C,eAAe5C,GAC5B,MAAOuX,GAAcvX,EAErB,MAAMA,KAOd,QAASgX,GAAeta,EAAM6B,EAAQV,EAAOwL,GAI3C,GAHM9K,YAAkByW,KACtBzW,EAAS,GAAIyW,GAAOzW,KAEjBA,EAAO4W,eACV,MAAOpX,SAAQ8F,OAAO,GAAIzD,OAAM,yBAElC,IAAMpB,IAAO,EAAAR,EAAAuC,aAAYvG,OAAO+d,UAAWlP,GACzCmM,UAAajX,EAAOkX,SACpBC,cAAiBnX,EAAOoX,eAE1B,QAAO,EAAAP,EAAAtW,eAAcpC,EAAM,OAAQ,qBAAsBsC,GACvD7B,YAAwB,OAAVU,EACdS,WAAW,EACXjB,uBAAyBkB,SAAQV,SACjCD,SAAW4a,eAAgB,uCAE1Bvb,KAAK,SAACyC,GAEL,MADAA,GAAKf,aAAee,EAAKf,cAAgB0K,EAAM8N,cACxC,GAAIe,GAAYxY,KAM7B,QAASqX,KAAuC,GAAdF,GAAcha,UAAAC,OAAA,GAAAC,SAAAF,UAAA,GAAAA,UAAA,GAAJ,EAC1B,MAAZga,GAAoC,mBAAXrW,UAC3BqW,EAAUrW,OAAOC,SAASgY,KAE5B,IAAM7O,IAAU,EAAApL,EAAAkL,aAAYmN,EAC5B,OAAKjN,GAAQlP,eAAe,UAI1B2b,MAAOzM,EAAA,MACPsN,KAAMtN,EAAA,aAJC,KAWX,QAAS0M,KACP,GAAIoC,SACJ,IAAsB,mBAAXlY,SACkB,mBAAlBA,QAAOgE,QAC2B,kBAAlChE,QAAOgE,OAAOmU,gBACvBD,EAAS,GAAIE,YAAWC,GACxBrY,OAAOgE,OAAOmU,gBAAgBD,OAE9B,KACEA,EAAS5e,GAAQ,cAAAmH,GAAA,GAAAb,OAAA,oCAAAa,GAAAiW,KAAA,mBAAAjW,MAAU6X,YAAYD,GACvC,MAAO5X,IAEX,IAAKyX,EAAQ,CACXA,EAAS,GAAIxW,OAAM2W,EACnB,KAAK,GAAIte,GAAI,EAAGA,EAAIme,EAAO5b,OAAQvC,IACjCme,EAAOne,GAAK6L,KAAK2S,MAAuB,IAAhB3S,KAAK2C,UAGjC,MAAOiQ,MAAKC,OAAOC,aAAaje,MAAM,KAAMyd,IACzC7X,QAAQ,MAAO,IACfA,QAAQ,MAAO,KACfA,QAAQ,MAAO,KV20CnBrG,OAAO4G,eAAe5H,EAAS,cAC7B2C,OAAO,IAET3C,EAAQ2f,SAAW3f,EAAQ0e,YAAc1e,EAAQwb,OAASxb,EAAQqe,SAAWre,EAAQwe,SAAWjb,MAEhG,IAAIqB,GAAiB,WAAc,QAASiD,GAAcC,EAAK/G,GAAK,GAAIgH,MAAeC,GAAK,EAAUC,GAAK,EAAWC,EAAK3E,MAAW,KAAM,IAAK,GAAiC4E,GAA7BC,EAAKN,EAAIO,OAAOC,cAAmBN,GAAMG,EAAKC,EAAGG,QAAQC,QAAoBT,EAAKU,KAAKN,EAAGxF,QAAY5B,GAAKgH,EAAKzE,SAAWvC,GAA3DiH,GAAK,IAAoE,MAAOxB,GAAOyB,GAAK,EAAMC,EAAK1B,EAAO,QAAU,KAAWwB,GAAMI,EAAW,QAAGA,EAAW,SAAO,QAAU,GAAIH,EAAI,KAAMC,IAAQ,MAAOH,GAAQ,MAAO,UAAUD,EAAK/G,GAAK,GAAI2H,MAAMC,QAAQb,GAAQ,MAAOA,EAAY,IAAIO,OAAOC,WAAYtH,QAAO8G,GAAQ,MAAOD,GAAcC,EAAK/G,EAAa,MAAM,IAAImB,WAAU,4DAEllB0d,EAAe,WAAc,QAASC,GAAiBC,EAAQC,GAAS,IAAK,GAAIhf,GAAI,EAAGA,EAAIgf,EAAMzc,OAAQvC,IAAK,CAAE,GAAIif,GAAaD,EAAMhf,EAAIif,GAAWpd,WAAaod,EAAWpd,aAAc,EAAOod,EAAWld,cAAe,EAAU,SAAWkd,KAAYA,EAAWnd,UAAW,GAAM7B,OAAO4G,eAAekY,EAAQE,EAAWjU,IAAKiU,IAAiB,MAAO,UAAU/d,EAAage,EAAYC,GAAiJ,MAA9HD,IAAYJ,EAAiB5d,EAAYhB,UAAWgf,GAAiBC,GAAaL,EAAiB5d,EAAaie,GAAqBje,KAGhiBjC,GU7oDe+E,SV8oDf/E,EUpoDeyb,iBVqoDfzb,EU1nDe8b,eV2nDf9b,EU3mDeqc,mBV4mDfrc,EU/lDesc,YVgmDftc,EU7iDe2c,iBV8iDf3c,EUlhDeod,iBVmhDfpd,EUhgDemF,eVigDfnF,EUx/Ce4d,WAjQhB,IAAA5Y,GAAA1E,EAAA,GACAsb,EAAAtb,EAAA,GAEM+e,EAAY,GAELb,aAAW,QACXH,aAAW,QAEX7C,EV8vDCxb,EU9vDDwb,OV8vDkB,WU7vD7B,QAAAA,GAAalI,GAuBX,GAvBiBvR,EAAA3B,KAAAob,GACjBpb,KAAK6b,SAAW3I,EAAK2I,UAAY3I,EAAK0I,WAAa,GACnD5b,KAAK+b,aAAe7I,EAAK6I,cAAgB7I,EAAK4I,eAAiB,GAC/D9b,KAAKsc,wBAA0BpJ,EAAKoJ,yBAA2BpJ,EAAK6M,2BAA6B,GAE7F7M,EAAK8M,cACPhgB,KAAK4c,YAAc1J,EAAK8M,cAAc,IAAM,GAE5ChgB,KAAK4c,YAAc1J,EAAK0J,aAAe,GAGzC5c,KAAKigB,WAAa/M,EAAK+M,YAAc/M,EAAKgN,aAAe,GACzDlgB,KAAKmgB,gBAAkBjN,EAAKiN,iBAAmBjN,EAAKkN,kBAAoB,GACxEpgB,KAAKqgB,WAAanN,EAAKmN,YAAcnN,EAAKoN,aAAe,GACzDtgB,KAAKugB,WAAarN,EAAKqN,YAAcrN,EAAKsN,aAAe,GACzDxgB,KAAKygB,UAAYvN,EAAKuN,WAAavN,EAAKwN,YAAc,GAEtD1gB,KAAK2gB,QAAUzN,EAAKyN,SAAWzN,EAAK0N,UAAY,GAChD5gB,KAAK6gB,UAAY3N,EAAK2N,WAAa3N,EAAK4N,YAAc,GAEtD9gB,KAAK+gB,qBAAuB7N,EAAK6N,sBAAwB7N,EAAK8N,uBAAyB,GACvFhhB,KAAKihB,wBAA0B/N,EAAK+N,yBAA2B/N,EAAKgO,2BAA6B,IAE5FlhB,KAAKsc,wBAAyB,CACjC,GAAyB,KAArBtc,KAAK4c,YACP,KAAM,IAAIpW,OAAM,4BAElB,IAAwB,KAApBxG,KAAKigB,WACP,KAAM,IAAIzZ,OAAM,2BAElB,IAAwB,KAApBxG,KAAKqgB,WACP,KAAM,IAAI7Z,OAAM,6BViyDrB,MA5BAgZ,GAAapE,IACXzP,IAAK,eACLpJ,MAAO,WUjwDR,MAAyB,KAAlBvC,KAAK6b,YVqwDXlQ,IAAK,iBACLpJ,MAAO,WUlwDR,OACEyd,eAAgBhgB,KAAK4c,aACrBsD,YAAalgB,KAAKigB,WAClBG,iBAAkBpgB,KAAKmgB,gBACvBG,YAAatgB,KAAKqgB,WAClBG,YAAaxgB,KAAKugB,WAClBG,WAAY1gB,KAAKygB,UACjBG,SAAU5gB,KAAK2gB,QACfG,WAAY9gB,KAAK6gB,UACjBG,sBAAuBhhB,KAAK+gB,qBAC5BG,0BAA2BlhB,KAAKihB,4BVuwDjCtV,IAAK,eACLpJ,MAAO,WUnwDR,MAAO,UAAYvC,KAAKsc,4BVwwDlBlB,KUpwDGkD,EVuwDM1e,EUvwDN0e,YVuwD4B,WUtwDvC,QAAAA,GAAapL,GAAMvR,EAAA3B,KAAAse,GACjBte,KAAKmhB,UAAYjO,EAAKiO,WAAajO,EAAKkO,WACxCphB,KAAKqhB,YAAcnO,EAAKmO,aAAenO,EAAKoO,aAC5CthB,KAAK+E,aAAemO,EAAKnO,cAAgBmO,EAAKqK,cAC9Cvd,KAAK8c,MAAQ5J,EAAK4J,MVwxDnB,MAZA0C,GAAalB,IACX3S,IAAK,eACLpJ,MAAO,WU1wDR,MAAO,UAAYvC,KAAKqhB,eV8wDvB1V,IAAK,cACLpJ,MAAO,WU3wDR,cAAevC,KAAKqhB,YAApB,QVgxDM/C,IAGM1e,GU/wDH2f,SV+wDsB,WU9wDjC,QAAAA,GAAarM,GAAMvR,EAAA3B,KAAAuf,GACjBvf,KAAKiE,MAAQiP,EAAKjP,OAAS,GVgyD5B,MAZAub,GAAaD,IACX5T,IAAK,eACLpJ,MAAO,WUlxDR,MAAO,UAAYvC,KAAKiE,SVsxDvB0H,IAAK,cACLpJ,MAAO,WUnxDR,cAAevC,KAAKiE,MAApB,QVwxDMsb,MA8UJ,SAAS1f,EAAQD,EAASM,GWtsEhCL,EAAAD,SAAAM,EAAA,eACA,MAA0E,IAA1EU,OAAA4G,kBAAiC,KAAQxB,IAAA,WAAmB,YAAc7E,KX+sEpE,SAAStB,EAAQD,GYjtEvBC,EAAAD,QAAA,SAAA2hB,GACA,IACA,QAAAA,IACG,MAAAla,GACH,YZ0tEM,SAASxH,EAAQD,Ga9tEvBC,EAAAD,QAAA,SAAA4hB,GACA,sBAAAA,GAAA,OAAAA,EAAA,kBAAAA,KbsuEM,SAAS3hB,EAAQD,IcvuEvB,SAAA8X,GAAA,YA+CA,SAAA5N,KACAqL,GAAA,CAGA,KAFA,GAAAxU,GAAA8gB,EACAjY,EAAA6L,EAAAnS,OACAsG,GAAA,CAIA,IAHAiY,EAAApM,EACAA,KACA1U,GAAA,IACAA,EAAA6I,GACAiY,EAAA9gB,IAEA6I,GAAA6L,EAAAnS,OAEAiS,GAAA,EAIA,QAAAuM,GAAAC,GACA,IAAAtM,EAAAhN,KAAAsZ,IAAAxM,GACAyM,IAjEA,GAEAA,GAFAC,EAAAnK,EAAAoK,kBAAApK,EAAAqK,sBAKA,IAAAF,EAAA,CACA,GAAAxY,GAAA,EACA2Y,EAAA,GAAAH,GAAA/X,GACAqD,EAAAuK,EAAAuK,SAAAC,eAAA,GACAF,GAAAG,QAAAhV,GACAiV,eAAA,IAEAR,EAAA,WACAzU,EAAArH,KAAAuD,MAAA,OAEG,IAAAqO,EAAA2K,cAAA,mBAAA3K,GAAA4K,eAOHV,EADG,YAAAlK,IAAA,sBAAAA,GAAAuK,SAAAM,cAAA,UACH,WAIA,GAAAC,GAAA9K,EAAAuK,SAAAM,cAAA,SACAC,GAAAC,mBAAA,WACA3Y,IAEA0Y,EAAAC,mBAAA,KACAD,EAAAE,WAAAC,YAAAH,GACAA,EAAA,MAEA9K,EAAAuK,SAAAW,gBAAAC,YAAAL,IAGA,WACAhU,WAAA1E,EAAA,QAvBG,CACH,GAAAgZ,GAAA,GAAApL,GAAA4K,cACAQ,GAAAC,MAAAC,UAAAlZ,EACA8X,EAAA,WACAkB,EAAAG,MAAAC,YAAA,IAwBA,GAAA/N,GACAE,IAkBAxV,GAAAD,QAAA8hB,IdgvE8BnhB,KAAKX,EAAU,WAAa,MAAOI,WAI3D,SAASH,EAAQD,GenzEvB,kBAAAgB,QAAAyB,OAEAxC,EAAAD,QAAA,SAAAujB,EAAAC,GACAD,EAAAE,OAAAD,EACAD,EAAAtiB,UAAAD,OAAAyB,OAAA+gB,EAAAviB,WACAyB,aACAC,MAAA4gB,EACA3gB,YAAA,EACAC,UAAA,EACAC,cAAA,MAMA7C,EAAAD,QAAA,SAAAujB,EAAAC,GACAD,EAAAE,OAAAD,CACA,IAAAE,GAAA,YACAA,GAAAziB,UAAAuiB,EAAAviB,UACAsiB,EAAAtiB,UAAA,GAAAyiB,GACAH,EAAAtiB,UAAAyB,YAAA6gB,If4zEM,SAAStjB,EAAQD,EAASM,IgBh1EhC,SAAAgJ,GAAA,YAEAtJ,GAAAuE,QAAAjE,EAAA,IAEAN,EAAA0K,SAAApK,EAAA,IACAN,EAAA4K,OAAAtK,EAAA,GACA,IAAAqjB,GAAArjB,EAAA,GAGAN,GAAA+K,iBAAA,SAAAZ,EAAAG,GAYA,MAXAA,IACAH,EAAA1G,KAAA,SAAAQ,GACAqF,EAAAY,SAAA,WACAI,EAAA,KAAArG,MAEK,SAAA6E,GACLQ,EAAAY,SAAA,WACAI,EAAAxB,OAIAqB,GAIAnK,EAAA6K,YAAA,SAAArB,GACA,MAAAma,GAAA,SAAAviB,GACA,GAAA0J,GAAA1J,EAAA6I,MACAE,EAAAX,EAAA/H,MAAArB,KAAAgB,EAIA,OAHA,kBAAA0J,IACA9K,EAAA+K,iBAAAZ,EAAAW,GAEAX,KAMAnK,EAAA4jB,IAAA,SAAAzZ,EAAAW,GACA,MAAAX,GAAA1G,KAAA,SAAAQ,GACA,GAAA4f,GAAA/Y,GACA,yBAAA+Y,GAAApgB,KACAogB,EAAApgB,KAAA,WACA,MAAAQ,KAGAA,GACG,SAAA6E,GACH,GAAA+a,GAAA/Y,GACA,sBAAA+Y,GAAApgB,KACA,MAAAogB,GAAApgB,KAAA,WACA,KAAAqF,IAGA,MAAAA,MAIA9I,EAAA8jB,cAAA,SAAArO,EAAAsO,GACA,kBACA,GAAA3iB,GAAAiC,UACA2gB,EAAA5jB,IACA,OAAAqV,GAAAwO,IAAA,WACA,MAAAF,GAAAtiB,MAAAuiB,EAAA5iB,OAKApB,EAAAyL,QAAA,SAAAyY,GAEA,OADAjgB,MACAlD,EAAA,EAAA6I,EAAAsa,EAAA5gB,OAAoCvC,EAAA6I,EAAS7I,IAC7CkD,IAAAvC,OAAAwiB,EAAAnjB,GAEA,OAAAkD,IAKAjE,EAAA4N,KAAA,SAAA9F,GAGA,OAFAgG,MAEA/M,EAAA,EAAA6I,EAAA9B,EAAAxE,OAAmCvC,EAAA6I,EAAS7I,IAC5C+M,EAAA,IAAAhG,EAAA/G,KAAA,CAGA,IAAA8M,GAAA7M,OAAA6M,KAAAC,GACAqW,EAAA,GAAAzb,OAAAmF,EAAAvK,OAEA,KAAAvC,EAAA,EAAA6I,EAAAiE,EAAAvK,OAAgCvC,EAAA6I,EAAS7I,IACzCojB,EAAApjB,GAAA8M,EAAA9M,GAAAwL,UAAA,EAEA,OAAA4X,GAGA,IAAAnZ,GAAA1K,EAAA,IACA2K,EAAA3K,EAAA,GAEAN,GAAAkL,IAAA,SAAAC,GAEA,MAAA7B,GAAA8B,QAGAH,EAAAI,KAAAF,GAFAH,EAAAM,WAAA,OAAAC,OAAAJ,GAAAK,OAAA,UhBu1E8B7K,KAAKX,EAASM,EAAoB,KAI1D,SAASL,EAAQD,EAASM,GiB/7EhC,YAkBA,SAAA8jB,GAAAhY,EAAAuK,GACA,gBAAA9K,GAEA,OADAwY,MACAtjB,EAAA,EAAAujB,EAAAlY,EAAA9I,OAAyCvC,EAAAujB,EAAUvjB,IAAA,CAGnD,OAFA+K,GAAAI,EAAAE,EAAArL,IACA4B,EAAAkJ,EACA0Y,EAAA,EAAAC,EAAA1Y,EAAAxI,OAAgDihB,EAAAC,EAAUD,IAAA,CAC1D,GAAAxY,GAAAD,EAAAyY,EAEA,IADA5hB,IAAAoJ,IACApJ,EACA,MAGA0hB,EAAA5b,KAAA9F,GAEAgU,EAAA0N,IAIA,QAAAI,GAAAzX,EAAA2J,GACA,GAAA7K,GAAAI,EAAAc,EACA,iBAAAnB,GAEA,OADAlJ,GAAAkJ,EACA9K,EAAA,EAAA6I,EAAAkC,EAAAxI,OAA6CvC,EAAA6I,EAAS7I,IAAA,CACtD,GAAAgL,GAAAD,EAAA/K,EAEA,IADA4B,IAAAoJ,IACApJ,EACA,OAGAgU,EAAAhU,IAIA,QAAA+hB,GAAA1X,EAAA2J,GACA,gBAAA9K,GACA8K,EAAA9K,EAAAmB,KAIA,QAAA2X,GAAAvY,EAAAuK,GACA,gBAAA9K,GAEA,OADAwY,MACAtjB,EAAA,EAAA6I,EAAAwC,EAAA9I,OAAwCvC,EAAA6I,EAAS7I,IACjDsjB,EAAA5b,KAAAoD,EAAAO,EAAArL,IAEA4V,GAAA0N,IAIA,QAAAO,GAAAxY,GACA,OAAArL,GAAA,EAAA6I,EAAAwC,EAAA9I,OAAsCvC,EAAA6I,EAAS7I,IAAA,CAC/C,GAAAiM,GAAAZ,EAAArL,EACA,IAAAiM,EAAA3G,QAAA,UACA,SAGA,SAGA,QAAAwe,GAAAzY,EAAAuK,GACA,GAAAmO,GAAAF,EAAAxY,GACA2Y,EAAA,IAAA3Y,EAAA9I,MAIA,OAAAwhB,GACAC,EACAL,EAAAtY,EAAA,GAAAuK,GAEAgO,EAAAvY,EAAAuK,GAGAoO,EACAN,EAAArY,EAAA,GAAAuK,GAEAyN,EAAAhY,EAAAuK,GAKA,QAAAqO,GAAAC,EAAAtO,GAGA,GAAAvK,GAAApL,OAAA6M,KAAAoX,EAAA7Y,OAEA,OAAAyY,GAAAzY,EAAAuK,GAIA,QAAAuO,KACA,SAAAte,OAAA,wBAGA,QAAAue,GAAAC,EAAAC,GACA,GAAAC,GAAAF,EAAAG,MAAAF,EAIA,KAAAC,EAAAxX,MAAAwX,EAAAxX,IAAA1B,OACA,SAAAxF,OAAA,QAAAwe,EAAAI,IAAA,cAAAH,EACA,6EArHA,GAAAI,GAAAnlB,EAAA,GACAolB,EAAAplB,EAAA,IACA4L,EAAAuZ,EAAAvZ,WAwHAyZ,EAAAD,GACAxc,KAAA,UACA8b,SACAE,UACAC,iBAGAllB,GAAAD,QAAA2lB,GjBq8EM,SAAS1lB,EAAQD,GkBxkFvB,YAIA,SAAA4lB,GAAApc,GACA,kBACA,GAAAI,GAAAvG,UAAAC,MACA,IAAAsG,EAAA,CAGA,IAFA,GAAAxI,MACAL,GAAA,IACAA,EAAA6I,GACAxI,EAAAL,GAAAsC,UAAAtC,EAEA,OAAAyI,GAAA7I,KAAAP,KAAAgB,GAEA,MAAAoI,GAAA7I,KAAAP,UAbAH,EAAAD,QAAA4lB,GlB8lFM,SAAS3lB,EAAQD,GAEtB,YmBlmFD,SAAS6lB,GAAUha,GACjB,MAAOA,GAAIia,KAAO,IAAMja,EAAIpL,GAG9B,QAASslB,GAAWC,EAAWC,GAC7B,MAAOD,GAAUH,EAASI,IAG5B,QAASC,GAAgBC,EAAaH,EAAWI,GAC/C,GAAIC,IACFb,IAAKW,EAAY1lB,GACjB6lB,MAAOH,EAAYL,KACnBS,KAAOJ,EAAYK,MAAQL,EAAYK,KAAKC,IAC5CL,MAAOplB,OAAO+d,UAAWoH,EAAYC,MAAOA,GAC5CM,WAAYP,EAAYO,WACxBC,UAAW,SAACzd,GACV,GAAI0d,GAAOT,EAAYU,cAAc3d,EACrC,IAAa3F,SAATqjB,GAAoCrjB,SAAdqjB,EAAK1gB,KAC/B,MAAkB,QAAd0gB,EAAK1gB,KAAsB,KAC1BwC,MAAMC,QAAQie,EAAK1gB,MACjB0gB,EAAK1gB,KAAK4H,IAAI,SAAAmY,GAAA,MAAOF,GAAUC,EAAWC,KADXF,EAAUC,EAAWY,EAAK1gB,OAUpE,OANIigB,GAAYU,gBACdR,EAASQ,cAAgBV,EAAYU,eAGvCb,EAAUH,EAASM,IAAgBE,EAE5BA,EAGT,QAASS,GAAgBjb,GAAqB,GAAhBma,GAAgB3iB,UAAAC,OAAA,GAAAC,SAAAF,UAAA,GAAAA,UAAA,MAEtC0jB,EAAWlb,EAAIkb,QAMrB,OAJIre,OAAMC,QAAQoe,IAChBA,EAAS9U,QAAQ,SAAC+U,GAAD,MAAOd,GAAec,EAAGhB,EAAWna,EAAIua,SAGvD1d,MAAMC,QAAQkD,EAAI3F,MACb2F,EAAI3F,KAAK4H,IAAI,SAACkZ,GAAD,MAAOd,GAAec,EAAGhB,EAAWna,EAAIua,SAErDF,EAAera,EAAI3F,KAAM8f,EAAWna,EAAIua,OnByjFlDplB,OAAO4G,eAAe5H,EAAS,cAC7B2C,OAAO,IAyDT3C,EAAQ8B,QmB/mFMglB,GnBmnFT,SAAS7mB,EAAQD,GoBlqFvB,GAAAinB,GAAAhnB,EAAAD,SAA6BoW,QAAA,QAC7B,iBAAA8Q,WAAAD,IpByqFM,SAAShnB,EAAQD,GqBzqFvBC,EAAAD,QAAA,SAAA4hB,GACA,GAAAre,QAAAqe,EAAA,KAAA1f,WAAA,yBAAA0f,EACA,OAAAA,KrBkrFM,SAAS3hB,EAAQD,GsBrrFvB,GAAAkB,MAAuBA,cACvBjB,GAAAD,QAAA,SAAA4hB,EAAA7V,GACA,MAAA7K,GAAAP,KAAAihB,EAAA7V;GtB6rFM,SAAS9L,EAAQD,EAASM,GuB/rFhC,GAAA6mB,GAAA7mB,EAAA,IACA8mB,EAAA9mB,EAAA,GACAL,GAAAD,QAAAM,EAAA,aAAA+mB,EAAAtb,EAAApJ,GACA,MAAAwkB,GAAAG,EAAAD,EAAAtb,EAAAqb,EAAA,EAAAzkB,KACC,SAAA0kB,EAAAtb,EAAApJ,GAED,MADA0kB,GAAAtb,GAAApJ,EACA0kB,IvBusFM,SAASpnB,EAAQD,EAASM,GwB5sFhC,GAAAinB,GAAAjnB,EAAA,GAEAL,GAAAD,QAAAgB,OAAA,KAAAwmB,qBAAA,GAAAxmB,OAAA,SAAA4gB,GACA,gBAAA2F,EAAA3F,KAAApR,MAAA,IAAAxP,OAAA4gB,KxBqtFM,SAAS3hB,EAAQD,GyBxtFvB,GAAAynB,GAAA7a,KAAA6a,KACAlI,EAAA3S,KAAA2S,KACAtf,GAAAD,QAAA,SAAA4hB,GACA,MAAAhH,OAAAgH,MAAA,GAAAA,EAAA,EAAArC,EAAAkI,GAAA7F,KzBiuFM,SAAS3hB,EAAQD,EAASM,G0BpuFhC,GAAAonB,GAAApnB,EAAA,IACAqnB,EAAArnB,EAAA,GACAL,GAAAD,QAAA,SAAA4hB,GACA,MAAA8F,GAAAC,EAAA/F,M1B6uFM,SAAS3hB,EAAQD,G2BjvFvB,GAAAS,GAAA,EACAmnB,EAAAhb,KAAA2C,QACAtP,GAAAD,QAAA,SAAA+L,GACA,gBAAArK,OAAA6B,SAAAwI,EAAA,GAAAA,EAAA,QAAAtL,EAAAmnB,GAAAzN,SAAA,O3ByvFM,SAASla,EAAQD,EAASM,I4B5vFhC,SAAAgJ,GAsCA,QAAAue,KAIA,2BAAA7gB,kBAAA,mBAAAA,QAAAsC,SAAA,aAAAtC,OAAAsC,QAAAwc,QAMA,mBAAAzD,qBAAA,oBAAAA,UAAAW,gBAAA8E,OAEA,mBAAA9gB,wBAAAU,kBAAAqgB,SAAArgB,QAAAsgB,WAAAtgB,QAAAugB,QAGA,mBAAA3Z,iCAAA4Z,WAAA5Z,UAAA4Z,UAAAC,cAAAC,MAAA,mBAAArP,SAAAsP,OAAAC,GAAA,SAEA,mBAAAha,iCAAA4Z,WAAA5Z,UAAA4Z,UAAAC,cAAAC,MAAA,uBAsBA,QAAAG,GAAAnnB,GACA,GAAAymB,GAAAznB,KAAAynB,SASA,IAPAzmB,EAAA,IAAAymB,EAAA,SACAznB,KAAAooB,WACAX,EAAA,WACAzmB,EAAA,IACAymB,EAAA,WACA,IAAA7nB,EAAAyoB,SAAAroB,KAAAsoB,MAEAb,EAAA,CAEA,GAAAhnB,GAAA,UAAAT,KAAAuoB,KACAvnB,GAAA8L,OAAA,IAAArM,EAAA,iBAKA,IAAA8R,GAAA,EACAiW,EAAA,CACAxnB,GAAA,GAAAiG,QAAA,uBAAA+gB,GACA,OAAAA,IACAzV,IACA,OAAAyV,IAGAQ,EAAAjW,MAIAvR,EAAA8L,OAAA0b,EAAA,EAAA/nB,IAUA,QAAAkN,KAGA,sBAAArG,UACAA,QAAAqG,KACAgK,SAAA9W,UAAAQ,MAAAd,KAAA+G,QAAAqG,IAAArG,QAAArE,WAUA,QAAA+a,GAAAyK,GACA,IACA,MAAAA,EACA7oB,EAAA6d,QAAAiL,WAAA,SAEA9oB,EAAA6d,QAAAkL,MAAAF,EAEG,MAAAphB,KAUH,QAAA8W,KACA,IACA,MAAAve,GAAA6d,QAAAkL,MACG,MAAAthB,IAGH,sBAAA6B,IAAA,OAAAA,GACA,MAAAA,GAAA4M,IAAA8S,MAqBA,QAAAC,KACA,IACA,MAAAjiB,QAAAkiB,aACG,MAAAzhB,KA9KHzH,EAAAC,EAAAD,QAAAM,EAAA,IACAN,EAAA+N,MACA/N,EAAAuoB,aACAvoB,EAAAoe,OACApe,EAAAue,OACAve,EAAA6nB,YACA7nB,EAAA6d,QAAA,mBAAAsL,SACA,mBAAAA,QAAAtL,QACAsL,OAAAtL,QAAAuL,MACAH,IAMAjpB,EAAAqpB,QACA,gBACA,cACA,YACA,aACA,aACA,WAmCArpB,EAAAspB,WAAA/E,EAAA,SAAAgF,GACA,IACA,MAAAzjB,MAAAC,UAAAwjB,GACG,MAAA/iB,GACH,qCAAAA,EAAA2C,UAkGAnJ,EAAAwpB,OAAAjL,O5BixF8B5d,KAAKX,EAASM,EAAoB,KAI1D,SAASL,EAAQD,EAASM,I6Bz7FhC,SAAAgJ,GAAA,YAIA,SAAAmgB,MAeA,QAAAllB,GAAAmlB,GACA,qBAAAA,GACA,SAAAxnB,WAAA,8BAEA9B,MAAAyc,MAAA8M,EACAvpB,KAAAqV,SACArV,KAAAwpB,QAAA,OAEAtgB,EAAA8B,UACAhL,KAAAypB,QAAAC,GAEAJ,IAAAD,GACAM,EAAA3pB,KAAAspB,GA4BA,QAAAM,GAAA7f,EAAA8f,EAAAC,GACA9pB,KAAA+J,UACA,kBAAA8f,KACA7pB,KAAA6pB,cACA7pB,KAAA+pB,cAAA/pB,KAAAgqB,oBAEA,kBAAAF,KACA9pB,KAAA8pB,aACA9pB,KAAAiqB,aAAAjqB,KAAAkqB,mBAgBA,QAAAC,GAAApgB,EAAAL,EAAAnH,GACAmf,EAAA,WACA,GAAA0I,EACA,KACAA,EAAA1gB,EAAAnH,GACK,MAAA8E,GACL,MAAAgjB,GAAApgB,OAAAF,EAAA1C,GAEA+iB,IAAArgB,EACAsgB,EAAApgB,OAAAF,EAAA,GAAAjI,WAAA,uCAEAuoB,EAAA9b,QAAAxE,EAAAqgB,KA8CA,QAAAE,GAAA9oB,GAEA,GAAA6B,GAAA7B,KAAA6B,IACA,IAAA7B,GAAA,gBAAAA,IAAA,kBAAA6B,GACA,kBACAA,EAAAhC,MAAAG,EAAAyB,YAKA,QAAA0mB,GAAA3nB,EAAAuoB,GAGA,QAAAC,GAAAjoB,GACA8G,IAGAA,GAAA,EACAghB,EAAApgB,OAAAjI,EAAAO,IAGA,QAAAkoB,GAAAloB,GACA8G,IAGAA,GAAA,EACAghB,EAAA9b,QAAAvM,EAAAO,IAGA,QAAAmoB,KACAH,EAAAE,EAAAD,GAlBA,GAAAnhB,IAAA,EAqBAe,EAAAugB,EAAAD,EACA,WAAAtgB,EAAA3F,QACA+lB,EAAApgB,EAAA7H,OAIA,QAAAooB,GAAAjhB,EAAAnH,GACA,GAAAqoB,KACA,KACAA,EAAAroB,MAAAmH,EAAAnH,GACAqoB,EAAAnmB,OAAA,UACG,MAAA4C,GACHujB,EAAAnmB,OAAA,QACAmmB,EAAAroB,MAAA8E,EAEA,MAAAujB,GAIA,QAAArc,GAAAhM,GACA,MAAAA,aAAAvC,MACAuC,EAEA8nB,EAAA9b,QAAA,GAAAvO,MAAAqpB,GAAA9mB,GAIA,QAAA0H,GAAAvB,GACA,GAAAqB,GAAA,GAAA/J,MAAAqpB,EACA,OAAAgB,GAAApgB,OAAAF,EAAArB,GAIA,QAAAtE,GAAAymB,GAqBA,QAAAC,GAAAvoB,EAAA5B,GAOA,QAAAoqB,GAAAC,GACAC,EAAAtqB,GAAAqqB,IACAE,IAAA1hB,GAAAH,IACAA,GAAA,EACAghB,EAAA9b,QAAAxE,EAAAkhB,IAVAjpB,EAAAuM,QAAAhM,GAAAc,KAAA0nB,EAAA,SAAA1kB,GACAgD,IACAA,GAAA,EACAghB,EAAApgB,OAAAF,EAAA1D,MAxBA,GAAArE,GAAAhC,IACA,uBAAAY,OAAAC,UAAAkZ,SAAAxZ,KAAAsqB,GACA,MAAA7qB,MAAAiK,OAAA,GAAAnI,WAAA,oBAGA,IAAA0H,GAAAqhB,EAAA3nB,OACAmG,GAAA,CACA,KAAAG,EACA,MAAAxJ,MAAAuO,WAQA,KALA,GAAA0c,GAAA,GAAA3iB,OAAAkB,GACA0hB,EAAA,EACAvqB,GAAA,EACAoJ,EAAA,GAAA/J,MAAAqpB,KAEA1oB,EAAA6I,GACAshB,EAAAD,EAAAlqB,KAEA,OAAAoJ,GAmBA,QAAAohB,GAAAN,GAmBA,QAAAvB,GAAA/mB,GACAP,EAAAuM,QAAAhM,GAAAc,KAAA,SAAAkC,GACA8D,IACAA,GAAA,EACAghB,EAAA9b,QAAAxE,EAAAxE,KAEK,SAAAc,GACLgD,IACAA,GAAA,EACAghB,EAAApgB,OAAAF,EAAA1D,MA3BA,GAAArE,GAAAhC,IACA,uBAAAY,OAAAC,UAAAkZ,SAAAxZ,KAAAsqB,GACA,MAAA7qB,MAAAiK,OAAA,GAAAnI,WAAA,oBAGA,IAAA0H,GAAAqhB,EAAA3nB,OACAmG,GAAA,CACA,KAAAG,EACA,MAAAxJ,MAAAuO,WAMA,KAHA,GAAA5N,IAAA,EACAoJ,EAAA,GAAA/J,MAAAqpB,KAEA1oB,EAAA6I,GACA8f,EAAAuB,EAAAlqB,GAEA,OAAAoJ,GAtQA,GAAA2X,GAAAxhB,EAAA,IAKAmqB,KAEAe,GAAA,YACAC,GAAA,aACA9B,GAAA,UAEA,KAAArgB,EAAA8B,QAEA,GAAA0e,IAAA,YAGA7pB,GAAAD,QAAAuE,EAkBAA,EAAAtD,UAAAiO,MAAA,SAAAgb,GACA,MAAA9pB,MAAAqD,KAAA,KAAAymB,IAEA3lB,EAAAtD,UAAAwC,KAAA,SAAAwmB,EAAAC,GACA,qBAAAD,IAAA7pB,KAAAyc,QAAA4O,GACA,kBAAAvB,IAAA9pB,KAAAyc,QAAA2O,EACA,MAAAprB,KAEA,IAAA+J,GAAA,GAAA/J,MAAAsC,YAAA+mB,EAOA,IALAngB,EAAA8B,SACAhL,KAAAypB,UAAAC,IACA1pB,KAAAypB,QAAA,MAGAzpB,KAAAyc,QAAA8M,EAAA,CACA,GAAAD,GAAAtpB,KAAAyc,QAAA4O,EAAAxB,EAAAC,CACAK,GAAApgB,EAAAuf,EAAAtpB,KAAAwpB,aAEAxpB,MAAAqV,MAAAhN,KAAA,GAAAuhB,GAAA7f,EAAA8f,EAAAC,GAGA,OAAA/f,IAaA6f,EAAA/oB,UAAAkpB,cAAA,SAAAxnB,GACA8nB,EAAA9b,QAAAvO,KAAA+J,QAAAxH,IAEAqnB,EAAA/oB,UAAAmpB,mBAAA,SAAAznB,GACA4nB,EAAAnqB,KAAA+J,QAAA/J,KAAA6pB,YAAAtnB,IAEAqnB,EAAA/oB,UAAAopB,aAAA,SAAA1nB,GACA8nB,EAAApgB,OAAAjK,KAAA+J,QAAAxH,IAEAqnB,EAAA/oB,UAAAqpB,kBAAA,SAAA3nB,GACA4nB,EAAAnqB,KAAA+J,QAAA/J,KAAA8pB,WAAAvnB,IAmBA8nB,EAAA9b,QAAA,SAAAvM,EAAAO,GACA,GAAA6H,GAAAugB,EAAAL,EAAA/nB,EACA,cAAA6H,EAAA3F,OACA,MAAA4lB,GAAApgB,OAAAjI,EAAAoI,EAAA7H,MAEA,IAAAgoB,GAAAngB,EAAA7H,KAEA,IAAAgoB,EACAZ,EAAA3nB,EAAAuoB,OACG,CACHvoB,EAAAya,MAAA4O,EACArpB,EAAAwnB,QAAAjnB,CAGA,KAFA,GAAA5B,IAAA,EACA6I,EAAAxH,EAAAqT,MAAAnS,SACAvC,EAAA6I,GACAxH,EAAAqT,MAAA1U,GAAAopB,cAAAxnB,GAGA,MAAAP,IAEAqoB,EAAApgB,OAAA,SAAAjI,EAAAqE,GACArE,EAAAya,MAAA2O,EACAppB,EAAAwnB,QAAAnjB,EAEA6C,EAAA8B,SACAhJ,EAAAynB,UAAAC,GACAhI,EAAA,WACA1f,EAAAynB,UAAAC,GACAxgB,EAAAqN,KAAA,qBAAAlQ,EAAArE,IAOA,KAFA,GAAArB,IAAA,EACA6I,EAAAxH,EAAAqT,MAAAnS,SACAvC,EAAA6I,GACAxH,EAAAqT,MAAA1U,GAAAspB,aAAA5jB,EAEA,OAAArE,IAsDAmC,EAAAoK,UAQApK,EAAA8F,SAMA9F,EAAAC,MAuCAD,EAAAgnB,S7B89F8B5qB,KAAKX,EAASM,EAAoB,KAI1D,SAASL,EAAQD,G8BttGvB,YAmBA,SAAA8lB,GAAAlkB,GACA,cAAAA,EACA6d,OAAA7d,GAEA,gBAAAA,IAAA,kBAAAA,GACA8pB,EAAAC,EAAAhrB,KAAAiB,KAAA,eACAA,GAGA,QAAAgqB,GAAAhqB,GACA,cAAAA,SAAAoF,OAGA,QAAA6kB,GAAAjqB,GAKA,IAAAA,GAAA,WAAAkkB,EAAAlkB,MAAAkqB,UAAAF,EAAAhqB,GACA,QAGA,KAEA,GAAAA,EAAAc,cACAqpB,EAAAprB,KAAAiB,EAAA,iBACAmqB,EAAAprB,KAAAiB,EAAAc,YAAAzB,UAAA,iBACA,SAEG,MAAAwG,GAEH,SAKA,GAAAsE,EACA,KAAAA,IAAAnK,IAEA,MAAA2B,UAAAwI,GAAAggB,EAAAprB,KAAAiB,EAAAmK,GAIA,QAAAigB,GAAApqB,GACA,mBAAAkkB,EAAAlkB,GAOA,QAAAgJ,KAQA,IAJA,GAAAsO,MACAnY,GAAA,EACA6I,EAAAvG,UAAAC,OACAlC,EAAA,GAAAsH,OAAAkB,KACA7I,EAAA6I,GACAxI,EAAAL,GAAAsC,UAAAtC,EAEA,IAAAkrB,KACA/S,GAAAzQ,MAAcrH,OAAAoJ,QAAqByhB,YAAAlgB,IAAA,QAEnC,KADA,GAAAxD,GACAA,EAAA2Q,EAAAjP,OACAiiB,EAAAhT,EAAA3Q,EAAAnH,KAAAmH,EAAAiC,OAEA,OAAAyhB,GAAAlgB,IAGA,QAAAmgB,GAAAhT,EAAA9X,EAAAoJ,GACA,GAAApH,GAAA8F,EAAAijB,EAAAC,EAAAC,EAAA1hB,EAMA2hB,EALAxM,EAAA1e,EAAA,OACAL,EAAA,EACAuC,EAAAlC,EAAAkC,OACAipB,GAAA,EACAC,EAAA,KAuBA,KAnBA,iBAAA1M,KACAyM,EAAAzM,EACAA,EAAA1e,EAAA,OAEAL,EAAA,GAIA,gBAAA+e,IAAAkM,EAAAlM,KACAA,MAIAxc,IAAAvC,IAEA+e,EAAA1f,OACAW,GAGQA,EAAAuC,EAAYvC,IAEpB,UAAAqC,EAAAhC,EAAAL,IAAA,CACAurB,EAAA3jB,EAAAvF,EAEA,KAAA8F,IAAA9F,GAEA,KAAA8F,IAAAlI,QAAAC,WAAA,CACA,GAAAqrB,IAAAE,EAAAC,KAAAvjB,GACA,QAOA,IAJAijB,EAAArM,EAAA5W,GACAkjB,EAAAhpB,EAAA8F,GAGA4W,IAAAsM,EACA,QAIAG,IAAAH,IAAAP,EAAAO,KACAC,EAAA1jB,EAAAyjB,MACAC,GACAA,GAAA,EACA1hB,EAAAwhB,GAAAxjB,EAAAwjB,SAGAxhB,EAAAwhB,GAAAN,EAAAM,QAIAjT,EAAAzQ,MACArH,MAAAmrB,EAAA5hB,EAAAyhB,GACA5hB,QACAyhB,UAAAnM,EACA/T,IAAA7C,MAKW3F,SAAA6oB,IACXzjB,EAAAvF,IAAA4oB,EAAAI,KACAtM,EAAA5W,GAAAkjB,KAUA5hB,EAAAyhB,UAAAzhB,EAAAuB,KAAA+T,EAjKA,OANA4L,MAEAgB,GACA,+CACA,kCAEA3rB,EAAA,EAAeA,EAAA2rB,EAAAppB,OAAkBvC,IAAA,CACjC,GAAA4rB,GAAAD,EAAA3rB,EACA2qB,GAAA,WAAAiB,EAAA,KAAAA,EAAAxE,cAGA,GAAAwD,GAAAD,EAAAvR,SACA4R,EAAAL,EAAAxqB,eAiDAyH,EAAAD,MAAAC,SAAA,SAAA/G,GACA,gBAAAkkB,EAAAlkB,GA6GA3B,GAAAD,QAAA4K,G9B+tGM,SAAS3K,EAAQD,EAASM,G+B/4GhC,YAEA,IAAAssB,GAAAtsB,EAAA,IAAAssB,MAEA3sB,GAAAD,QAAA,SAAA6sB,EAAAhhB,EAAAihB,GACA,MAAAF,GAAAnrB,MAAAorB,GAAAhhB,EAAAihB,M/Bs5GM,SAAS7sB,EAAQD,EAASM,GgC35GhC,YAOA,SAAAysB,GAAAF,GAGA,MAAAA,GAAAG,SACAxZ,SAAA,WACAC,OAAA,YACAwZ,cAAA,IACGxpB,KAAA,SAAAypB,GACH,GAAAjpB,IACAkpB,UACA/H,KAAA,KACAlc,KAAA,YACA4c,KAAA,UACAlT,KACAxG,SAAoBoZ,IAAA,WA0BpB,OArBAvhB,GAAAkpB,QAAA7a,EAAA7G,QAAAxH,EAAAkpB,QAAAD,EAAApa,KAAAgB,OAAA,SAAAb,GACA,gBAAAA,EAAApH,IAAAuhB,WACKtf,IAAA,SAAAmF,GACL,GAAAoa,GAAA9pB,SAAA0P,EAAApH,IAAA0Z,MAAAvkB,OAAA6M,KAAAoF,EAAApH,IAAA0Z,SAEA,OAAA8H,GAAAvf,IAAA,SAAAuX,GACA,GAAAC,GAAArS,EAAApH,IAAA0Z,MAAAF,EACA,QACAD,KAAAnS,EAAAxS,GACAyI,KAAAmc,EACAS,KAAA,OACAlT,IAAAJ,EAAA8S,EAAAliB,QAAAwP,WAMA3O,EAAAkpB,QAAApc,KAAA,SAAArE,EAAAC,GACA,MAAA2F,GAAAnF,QAAAT,EAAAxD,KAAAyD,EAAAzD,QAEAjF,EAAAqpB,WAAArpB,EAAAkpB,QAAA7pB,OACAW,IA7CA,GAAAqO,GAAAhS,EAAA,GAEAmlB,EAAAnlB,EAAA,GACAkS,EAAAiT,EAAAjT,eA8CAvS,GAAAD,QAAA+sB,GhCk6GM,SAAS9sB,EAAQD,EAASM,GiCr9GhC,YAEA,IAAAgS,GAAAhS,EAAA,GACAqK,EAAA2H,EAAA3H,KAMA1K,GAAAD,QAAA,SAAAgU,GAsBA,MArBAA,GAAArJ,EAAAqJ,GAEAA,EAAArB,QACAqB,EAAArB,WAGA,sBAAAV,QAAA,SAAAlG,GACAiI,EAAArB,MAAA5G,KACAiI,EAAAjI,GAAAiI,EAAArB,MAAA5G,SACAiI,GAAArB,MAAA5G,MAIAiI,EAAA5H,SACA4H,EAAArB,MAAAvG,OAAA4H,EAAA5H,aACA4H,GAAA5H,QAGA4H,EAAA8R,OACA9R,EAAA8R,KAAA,QAEA9R,IjC49GM,SAAS/T,EAAQD,EAASM,GkC3/GhC,YAEA,SAAAitB,GAAAC,GAA+B,MAAAA,IAAA,gBAAAA,IAAA,WAAAA,KAAA,QAAAA,EAE/B,GAAAC,GAAAF,EAAAjtB,EAAA,KAGAotB,EAAA,kBAAAnpB,iBAAAkpB,CAEAxtB,GAAAD,QAAA0tB,GlCigHM,SAASztB,EAAQD,EAASM,ImCvgHhC,SAAAP,GAGAE,EAAAD,QAAAD,KAeC,SAAAwD,GAED,YAiBA,IAAAoqB,GAAA,SAAApsB,EAAAC,GACA,MAAAD,GAAAC,EAAA,YAGAosB,EAAA,SAAA5d,EAAAzO,EAAAC,EAAAoY,EAAAiU,EAAAjP,GAEA,MADArd,GAAAosB,IAAApsB,EAAAyO,GAAA2d,EAAA/T,EAAAgF,IACA+O,EAAApsB,GAAAssB,EAAAtsB,IAAA,GAAAssB,EAAArsB,IAGAssB,EAAA,SAAAvsB,EAAAC,EAAAX,EAAAktB,EAAAnU,EAAAiU,EAAAjP,GACA,MAAAgP,GAAApsB,EAAAX,GAAAW,EAAAusB,EAAAxsB,EAAAC,EAAAoY,EAAAiU,EAAAjP,IAGAoP,EAAA,SAAAzsB,EAAAC,EAAAX,EAAAktB,EAAAnU,EAAAiU,EAAAjP,GACA,MAAAgP,GAAApsB,EAAAusB,EAAAltB,GAAAktB,EAAAxsB,EAAAC,EAAAoY,EAAAiU,EAAAjP,IAGAqP,EAAA,SAAA1sB,EAAAC,EAAAX,EAAAktB,EAAAnU,EAAAiU,EAAAjP,GACA,MAAAgP,GAAApsB,EAAAX,EAAAktB,EAAAxsB,EAAAC,EAAAoY,EAAAiU,EAAAjP,IAGAsP,EAAA,SAAA3sB,EAAAC,EAAAX,EAAAktB,EAAAnU,EAAAiU,EAAAjP,GACA,MAAAgP,GAAA/sB,GAAAW,GAAAusB,GAAAxsB,EAAAC,EAAAoY,EAAAiU,EAAAjP,IAGAuP,EAAA,SAAAvU,EAAA/B,GACA,GAAAtW,GAAAqY,EAAA,GACApY,EAAAoY,EAAA,GACA/Y,EAAA+Y,EAAA,GACAmU,EAAAnU,EAAA,EAEArY,GAAAusB,EAAAvsB,EAAAC,EAAAX,EAAAktB,EAAAlW,EAAA,iBACAkW,EAAAD,EAAAC,EAAAxsB,EAAAC,EAAAX,EAAAgX,EAAA,kBACAhX,EAAAitB,EAAAjtB,EAAAktB,EAAAxsB,EAAAC,EAAAqW,EAAA,iBACArW,EAAAssB,EAAAtsB,EAAAX,EAAAktB,EAAAxsB,EAAAsW,EAAA,mBACAtW,EAAAusB,EAAAvsB,EAAAC,EAAAX,EAAAktB,EAAAlW,EAAA,iBACAkW,EAAAD,EAAAC,EAAAxsB,EAAAC,EAAAX,EAAAgX,EAAA,kBACAhX,EAAAitB,EAAAjtB,EAAAktB,EAAAxsB,EAAAC,EAAAqW,EAAA,mBACArW,EAAAssB,EAAAtsB,EAAAX,EAAAktB,EAAAxsB,EAAAsW,EAAA,iBACAtW,EAAAusB,EAAAvsB,EAAAC,EAAAX,EAAAktB,EAAAlW,EAAA,iBACAkW,EAAAD,EAAAC,EAAAxsB,EAAAC,EAAAX,EAAAgX,EAAA,mBACAhX,EAAAitB,EAAAjtB,EAAAktB,EAAAxsB,EAAAC,EAAAqW,EAAA,eACArW,EAAAssB,EAAAtsB,EAAAX,EAAAktB,EAAAxsB,EAAAsW,EAAA,oBACAtW,EAAAusB,EAAAvsB,EAAAC,EAAAX,EAAAktB,EAAAlW,EAAA,kBACAkW,EAAAD,EAAAC,EAAAxsB,EAAAC,EAAAX,EAAAgX,EAAA,kBACAhX,EAAAitB,EAAAjtB,EAAAktB,EAAAxsB,EAAAC,EAAAqW,EAAA,oBACArW,EAAAssB,EAAAtsB,EAAAX,EAAAktB,EAAAxsB,EAAAsW,EAAA,mBAEAtW,EAAAysB,EAAAzsB,EAAAC,EAAAX,EAAAktB,EAAAlW,EAAA,iBACAkW,EAAAC,EAAAD,EAAAxsB,EAAAC,EAAAX,EAAAgX,EAAA,kBACAhX,EAAAmtB,EAAAntB,EAAAktB,EAAAxsB,EAAAC,EAAAqW,EAAA,kBACArW,EAAAwsB,EAAAxsB,EAAAX,EAAAktB,EAAAxsB,EAAAsW,EAAA,kBACAtW,EAAAysB,EAAAzsB,EAAAC,EAAAX,EAAAktB,EAAAlW,EAAA,iBACAkW,EAAAC,EAAAD,EAAAxsB,EAAAC,EAAAX,EAAAgX,EAAA,gBACAhX,EAAAmtB,EAAAntB,EAAAktB,EAAAxsB,EAAAC,EAAAqW,EAAA,mBACArW,EAAAwsB,EAAAxsB,EAAAX,EAAAktB,EAAAxsB,EAAAsW,EAAA,kBACAtW,EAAAysB,EAAAzsB,EAAAC,EAAAX,EAAAktB,EAAAlW,EAAA,gBACAkW,EAAAC,EAAAD,EAAAxsB,EAAAC,EAAAX,EAAAgX,EAAA,mBACAhX,EAAAmtB,EAAAntB,EAAAktB,EAAAxsB,EAAAC,EAAAqW,EAAA,kBACArW,EAAAwsB,EAAAxsB,EAAAX,EAAAktB,EAAAxsB,EAAAsW,EAAA,kBACAtW,EAAAysB,EAAAzsB,EAAAC,EAAAX,EAAAktB,EAAAlW,EAAA,mBACAkW,EAAAC,EAAAD,EAAAxsB,EAAAC,EAAAX,EAAAgX,EAAA,gBACAhX,EAAAmtB,EAAAntB,EAAAktB,EAAAxsB,EAAAC,EAAAqW,EAAA,kBACArW,EAAAwsB,EAAAxsB,EAAAX,EAAAktB,EAAAxsB,EAAAsW,EAAA,oBAEAtW,EAAA0sB,EAAA1sB,EAAAC,EAAAX,EAAAktB,EAAAlW,EAAA,cACAkW,EAAAE,EAAAF,EAAAxsB,EAAAC,EAAAX,EAAAgX,EAAA,mBACAhX,EAAAotB,EAAAptB,EAAAktB,EAAAxsB,EAAAC,EAAAqW,EAAA,mBACArW,EAAAysB,EAAAzsB,EAAAX,EAAAktB,EAAAxsB,EAAAsW,EAAA,kBACAtW,EAAA0sB,EAAA1sB,EAAAC,EAAAX,EAAAktB,EAAAlW,EAAA,kBACAkW,EAAAE,EAAAF,EAAAxsB,EAAAC,EAAAX,EAAAgX,EAAA,kBACAhX,EAAAotB,EAAAptB,EAAAktB,EAAAxsB,EAAAC,EAAAqW,EAAA,kBACArW,EAAAysB,EAAAzsB,EAAAX,EAAAktB,EAAAxsB,EAAAsW,EAAA,oBACAtW,EAAA0sB,EAAA1sB,EAAAC,EAAAX,EAAAktB,EAAAlW,EAAA,iBACAkW,EAAAE,EAAAF,EAAAxsB,EAAAC,EAAAX,EAAAgX,EAAA,kBACAhX,EAAAotB,EAAAptB,EAAAktB,EAAAxsB,EAAAC,EAAAqW,EAAA,kBACArW,EAAAysB,EAAAzsB,EAAAX,EAAAktB,EAAAxsB,EAAAsW,EAAA,gBACAtW,EAAA0sB,EAAA1sB,EAAAC,EAAAX,EAAAktB,EAAAlW,EAAA,iBACAkW,EAAAE,EAAAF,EAAAxsB,EAAAC,EAAAX,EAAAgX,EAAA,mBACAhX,EAAAotB,EAAAptB,EAAAktB,EAAAxsB,EAAAC,EAAAqW,EAAA,kBACArW,EAAAysB,EAAAzsB,EAAAX,EAAAktB,EAAAxsB,EAAAsW,EAAA,kBAEAtW,EAAA2sB,EAAA3sB,EAAAC,EAAAX,EAAAktB,EAAAlW,EAAA,iBACAkW,EAAAG,EAAAH,EAAAxsB,EAAAC,EAAAX,EAAAgX,EAAA,kBACAhX,EAAAqtB,EAAArtB,EAAAktB,EAAAxsB,EAAAC,EAAAqW,EAAA,oBACArW,EAAA0sB,EAAA1sB,EAAAX,EAAAktB,EAAAxsB,EAAAsW,EAAA,iBACAtW,EAAA2sB,EAAA3sB,EAAAC,EAAAX,EAAAktB,EAAAlW,EAAA,kBACAkW,EAAAG,EAAAH,EAAAxsB,EAAAC,EAAAX,EAAAgX,EAAA,mBACAhX,EAAAqtB,EAAArtB,EAAAktB,EAAAxsB,EAAAC,EAAAqW,EAAA,iBACArW,EAAA0sB,EAAA1sB,EAAAX,EAAAktB,EAAAxsB,EAAAsW,EAAA,mBACAtW,EAAA2sB,EAAA3sB,EAAAC,EAAAX,EAAAktB,EAAAlW,EAAA,iBACAkW,EAAAG,EAAAH,EAAAxsB,EAAAC,EAAAX,EAAAgX,EAAA,kBACAhX,EAAAqtB,EAAArtB,EAAAktB,EAAAxsB,EAAAC,EAAAqW,EAAA,mBACArW,EAAA0sB,EAAA1sB,EAAAX,EAAAktB,EAAAxsB,EAAAsW,EAAA,mBACAtW,EAAA2sB,EAAA3sB,EAAAC,EAAAX,EAAAktB,EAAAlW,EAAA,iBACAkW,EAAAG,EAAAH,EAAAxsB,EAAAC,EAAAX,EAAAgX,EAAA,oBACAhX,EAAAqtB,EAAArtB,EAAAktB,EAAAxsB,EAAAC,EAAAqW,EAAA,iBACArW,EAAA0sB,EAAA1sB,EAAAX,EAAAktB,EAAAxsB,EAAAsW,EAAA,kBAEA+B,EAAA,GAAA+T,EAAApsB,EAAAqY,EAAA,IACAA,EAAA,GAAA+T,EAAAnsB,EAAAoY,EAAA,IACAA,EAAA,GAAA+T,EAAA9sB,EAAA+Y,EAAA,IACAA,EAAA,GAAA+T,EAAAI,EAAAnU,EAAA,KAkBAwU,EAAA,SAAAP,GACA,GACA9sB,GADAstB,IAGA,KAAAttB,EAAA,EAAmBA,EAAA,GAAQA,GAAA,EAC3BstB,EAAAttB,GAAA,GAAA8sB,EAAAS,WAAAvtB,IAAA8sB,EAAAS,WAAAvtB,EAAA,QAAA8sB,EAAAS,WAAAvtB,EAAA,SAAA8sB,EAAAS,WAAAvtB,EAAA,OAEA,OAAAstB,IAGAE,EAAA,SAAAhtB,GACA,GACAR,GADAstB,IAGA,KAAAttB,EAAA,EAAmBA,EAAA,GAAQA,GAAA,EAC3BstB,EAAAttB,GAAA,GAAAQ,EAAAR,IAAAQ,EAAAR,EAAA,QAAAQ,EAAAR,EAAA,SAAAQ,EAAAR,EAAA,OAEA,OAAAstB,IAGAG,EAAA,SAAAX,GACA,GAEA9sB,GACAuC,EACAmrB,EACAC,EACAC,EACAC,EAPAC,EAAAhB,EAAAvqB,OACAuZ,GAAA,4CAQA,KAAA9b,EAAA,GAAoBA,GAAA8tB,EAAQ9tB,GAAA,GAC5BotB,EAAAtR,EAAAuR,EAAAP,EAAAthB,UAAAxL,EAAA,GAAAA,IAKA,KAHA8sB,IAAAthB,UAAAxL,EAAA,IACAuC,EAAAuqB,EAAAvqB,OACAmrB,GAAA,iCACA1tB,EAAA,EAAmBA,EAAAuC,EAAYvC,GAAA,EAC/B0tB,EAAA1tB,GAAA,IAAA8sB,EAAAS,WAAAvtB,OAAA,KAGA,IADA0tB,EAAA1tB,GAAA,UAAAA,EAAA,MACAA,EAAA,GAEA,IADAotB,EAAAtR,EAAA4R,GACA1tB,EAAA,EAAuBA,EAAA,GAAQA,GAAA,EAC/B0tB,EAAA1tB,GAAA,CAcA,OATA2tB,GAAA,EAAAG,EACAH,IAAAvU,SAAA,IAAAiO,MAAA,kBACAuG,EAAA5V,SAAA2V,EAAA,OACAE,EAAA7V,SAAA2V,EAAA,UAEAD,EAAA,IAAAE,EACAF,EAAA,IAAAG,EAEAT,EAAAtR,EAAA4R,GACA5R,GAGAiS,EAAA,SAAAvtB,GACA,GAEAR,GACAuC,EACAmrB,EACAC,EACAC,EACAC,EAPAC,EAAAttB,EAAA+B,OACAuZ,GAAA,4CAQA,KAAA9b,EAAA,GAAoBA,GAAA8tB,EAAQ9tB,GAAA,GAC5BotB,EAAAtR,EAAA0R,EAAAhtB,EAAAwtB,SAAAhuB,EAAA,GAAAA,IAWA,KAJAQ,EAAAR,EAAA,GAAA8tB,EAAAttB,EAAAwtB,SAAAhuB,EAAA,OAAAqe,YAAA,GAEA9b,EAAA/B,EAAA+B,OACAmrB,GAAA,iCACA1tB,EAAA,EAAmBA,EAAAuC,EAAYvC,GAAA,EAC/B0tB,EAAA1tB,GAAA,IAAAQ,EAAAR,OAAA,KAIA,IADA0tB,EAAA1tB,GAAA,UAAAA,EAAA,MACAA,EAAA,GAEA,IADAotB,EAAAtR,EAAA4R,GACA1tB,EAAA,EAAuBA,EAAA,GAAQA,GAAA,EAC/B0tB,EAAA1tB,GAAA,CAeA,OAVA2tB,GAAA,EAAAG,EACAH,IAAAvU,SAAA,IAAAiO,MAAA,kBACAuG,EAAA5V,SAAA2V,EAAA,OACAE,EAAA7V,SAAA2V,EAAA,UAEAD,EAAA,IAAAE,EACAF,EAAA,IAAAG,EAEAT,EAAAtR,EAAA4R,GAEA5R,GAGAmS,GAAA,iEAEAC,EAAA,SAAAJ,GACA,GACAtK,GADAsJ,EAAA,EAEA,KAAAtJ,EAAA,EAAmBA,EAAA,EAAOA,GAAA,EAC1BsJ,GAAAmB,EAAAH,GAAA,EAAAtK,EAAA,MAAAyK,EAAAH,GAAA,EAAAtK,EAAA,GAEA,OAAAsJ,IAGAqB,EAAA,SAAAtV,GACA,GAAA7Y,EACA,KAAAA,EAAA,EAAmBA,EAAA6Y,EAAAtW,OAAcvC,GAAA,EACjC6Y,EAAA7Y,GAAAkuB,EAAArV,EAAA7Y,GAEA,OAAA6Y,GAAAxF,KAAA,KAGA+a,EAAA,SAAAtB,GACA,MAAAqB,GAAAV,EAAAX,KAaAuB,EAAA,WAEAhvB,KAAAivB,QAsSA,OAjSA,qCAAAF,EAAA,WACAxB,EAAA,SAAA/T,EAAA0V,GACA,GAAAC,IAAA,MAAA3V,IAAA,MAAA0V,GACAE,GAAA5V,GAAA,KAAA0V,GAAA,KAAAC,GAAA,GACA,OAAAC,IAAA,SAAAD,IAaAH,EAAAnuB,UAAAwuB,OAAA,SAAAnX,GASA,MAPA,kBAAAmU,KAAAnU,KACAA,EAAAoX,SAAA3f,mBAAAuI,KAIAlY,KAAAuvB,aAAArX,GAEAlY,MAUAgvB,EAAAnuB,UAAA0uB,aAAA,SAAAC,GACAxvB,KAAAyvB,OAAAD,EACAxvB,KAAA0vB,SAAAF,EAAAtsB,MAEA,IACAvC,GADAuC,EAAAlD,KAAAyvB,MAAAvsB,MAGA,KAAAvC,EAAA,GAAoBA,GAAAuC,EAAavC,GAAA,GACjCotB,EAAA/tB,KAAA2vB,OAAA3B,EAAAhuB,KAAAyvB,MAAAtjB,UAAAxL,EAAA,GAAAA,IAKA,OAFAX,MAAAyvB,MAAAzvB,KAAAyvB,MAAAG,OAAAjvB,EAAA,IAEAX,MAYAgvB,EAAAnuB,UAAAgvB,IAAA,SAAAC,GACA,GAEAnvB,GAEAovB,EAJAC,EAAAhwB,KAAAyvB,MACAvsB,EAAA8sB,EAAA9sB,OAEAmrB,GAAA,gCAGA,KAAA1tB,EAAA,EAAmBA,EAAAuC,EAAYvC,GAAA,EAC/B0tB,EAAA1tB,GAAA,IAAAqvB,EAAA9B,WAAAvtB,OAAA,KAQA,OALAX,MAAAiwB,QAAA5B,EAAAnrB,GACA6sB,EAAAD,EAAA9vB,KAAA2vB,OAAAb,EAAA9uB,KAAA2vB,QAEA3vB,KAAAivB,QAEAc,GASAf,EAAAnuB,UAAAovB,QAAA,SAAA5B,EAAAnrB,GACA,GACAorB,GACAC,EACAC,EAHA7tB,EAAAuC,CAMA,IADAmrB,EAAA1tB,GAAA,UAAAA,EAAA,MACAA,EAAA,GAEA,IADAotB,EAAA/tB,KAAA2vB,OAAAtB,GACA1tB,EAAA,EAAuBA,EAAA,GAAQA,GAAA,EAC/B0tB,EAAA1tB,GAAA,CAMA2tB,GAAA,EAAAtuB,KAAA0vB,QACApB,IAAAvU,SAAA,IAAAiO,MAAA,kBACAuG,EAAA5V,SAAA2V,EAAA,OACAE,EAAA7V,SAAA2V,EAAA,UAEAD,EAAA,IAAAE,EACAF,EAAA,IAAAG,EACAT,EAAA/tB,KAAA2vB,OAAAtB,IAQAW,EAAAnuB,UAAAouB,MAAA,WAKA,MAJAjvB,MAAAyvB,MAAA,GACAzvB,KAAA0vB,QAAA,EACA1vB,KAAA2vB,QAAA,6CAEA3vB,MAOAgvB,EAAAnuB,UAAAqvB,QAAA,iBACAlwB,MAAA2vB,aACA3vB,MAAAyvB,YACAzvB,MAAA0vB,SAaAV,EAAA/jB,KAAA,SAAAiN,EAAA4X,GAEA,kBAAAzD,KAAAnU,KACAA,EAAAoX,SAAA3f,mBAAAuI,IAGA,IAAAjN,GAAAmjB,EAAAlW,EAEA,OAAA4X,GAAA7kB,EAAA6jB,EAAA7jB,IAWA+jB,EAAAmB,WAAA,SAAAC,EAAAN,GACA,GAAA7kB,GAAAmjB,EAAAgC,EAEA,OAAAN,GAAA7kB,EAAA6jB,EAAA7jB,IAQA+jB,EAAAqB,YAAA,WAEArwB,KAAAivB,SAYAD,EAAAqB,YAAAxvB,UAAAwuB,OAAA,SAAA3nB,GAGA,GAEA/G,GAFAqvB,EAAAhwB,KAAAswB,mBAAAtwB,KAAAyvB,MAAA/nB,GACAxE,EAAA8sB,EAAA9sB,MAKA,KAFAlD,KAAA0vB,SAAAhoB,EAAA6oB,WAEA5vB,EAAA,GAAoBA,GAAAuC,EAAavC,GAAA,GACjCotB,EAAA/tB,KAAA2vB,OAAAxB,EAAA6B,EAAArB,SAAAhuB,EAAA,GAAAA,IAMA,OAFAX,MAAAyvB,MAAA9uB,EAAA,GAAAuC,EAAA8sB,EAAArB,SAAAhuB,EAAA,OAAAqe,YAAA,GAEAhf,MAYAgvB,EAAAqB,YAAAxvB,UAAAgvB,IAAA,SAAAC,GACA,GAGAnvB,GACAovB,EAJAC,EAAAhwB,KAAAyvB,MACAvsB,EAAA8sB,EAAA9sB,OACAmrB,GAAA,gCAIA,KAAA1tB,EAAA,EAAmBA,EAAAuC,EAAYvC,GAAA,EAC/B0tB,EAAA1tB,GAAA,IAAAqvB,EAAArvB,OAAA,KAQA,OALAX,MAAAiwB,QAAA5B,EAAAnrB,GACA6sB,EAAAD,EAAA9vB,KAAA2vB,OAAAb,EAAA9uB,KAAA2vB,QAEA3vB,KAAAivB,QAEAc,GAGAf,EAAAqB,YAAAxvB,UAAAovB,QAAAjB,EAAAnuB,UAAAovB,QAOAjB,EAAAqB,YAAAxvB,UAAAouB,MAAA,WAKA,MAJAjvB,MAAAyvB,MAAA,GAAAzQ,YAAA,GACAhf,KAAA0vB,QAAA,EACA1vB,KAAA2vB,QAAA,6CAEA3vB,MAOAgvB,EAAAqB,YAAAxvB,UAAAqvB,QAAAlB,EAAAnuB,UAAAqvB,QAUAlB,EAAAqB,YAAAxvB,UAAAyvB,mBAAA,SAAAE,EAAAC,GACA,GAAAC,GAAAF,EAAAttB,OACAkH,EAAA,GAAA4U,YAAA0R,EAAAD,EAAAF,WAKA,OAHAnmB,GAAAumB,IAAAH,GACApmB,EAAAumB,IAAA,GAAA3R,YAAAyR,GAAAC,GAEAtmB,GAWA4kB,EAAAqB,YAAAplB,KAAA,SAAAvD,EAAAooB,GACA,GAAA7kB,GAAAyjB,EAAA,GAAA1P,YAAAtX,GAEA,OAAAooB,GAAA7kB,EAAA6jB,EAAA7jB,IAGA+jB,KnCkhHM,SAASnvB,EAAQD,EAASM,GoCvmIhC,YAOA,SAAA0wB,GAAAnE,EAAAoE,EAAAnE,GACA,sBAAAmE,GACAvD,EAAArjB,OAAA,GAAAzD,OAAA,uBAGAimB,EAAAzmB,IAAA6qB,GAAA/hB,MAAA,SAAA1I,GAEA,SAAAA,EAAA3B,OACA,KAAA2B,EAEA,YACG/C,KAAA,SAAAoI,GAEH,GAAAqlB,GAAArlB,EAAA0a,KACA4K,EAAArE,EAAAjhB,EAEA,OAAAslB,IAQAA,EAAA3L,IAAAyL,EACAE,EAAA5K,KAAA2K,EACAE,EAAAvE,EAAAsE,EAAArE,KAPcuE,SAAA,EAAA5K,IAAAyK,KAWd,QAAAE,GAAAvE,EAAAhhB,EAAAihB,GACA,MAAAD,GAAAyE,IAAAzlB,GAAApI,KAAA,SAAAQ,GACA,OACAotB,SAAA,EACA5K,IAAAxiB,EAAAwiB,MAEG,SAAAjgB,GAEH,SAAAA,EAAA3B,OACA,KAAA2B,EAEA,OAAAwqB,GAAAnE,EAAAhhB,EAAA2Z,IAAAsH,KA9CA,GAAAY,GAAAptB,EAAA,GAkDAN,GAAA4sB,OAAA,SAAAqE,EAAAnE,EAAAhiB,GACA,GAAA+hB,GAAAzsB,KACA+J,EAAA6mB,EAAAnE,EAAAoE,EAAAnE,EACA,yBAAAhiB,GACAX,MAEAA,GAAA1G,KAAA,SAAAC,GACAoH,EAAA,KAAApH,IACGoH,IAGH9K,EAAAuxB,eAAA,SAAAN,EAAAplB,EAAAf,GACA,GAAA+hB,GAAAzsB,IAEA,iBAAA6wB,KACAnmB,EAAAe,EACAA,EAAAolB,EACAA,EAAAplB,EAAA2Z,IAGA,IAAAsH,GAAA,SAAA0E,GACA,OAAAA,EAAAjL,MAGA1a,GAGA1B,EAAA6mB,EAAAnE,EAAAoE,EAAAnE,EACA,yBAAAhiB,GACAX,MAEAA,GAAA1G,KAAA,SAAAC,GACAoH,EAAA,KAAApH,IACGoH,IAKH,mBAAA9D,gBAAAyqB,SACAzqB,OAAAyqB,QAAAC,OAAA1xB,IpC+mIM,SAASC,EAAQD,GAEtB,YAQA,SAAS+B,GAAgBC,EAAUC,GAAe,KAAMD,YAAoBC,IAAgB,KAAM,IAAIC,WAAU,qCANhHlB,OAAO4G,eAAe5H,EAAS,cAC7B2C,OAAO,GAGT,IAAIid,GAAe,WAAc,QAASC,GAAiBC,EAAQC,GAAS,IAAK,GAAIhf,GAAI,EAAGA,EAAIgf,EAAMzc,OAAQvC,IAAK,CAAE,GAAIif,GAAaD,EAAMhf,EAAIif,GAAWpd,WAAaod,EAAWpd,aAAc,EAAOod,EAAWld,cAAe,EAAU,SAAWkd,KAAYA,EAAWnd,UAAW,GAAM7B,OAAO4G,eAAekY,EAAQE,EAAWjU,IAAKiU,IAAiB,MAAO,UAAU/d,EAAage,EAAYC,GAAiJ,MAA9HD,IAAYJ,EAAiB5d,EAAYhB,UAAWgf,GAAiBC,GAAaL,EAAiB5d,EAAaie,GAAqBje,KAI7gBjC,GqCttIP2xB,arCstI8B,WqCrtIzC,QAAAA,GAAa9T,EAAS+T,GAAQ7vB,EAAA3B,KAAAuxB,GACvB9T,GAA6B,mBAAX7W,UACrB6W,EAAU7W,OAAOkiB,cAEnB9oB,KAAKyd,QAAUA,EACfzd,KAAKwxB,OAASA,GAAU,crC8wIzB,MAnDAhS,GAAa+R,IACX5lB,IAAK,OACLpJ,MAAO,SqC1tIJoJ,EAAKpJ,GAAO,GAAAoG,GAAA3I,IAChB,OAAO,IAAImE,SAAQ,SAAAoK,GACjB5F,EAAK8U,QAAQgU,QAAQ9oB,EAAK6oB,OAAS7lB,EAAKjG,KAAKC,UAAUpD,IACvDgM,EAAQhM,QrCguIToJ,IAAK,OACLpJ,MAAO,SqC7tIJoJ,GAAK,GAAA+lB,GAAA1xB,IACT,OAAO,IAAImE,SAAQ,SAAAoK,GACjB,GAAMojB,GAAOD,EAAKjU,QAAQmU,QAAQF,EAAKF,OAAS7lB,EAC3CgmB,GAGHpjB,EAAQ7I,KAAKmsB,MAAMF,IAFnBpjB,SrCsuIH5C,IAAK,SACLpJ,MAAO,SqChuIFoJ,GAAK,GAAAmmB,GAAA9xB,IACX,OAAO,IAAImE,SAAQ,SAAAoK,GAAA,MAAWA,GAC5BujB,EAAKrU,QAAQiL,WAAWoJ,EAAKN,OAAS7lB,SrCsuIvCA,IAAK,QACLpJ,MAAO,WqCpuID,GAAAwvB,GAAA/xB,IACP,OAAO,IAAImE,SAAQ,SAAAoK,GAEjB,IAAK,GADCkP,GAAUsU,EAAKtU,QACZ9c,EAAI,EAAGA,EAAI8c,EAAQva,OAAQvC,IAAK,CACvC,GAAMgL,GAAM8R,EAAQ9R,IAAIhL,EACS,KAA7BgL,EAAI1F,QAAQ8rB,EAAKP,SACnB/T,EAAQiL,WAAW/c,GAGvB4C,UrC2uIIgjB,KAGW3xB,EqCzuIRoyB,crCyuIgC,WqCxuI3C,QAAAA,KAAerwB,EAAA3B,KAAAgyB,GACbhyB,KAAKiL,KAAOrK,OAAOyB,OAAO,MrCuwI3B,MAzBAmd,GAAawS,IACXrmB,IAAK,OACLpJ,MAAO,SqC7uIJoJ,EAAKpJ,GAET,MADAvC,MAAKiL,KAAKU,GAAOpJ,EACV4B,QAAQoK,QAAQhM,MrCgvItBoJ,IAAK,OACLpJ,MAAO,SqC9uIJoJ,GACJ,MAAOxH,SAAQoK,QAAQvO,KAAKiL,KAAKU,OrCivIhCA,IAAK,SACLpJ,MAAO,SqC/uIFoJ,GACN,GAAMsmB,SAAiBjyB,MAAKiL,KAAKU,EACjC,OAAOxH,SAAQoK,QAAQ0jB,MrCkvItBtmB,IAAK,QACLpJ,MAAO,WqC9uIR,MADAvC,MAAKiL,KAAOrK,OAAOyB,OAAO,MACnB8B,QAAQoK,crCovITyjB,MAKJ,SAASnyB,EAAQD,GAEtB,YAUA,SAAS+B,GAAgBC,EAAUC,GAAe,KAAMD,YAAoBC,IAAgB,KAAM,IAAIC,WAAU,qCsCr0I1G,QAASowB,KACd,MAAO,IAAI/tB,SAAQ,SAAUoK,EAAStE,GACpC,GAAsB,mBAAXrD,QACT,MAAOqD,GAAO,GAAIzD,OAAM,wCACnB,KAAKI,OAAOurB,OACjB,MAAOloB,GAAO,GAAIzD,OAAM,uCACnB,KAAKI,OAAOurB,OAAOjP,YACxB,MAAOjZ,GAAO,GAAIzD,OAAM,+CAE1B,IAAMM,GAASF,OAAOC,SAASC,OACzBsrB,GAAUC,OAAQ,YACpB7c,EAAU,KACR8c,EAAW,QAAXA,GAAqBhb,GACzB,GAAIrT,SACJ,KACEA,EAAQ,GAAIsb,IACVgT,QAASjb,EAAMxR,KAAKysB,QACpBtuB,MAAOqT,EAAMxR,KAAK7B,QAEpB,MAAOoD,GAEP,WADA4C,GAAO5C,GAGTT,OAAO4rB,oBAAoB,UAAWF,GACtCrd,aAAaO,GACbjH,GAAU5J,OAAQ,KAAMV,UAE1B2C,QAAO6rB,iBAAiB,UAAWH,GAAU,GAC7C1rB,OAAOurB,OAAOjP,YAAYkP,EAAQtrB,GAClC0O,EAAUhH,WAAW,WACnBvE,EAAO,GAAIzD,OAAM,6CAChBksB,KtC8xIN9xB,OAAO4G,eAAe5H,EAAS,cAC7B2C,OAAO,GAGT,IAAIid,GAAe,WAAc,QAASC,GAAiBC,EAAQC,GAAS,IAAK,GAAIhf,GAAI,EAAGA,EAAIgf,EAAMzc,OAAQvC,IAAK,CAAE,GAAIif,GAAaD,EAAMhf,EAAIif,GAAWpd,WAAaod,EAAWpd,aAAc,EAAOod,EAAWld,cAAe,EAAU,SAAWkd,KAAYA,EAAWnd,UAAW,GAAM7B,OAAO4G,eAAekY,EAAQE,EAAWjU,IAAKiU,IAAiB,MAAO,UAAU/d,EAAage,EAAYC,GAAiJ,MAA9HD,IAAYJ,EAAiB5d,EAAYhB,UAAWgf,GAAiBC,GAAaL,EAAiB5d,EAAaie,GAAqBje,KAEhiBjC,GsCn0IesyB,aAFhB,IAAMQ,GAAwB,IAqCjBnT,EtC00IG3f,EsC10IH2f,StC00IsB,WsCz0IjC,QAAAA,GAAarM,GAAMvR,EAAA3B,KAAAuf,GACjBvf,KAAKuyB,QAAUrf,EAAKqf,SAAW,GAC/BvyB,KAAKiE,MAAQiP,EAAKjP,OAAS,GtCs1I5B,MAPAub,GAAaD,IACX5T,IAAK,eACLpJ,MAAO,WsC70IR,MAAO,SAAW6c,KAAQpf,KAAKuyB,QAAb,IAAwBvyB,KAAKiE,WtCk1IzCsb,MAKJ,SAAS1f,EAAQD,EAASM,GAE/B,YuCh4IM,SAASmC,GAAQS,EAAM0M,EAAS8W,GACrC,MAAOxjB,GAAKuB,OAAOhB,KAAK,SAACgB,GACvBmL,GAAU,EAAAmjB,EAAA9b,kBAAiB/T,EAAMuB,EAAMmL,GACnCnL,IACFiiB,EAAWsM,QAAUpjB,EAEvB,IAAMzM,IAAO,EAAA6B,EAAA2K,YAAWzM,EAAMuB,EAAMmL,EAAS8W,EAAWlB,KAClDyN,EAAWvM,EAAWlB,IAAM,MAAQ,MAE1C,cADOkB,GAAWlB,KACX,EAAA5J,EAAAtW,eAAcpC,EAAM+vB,EAAU9vB,EAAMujB,GAAYjjB,KAAK,SAACC,GAC3D,MAAIe,GACKyuB,EAAKhwB,EAAM0M,EAASlM,EAAK8hB,KAEzB9hB,EAAKwC,SAMb,QAASgtB,GAAMhwB,EAAM0M,EAASnP,GACnC,MAAOyC,GAAKuB,OAAOhB,KAAK,SAACgB,GAGvB,GAFAmL,GAAU,EAAAmjB,EAAA9b,kBAAiB/T,EAAMuB,EAAMmL,IAElCnP,EACH,MAAO8D,SAAQ8F,OAAO,GAAIzD,OAAM,wBAGlC,IAAMzD,IAAO,EAAA6B,EAAA2K,YAAWzM,EAAMuB,EAAMmL,EAASnP,EAC7C,QAAO,EAAAmb,EAAAtW,eAAcpC,EAAM,MAAOC,GAAMM,KAAK,SAACC,GAC5C,MAAIe,GACKzD,OAAO+d,OAAOrb,GAAO6iB,KAAM4M,IAE3BzvB,MAMR,QAAS0vB,GAAUlwB,EAAM0M,EAASyjB,GACvC,MAAMA,aAAe3qB,OAGF,IAAf2qB,EAAI/vB,OAICiB,QAAQoK,YAGVzL,EAAKuB,OAAOhB,KAAK,SAACgB,GACvB,GAAIA,EACF,MAAOF,SAAQ8F,OAAO,GAAIzD,OAAM,mCAGlC,IAAMzD,IAAO,EAAA6B,EAAA2K,YAAWzM,EAAMuB,EAAMmL,EAAS,aAAcqd,cAAc,GAEzE,QAAO,EAAArR,EAAAtW,eAAcpC,EAAM,OAAQC,GAAO0K,KAAMwlB,IAC7C5vB,KAAK,SAACC,GACL,GAAM4vB,MADQC,GAAA,EAAAC,GAAA,EAAAC,EAAAlwB,MAAA,KAGd,OAAAmwB,GAAAC,EAAkBjwB,EAAKoP,KAAvBzK,OAAAC,cAAAirB,GAAAG,EAAAC,EAAAprB,QAAAC,MAAA+qB,GAAA,EAA6B,IAAlBtgB,GAAkBygB,EAAA/wB,MACpBoJ,EAAmBkH,EAAnBlH,IAAKF,EAAcoH,EAAdpH,IAAKpF,EAASwM,EAATxM,KACjB6sB,GAAKvnB,GAAOtF,GAASA,UAAUoF,QALnB,MAAArF,GAAAgtB,GAAA,EAAAC,EAAAjtB,EAAA,aAAA+sB,GAAAI,EAAAC,QAAAD,EAAAC,SAAA,WAAAJ,EAAA,KAAAC,IAQd,MAAOH,KAERpkB,MAAM,SAACzI,GACN,GAAqB,MAAjBA,EAAM5B,OAAgB,MAAON,SAAQ8F,OAAO5D,EAIhD,IAAM6sB,MALUO,GAAA,EAAAC,GAAA,EAAAC,EAAAxwB,MAAA,KAOhB,OAAAywB,GAAAC,EAAiBZ,EAAjBhrB,OAAAC,cAAAurB,GAAAG,EAAAC,EAAA1rB,QAAAC,MAAAqrB,GAAA,EAAsB,IAAXpzB,GAAWuzB,EAAArxB,KACpB2wB,GAAK7yB,IAAOgG,UARE,MAAAD,GAAAstB,GAAA,EAAAC,EAAAvtB,EAAA,aAAAqtB,GAAAI,EAAAL,QAAAK,EAAAL,SAAA,WAAAE,EAAA,KAAAC,IAWhB,MAAOT,OAtCJ/uB,QAAQ8F,OAAO,GAAIzD,OAAM,4CA2C7B,QAASstB,GAAShxB,EAAM0M,GAC7B,MAAO1M,GAAKuB,OAAOhB,KAAK,SAACgB,GACvB,GAAIA,EACF,MAAOF,SAAQ8F,OAAO,GAAIzD,OAAM,kCAGlC,IAAMzD,IAAO,EAAA6B,EAAA2K,YAAWzM,EAAMuB,EAAMmL,EAAS,aAAcqd,cAAc,GAEzE,QAAO,EAAArR,EAAAtW,eAAcpC,EAAM,OAAQC,MAClCM,KAAK,SAACC,GACL,GAAM4vB,MADQa,GAAA,EAAAC,GAAA,EAAAC,EAAA9wB,MAAA,KAGd,OAAA+wB,GAAAC,EAAkB7wB,EAAKoP,KAAvBzK,OAAAC,cAAA6rB,GAAAG,EAAAC,EAAAhsB,QAAAC,MAAA2rB,GAAA,EAA6B,IAAlBlhB,GAAkBqhB,EAAA3xB,MACnBkJ,EAAQoH,EAARpH,GAEHA,GAAI2Z,IAAI4C,MAAM,cAAckL,EAAK7qB,KAAKoD,IAN/B,MAAArF,GAAA4tB,GAAA,EAAAC,EAAA7tB,EAAA,aAAA2tB,GAAAI,EAAAX,QAAAW,EAAAX,SAAA,WAAAQ,EAAA,KAAAC,IAQd,MAAOf,KAERpkB,MAAM,SAAAzI,GAGL,GAAqB,MAAjBA,EAAM5B,OAAgB,QAC1B,MAAM4B,OAKL,QAAS+tB,GAAatxB,EAAM0M,EAASxM,GAC1C,MAAOF,GAAKuB,OAAOhB,KAAK,SAACgB,GACvBmL,GAAU,EAAAmjB,EAAA9b,kBAAiB/T,EAAMuB,EAAMmL,EACvC,IAAMzM,IAAO,EAAA6B,EAAA2K,YAAWzM,EAAMuB,EAAMmL,EAAS,WAAYxM,EACzD,QAAO,EAAAwY,EAAAtW,eAAcpC,EAAM,MAAOC,KAI/B,QAASoI,GAAQrI,EAAM0M,EAAS/D,EAAK4oB,GAC1C,MAAOvxB,GAAKuB,OAAOhB,KAAK,SAACgB,GACvBmL,GAAU,EAAAmjB,EAAA9b,kBAAiB/T,EAAMuB,EAAMmL,EADP,IAEzB4V,GAAa3Z,EAAb2Z,IAAKe,EAAQ1a,EAAR0a,IAEZ,KAAKf,EACH,MAAOjhB,SAAQ8F,OAAO,GAAIzD,OAAM,wCAGlC,KAAKnC,IAAS8hB,EACZ,MAAOhiB,SAAQ8F,OAAO,GAAIzD,OAAM,yCAIhC6tB,GADEhwB,EACQzD,OAAO+d,QAASyG,OAAOiP,GAEvBzzB,OAAO+d,QAASyG,MAAKe,QAAQkO,EAGzC,IAAMtxB,IAAO,EAAA6B,EAAA2K,YAAWzM,EAAMuB,EAAMmL,EAAS4V,EAC7C,QAAO,EAAA5J,EAAAtW,eAAcpC,EAAM,MAAOC,EAAMsxB,GAAShxB,KAAK,SAACC,GACrD,MAAIe,GACKyuB,EAAKhwB,EAAM0M,EAAS4V,GAEpB9hB,EAAKwC,SAMb,QAASwuB,GAAkBxxB,EAAM0M,EAAS4V,EAAKiP,GAAoB,GAAXE,GAAWtxB,UAAAC,OAAA,GAAAC,SAAAF,UAAA,GAAAA,UAAA,GAAH,CACrE,OAAOH,GAAKuB,OAAOhB,KAAK,SAACgB,GAEvB,MADAmL,IAAU,EAAAmjB,EAAA9b,kBAAiB/T,EAAMuB,EAAMmL,GAChCsjB,EAAKhwB,EAAM0M,EAAS4V,GACxB/hB,KAAK,SAACoI,GACL,MAAON,GAAOrI,EAAM0M,EAAS/D,EAAK7K,OAAO+d,QAASyG,OAAO3Z,EAAK4oB,MAE/DvlB,MAAM,SAAC1I,GACN,GAAImuB,EAAQ,EACV,MAAOD,GAAiBxxB,EAAM0M,EAAS4V,EAAKiP,EAASE,EAAQ,EAE7D,MAAMnuB,OAMT,QAASouB,GAAS1xB,EAAM0M,EAAS/D,GACtC,MAAO3I,GAAKuB,OAAOhB,KAAK,SAACgB,GACvBmL,GAAU,EAAAmjB,EAAA9b,kBAAiB/T,EAAMuB,EAAMmL,EADP,IAEzB4V,GAAa3Z,EAAb2Z,IAAKe,EAAQ1a,EAAR0a,IAEZ,KAAKf,EACH,MAAOjhB,SAAQ8F,OAAO,GAAIzD,OAAM,wCAGlC,KAAKnC,IAAS8hB,EACZ,MAAOhiB,SAAQ8F,OAAO,GAAIzD,OAAM,yCAGlC,IAAMiJ,GAAQpL,EAAO,MAASgiB,IAAKF,GAC7BpjB,GAAO,EAAA6B,EAAA2K,YAAWzM,EAAMuB,EAAMmL,EAAS4V,EAAK3V,EAClD,QAAO,EAAA+L,EAAAtW,eAAcpC,EAAM,SAAUC,GAAMM,KAAK,SAACC,GAC/C,MAAIe,IACMhE,GAAI+kB,EAAKiB,IAAK0M,GAEfzvB,MvCysId1C,OAAO4G,eAAe5H,EAAS,cAC7B2C,OAAO,IAET3C,EuCr4IeyC,SvCs4IfzC,EuCn3IekzB,OvCo3IflzB,EuCj2IeozB,WvCk2IfpzB,EuCrzIek0B,UvCszIfl0B,EuC1xIew0B,cvC2xIfx0B,EuCnxIeuL,SvCoxIfvL,EuCtvIe00B,mBvCuvIf10B,EuCtuIe40B,SA5KhB,IAAA5vB,GAAA1E,EAAA,GACAyyB,EAAAzyB,EAAA,GACAsb,EAAAtb,EAAA,GAEM6yB,EAAQ,mBvC2pJR,SAASlzB,EAAQD,EAASM,GAE/B,YA0CA,SAASqB,GAAuBC,GAAO,MAAOA,IAAOA,EAAIC,WAAaD,GAAQE,QAASF,GwChsJxF,QAASizB,GAAkB3rB,GACzB,MAAOA,IAAQA,EAAK4rB,OAGtB,QAASC,GAAqB7rB,GAC5B,MAAI,WAAWujB,KAAKvjB,GAAc,aACzB,WAAWujB,KAAKvjB,GAAc,aAC3B,KAGd,QAAS8rB,GAAU9xB,EAAMgD,EAAMX,EAAQpC,EAAMC,GAC3C,IAAK8C,EACH,KAAM,IAAIU,OAAM,wBAIdV,GAAKgZ,QAAUhZ,EAAKgZ,iBAAkBuR,eACxCvqB,EAAOA,EAAKgZ,OAGd,IAAM+V,GAAmC,mBAAhBxE,cAA+BvqB,YAAgBuqB,aAClEyE,EAA0B,mBAATC,OAAwBjvB,YAAgBivB,MACzDC,EAA0B,mBAATC,OAAwBnvB,YAAgBmvB,MACzDC,EAAYpvB,EAAKqvB,YAAa,GAA6B,kBAAdrvB,GAAKsvB,KAClDC,EAA4B,gBAATvvB,EAEzB,MAAK+uB,GAAaC,GAAWE,GAAWE,GAAaG,GACnD,KAAM,IAAI7uB,OAAM,oBAjBkC,IAAAlC,GAoBoBtB,MAAnE+C,EApB+CzB,EAoB/CyB,YAAauvB,EApBkChxB,EAoBlCgxB,cAAeC,EApBmBjxB,EAoBnBixB,SAAUC,EApBSlxB,EAoBTkxB,iBAAkBC,EApBTnxB,EAoBSmxB,OACxD1vB,KACC8uB,EACF9uB,EAAc2vB,EACLZ,GACT/uB,EAAcD,EAAK4f,MAAQiP,EAAoB7uB,EAAKgD,KAAKif,gBAAkB2N,EACtEF,IACHA,EAAmB1vB,EAAK0vB,mBAEjBR,EACTjvB,EAAcD,EAAK4f,MAAQgQ,EAClBR,EACTnvB,EAAc2vB,EACW,gBAAT5vB,KAChBC,EAAc,eAIdyvB,GAAgD,gBAArBA,KAC7BA,EAAmB,GAAI9a,MAAK8a,GAG9B,IAAMxxB,IACJ4a,eAAgB7Y,EAOlB,OALIuvB,KAAetxB,EAAQ,kBAAoBqb,OAAOiW,IAClDC,IAAUvxB,EAAQ,eAAiBuxB,GACnCC,IAAkBxxB,EAAA,KAAkBwxB,EAAiBG,eACrDF,IAASzxB,EAAQ,YAAcyxB,IAE5B,EAAAja,EAAA3Y,WAAUC,EAAMC,GACrBoC,OAAQA,EACRnB,QAASA,EACToB,KAAMU,IAELzC,KAAK,SAACQ,GACL,GAAMqC,GAAOrC,EAAIqC,MACjB,OAAKrC,GAAIgC,GAGAK,EAAK7C,KAALoD,EAAA/E,SAFAwE,EAAK7C,KAAK,SAAA+C,GAAS,KAAMA,OAOjC,QAAS/D,GAAQS,EAAMgD,EAAM9C,GAAS,GAAAuB,GACXvB,MAA3B8F,EADsCvE,EACtCuE,KAAM8sB,EADgCrxB,EAChCqxB,MAAOC,EADyBtxB,EACzBsxB,UASlB,IANK/sB,GAA6B,gBAAdhD,GAAKgD,OACvBA,EAAOhD,EAAKgD,MAGdA,EAAO2rB,EAAiB3rB,GAEJ,gBAATA,IAA8B,KAATA,EAC9B,KAAM,IAAItC,OAAM,wBAGCrD,UAAf0yB,IACFA,GAAa,EAGf,IAAM9yB,aAAiB4M,mBAAmBimB,GAAS,IAC7CnmB,WAAiBE,mBAAmB7G,GAApC,yBAAkE+sB,CACxE,OAAOjB,GAAS9xB,EAAMgD,EAAM,OAArB,GAAgC/C,EAAO0M,EAASzM,GAGlD,QAAS8yB,GAAiBhzB,EAAME,GAAS,GAAA+yB,GACR/yB,MAAjC8F,EADyCitB,EACzCjtB,KAAM8sB,EADmCG,EACnCH,MAAOJ,EAD4BO,EAC5BP,gBAIlB,IAFA1sB,EAAO2rB,EAAiB3rB,GAEJ,gBAATA,IAA8B,KAATA,EAC9B,KAAM,IAAItC,OAAM,wBAGdgvB,IAAgD,gBAArBA,KAC7BA,EAAmB,GAAI9a,MAAK8a,GAG9B,IAAMzyB,aAAiB4M,mBAAmBimB,GAAS,IAC7CnmB,WAAiBE,mBAAmB7G,GAApC,iBACN,QAAO,EAAA0S,EAAAtW,eAAcpC,EAAM,OAApB,GAA+BC,EAAO0M,EAAStM,QACpDa,SACE0W,KAAQ8a,EAAmBA,EAAiBG,cAAgB,MAKlE,QAASK,GAAsBlzB,EAAMgG,EAAMmtB,GACzC,GAAIA,IAAoBA,EAAgB3P,WAAY,KAAM,IAAI9f,OAAM,6BAEpEsC,GAAO2rB,EAAiB3rB,EAExB,IAAM/F,IAAUkzB,EAAgB7Q,MAAQ8Q,EAAc,GAAKD,EAAgB3P,WAAWvjB,MAAhF,IAAwF+F,CAE9F,OAAOhG,GAAKqU,MAAMgf,WAAWpzB,GAAQ,KAClC+L,MAAM,SAAAzI,GACL,GAAM+vB,GAAc1wB,KAAKmsB,MAAMxrB,EAAM0C,SAC/BstB,EAASD,EAAYC,MAC3B,IAAIA,GAAUA,EAAOnzB,QAA+B,QAArBmzB,EAAO,GAAG5xB,OACvC,MAAO3B,GAAKqU,MAAM2e,iBAChBhtB,KAAMA,EACN8sB,MAAOK,GAAmBA,EAAgB7Q,KAI9C,MAAMiR,KAIL,QAASC,GAAuBxzB,EAAMC,EAAMwzB,GACjD,GAAMpmB,GAAQpN,EAAKqN,MAAM,KAAKsD,OAAO,SAAA8iB,GAAA,MAAiB,KAATA,IAEvCC,EAAuB3zB,EAAKqU,MAAMuf,SAASR,EAAaK,EAE9D,OAAOpmB,GAAMjN,OACTiN,EAAMwmB,OAAO,SAACC,EAAwBJ,GACtC,MAAOI,GACJvzB,KAAK,SAAA4yB,GAAA,MAAmBD,GAAqBlzB,EAAM0zB,EAAMP,MAC3DQ,GACCA,EAGD,QAASI,GAAY/zB,EAAMzC,EAAIyF,EAAM9C,GAC1C,MAAO4xB,GAAS9xB,EAAMgD,EAAM,MAArB,UAAsC6J,mBAAmBtP,GAAO2C,GAGzE,QAAS8zB,GAAoBh0B,EAAMi0B,EAAOh0B,EAAMC,GAC9C,IAAK+zB,GAA0B,YAAjB,mBAAOA,GAAP,YAAAC,EAAOD,IACnB,KAAM,IAAIvwB,OAAM,yBAFqC,IAAAywB,GAKrCj0B,MAAXyyB,EALgDwB,EAKhDxB,QACDrwB,GACJU,MACEwgB,WAAY1lB,OAAO+d,UAEjBoY,GACEjuB,KAAM2rB,EAAiBsC,EAAMjuB,SAIrC,QAAO,EAAA0S,EAAAtW,eAAcpC,EAAM,QAASC,EAAMqC,GACxCpB,SACEkzB,WAAYzB,GAAW,MAKtB,QAAS0B,GAAsBr0B,EAAMzC,EAAI02B,EAAO/zB,GACrD,MAAO8zB,GAAmBh0B,EAAMi0B,EAAzB,UACKpnB,mBAAmBtP,GAAO2C,GAGjC,QAASo0B,GAAwBt0B,EAAMC,EAAMg0B,EAAO/zB,GACzD,MAAO8zB,GAAmBh0B,EAAMi0B,EAAzB,wBACmBpnB,mBAAmB5M,GAASC,GAGjD,QAASq0B,GAAWv0B,EAAMzC,EAAI2C,GACnC,GAAkB,gBAAP3C,IAA0B,KAAPA,EAC5B,KAAM,IAAImG,OAAM,sBAF0B,IAAA8wB,GAI1Bt0B,MAAXyyB,EAJqC6B,EAIrC7B,OACP,QAAO,EAAAja,EAAAtW,eAAcpC,EAAM,SAApB,UAAwC6M,mBAAmBtP,GAAO8C,QACvEa,SACEkzB,WAAYzB,GAAW,MAKtB,QAASiB,GAAU5zB,EAAMzC,GAAkC,GAA9Bk2B,KAA8BtzB,UAAAC,OAAA,GAAAC,SAAAF,UAAA,KAAAA,UAAA,GAAdD,EAAcC,UAAAC,OAAA,GAAAC,SAAAF,UAAA,GAAAA,UAAA,KAChE,IAAIszB,GAAWzzB,EAAKyzB,QAAQgB,YAAb5E,EAAAzb,eAAyC,CACtD,GAAIuV,GAAK3pB,EAAKyzB,QAAQiB,YAAb7E,EAAAzb,cACT,OAAO/S,SAAQC,KACbqoB,EAAGzmB,IAAI3F,GACPosB,EAAGqG,KAAKlyB,OAAO+d,QAAS7M,UAAY2lB,OAAUp3B,IAAQ2C,MACrDK,KAAK,SAAAq0B,GAAqB,GAAAC,GAAAnzB,EAAAkzB,EAAA,GAAnBjsB,EAAmBksB,EAAA,GAAdC,EAAcD,EAAA,EAK3B,OAJIt3B,KAAO61B,IACT0B,EAAS1E,KAAO0E,EAAS1E,KAAKxf,OAAO,SAAAjI,GAAA,MAAOA,GAAI2Z,MAAQyS,KAE1DD,EAAWE,EAAUF,EAAS1E,KAAKxlB,IAAI,SAAAjC,GAAA,MAAOssB,GAASC,EAAUl1B,EAAM2I,OAChEssB,EAASC,EAAUl1B,EAAM2I,EAAKmsB,MAGzC,GAAMnoB,GAAwC,IAAhC7O,OAAO6M,KAAKzK,GAASE,OAAe,GAApC,IAA6C+0B,EAAkBj1B,EAC7E,QAAO,EAAAwY,EAAAtW,eAAcpC,EAAM,MAApB,UAAqC6M,mBAAmBtP,GAAMoP,GAClEpM,KAAK00B,GAGH,QAAS5B,GAAYrzB,EAAMC,GAChC,OAAO,EAAAyY,EAAAtW,eAAcpC,EAAM,MAApB,wBAAmD6M,mBAAmB5M,IAC1EM,KAAK00B,GAGH,QAASG,GAAcp1B,EAAMzC,GAClC,OAAO,EAAAmb,EAAA3Y,WAAUC,EAAV,mBAAmC6M,mBAAmBtP,IAGxD,QAAS83B,GAAgBr1B,EAAMC,GACpC,OAAO,EAAAyY,EAAA3Y,WAAUC,EAAV,wBAAwC6M,mBAAmB5M,IAGpE,QAASq1B,GAA4Bv0B,GACnC,GAAIgb,GAAOhb,EAAImiB,OAASniB,EAAImiB,MAAMqS,OAClC,KAAKxZ,EAAM,KAAM,IAAIrY,OAAM,qCAC3B,OAAOqY,GAGF,QAASyZ,GAAuBx1B,EAAMC,GAC3C,OAAO,EAAAyY,EAAAtW,eAAcpC,EAAM,OAApB,yBAAqD6M,mBAAmB5M,IAC5EM,KAAK+0B,GAGH,QAASG,GAAqBz1B,EAAMzC,GACzC,OAAO,EAAAmb,EAAAtW,eAAcpC,EAAM,OAApB,uBAAmD6M,mBAAmBtP,IAC1EgD,KAAK+0B,GAGH,QAASI,GAAa11B,GAAyB,GAAnB21B,GAAmBx1B,UAAAC,OAAA,GAAAC,SAAAF,UAAA,GAAAA,UAAA,MAARmU,EAAQnU,UAAA,EACpD,KAAKmU,IAAWA,EAAOkP,WACrB,KAAM9f,OAAM,0DAGd,IAAMkyB,GAAathB,EAAOkP,WAAWvjB,KAAK41B,SAAS,KAC/CvhB,EAAOkP,WAAWvjB,KACbqU,EAAOkP,WAAWvjB,KAFR,GAInB,UAAU21B,EAAaD,EAAK3vB,KAGvB,QAAS8vB,GAAwB91B,EAAMzC,EAAIw4B,GAChD,MAAKx4B,IAGE,EAAAmb,EAAAtW,eAAcpC,EAAM,OAApB,4BACLgD,MACE4f,KAAM,sBACNY,YACEwS,aACE3hB,OACEuO,KAAM,gBACNqT,OAAQ,OACR9N,QAAS5qB,GACTyR,SAAU,iBAEZknB,YACEtT,KAAMmT,EACNE,OAAQ,OACR9N,QAAS5qB,SAKhBgD,KAAK,SAAAyC,GAAA,OAAUmzB,uBAAwBnzB,EAAKwgB,WAAW4S,MAAMC,MAAS94B,SAAUA,KArB1E8D,QAAQ8F,OAAOzD,MAAM,oDAwBzB,QAAS4yB,GAAuBt2B,EAAMu2B,GAAuB,GAAhBvwB,GAAgB7F,UAAAC,OAAA,GAAAC,SAAAF,UAAA,GAAAA,UAAA,GAAT,QACnDq2B,GACJ5T,KAAM,mBACNY,YACExd,KAAMA,EACNqO,MAAOkiB,GAGX,QAAO,EAAA7d,EAAAtW,eAAcpC,EAAM,OAApB,kBAA+CgD,KAAMwzB,IAC3Dj2B,KAAK+0B,GAGD,QAASmB,GAAqBz2B,EAAMmwB,GAAqB,GAAhBnqB,GAAgB7F,UAAAC,OAAA,GAAAC,SAAAF,UAAA,GAAAA,UAAA,GAAT,QAC/Cq2B,GACJ5T,KAAM,mBACNY,YACExd,KAAMA,EACNmqB,IAAKA,GAGT,QAAO,EAAAzX,EAAAtW,eAAcpC,EAAM,OAApB,kBAA+CgD,KAAMwzB,IAC3Dj2B,KAAK+0B,GAGD,QAASoB,GAAW12B,GACzB,OAAO,EAAA0Y,EAAAtW,eAAcpC,EAAM,MAApB,gBAGF,QAAS22B,GAAY32B,GAC1B,OAAO,EAAA0Y,EAAAtW,eAAcpC,EAAM,SAApB,gBAGF,QAAS42B,GAAa52B,EAAMzC,GACjC,OAAO,EAAAmb,EAAAtW,eAAcpC,EAAM,OAApB,gBAA4C6M,mBAAmBtP,IAGjE,QAASs5B,GAAa72B,EAAMzC,EAAI2C,GAAS,GAAA42B,GAC5B52B,MAAXyyB,EADuCmE,EACvCnE,OACP,QAAO,EAAAja,EAAAtW,eAAcpC,EAAM,SAApB,gBAA8C6M,mBAAmBtP,GAAO8C,QAC7Ea,SACEkzB,WAAYzB,GAAW,MAK7B,QAASsC,GAAUv2B,GAEjB,MADAA,GAAIq4B,MAAgC,cAAxBr4B,EAAI8kB,WAAWZ,KACpBlkB,EAGT,QAASy2B,GAAmBj1B,GAC1B,GAAIkQ,KACJ,KAAK,GAAMpK,KAAQ9F,GACjBkQ,EAAK7K,KAAL,QAAkBsH,mBAAmB7G,GAArC,KAA+C6G,mBAAmB3M,EAAQ8F,IAE5E,OAAOoK,GAAKc,KAAK,KAGnB,QAASgkB,GAAWl1B,EAAM2I,GAAoB,GAAf+jB,GAAevsB,UAAAC,OAAA,GAAAC,SAAAF,UAAA,GAAAA,UAAA,MACxCsH,EAAQ7E,KAAKmsB,MAAMnsB,KAAKC,UAAU8F,GAGtC,cAFOlB,GAAM6a,UACN7a,GAAM4b,MAEXf,IAAK3Z,EAAI2Z,IACTe,KAAM1a,EAAI0a,KACVD,sBACAI,WAAY/b,EACZkc,eACE+I,UACE1pB,KAAM0pB,EACNpJ,MACE3X,MAAO+gB,EAAStsB,UAItBqjB,UAAW,SAACzd,GACV,GAAa,aAATA,EACF,MAAO0mB,KAMf,QAASsI,GAAWgC,GAClB,GAAMC,GAAUD,EAASpmB,OAAO,SAAAwT,GAAA,MAA2B,cAAtBA,EAAEZ,WAAWZ,OAC5CvO,EAAQ2iB,EAASpmB,OAAO,SAAAwT,GAAA,MAA2B,cAAtBA,EAAEZ,WAAWZ,OAC1C/U,EAAO,SAAAwG,GAAA,MAASA,GAAMxG,KAAK,SAACxP,EAAGC,GAAJ,MAAUD,GAAEmlB,WAAWxd,KAAKkxB,cAAc54B,EAAEklB,WAAWxd,QACxF,OAAO6H,GAAKopB,GAASz4B,OAAOqP,EAAKwG,IxCgyIlCvW,OAAO4G,eAAe5H,EAAS,cAC7B2C,OAAO,IAET3C,EAAQi4B,aAAej4B,EAAQs2B,YAAc/yB,MAE7C,IAAIqB,GAAiB,WAAc,QAASiD,GAAcC,EAAK/G,GAAK,GAAIgH,MAAeC,GAAK,EAAUC,GAAK,EAAWC,EAAK3E,MAAW,KAAM,IAAK,GAAiC4E,GAA7BC,EAAKN,EAAIO,OAAOC,cAAmBN,GAAMG,EAAKC,EAAGG,QAAQC,QAAoBT,EAAKU,KAAKN,EAAGxF,QAAY5B,GAAKgH,EAAKzE,SAAWvC,GAA3DiH,GAAK,IAAoE,MAAOxB,GAAOyB,GAAK,EAAMC,EAAK1B,EAAO,QAAU,KAAWwB,GAAMI,EAAW,QAAGA,EAAW,SAAO,QAAU,GAAIH,EAAI,KAAMC,IAAQ,MAAOH,GAAQ,MAAO,UAAUD,EAAK/G,GAAK,GAAI2H,MAAMC,QAAQb,GAAQ,MAAOA,EAAY,IAAIO,OAAOC,WAAYtH,QAAO8G,GAAQ,MAAOD,GAAcC,EAAK/G,EAAa,MAAM,IAAImB,WAAU,4DAEllBk1B,EAA4B,kBAAX/uB,SAAoD,gBAApBA,QAAOC,SAAwB,SAAU1G,GAAO,aAAcA,IAAS,SAAUA,GAAO,MAAOA,IAAyB,kBAAXyG,SAAyBzG,EAAIc,cAAgB2F,QAAUzG,IAAQyG,OAAOpH,UAAY,eAAkBW,GAGtQ5B,GwCvlJeyC,SxCwlJfzC,EwCjkJek2B,kBxCkkJfl2B,EwCthJe02B,wBxCuhJf12B,EwC1gJei3B,axC2gJfj3B,EwCj/Ieu3B,uBxCk/Ifv3B,EwC7+Iew3B,yBxC8+Ifx3B,EwCz+Iey3B,YxC0+Ifz3B,EwC99Ie82B,WxC+9If92B,EwC58Ieu2B,axC68Ifv2B,EwCx8Ies4B,exCy8Ift4B,EwCr8Ieu4B,iBxCs8Ifv4B,EwC57Ie04B,wBxC67If14B,EwCx7Ie24B,sBxCy7If34B,EwCp7Ie44B,cxCq7If54B,EwCz6Ieg5B,yBxC06Ifh5B,EwCh5Iew5B,wBxCi5Ifx5B,EwCr4Ie25B,sBxCs4If35B,EwC13Ie45B,YxC23If55B,EwCv3Ie65B,axCw3If75B,EwCp3Ie85B,cxCq3If95B,EwCj3Ie+5B,aA/UhB,IAAAne,GAAAtb,EAAA,GACAsI,EAAAtI,EAAA,IxCqsJKuG,EAAYlF,EAAuBiH,GwCpsJxCmqB,EAAAzyB,EAAA,GAGag2B,gBAAc,yBACd2B,iBAAe,0BAEtBnC,EAAyB,4BxCwmKzB,SAAS71B,EAAQD,EAASM,GAE/B,YAqDA,SAAS+5B,GAAwBz4B,GAAO,GAAIA,GAAOA,EAAIC,WAAc,MAAOD,EAAc,IAAI04B,KAAa,IAAW,MAAP14B,EAAe,IAAK,GAAImK,KAAOnK,GAAWZ,OAAOC,UAAUC,eAAeP,KAAKiB,EAAKmK,KAAMuuB,EAAOvuB,GAAOnK,EAAImK,GAAgC,OAAtBuuB,GAAOx4B,QAAUF,EAAY04B,EAElQ,QAASv4B,GAAgBC,EAAUC,GAAe,KAAMD,YAAoBC,IAAgB,KAAM,IAAIC,WAAU,qCyC53JjH,QAASq4B,KACP,KAAM,IAAI3zB,OAAM,iCAGlB,QAAS4zB,GAAUC,EAASn5B,GAC1B,MAAO,YAA8B,OAAA2M,GAAA5K,UAAAC,OAANlC,EAAMsH,MAAAuF,GAAAC,EAAA,EAAAA,EAAAD,EAAAC,IAAN9M,EAAM8M,GAAA7K,UAAA6K,EACnC,OAAO5M,iBAAGm5B,GAAH/4B,OAAeN,KAI1B,QAASs5B,GAAYC,EAAK/4B,EAAKg5B,EAAOC,GACpC,IAAK,GAAMC,KAAQF,GAAO,CACxB,GAAIt5B,GAAKk5B,EAASG,EAAKC,EAAME,GACzBD,KACFv5B,GAAK,EAAA0D,EAAAgJ,YAAW1M,IAElBM,EAAIk5B,GAAQx5B,GzCuzJf,GAAIse,GAAe,WAAc,QAASC,GAAiBC,EAAQC,GAAS,IAAK,GAAIhf,GAAI,EAAGA,EAAIgf,EAAMzc,OAAQvC,IAAK,CAAE,GAAIif,GAAaD,EAAMhf,EAAIif,GAAWpd,WAAaod,EAAWpd,aAAc,EAAOod,EAAWld,cAAe,EAAU,SAAWkd,KAAYA,EAAWnd,UAAW,GAAM7B,OAAO4G,eAAekY,EAAQE,EAAWjU,IAAKiU,IAAiB,MAAO,UAAU/d,EAAage,EAAYC,GAAiJ,MAA9HD,IAAYJ,EAAiB5d,EAAYhB,UAAWgf,GAAiBC,GAAaL,EAAiB5d,EAAaie,GAAqBje,KyCpnKjiB3B,GAAA,GACA,IAAA0E,GAAA1E,EAAA,GACAy6B,EAAAz6B,EAAA,IACA4E,EAAA5E,EAAA,IACA06B,EAAA16B,EAAA,GAAY26B,EzC6nKAZ,EAAwBW,GyC5nKpCE,EAAA56B,EAAA,IAAY4F,EzCgoKAm0B,EAAwBa,GyC/nKpCtf,EAAAtb,EAAA,GAAY2C,EzCmoKKo3B,EAAwBze,GyCloKzCuf,EAAA76B,EAAA,IAAY86B,EzCsoKCf,EAAwBc,GyCroKrCE,EAAA/6B,EAAA,IAAYiX,EzCyoKC8iB,EAAwBgB,GyCxoKrCC,EAAAh7B,EAAA,IAAYi7B,EzC4oKGlB,EAAwBiB,GyC3oKvCE,EAAAl7B,EAAA,IAAYm7B,EzC+oKApB,EAAwBmB,GyC9oKpCE,EAAAp7B,EAAA,IAAYq2B,EzCkpKG0D,EAAwBqB,GyCjpKvCC,EAAAr7B,EAAA,IAAYs7B,EzCqpKIvB,EAAwBsB,GyCppKxCE,EAAAv7B,EAAA,IAAYqmB,EzCwpKK0T,EAAwBwB,GyCrpK7BC,EAGRb,EAHFtb,SACaoc,EAEXd,EAFFvc,YACQsd,EACNf,EADFzf,OAGIygB,EAAW,EACXC,EAAc,EACdC,EAAY,EACZC,EAAS,EAETC,GACJhc,WAAY,kCAGRic,GACJ75B,OAAQyD,EAAKzD,OACbywB,KAAMhtB,EAAKgtB,KACXE,SAAUltB,EAAKktB,SACfc,QAAShuB,EAAKguB,QACd3oB,OAAQrF,EAAKqF,OACbsT,OAAQ3Y,EAAK0uB,QACbF,iBAAkBxuB,EAAKwuB,iBACvBF,YAAatuB,EAAKsuB,YAClB+H,YAAanB,EAAMmB,YACnB1sB,MAAOurB,EAAMvrB,MACb2sB,mBAAoB7V,EAAU6V,mBAC9BC,sBAAuB9V,EAAU8V,sBACjCC,oBAAqB/V,EAAU+V,oBAC/BC,qBAAsBhW,EAAUgW,qBAChCrM,QAAS,WAEP,OADA,EAAAtrB,EAAA2C,MAAK,wDACEzB,EAAK0uB,QAALnzB,MAAAyE,EAAA7C,aAILu5B,GACJ73B,OAAQk2B,EAAKl2B,OACb0W,eAAgBwf,EAAKxf,eACrBK,aAAcmf,EAAKnf,aACnBO,iBAAkB4e,EAAK5e,iBACvBC,UAAW2e,EAAK3e,UAChBK,eAAgBse,EAAKte,eACrBS,eAAgB6d,EAAK7d,eACrBjY,aAAc81B,EAAK91B,cAGf03B,GACJp6B,OAAQ8U,EAAM9U,OACdyzB,gBAAiB3e,EAAM2e,gBACvBQ,sBAAuBnf,EAAMmf,sBAC7BO,WAAY1f,EAAM0f,WAClBM,qBAAsBhgB,EAAMggB,qBAC5BC,uBAAwBjgB,EAAMigB,uBAC9BC,UAAWlgB,EAAMkgB,UACjBX,SAAUvf,EAAMuf,SAChBP,WAAYhf,EAAMgf,WAClB+B,aAAc/gB,EAAM+gB,aACpBC,eAAgBhhB,EAAMghB,eACtBI,oBAAqBphB,EAAMohB,oBAC3BmE,gBAAiBvlB,EAAMmhB,sBACvBA,sBAAuBnhB,EAAMmhB,sBAC7BqE,eAAgB,WAEd,OADA,EAAA/3B,EAAA2C,MAAK,+EACE4P,EAAMiiB,sBAAN/3B,MAAA8V,EAAAlU,YAETm2B,sBAAuBjiB,EAAMiiB,sBAC7BG,oBAAqBpiB,EAAMoiB,oBAC3Bf,YAAarhB,EAAMqhB,YACnBI,uBAAwBzhB,EAAMyhB,uBAC9BnpB,MAAOurB,EAAM4B,WACbpD,UAAWriB,EAAMqiB;AACjBC,WAAYtiB,EAAMsiB,WAClBC,YAAaviB,EAAMuiB,YACnBC,YAAaxiB,EAAMwiB,aAGfkD,GACJx6B,OAAQ84B,EAAQ94B,OAChBy6B,cAAe3B,EAAQ2B,cACvBC,kBAAmB5B,EAAQ4B,kBAC3BC,SAAU7B,EAAQ6B,UAGdC,GACJ56B,OAAQg5B,EAAKh5B,OACboM,MAAO4sB,EAAK5sB,MACZyuB,OAAQ7B,EAAK6B,QAGTC,GACJC,KAAM7G,EAAQ6G,KACdC,YAAa9G,EAAQ8G,YAErB9F,YAAahB,EAAQgB,YACrBC,YAAajB,EAAQiB,YACrB8F,eAAgB/G,EAAQ+G,eACxBC,gBAAiBhH,EAAQgH,gBACzBC,mBAAoBjH,EAAQiH,mBAE5BC,eAAgBlH,EAAQkH,eACxBC,kBAAmBnH,EAAQmH,kBAC3BC,gBAAiBpH,EAAQoH,gBACzBC,mBAAoBrH,EAAQqH,mBAE5BC,uBAAwBtH,EAAQsH,uBAChCC,yBAA0BvH,EAAQuH,yBAClCC,wBAAyBxH,EAAQwH,wBACjCC,2BAA4BzH,EAAQyH,4BAGhCC,GACJC,UAAW1C,EAAS0C,UACpBC,iBAAkB3C,EAAS2C,iBAC3BC,YAAa5C,EAAS4C,YACtBC,eAAgB7C,EAAS6C,eACzBC,WAAY9C,EAAS8C,WACrBC,iBAAkB/C,EAAS+C,iBAC3BC,eAAgBhD,EAASgD,gBAGrBC,EAA0B,SAAA1hB,GAC9B,GAAM/V,GAAM,GAAI03B,KAAI3hB,EAQpB,OAPI/V,GAAI23B,eAAiB33B,EAAI23B,aAAaC,IAAI,aAC5C53B,EAAI23B,aAAatP,OAAO,YAAa,GAC3BroB,EAAI63B,QAAU73B,EAAI63B,OAAO54B,QAAQ,gBAAiB,IAG5De,EAAI63B,OAAS73B,EAAI63B,OAAS,gBAErB73B,EAAI+S,YAGPqB,EzC2pKQ,WyC1pKZ,QAAAA,GAAapY,GAASrB,EAAA3B,KAAAob,GACpBpb,KAAK8F,QACL9F,KAAKmX,SACLnX,KAAKm7B,WACLn7B,KAAKq7B,QACLr7B,KAAKu2B,WACLv2B,KAAKw7B,YACLx7B,KAAK66B,MACHzf,OAAQwgB,EACRtd,YAAaqd,EACbpc,SAAUmc,EACVoD,sBACAvN,4BACAS,+BAEFhyB,KAAK++B,SAAU,EACX/7B,GACFhD,KAAKo9B,KAAKp6B,GzCgzKb,MA/IAwc,GAAapE,IACXzP,IAAK,OACLpJ,MAAO,WyC/pKU,GAAdS,GAAcC,UAAAC,OAAA,GAAAC,SAAAF,UAAA,GAAAA,UAAA,KAClBjD,MAAK++B,SAAU,EACf/+B,KAAKg/B,QAAS,EACdh/B,KAAKi/B,OAAS,KACdj/B,KAAKk/B,WAAarD,EAClB77B,KAAKm/B,WAAa,KAClBn/B,KAAKo/B,SAAW,KAChBp/B,KAAKq/B,SAAWr8B,EAAQgT,SAAW,KACnChW,KAAKs7B,SAAW,IAEhB,IAAMr3B,GAAQjB,EAAQiB,MAChBq7B,EAAQt8B,EAAQs8B,KACtB,IAAIr7B,GAASq7B,EACX,KAAM,IAAI94B,OAAM,6DAGdvC,GACFjE,KAAKi/B,OAAS,GAAIvD,IAAaz3B,UACtBq7B,IACTt/B,KAAKg/B,QAAS,EACdh/B,KAAKo/B,SAAWE,EAAM7hB,QACtBzd,KAAKmb,cAAgBva,OAAO+d,UAAWsd,EAAqBqD,EAAMpkB,cAClElb,KAAKu/B,cAAgBD,EAAM5hB,cAAgByc,EAI7C,KADA,GAAInzB,GAAMhE,EAAQw8B,SAAW,GACE,MAAxBx4B,EAAIA,EAAI9D,OAAS,IACtB8D,EAAMA,EAAI/F,MAAM,GAAG,EAGrBjB,MAAK+c,KAAO/V,EAEZhH,KAAK+D,0BAA4DZ,SAAhCH,EAAQy8B,oBAAoCz8B,EAAQy8B,oBAAsB58B,EAAU6D,uBAErH,IAAM+zB,KAAoBz3B,EAAQy3B,eAClCH,GAAWt6B,KAAMA,KAAK8F,KAAMo2B,EAAWzB,GACvCH,EAAWt6B,KAAMA,KAAK66B,KAAM2B,EAAW/B,GACvCH,EAAWt6B,KAAMA,KAAKmX,MAAOslB,EAAYhC,GACzCH,EAAWt6B,KAAMA,KAAKm7B,QAAS0B,EAAcpC,GAC7CH,EAAWt6B,KAAMA,KAAKq7B,KAAM4B,EAAWxC,GACvCH,EAAWt6B,KAAMA,KAAKu2B,QAAS4G,EAAc1C,GAC7CH,EAAWt6B,KAAMA,KAAKw7B,SAAUyC,EAAexD,GAE3Cz3B,EAAQuzB,SACVv2B,KAAKu2B,QAAQ6G,KAAKp6B,EAAQuzB,SAI5Bv2B,KAAKsF,UAAY,WACf,GAAMtE,IAAQhB,MAAMsB,OAAOgH,MAAMzH,UAAUI,MAAMV,KAAK0C,WACtD,OAAOJ,GAAUqC,cAAc7D,MAAMrB,KAAMgB,OzCqqK5C2K,IAAK,YACLpJ,MAAO,WyClqK4B,GAAAoG,GAAA3I,KAA3B0/B,EAA2Bz8B,UAAAC,OAAA,GAAAC,SAAAF,UAAA,IAAAA,UAAA,GAC9BwZ,EAAQzc,KAAKk/B,UACnB,OAAIziB,KAAUuf,GAAUvf,IAAUqf,EACzB97B,KAAKm/B,YAGdn/B,KAAKk/B,WAAapD,EAClB97B,KAAKm/B,WAAan/B,KAAKqE,OAAOhB,KAAK,SAACgB,GAClC,GAAIA,GAAQsE,EAAKq2B,OACf,KAAM,IAAIx4B,OAAM,yCAElB,IAAImC,EAAKq2B,OAIP,MAHIU,IAAqB/2B,EAAKwS,cAAcyB,cAC1CjU,EAAKwS,cAAcyB,YAAc6hB,EAAwB91B,EAAKwS,cAAcyB,cAEvEie,EAAKrd,UAAL7U,EAELA,EAAKy2B,SACLz2B,EAAKwS,cACLxS,EAAK42B,cACLG,EAKJ,IAAIr7B,EACF,OAAO,EAAAS,EAAAotB,cACF,IAAIvpB,EAAKs2B,OACd,MAAO96B,SAAQoK,SAAS5J,OAAQ,KAAMV,MAAO0E,EAAKs2B,QAElD,MAAM,IAAIz4B,OAAM,+BAIpBxG,KAAKm/B,WAAW97B,KACd,WAAQsF,EAAKu2B,WAAalD,GAC1B,WAAQrzB,EAAKu2B,WAAanD,IAErB/7B,KAAKm/B,ezCqqKXxzB,IAAK,kBACLpJ,MAAO,SyCnqKOoC,EAAQV,GACvB,GAAMya,IAAS/Z,SAAQV,QACvB,OAAKjE,MAAKo/B,UAAYp/B,KAAKk/B,aAAepD,GAG1C97B,KAAKo/B,SAASphB,KAAK6c,EAAKzc,SAAUM,GAClC1e,KAAKm/B,WAAah7B,QAAQoK,QAAQmQ,GAC3B1e,KAAKm/B,YAJHh7B,QAAQoK,QAAQmQ,MzC0qKxB/S,IAAK,WACLpJ,MAAO,SyCpqKAQ,GAAM,GAAA2uB,GAAA1xB,IACd,OAAOA,MAAKqE,OAAOhB,KAAK,SAACgB,GACvB,GAAMs7B,GAAat7B,EAAO,UAAY,EACtC,OAAOqtB,GAAK3U,KAAO4iB,EAAa58B,OzC0qKjC4I,IAAK,OACLpJ,MAAO,WyCvqKF,GAAAuvB,GAAA9xB,IACN,OAAKA,MAAKq/B,SAcHl7B,QAAQoK,QAA0B,IAAlBvO,KAAKq/B,WAbnB,EAAAz6B,EAAAC,OAAM,iBAAMrB,OAASsuB,EAAK/U,KAAd,aAA+B,KAC/C1Z,KAAK,SAACQ,GACL,GAAKA,EAAIgC,GAGP,MAAOhC,GAAIqC,MAFX,MAAM,IAAIM,OAAM,iCAKnBnD,KAAK,SAACoB,GAEL,MADAqtB,GAAKuN,SAAiCl8B,SAAtBsB,EAAOm7B,WAA2B,EAAI,EAC/C9N,EAAKztB,azCgrKZ+W,IyCrpKVvb,GAAOD,QAAU,GAAIwb,GACrBxa,OAAO+d,OAAO9e,EAAOD,SAAUwb,SAAQmW,4BAAcS,iCzCorK/C,SAASnyB,EAAQD,EAASM,GAE/B,YAgHA,SAASqB,GAAuBC,GAAO,MAAOA,IAAOA,EAAIC,WAAaD,GAAQE,QAASF,GAEvF,QAASq+B,GAAkB3+B,GAAM,MAAO,YAAc,GAAI4+B,GAAM5+B,EAAGG,MAAMrB,KAAMiD,UAAY,OAAO,IAAIkB,SAAQ,SAAUoK,EAAStE,GAAU,QAAS81B,GAAKp0B,EAAKq0B,GAAO,IAAM,GAAIC,GAAOH,EAAIn0B,GAAKq0B,GAAUz9B,EAAQ09B,EAAK19B,MAAS,MAAO8D,GAAwB,WAAf4D,GAAO5D,GAAkB,MAAI45B,GAAK73B,SAAQmG,GAAQhM,GAAwB4B,QAAQoK,QAAQhM,GAAOc,KAAK,SAAUd,GAASw9B,EAAK,OAAQx9B,IAAW,SAAU6D,GAAO25B,EAAK,QAAS35B,KAAc,MAAO25B,GAAK,W0CplL1b,QAASG,GAAel5B,EAAKmG,EAASilB,EAAQtsB,EAAMq6B,GAClD,GAAMle,GAAW9U,EAAQizB,aACzB,KAAKne,EAAU,KAAM,IAAIzb,OAAM,qDAE/B,IAAMI,GAASqb,EAASoe,WACxB,KAAKz5B,EAAQ,KAAM,IAAIJ,OAAM,8CAE7B,IAAM85B,GAASre,EAASM,cAAc,SAEP,mBAApB4d,KAAgCG,EAAOC,OAASJ,GAE3DG,EAAOE,aAAa,MAAOx5B,GAC3Bs5B,EAAOG,UAAU5c,IAAI6c,GACrBvzB,EAAQ0V,YAAYyd,GACpBA,EAAOK,OAGP,IAAMC,GAAgB55B,EAAIoJ,MAAM,IAAK,GAAG4D,KAAK,IAE7C,OAAO,IAAI7P,SAAQ,SAACoK,EAAStE,GAC3B,GAAI42B,IAAa,EACXC,EAAiB,QAAjBA,GAAkBxpB,GACtB,GAAIA,EAAMxQ,SAAW85B,EAArB,CAEA,GAAMG,GAAYzpB,EAAMxR,KAAK4f,IAC7B,IAAkB,SAAdqb,EAIF,YADAz5B,QAAQC,MAAQD,QAAQC,KAAK,6DAI/B,IAAIw5B,cAAwB3O,EAAOhN,IAA/B,SAEF,MADAyb,IAAa,EACNvpB,EAAM0pB,OAAO9d,YAAYpd,EAAMwR,EAAMxQ,OAG9C,IAAI+5B,GAAcE,cAAwB3O,EAAOhN,IAA/B,UAMhB,OALC,QAAS,SAAU,WAAY,aAAavT,QAAQ,SAAAovB,GAC/C3pB,EAAMxR,KAAKo7B,aAAY/zB,EAAQua,MAAMwZ,WAAa5pB,EAAMxR,KAAKo7B,YAC7D5pB,EAAMxR,KAAKq7B,WAAWF,KAAO9zB,EAAQua,MAAMuZ,GAAW3pB,EAAMxR,KAAKq7B,WAAWF,GAA/C,SAG5B,CAGTr6B,GAAO4rB,oBAAoB,UAAWsO,EACtC,IAAMM,GAAoB,WAExBd,EAAO5d,YAAc4d,EAAO5d,WAAWC,YAAY2d,GAGrD,OAAIO,IAAcE,cAAwB3O,EAAOhN,IAA/B,sBACT7W,GAAS6yB,oBAAmB31B,IAAK6L,EAAMxR,KAAKmc,YAGrDmf,IAEIL,cAAwB3O,EAAOhN,IAA/B,SACKnb,EAAOo3B,EAAgBC,YAAYhqB,EAAMxR,KAAKO,QAGnDw6B,GAAcE,cAAwB3O,EAAOhN,IAA/B,UACT7W,EAAQ,MAGbsyB,GAAcE,cAAwB3O,EAAOhN,IAA/B,QACT7W,EAAQ+I,EAAMxR,KAAKmc,UAGvB4e,EAAL,OACS52B,EAAO,GAAIzD,OAAM,uDAW5BI,GAAO6rB,iBAAiB,UAAWqO,KAQvC,QAASS,GAAanP,EAAQoP,GAC5B,GAAMC,GAAWrP,EAAO9L,WAAWmb,SAC7BC,EAAmBF,GACpBC,OAAgB/tB,OAAO8tB,GACxBC,CACJ,OAAOjR,GAAMkR,GAGR,QAASr/B,GAAQS,EAAMuvB,EAAQ3M,GAAmC,GAA7B5f,GAA6B7C,UAAAC,OAAA,GAAAC,SAAAF,UAAA,GAAAA,UAAA,MAAlB61B,EAAkB71B,UAAAC,OAAA,GAAAC,SAAAF,UAAA,GAAAA,UAAA,KACvE,KAAKovB,EAAQ,KAAM,IAAI7rB,OAAJ,uDACnB,KAAKkf,EAAM,KAAM,IAAIlf,OAAJ,qDAEjB,IAAMm7B,IAAgB,EAAAnmB,EAAAtW,eAAcpC,EAAM,OAAQ,YAChDgD,MACE4f,KAAM,kBACNY,YACE+L,OAAQA,EACR3M,KAAMA,EACN5f,KAAMA,EACNgzB,YAAaA,KAmBnB,OAdA6I,GAAcC,MAAQ,SAACz0B,EAASgzB,GAC9B,MAAOwB,GAAct+B,KAAK,SAAA+uB,GACxB,GAAMyP,GAAUN,EAAYnP,EAAQtsB,EAAK07B,gBACnCM,EAAWlhC,OAAO+d,UAAW7Y,EAGnC,cAFOg8B,GAASN,eAEXK,EAIE3B,EAAc2B,EAAQhjB,KAAM1R,EAASilB,EAAQ0P,EAAU3B,GAHrDh8B,QAAQ8F,OAAO,GAAIzD,OAAM,gCAO/Bm7B,EAGT,QAASI,GAAkB3P,EAAQxrB,GACjC,MAAO,IAAIzC,SAAQ,SAACoK,EAAStE,GAC3B,GAAM+3B,GAAuB,QAAvBA,GAAwB1qB,GACxBA,EAAMxQ,SAAWsrB,EAAO9L,WAAW3hB,SAEvCiC,EAAO4rB,oBAAoB,UAAWwP,GACtCzzB,EAAQ+I,EAAMxR,OAGhBc,GAAO6rB,iBAAiB,UAAWuP,GACnCp7B,EAAOurB,OAAOjP,aACZwC,eAAgB0M,EAAOhN,IAAvB,UACCgN,EAAO9L,WAAW3hB,UAKlB,QAASm4B,GAAeh6B,EAAMm/B,EAAUC,GAE7C,GADAA,EAAgBA,GAAmC,mBAAXt7B,SAA0BA,QAC7Ds7B,EAAe,KAAM,IAAI17B,OAAM,2CAGpC,IADAy7B,EAAWA,GAAYC,EAAcr7B,SAASg4B,OAAOzuB,MAAM,KAAK,IAC3D6xB,EAAU,KAAM,IAAIz7B,OAAM,kCAE/B,QAAO,EAAAgV,EAAAtW,eAAcpC,EAAM,MAApB,YAAuCm/B,GAC3C5+B,KAAK,SAAA+uB,GACJ,GAAI+P,IAAa,EAEXC,EAAY,SAACr5B,GACjB,GAAIo5B,EAAY,KAAM,IAAI37B,OAAM,6CAChC27B,IAAa,EACbD,EAAc/P,OAAOjP,YAAYna,EAASqpB,EAAO9L,WAAW3hB,SAGxD09B,EAAe,SAAClB,EAAYmB,GAChC,GAAIH,EAAY,KAAM,IAAI37B,OAAM,qCAEhC,IAAMuC,IACJ2c,eAAgB0M,EAAOhN,IAAvB,UAEA+b,WAAYA,EAAWh0B,QACnBvM,OAAO+d,UAAWwiB,GAClBoB,UAAWpB,EAAWh0B,QAAQq1B,aAC9BC,SAAUtB,EAAWh0B,QAAQu1B,cAE3BvB,EACND,WAAYoB,EAGdJ,GAAc/P,OAAOjP,YAAYna,EAASqpB,EAAO9L,WAAW3hB,SAGxD0F,EAAS,WACb+3B,GAAW1c,eAAgB0M,EAAOhN,IAAvB,YASb,OAJA8c,GAAczP,iBAAiB,SAAU,WAClC0P,GAAY93B,MAGZ03B,EAAiB3P,EAAQ8P,GAC7B7+B,KAAK,SAAAyC,GACJ,OACE68B,QAAS,iBAAM78B,IACf88B,UAAW,iBAAMxQ,IACjBgQ,UAAW,SAAC32B,GACV,GAAMo3B,GAAa/8B,GAAQA,EAAKg9B,yBAC5B,qBAAuB,MAE3B,OAAOV,IACL1c,eAAgB0M,EAAOhN,IAAvB,IAA8Byd,EAC9B5gB,SAAUxW,KAGds3B,MAAO,SAAA18B,GAAA,MAAS+7B,IACd1c,eAAgB0M,EAAOhN,IAAvB,SACA/e,MAAOg7B,EAAgB2B,UAAU38B,MAEnCg8B,aAAcA,EACdh4B,OAAQA,OA4BpB,QAAS44B,GAAgB1gC,GACvB,QAAS,SAAU,YAAY2gC,SAAvB,mBAAuC3gC,GAAvC,YAAAy0B,EAAuCz0B,IAGjD,QAAS4gC,GAAqBn8B,EAAKlB,GACjC,GAAMs9B,GAAmBxiC,OAAO6M,KAAK3H,GAClC4N,OAAO,SAAA/H,GAAA,MAAOs3B,GAAen9B,EAAK6F,MAClC+B,IAAI,SAAA/B,GAAA,MAAUA,GAAV,IAAiB7F,EAAK6F,IAE7B,OAAOy3B,GAAiBlgC,OAAY8D,EAA7B,IAAoCo8B,EAAiBpvB,KAAK,KAAShN,E1C2uK3EpG,OAAO4G,eAAe5H,EAAS,cAC7B2C,OAAO,IAET3C,EAAQo9B,SAAWp9B,EAAQm9B,kBAAoB55B,MAE/C,IAAIkgC,GAAenjC,EAAoB,IAEnCojC,EAAgB/hC,EAAuB8hC,GAEvCrM,EAA4B,kBAAX/uB,SAAoD,gBAApBA,QAAOC,SAAwB,SAAU1G,GAAO,aAAcA,IAAS,SAAUA,GAAO,MAAOA,IAAyB,kBAAXyG,SAAyBzG,EAAIc,cAAgB2F,QAAUzG,IAAQyG,OAAOpH,UAAY,eAAkBW,IAMlQu7B,EAAoBn9B,EAAQm9B,kBAAoB,WAClD,GAAIz4B,GAAOu7B,EAAgCyD,EAAc5hC,QAAQ6hC,K0CtxK7D,QAAAC,GAAkC1gC,EAAM4iB,EAAM5f,GAA9C,GAAAssB,GAAAyP,EAAA4B,EAAAC,CAAA,OAAAJ,GAAA5hC,QAAAiiC,KAAA,SAAAC,GAAA,cAAAA,EAAAC,KAAAD,EAAAz7B,MAAA,UACAud,GAAS5f,EADT,CAAA89B,EAAAz7B,KAAA,aACqB,IAAI3B,OAAJ,qEADrB,cAAAo9B,GAAAz7B,KAAA,EAGgB9F,EAAOS,EAAM,WAAY4iB,EAAM5f,EAH/C,WAGCssB,EAHDwR,EAAAE,KAKCjC,EAAUN,EAAYnP,GALvB,CAAAwR,EAAAz7B,KAAA,aAMe,IAAI3B,OAAM,2BANzB,cAYCi9B,GAAU5B,EAAQhjB,KAAKzO,MAAM,KAAK,GAElCszB,EAAeD,EAAQx8B,QAAQ,MAAO,KAdvC28B,EAAAG,OAAA,SAeEj+B,EAAOq9B,EAAoBO,EAAc59B,GAAQ49B,EAfnD,yBAAAE,GAAAI,SAAAR,EAAAxjC,Q1Cs0KJ,OAAO,UAA2BikC,EAAKC,EAAKC,GAC1C,MAAO7/B,GAAKjD,MAAMrB,KAAMiD,cAIbrD,GAAQo9B,SAAW,WAChC,GAAIz4B,GAAQs7B,EAAgCyD,EAAc5hC,QAAQ6hC,K0C9yK9D,QAAAa,GAAyBthC,EAAM4iB,EAAMja,GAArC,GAAA44B,EAAA,OAAAf,GAAA5hC,QAAAiiC,KAAA,SAAAW,GAAA,cAAAA,EAAAT,KAAAS,EAAAn8B,MAAA,UACAvB,OADA,CAAA09B,EAAAn8B,KAAA,aACc,IAAI3B,OAAM,oDADxB,cAAA89B,GAAAn8B,KAAA,EAEwB40B,EAAkBj6B,EAAM4iB,EAAMja,EAFtD,QAEC44B,EAFDC,EAAAR,KAGLl9B,OAAOC,SAASgY,KAAOwlB,CAHlB,wBAAAC,GAAAN,SAAAI,EAAApkC,Q1C40KJ,OAAO,UAAkBukC,EAAKC,EAAKC,GACjC,MAAOlgC,GAAMlD,MAAMrB,KAAMiD,cAI7BrD,G0C3+KeyC,S1C4+KfzC,E0C17Kek9B,eA3KhB,IAAAthB,GAAAtb,EAAA,GAEMwgC,EAAc,aAGdW,EAAmB,WACvB,QAASqD,GAAoBC,EAAMC,GACjC,GAAMx6B,GAASxJ,OAAO+d,OAAOimB,EAAID,GAC3BE,GAAoB,OAAQ,UAClC,OAAOA,GAAiBlO,OAAO,SAACvsB,EAAQ06B,GAItC,MAHIH,GAAKG,KACPF,EAAGE,GAAYH,EAAKG,IAEf16B,GACNA,GAEL,OACE44B,UAAW,SAAC38B,GAAD,MAAWq+B,GAAmBr+B,OACzCi7B,YAAa,SAACx7B,GAAD,MAAU4+B,GAAmB5+B,EAAM,GAAIU,OAAMV,EAAKiD,eA2F7DynB,EAAQ,SAAA9oB,GAAA,MAAOA,IAAOA,EAAI,K1CswL1B,SAAS7H,EAAQD,EAASM,GAE/B,Y2Cn3LM,SAASuO,GAAO3L,EAAMiiC,GAC3B,OAAO,EAAAvpB,EAAAtW,eAAcpC,EAAM,MAApB,eAA0CiiC,GAC9C1hC,KAAK,SAAAyC,GAAA,MAAQA,GAAK5C,SAGhB,QAASg6B,GAAQp6B,EAAMiiC,GAC5B,OAAO,EAAAvpB,EAAAtW,eAAcpC,EAAM,MAApB,eAA0CiiC,GAG5C,QAAS1iC,GAAQS,EAAMiiC,EAAY/jC,EAAMgC,GAC9C,OAAO,EAAAwY,EAAAtW,eAAcpC,EAAM,OAApB,eAA2CiiC,GAChDj/B,MACE4f,KAAM,eACNY,YACErjB,UAAWjC,MACXgC,QAASA,U3Cs2LhBpC,OAAO4G,eAAe5H,EAAS,cAC7B2C,OAAO,IAET3C,E2Cx3Le6O,Q3Cy3Lf7O,E2Cp3Les9B,S3Cq3Lft9B,E2Cj3LeyC,QAXhB,IAAAmZ,GAAAtb,EAAA,I3Cw5LM,SAASL,EAAQD,EAASM,GAE/B,YAuBA,SAAS8kC,GAAgBxjC,EAAKmK,EAAKpJ,GAAiK,MAApJoJ,KAAOnK,GAAOZ,OAAO4G,eAAehG,EAAKmK,GAAOpJ,MAAOA,EAAOC,YAAY,EAAME,cAAc,EAAMD,UAAU,IAAkBjB,EAAImK,GAAOpJ,EAAgBf,E4C76LrM,QAAS26B,GAAar5B,EAAM0M,EAASxD,GAC1C,MAAOlJ,GAAKuB,OAAOhB,KAAK,SAACgB,GAEvB,GADAmL,GAAU,EAAAmjB,EAAA9b,kBAAiB/T,EAAMuB,EAAMmL,IAClClH,MAAMC,QAAQyD,IAA6B,IAAlBA,EAAO9I,OACnC,KAAM,IAAIsD,OAAM,iDAElB,OAAInC,GACK4gC,EAAcniC,EAAM0M,EAASxD,GAE7Bk5B,EAAcpiC,EAAM0M,EAASxD,KAKnC,QAASyD,GAAO3M,EAAMqiC,EAAUniC,GACrC,MAAOF,GAAKuB,OAAOhB,KAAK,SAACgB,GACvB,IAAK8gC,EACH,KAAM,IAAI3+B,OAAM,sCAElB,OAAInC,GACK+gC,EAAQtiC,EAAMqiC,EAAUniC,GAExBqiC,EAAQviC,EAAMqiC,EAAUniC,KAK9B,QAAS45B,GAAY95B,EAAMqiC,EAAUniC,GAC1C,GAAMkQ,GAAOoyB,EAAaH,EAAUniC,EACpC,QAAO,EAAAwY,EAAA/V,kBAAiB3C,EAAM,OAAQ,eAAgBoQ,GACnD7P,KAAK,SAACkC,GAAD,MAAcvC,GAAQuiC,cAAgBhgC,EAAWA,EAAS2tB,OAoBpE,QAAS+R,GAAeniC,EAAM0M,EAASxD,GACrC,GAAIw5B,GAAY,KAAOx5B,EAAO0B,IAAI+3B,GAAYzxB,KAAK,IAC/C0xB,GAAoBh4B,IAAKi4B,EAAgBn2B,EAASxD,GAAS2qB,OAAQ,UACnE5zB,cAAmByM,EAAnB,IAA8Bg2B,EAA9B,GACJ,QAAO,EAAAhqB,EAAAtW,eAAcpC,EAAM,MAAOC,EAAM2iC,GACrCriC,KAAK,kBAASmM,QAASA,EAASkW,KAAM,YAAa5c,KAAM08B,EAAWx5B,OAAQA,KAGjF,QAASk5B,GAAepiC,EAAM0M,EAASxD,GACrC,GAAIjJ,IAAO,EAAA6B,EAAA2K,YAAWzM,GAAM,EAAO0M,EAAS,UACxCk2B,GAAmBnzB,OAAUvG,UACjC,QAAO,EAAAwP,EAAAtW,eAAcpC,EAAM,OAAQC,EAAM2iC,GACtCriC,KAAK,SAACkC,GACL,GAAMqgC,IAAgBp2B,QAASA,EAASkW,KAAM,QAAS5c,KAAMvD,EAASlF,GAAI2L,SAE1E,IAAwB,WAApBzG,EAAS6E,OAAqB,MAAOw7B,EAGzC,IAAM9zB,KACNA,GAAS9F,EAAO,KAAOoF,IAAO,KAE9B,IAAM8B,GAAOoyB,EAAaM,GAAc9zB,SAAYA,IAChD/O,GAAO,EAAA6B,EAAA2K,YAAWzM,GAAM,EAAO8iC,EAAYp2B,QAAS,QACxD,QAAO,EAAAgM,EAAAtW,eAAcpC,EAAM,OAAQC,EAAMmQ,GACxC7P,KAAK,iBAAMuiC,KACX92B,MAAM,WACL,OAAO,EAAAlK,EAAAyJ,OAAM,KACZhL,KAAK,kBAAM,EAAAmY,EAAAtW,eAAcpC,EAAM,OAAQC,EAAMmQ,KAC7C7P,KAAK,iBAAMuiC,KACX92B,MAAM,WACL,OAAO,EAAAlK,EAAAyJ,OAAM,KAAKhL,KAAK,iBAAMuiC,WAQvC,QAASR,GAAStiC,EAAMqiC,EAAUniC,GAChC,GAAsB,cAAlBmiC,EAASzf,KACX,KAAM,IAAIlf,OAAM,6DAEdxD,GAAQgJ,SACV,EAAApH,EAAA2C,MAAK,qCAGP,IAAIxE,eAAmBoiC,EAAS31B,QAA5B,IAAuC21B,EAASr8B,KAAhD,IACAoK,EAAO2yB,EAAmBV,EAAUniC,EACxC,QAAO,EAAAwY,EAAAtW,eAAcpC,EAAM,OAAQC,EAAMmQ,GACtC7P,KAAK,SAACkC,GAAD,MAAcA,GAASmI,IAAI,SAAAkZ,GAAA,MAAKA,GAAErkB,UAI5C,QAAS8iC,GAASviC,EAAMqiC,EAAUniC,GAChC,GAAMkQ,GAAOoyB,EAAaH,EAAUniC,GAEhCD,GAAO,EAAA6B,EAAA2K,YAAWzM,GAAM,EAAOqiC,EAAS31B,QAAS,QACrD,QAAO,EAAAgM,EAAAtW,eAAcpC,EAAM,OAAQC,EAAMmQ,GACtC7P,KAAK,SAACkC,GAAD,MAAcvC,GAAQuiC,cAAgBhgC,EAAWA,EAAS2tB,OAGpE,QAASoS,GAAcH,EAAUniC,GAC/B,GAAsB,UAAlBmiC,EAASzf,KACX,KAAM,IAAIlf,OAAM,uDAGlB,IAAI0M,IACF4yB,UAAWX,EAASr8B,KACpBkD,OAAQhJ,EAAQgJ,OAChB8F,SAAU9O,EAAQ8O,SAClBi0B,MAAO/iC,EAAQ+iC,MACfC,KAAMhjC,EAAQgjC,KACdC,MAAOjjC,EAAQijC,MACft1B,KAAM3N,EAAQ2N,KAOhB,OAJI3N,GAAQkjC,aACVhzB,EAAKvC,KAAOw0B,EAASn5B,OAAO0B,IAAI,SAAAwZ,GAAA,MAAA8d,MAAS9d,EAAI,WAGxChU,EAIT,QAASuyB,GAAY38B,GACnB,MAAOA,GAAKq9B,OAAO,GAAGC,cAAgBt9B,EAAK7H,MAAM,GAGnD,QAAS0kC,GAAiBn2B,EAASxD,GAGjC,MAFAA,GAAS,IAAMA,EAAO0B,IAAI,SAAA5E,GAAA,MAAQ,OAASA,IAAMkL,KAAK,KAAO,IAEtDqyB,EAAap/B,QAAQ,qBAAsBuI,EAAQuY,eACtC9gB,QAAQ,oBAAqB+E,GAU5C,QAASs6B,GAAex0B,GAAuC,GAA7B/O,GAA6BE,UAAAC,OAAA,GAAAC,SAAAF,UAAA,GAAAA,UAAA,MAAlB+N,EAAkB/N,UAAAC,OAAA,GAAAC,SAAAF,UAAA,GAAAA,UAAA,GAAP,KAC7D,IAA0B,YAAtB,mBAAQ6O,GAAR,YAAAklB,EAAQllB,IACV,QAAS/O,EAAMiO,EAAUc,GAG3B,IAAIrE,GAAO7M,OAAO6M,KAAKqE,EACvB,IAAoB,IAAhBrE,EAAKvK,OACP,KAAM,IAAIsD,OAAM,iBAEhB,OAAOiH,GAAKkpB,OAAO,SAAU4P,EAAK9uB,GAChC,GAAI+uB,EAAevgC,QAAQwR,MAAO,EAChC,KAAM,IAAIjR,OAAM,kDACX,OAAIigC,GAAexgC,QAAQwR,MAAO,EAChC8uB,EAAIjlC,OAAOglC,EAAcx0B,EAAS2F,GAAI1U,EAAM0U,IAE5C8uB,EAAIjlC,OAAOglC,EAAcx0B,EAAS2F,GAAI1U,EAAKzB,OAAOmW,GAAI,aAY9D,QAASivB,GAAmB50B,GACjC,GAAI60B,GAAUL,EAAcx0B,EAC5B,OAAO60B,GAAQhQ,OAAO,SAAU4P,EAAK7yB,GAAQ,GAAAkzB,GAAApiC,EACnBkP,EADmB,GACtC3Q,EADsC6jC,EAAA,GAChCC,EADgCD,EAAA,GAC5BrkC,EAD4BqkC,EAAA,GAEvCh6B,EAAQ7J,EAAKiR,KAAK,IAGtB,OAFAuyB,GAAI35B,GAAS25B,EAAI35B,OACjB25B,EAAI35B,GAAOi6B,GAAMtkC,EACVgkC,OAMX,QAASO,GAAeh1B,EAAUoB,GAChC,GAAI3Q,GAAQuP,EAAA,IACRi1B,EAAQC,EACRC,EAAQC,EACRC,QAEJ,IAAI5kC,EAGF,MAFA2Q,GAAKE,SAAS/K,KAAK9F,GACnB2Q,EAAKG,OAAOhL,KAAK9F,IACV,CAIT,IADAA,EAAQuP,EAAA,IAEN,KAAM,IAAItL,OAAM,mDAuBlB,OApBAjE,GAAQuP,EAAA,KACJvP,IACFwkC,EAAQxkC,GAGVA,EAAQuP,EAAA,KACJvP,IACF0kC,EAAQ1kC,EACR4kC,GAAe,GAGjB5kC,EAAQuP,EAAA,IACJvP,IACF0kC,EAAQ1kC,EACR4kC,GAAe,GAGjBj0B,EAAKE,SAAS/K,KAAK0+B,GACnB7zB,EAAKG,OAAOhL,KAAK4+B,GACI9jC,SAAjBgkC,IAA4Bj0B,EAAKK,cAAgB4zB,IAC9C,EAKF,QAAStB,GAAoBV,EAAU11B,GAC5C,GAAI23B,IACFh0B,YACAC,UACAsjB,QAAQ,GAEN0Q,EAAsB,KACtBC,EAAqBZ,EAAkBj3B,EAAMqC,SAiCjD,OA/BAqzB,GAASn5B,OAAO6F,QAAQ,SAAUjF,GAChC,GAAIkF,GAAWw1B,EAAmB16B,EAElC,IAAIkF,GAAmC,MAAvBu1B,EACd,KAAM,IAAI7gC,OAAM,qBAAuBoG,EAAQ,gBAAkBy6B,EAAsB,oCAClF,IAAIv1B,EAAU,CACnBA,EAASy1B,MAAO,CAChB,IAAIC,GAAcV,EAAch1B,EAAUs1B,EACtCI,KAAaH,EAAsBz6B,OACP,OAAvBy6B,IACTA,EAAsBz6B,EACtBw6B,EAAQ/zB,OAAOhL,KAAK6+B,MAIxBtmC,OAAO6M,KAAK65B,GAAoBz1B,QAAQ,SAAUjF,GAChD,IAAK06B,EAAmB16B,GAAO26B,KAC7B,KAAM,IAAI/gC,OAAM,0BAA4BoG,EAAQ,0BAIpD6C,EAAMy2B,aACRkB,GACElB,YAAY,EACZvP,QAAQ,EACRvjB,SAAUg0B,EAAQ/zB,OAClBA,OAAQ+zB,EAAQh0B,SAChBG,cAAe6zB,EAAQ7zB,gBAIpB6zB,E5CsoLRxmC,OAAO4G,eAAe5H,EAAS,cAC7B2C,OAAO,GAGT,IAAIiC,GAAiB,WAAc,QAASiD,GAAcC,EAAK/G,GAAK,GAAIgH,MAAeC,GAAK,EAAUC,GAAK,EAAWC,EAAK3E,MAAW,KAAM,IAAK,GAAiC4E,GAA7BC,EAAKN,EAAIO,OAAOC,cAAmBN,GAAMG,EAAKC,EAAGG,QAAQC,QAAoBT,EAAKU,KAAKN,EAAGxF,QAAY5B,GAAKgH,EAAKzE,SAAWvC,GAA3DiH,GAAK,IAAoE,MAAOxB,GAAOyB,GAAK,EAAMC,EAAK1B,EAAO,QAAU,KAAWwB,GAAMI,EAAW,QAAGA,EAAW,SAAO,QAAU,GAAIH,EAAI,KAAMC,IAAQ,MAAOH,GAAQ,MAAO,UAAUD,EAAK/G,GAAK,GAAI2H,MAAMC,QAAQb,GAAQ,MAAOA,EAAY,IAAIO,OAAOC,WAAYtH,QAAO8G,GAAQ,MAAOD,GAAcC,EAAK/G,EAAa,MAAM,IAAImB,WAAU,4DAEllBk1B,EAA4B,kBAAX/uB,SAAoD,gBAApBA,QAAOC,SAAwB,SAAU1G,GAAO,aAAcA,IAAS,SAAUA,GAAO,MAAOA,IAAyB,kBAAXyG,SAAyBzG,EAAIc,cAAgB2F,QAAUzG,IAAQyG,OAAOpH,UAAY,eAAkBW,GAEtQ5B,G4Ch6Leu8B,c5Ci6Lfv8B,E4Cn5Le6P,Q5Co5Lf7P,E4Cv4Leg9B,a5Cw4Lfh9B,E4C3wLe0mC,gB5C4wLf1mC,E4CjvLe8mC,oB5CkvLf9mC,E4C3rLeimC,oBA9OhB,IAAAjhC,GAAA1E,EAAA,GACAyyB,EAAAzyB,EAAA,GACAsb,EAAAtb,EAAA,GAqCMumC,GAAkB,MAAO,MAAO,OAAQ,MAAO,QAC/CD,GAAkB,MAAO,OAAQ,QAGjCH,EAAgB,SAAU56B,GACI,uBAA9BA,EAAImnB,QAAQ7K,eACdxR,KAAKkxB,kBAAmBh8B,IAEzBsO,WAAW9S,QAAQ,KAAM,IAAIA,QAAQ,MAAO,IACzCigC,GAAoBQ,IAAU,KAC9BV,EAAiB,M5C4qMjB,SAASnnC,EAAQD,EAASM,GAE/B,YAqCA,SAASqB,GAAuBC,GAAO,MAAOA,IAAOA,EAAIC,WAAaD,GAAQE,QAASF,G6C/uMjF,QAAS47B,GAAMt6B,EAAfwB,GAAsD,GAAAqjC,GAAArjC,EAA/BtB,UAA+BG,SAAAwkC,OAAAC,EAAAtjC,EAAjBujC,WAAiB1kC,SAAAykC,OAAAzU,GAAA,EAAAC,GAAA,EAAAC,EAAAlwB,MAAA,KAC3D,OAAAmwB,GAAAC,EAAoBsU,EAApB5/B,OAAAC,cAAAirB,GAAAG,EAAAC,EAAAprB,QAAAC,MAAA+qB,GAAA,EAA8B,IAArB3jB,GAAqB8jB,EAAA/wB,KAC5B+6B,GAAex6B,EAAM0M,EAASxM,IAF2B,MAAAoD,GAAAgtB,GAAA,EAAAC,EAAAjtB,EAAA,aAAA+sB,GAAAI,EAAAC,QAAAD,EAAAC,SAAA,WAAAJ,EAAA,KAAAC,KAQ7D,QAASyU,GAAShlC,EAAM0M,GAGtB,MAFA1M,GAAKw4B,SAAWx4B,EAAKw4B,aACrBx4B,EAAKw4B,SAAS9rB,GAAW1M,EAAKw4B,SAAS9rB,OAChC1M,EAAKw4B,SAAS9rB,GAGhB,QAAS6tB,GAAav6B,GAE3B,MADAA,GAAKw4B,SAAWx4B,EAAKw4B,aACd16B,OAAO6M,KAAK3K,EAAKw4B,UAOnB,QAAS/D,GAAaz0B,EAAM0M,GACjC,MAAsCrM,UAA/Bq0B,EAAY10B,EAAM0M,GAGpB,QAASgoB,GAAa10B,EAAM0M,GACjC,MAAOs4B,GAAQhlC,EAAM0M,GAASu4B,SAGzB,QAASC,GAAallC,EAAM0M,EAASu4B,GAE1C,MADAjlC,GAAKw4B,SAAS9rB,GAASu4B,SAAWA,EAC3BvQ,EAAY10B,EAAM0M,GAGpB,QAAS8tB,GAAgBx6B,EAAM0M,GAAuB,GAAdxM,GAAcC,UAAAC,OAAA,GAAAC,SAAAF,UAAA,GAAAA,UAAA,KAO3D,OANKglC,KACHC,EAAAxmC,QAAQ4vB,OAAR6W,EAAAzmC,SAC2C,mBAAhC0mC,8BAA6CF,EAAAxmC,QAAQ4vB,OAAO8W,6BACvEH,GAAe,GAGb1Q,EAAYz0B,EAAM0M,GACbrL,QAAQoK,QAAQipB,EAAY10B,EAAM0M,KAG3Cw4B,EAAYllC,EAAM0M,EAAS,GAAA04B,GAAAxmC,QAAY8N,EAASxM,IACzCqlC,EAAcvlC,EAAM0M,GAASnM,KAAK,iBAAMm0B,GAAY10B,EAAM0M,MAG5D,QAAS+tB,GAAiBz6B,EAAM0M,GACrC,MAAK+nB,GAAYz0B,EAAM0M,GAIhBuuB,EAAwBj7B,EAAM0M,GAClCnM,KAAK,iBAAMs6B,GAAgB76B,EAAM0M,KACjCnM,KAAK,iBAAMm0B,GAAY10B,EAAM0M,GAAS0gB,YACtC7sB,KAAK,SAAAkC,GAEJ,MADAyiC,GAAYllC,EAAM0M,EAASrM,QACpBoC,IARFpB,QAAQoK,SAAQ,GAYpB,QAASivB,GAAoB16B,GAClC,GAAM+kC,GAAWxK,EAAYv6B,GACvBotB,EAAU,SAAC1gB,GAAD,MAAa+tB,GAAgBz6B,EAAM0M,GACnD,OAAOrL,SAAQC,IAAIyjC,EAASn6B,IAAIwiB,IAGlC,QAASmY,GAAevlC,EAAM0M,GAC5B,MAAIA,qBACKgoB,EAAY10B,EAAM0M,GAAS84B,aAAa/1B,OAAQvG,QAAS,aAE3D7H,QAAQoK,UAOV,QAASkvB,GAAgB36B,EAAM0M,GACpC,MAAyCrM,UAAlColC,EAAezlC,EAAM0M,GAG9B,QAAS+4B,GAAgBzlC,EAAM0M,GAC7B,MAAOs4B,GAAQhlC,EAAM0M,GAASg5B,YAGhC,QAASC,GAAgB3lC,EAAM0M,EAASg5B,GAEtC,MADA1lC,GAAKw4B,SAAS9rB,GAASg5B,YAAcA,EAC9BD,EAAezlC,EAAM0M,GAG9B,QAASk5B,GAAmB5lC,EAAM0M,GAChC,MAAO1M,GAAKa,YACTN,KAAK,SAAAO,GACJ,GAAM+kC,GAAQ/kC,EAAYK,MAAM2kC,aAChC,QAAQ9lC,EAAKia,KAAO,SAAWvN,GAASvI,QAAQ,KAAzC,KAAoD0hC,KAIjE,QAASE,GAAuB/lC,EAAM0M,GACpC,MAAOs4B,GAAQhlC,EAAM0M,GAASs5B,mBAGhC,QAASC,GAAuBjmC,EAAM0M,EAASzF,GAE7C,MADAjH,GAAKw4B,SAAS9rB,GAASs5B,mBAAqB/+B,EACrC8+B,EAAsB/lC,EAAM0M,GAG9B,QAASkuB,GAAmB56B,EAAM0M,GAAuB,GAAdxM,GAAcC,UAAAC,OAAA,GAAAC,SAAAF,UAAA,GAAAA,UAAA,KAC9D,OAAO8lC,GAAsBjmC,EAAM0M,EAAS,GAAIrL,SAAQ,SAACoK,EAAStE,GAIhE,MAHKstB,GAAYz0B,EAAM0M,IACrB8tB,EAAex6B,EAAM0M,GAEnBxM,EAAQgmC,QAAS,EACZ/+B,EAAO,GAAIzD,OAAM,oDAGtB,EAAA5B,EAAAwJ,cACFnE,EAAOg/B,QACPjmC,EAAQwnB,SAAWxnB,EAAQwnB,QAAQye,SAIrCP,GAAkB5lC,EAAM0M,GACrBnM,KAAK,SAAA2D,GAAA,MAAOyhC,GAAe3lC,EAAM0M,EAChCgoB,EAAY10B,EAAM0M,GAAS05B,UAAUvE,KAAK39B,EAAKhE,GAASkT,GAAG,WAAY,SAAC+pB,GACtEwI,EAAe3lC,EAAM0M,EAASrM,QAC9BoL,EAAQ0xB,GACRj9B,EAAQmmC,YAAcnmC,EAAQmmC,WAAWlJ,KACxC/pB,GAAG,QAAS,SAAC9P,GACI,oCAAdA,EAAIC,MACNvD,EAAKa,YAAYN,KAAK,SAAAkB,GAAqB,GAAnBI,GAAmBJ,EAAnBI,OAAQV,EAAWM,EAAXN,OAC9B,EAAAa,EAAAC,cAAajC,EAAM6B,EAAQV,GACxBZ,KAAK,SAAC2B,GAAD,MAAclC,GAAKmC,gBAAgBN,EAAQK,KAChD3B,KAAK,SAACO,GAAD,MAAiB85B,GAAkB56B,EAAM0M,EAASxM,QAG5DsE,QAAQC,KAAR,sBAAmCiI,EAAnC,YACAlI,QAAQC,KAAKnB,GACbqiC,EAAe3lC,EAAM0M,EAASrM,QAC9B8G,EAAO7D,GACPpD,EAAQwnB,SAAWxnB,EAAQwnB,QAAQpkB,YAOxC,QAASu3B,GAAiB76B,EAAM0M,GACrC,MAAKgoB,GAAY10B,EAAM0M,IAAaiuB,EAAe36B,EAAM0M,GAIlD,GAAIrL,SAAQ,SAAAoK,GACjB,IACEs6B,EAAsB/lC,EAAM0M,GAASnM,KAAK,WACxCkL,MAEFg6B,EAAezlC,EAAM0M,GAASnF,SAE9B,MAAOhD,GACPkH,OAXKpK,QAAQoK,UAgBZ,QAASqvB,GAAoB96B,GAClC,GAAM+kC,GAAWxK,EAAYv6B,GACvBkhC,EAAO,SAACx0B,GAAD,MAAamuB,GAAgB76B,EAAM0M,GAChD,OAAOrL,SAAQC,IAAIyjC,EAASn6B,IAAIs2B,IAOlC,QAASoF,GAAwBtmC,EAAM0M,GACrC,MAAOs4B,GAAQhlC,EAAM0M,GAAS65B,SAGhC,QAASC,GAAwBxmC,EAAM0M,EAAS65B,GAC9CvmC,EAAKw4B,SAAS9rB,GAAS65B,SAAWA,EAG7B,QAASxL,GAAwB/6B,EAAM0M,GAC5C,MAAiDrM,UAA1CimC,EAAuBtmC,EAAM0M,GAG/B,QAASsuB,GAA0Bh7B,EAAM0M,EAAS+5B,GAAqB,GAAdvmC,GAAcC,UAAAC,OAAA,GAAAC,SAAAF,UAAA,GAAAA,UAAA,KAE5E,OAAI46B,GAAuB/6B,EAAM0M,GACxB45B,EAAuBtmC,EAAM0M,GAG/B85B,EAAuBxmC,EAAM0M,EAASg6B,YAAY,WACvD,OAAI,EAAA5kC,EAAAwJ,iBAEF9G,SAAQ24B,KAAKgJ,QAGVxL,EAAe36B,EAAM0M,IACxBkuB,EAAkB56B,EAAM0M,EAASxM,KAG1B,IAARumC,IAGE,QAASxL,GAAyBj7B,EAAM0M,GAK7C,MAJIquB,GAAuB/6B,EAAM0M,KAC/Bi6B,cAAcL,EAAuBtmC,EAAM0M,IAC3C85B,EAAuBxmC,EAAM0M,EAASrM,SAEpCs6B,EAAe36B,EAAM0M,GAChBmuB,EAAgB76B,EAAM0M,GAGxBrL,QAAQoK,UAGV,QAASyvB,GAA4Bl7B,GAC1C,GAAM+kC,GAAWxK,EAAYv6B,GACvBkhC,EAAO,SAACx0B,GAAD,MAAauuB,GAAwBj7B,EAAM0M,GACxD,OAAOrL,SAAQC,IAAIyjC,EAASn6B,IAAIs2B,I7C0+LjCpjC,OAAO4G,eAAe5H,EAAS,cAC7B2C,OAAO,IAET3C,EAAQqpC,wBAA0B9lC,OAClCvD,E6ChtMew9B,O7CitMfx9B,E6CnsMey9B,c7CosMfz9B,E6C3rMe23B,c7C4rMf33B,E6CxrMe43B,c7CyrMf53B,E6CrrMeooC,c7CsrMfpoC,E6CjrMe09B,iB7CkrMf19B,E6CnqMe29B,kB7CoqMf39B,E6CtpMe49B,qB7CupMf59B,E6CtoMe69B,iB7CuoMf79B,E6CzmMe89B,oB7C0mMf99B,E6ClkMe+9B,kB7CmkMf/9B,E6CjjMeg+B,qB7CkjMfh+B,E6ChiMei+B,yB7CiiMfj+B,E6C7hMek+B,2B7C8hMfl+B,E6C3gMem+B,0B7C4gMfn+B,E6ChgMeo+B,4BAnPhB,IAAArL,GAAAzyB,EAAA,GACA4E,EAAA5E,EAAA,GACA0E,EAAA1E,EAAA,GACAwpC,EAAAxpC,EAAA,I7C0vMKgoC,EAAY3mC,EAAuBmoC,G6CzvMxCC,EAAAzpC,EAAA,I7C6vMKioC,EAAgB5mC,EAAuBooC,G6C3vM/BV,4BAA0B,sDAEnChB,GAAe,G7C8hNb,SAASpoC,EAAQD,EAASM,GAE/B,Y8CtiND,SAAS0pC,GAAiBC,GACxB,MAAO,UAAU/mC,EAAM2I,EAAKwnB,GAC1B,IAAKxnB,EAAK,KAAM,IAAIjF,OAAM,uBACrB8B,OAAMC,QAAQ0qB,KAAMA,GAAOA,GAEhC,IAAM6W,GAAO7W,EAAIvlB,IAAI,SAACrN,GAAD,OAAUqlB,qBAAqBrlB,OAEpD,QAAO,EAAAmb,EAAAtW,eAAcpC,EAAM+mC,EAAME,EAAmBt+B,IAAO3F,KAAMgkC,KAO9D,QAASxN,GAAqBx5B,EAAM2I,GACzC,IAAKA,EAAK,KAAM,IAAIjF,OAAM,uBAC1B,QAAO,EAAAgV,EAAAtW,eAAcpC,EAAM,MAAOinC,EAAmBt+B,IAClDpI,KAAK,SAAC8T,GAAD,MAAWA,GAAMzJ,IAAI,SAAC+qB,GAAD,MAAUA,GAAKrT,QAGvC,QAASmX,GAAsBz5B,EAAM2I,EAAKzI,GAC/C,IAAKyI,EAAK,KAAM,IAAIjF,OAAM,uBAC1B,IAAMwjC,GAASppC,OAAO6M,KAAKzK,GAAS0K,IAAI,SAAA/B,GAAA,eAAgBA,EAAhB,KAAwB3I,EAAQ2I,KAAQqI,KAAK,GAErF,QAAO,EAAAwH,EAAA/V,kBAAiB3C,EAAM,MAAUinC,EAAmBt+B,GAApD,+BAAuFu+B,GAGhG,QAASD,GAAoBt+B,GAC3B,GAAMia,GAAO/V,mBAAmBlE,EAAIya,OAC9B7lB,EAAKsP,mBAAmBlE,EAAI2Z,IAClC,gBAAgBM,EAAhB,IAAwBrlB,EAAxB,4B9C0gNDO,OAAO4G,eAAe5H,EAAS,cAC7B2C,OAAO,IAET3C,EAAQy8B,sBAAwBz8B,EAAQw8B,mBAAqBj5B,OAC7DvD,E8C9hNe08B,sB9C+hNf18B,E8CzhNe28B,sBAvBhB,IAAA/gB,GAAAtb,EAAA,GACAyyB,EAAAzyB,EAAA,EAaak8B,sBAAqBwN,EAAgB,QACrCvN,wBAAwBuN,EAAgB,W9CilN/C,SAAS/pC,EAAQD,EAASM,GAE/B,Y+ChmNM,SAASg+B,GAAWp7B,GACzB,OAAO,EAAA0Y,EAAAtW,eAAcpC,EAAM,MAApB,wBAGF,QAASq7B,GAAkBr7B,EAAMmnC,EAAmBC,GACzD,OAAO,EAAA1uB,EAAAtW,eAAcpC,EAAM,MAApB,wBACLqnC,mBAAoBF,EACpBG,eAAgBF,IAIb,QAAS9L,GAAat7B,GAC3B,OAAO,EAAA0Y,EAAAtW,eAAcpC,EAAM,MAApB,sBAGF,QAASu7B,GAAgBv7B,EAAMlB,GACpC,OAAO,EAAA4Z,EAAAtW,eAAcpC,EAAM,MAApB,qBAAiDlB,GAGnD,QAAS08B,GAAYx7B,GAC1B,OAAO,EAAA0Y,EAAAtW,eAAcpC,EAAM,MAApB,qBAGF,QAASy7B,GAAkBz7B,EAAMzC,GACtC,OAAO,EAAAmb,EAAAtW,eAAcpC,EAAM,SAApB,qBAAmDzC,GAGrD,QAASm+B,GAAgB17B,GAC9B,OAAO,EAAA0Y,EAAAtW,eAAcpC,EAAM,OAAQ,0B/CskNpClC,OAAO4G,eAAe5H,EAAS,cAC7B2C,OAAO,IAET3C,E+CrmNes+B,Y/CsmNft+B,E+ClmNeu+B,mB/CmmNfv+B,E+C5lNew+B,c/C6lNfx+B,E+CzlNey+B,iB/C0lNfz+B,E+CtlNe0+B,a/CulNf1+B,E+CnlNe2+B,mB/ColNf3+B,E+ChlNe4+B,gBA7BhB,IAAAhjB,GAAAtb,EAAA,I/CkpNM,SAASL,EAAQD,EAASM,GgDlpNhCL,EAAAD,QAAAM,EAAA,KhDypNM,SAASL,EAAQD,GiDzpNvBC,EAAAD,QAAA,SAAA4hB,GACA,qBAAAA,GAAA,KAAA1f,WAAA0f,EAAA,sBACA,OAAAA,KjDiqNM,SAAS3hB,EAAQD,EAASM,GkDnqNhC,GAAAmqC,GAAAnqC,EAAA,GACAL,GAAAD,QAAA,SAAA4hB,GACA,IAAA6oB,EAAA7oB,GAAA,KAAA1f,WAAA0f,EAAA,qBACA,OAAAA,KlD2qNM,SAAS3hB,EAAQD,EAASM,GmD5qNhC,GAAAoqC,GAAApqC,EAAA,IACAqqC,EAAArqC,EAAA,IACAsqC,EAAAtqC,EAAA,GACAL,GAAAD,QAAA,SAAA6qC,GACA,gBAAAC,EAAAC,EAAAC,GACA,GAGAroC,GAHAsoC,EAAAP,EAAAI,GACAxnC,EAAAqnC,EAAAM,EAAA3nC,QACAqP,EAAAi4B,EAAAI,EAAA1nC,EAIA,IAAAunC,GAAAE,MAAA,KAAAznC,EAAAqP,GAGA,GAFAhQ,EAAAsoC,EAAAt4B,KAEAhQ,KAAA,aAEK,MAAYW,EAAAqP,EAAeA,IAAA,IAAAk4B,GAAAl4B,IAAAs4B,KAChCA,EAAAt4B,KAAAo4B,EAAA,MAAAF,IAAAl4B,GAAA,CACK,QAAAk4B,IAAA,KnDurNC,SAAS5qC,EAAQD,GoD3sNvB,GAAAma,MAAiBA,QAEjBla,GAAAD,QAAA,SAAA4hB,GACA,MAAAzH,GAAAxZ,KAAAihB,GAAAvgB,MAAA,QpDmtNM,SAASpB,EAAQD,EAASM,GqDrtNhC,GAAA4qC,GAAA5qC,EAAA,GACAL,GAAAD,QAAA,SAAAsB,EAAA0iB,EAAA1gB,GAEA,GADA4nC,EAAA5pC,GACAiC,SAAAygB,EAAA,MAAA1iB,EACA,QAAAgC,GACA,uBAAA/B,GACA,MAAAD,GAAAX,KAAAqjB,EAAAziB,GAEA,wBAAAA,EAAAC,GACA,MAAAF,GAAAX,KAAAqjB,EAAAziB,EAAAC,GAEA,wBAAAD,EAAAC,EAAAX,GACA,MAAAS,GAAAX,KAAAqjB,EAAAziB,EAAAC,EAAAX,IAGA,kBACA,MAAAS,GAAAG,MAAAuiB,EAAA3gB,crD+tNM,SAASpD,EAAQD,EAASM,GsDhvNhC,GAAAmqC,GAAAnqC,EAAA,IACA+hB,EAAA/hB,EAAA,GAAA+hB,SAEA8oB,EAAAV,EAAApoB,IAAAooB,EAAApoB,EAAAM,cACA1iB,GAAAD,QAAA,SAAA4hB,GACA,MAAAupB,GAAA9oB,EAAAM,cAAAf,QtDwvNM,SAAS3hB,EAAQD,GuD5vNvBC,EAAAD,QAAA,gGAEAwQ,MAAA,MvDowNM,SAASvQ,EAAQD,EAASM,GwDvwNhC,GAAAwX,GAAAxX,EAAA,GACA2mB,EAAA3mB,EAAA,IACA8qC,EAAA9qC,EAAA,IACA+qC,EAAA/qC,EAAA,IACAq6B,EAAAr6B,EAAA,IACAgrC,EAAA,YAEAC,EAAA,SAAAzlB,EAAA5c,EAAAk4B,GACA,GAQAr1B,GAAAy/B,EAAAxgB,EAAAygB,EARAC,EAAA5lB,EAAAylB,EAAAI,EACAC,EAAA9lB,EAAAylB,EAAAM,EACAC,EAAAhmB,EAAAylB,EAAAQ,EACAC,EAAAlmB,EAAAylB,EAAAU,EACAC,EAAApmB,EAAAylB,EAAAY,EACArsB,EAAA8rB,EAAA9zB,EAAAg0B,EAAAh0B,EAAA5O,KAAA4O,EAAA5O,QAAkF4O,EAAA5O,QAAuBoiC,GACzGtrC,EAAA4rC,EAAA3kB,IAAA/d,KAAA+d,EAAA/d,OACAkjC,EAAApsC,EAAAsrC,KAAAtrC,EAAAsrC,MAEAM,KAAAxK,EAAAl4B,EACA,KAAA6C,IAAAq1B,GAEAoK,GAAAE,GAAA5rB,GAAAvc,SAAAuc,EAAA/T,GAEAif,GAAAwgB,EAAA1rB,EAAAshB,GAAAr1B,GAEA0/B,EAAAS,GAAAV,EAAA7Q,EAAA3P,EAAAlT,GAAAk0B,GAAA,kBAAAhhB,GAAA2P,EAAA5iB,SAAApX,KAAAqqB,KAEAlL,GAAAurB,EAAAvrB,EAAA/T,EAAAif,EAAAlF,EAAAylB,EAAAc,GAEArsC,EAAA+L,IAAAif,GAAAogB,EAAAprC,EAAA+L,EAAA0/B,GACAO,GAAAI,EAAArgC,IAAAif,IAAAohB,EAAArgC,GAAAif,GAGAlT,GAAAmP,OAEAskB,EAAAI,EAAA,EACAJ,EAAAM,EAAA,EACAN,EAAAQ,EAAA,EACAR,EAAAU,EAAA,EACAV,EAAAY,EAAA,GACAZ,EAAAe,EAAA,GACAf,EAAAc,EAAA,GACAd,EAAAgB,EAAA,IACAtsC,EAAAD,QAAAurC,GxD8wNM,SAAStrC,EAAQD,EAASM,GyDxzNhCL,EAAAD,SAAAM,EAAA,MAAAA,EAAA,eACA,MAAuG,IAAvGU,OAAA4G,eAAAtH,EAAA,gBAAsE8F,IAAA,WAAmB,YAAc7E,KzDg0NjG,SAAStB,EAAQD,EAASM,G0Dj0NhC,YAEA,IAAAksC,GAAAlsC,EAAA,IACAmsC,EAAAnsC,EAAA,IACAosC,EAAApsC,EAAA,IACAqsC,EAAArsC,EAAA,IACAonB,EAAApnB,EAAA,IACAssC,EAAA5rC,OAAA+d,MAGA9e,GAAAD,SAAA4sC,GAAAtsC,EAAA,eACA,GAAAusC,MACAV,KAEAJ,EAAA1jC,SACAykC,EAAA,sBAGA,OAFAD,GAAAd,GAAA,EACAe,EAAAt8B,MAAA,IAAAyB,QAAA,SAAA4F,GAAoCs0B,EAAAt0B,OACjB,GAAnB+0B,KAAmBC,GAAAd,IAAA/qC,OAAA6M,KAAA++B,KAAsCT,IAAA/3B,KAAA,KAAA04B,IACxD,SAAAhtB,EAAAshB,GAMD,IALA,GAAA2L,GAAAJ,EAAA7sB,GACAktB,EAAA3pC,UAAAC,OACAqP,EAAA,EACAs6B,EAAAR,EAAAnlB,EACA4lB,EAAAR,EAAAplB,EACA0lB,EAAAr6B,GAMA,IALA,GAIA5G,GAJAggC,EAAArkB,EAAArkB,UAAAsP,MACA9E,EAAAo/B,EAAAT,EAAAT,GAAArqC,OAAAurC,EAAAlB,IAAAS,EAAAT,GACAzoC,EAAAuK,EAAAvK,OACAihB,EAAA,EAEAjhB,EAAAihB,GAAA2oB,EAAAvsC,KAAAorC,EAAAhgC,EAAA8B,EAAA0W,QAAAwoB,EAAAhhC,GAAAggC,EAAAhgC,GACG,OAAAghC,IACFH,G1Dw0NK,SAAS3sC,EAAQD,EAASM,G2Dz2NhC,GAAA6sC,GAAA7sC,EAAA,IACA8sC,EAAA9sC,EAAA,IACA+sC,EAAA/sC,EAAA,IACA6mB,EAAAnmB,OAAA4G,cAEA5H,GAAAsnB,EAAAhnB,EAAA,IAAAU,OAAA4G,eAAA,SAAAqjC,EAAAgB,EAAAqB,GAIA,GAHAH,EAAAlC,GACAgB,EAAAoB,EAAApB,GAAA,GACAkB,EAAAG,GACAF,EAAA,IACA,MAAAjmB,GAAA8jB,EAAAgB,EAAAqB,GACG,MAAA7lC,IACH,UAAA6lC,IAAA,OAAAA,GAAA,KAAAprC,WAAA,2BAEA,OADA,SAAAorC,KAAArC,EAAAgB,GAAAqB,EAAA3qC,OACAsoC,I3Di3NM,SAAShrC,EAAQD,G4D/3NvBA,EAAAsnB,EAAAtmB,OAAAusC,uB5Ds4NM,SAASttC,EAAQD,EAASM,G6Dt4NhC,GAAA0+B,GAAA1+B,EAAA,IACAoqC,EAAApqC,EAAA,IACAktC,EAAAltC,EAAA,QACAmtC,EAAAntC,EAAA,eAEAL,GAAAD,QAAA,SAAAqnB,EAAAqmB,GACA,GAGA3hC,GAHAk/B,EAAAP,EAAArjB,GACAtmB,EAAA,EACAyJ,IAEA,KAAAuB,IAAAk/B,GAAAl/B,GAAA0hC,GAAAzO,EAAAiM,EAAAl/B,IAAAvB,EAAA/B,KAAAsD,EAEA,MAAA2hC,EAAApqC,OAAAvC,GAAAi+B,EAAAiM,EAAAl/B,EAAA2hC,EAAA3sC,SACAysC,EAAAhjC,EAAAuB,IAAAvB,EAAA/B,KAAAsD,GAEA,OAAAvB,K7D84NM,SAASvK,EAAQD,EAASM,G8D55NhC,GAAAqtC,GAAArtC,EAAA,IACAstC,EAAAttC,EAAA,GAEAL,GAAAD,QAAAgB,OAAA6M,MAAA,SAAAo9B,GACA,MAAA0C,GAAA1C,EAAA2C,K9Dq6NM,SAAS3tC,EAAQD,G+D16NvBA,EAAAsnB,KAAcE,sB/Di7NR,SAASvnB,EAAQD,GgEj7NvBC,EAAAD,QAAA,SAAA6tC,EAAAlrC,GACA,OACAC,aAAA,EAAAirC,GACA/qC,eAAA,EAAA+qC,GACAhrC,WAAA,EAAAgrC,GACAlrC,WhE07NM,SAAS1C,EAAQD,EAASM,GiE/7NhC,GAAAwX,GAAAxX,EAAA,GACA8qC,EAAA9qC,EAAA,IACA0+B,EAAA1+B,EAAA,IACAwtC,EAAAxtC,EAAA,WACAytC,EAAA,WACAC,EAAAj2B,SAAAg2B,GACAE,GAAA,GAAAD,GAAAx9B,MAAAu9B,EAEAztC,GAAA,IAAA4tC,cAAA,SAAAtsB,GACA,MAAAosB,GAAArtC,KAAAihB,KAGA3hB,EAAAD,QAAA,SAAAirC,EAAAl/B,EAAAiP,EAAAmzB,GACA,GAAAniB,GAAA,kBAAAhR,EACAgR,KAAAgT,EAAAhkB,EAAA,SAAAowB,EAAApwB,EAAA,OAAAjP,IACAk/B,EAAAl/B,KAAAiP,IACAgR,IAAAgT,EAAAhkB,EAAA8yB,IAAA1C,EAAApwB,EAAA8yB,EAAA7C,EAAAl/B,GAAA,GAAAk/B,EAAAl/B,GAAAkiC,EAAA75B,KAAAqL,OAAA1T,MACAk/B,IAAAnzB,EACAmzB,EAAAl/B,GAAAiP,EACGmzB,EAGAlD,EAAAl/B,GACHk/B,EAAAl/B,GAAAiP,EAEAowB,EAAAH,EAAAl/B,EAAAiP,UALAiwB,GAAAl/B,GACAq/B,EAAAH,EAAAl/B,EAAAiP,OAOCjD,SAAA9W,UAAA8sC,EAAA,WACD,wBAAA3tC,YAAA0tC,IAAAE,EAAArtC,KAAAP,SjEu8NM,SAASH,EAAQD,EAASM,GkEp+NhC,GAAA8tC,GAAA9tC,EAAA,YACA+tC,EAAA/tC,EAAA,GACAL,GAAAD,QAAA,SAAA+L,GACA,MAAAqiC,GAAAriC,KAAAqiC,EAAAriC,GAAAsiC,EAAAtiC,MlE4+NM,SAAS9L,EAAQD,EAASM,GmE/+NhC,GAAAwX,GAAAxX,EAAA,GACAguC,EAAA,qBACAC,EAAAz2B,EAAAw2B,KAAAx2B,EAAAw2B,MACAruC,GAAAD,QAAA,SAAA+L,GACA,MAAAwiC,GAAAxiC,KAAAwiC,EAAAxiC,SnEu/NM,SAAS9L,EAAQD,EAASM,GoE3/NhC,GAAAkuC,GAAAluC,EAAA,IACA+M,EAAAT,KAAAS,IACAR,EAAAD,KAAAC,GACA5M,GAAAD,QAAA,SAAA2S,EAAArP,GAEA,MADAqP,GAAA67B,EAAA77B,GACAA,EAAA,EAAAtF,EAAAsF,EAAArP,EAAA,GAAAuJ,EAAA8F,EAAArP,KpEmgOM,SAASrD,EAAQD,EAASM,GqEvgOhC,GAAAkuC,GAAAluC,EAAA,IACAuM,EAAAD,KAAAC,GACA5M,GAAAD,QAAA,SAAA4hB,GACA,MAAAA,GAAA,EAAA/U,EAAA2hC,EAAA5sB,GAAA,sBrEghOM,SAAS3hB,EAAQD,EAASM,GsEnhOhC,GAAAqnB,GAAArnB,EAAA,GACAL,GAAAD,QAAA,SAAA4hB,GACA,MAAA5gB,QAAA2mB,EAAA/F,MtE4hOM,SAAS3hB,EAAQD,EAASM,GuE9hOhC,GAAAmqC,GAAAnqC,EAAA,GAGAL,GAAAD,QAAA,SAAA4hB,EAAAmqB,GACA,IAAAtB,EAAA7oB,GAAA,MAAAA,EACA,IAAAtgB,GAAA0Z,CACA,IAAA+wB,GAAA,mBAAAzqC,EAAAsgB,EAAAzH,YAAAswB,EAAAzvB,EAAA1Z,EAAAX,KAAAihB,IAAA,MAAA5G,EACA,uBAAA1Z,EAAAsgB,EAAA6sB,WAAAhE,EAAAzvB,EAAA1Z,EAAAX,KAAAihB,IAAA,MAAA5G,EACA,KAAA+wB,GAAA,mBAAAzqC,EAAAsgB,EAAAzH,YAAAswB,EAAAzvB,EAAA1Z,EAAAX,KAAAihB,IAAA,MAAA5G,EACA,MAAA9Y,WAAA,6CvEuiOM,SAASjC,EAAQD,EAASM,GwEhjOhC,GAAAirC,GAAAjrC,EAAA,GAEAirC,KAAAQ,EAAAR,EAAAI,EAAA,UAA0C5sB,OAAAze,EAAA,OxEwjOpC,SAASL,EAAQD,GyE9gOvB,QAAAiyB,GAAA3Z,GAEA,GADAA,EAAAmH,OAAAnH,KACAA,EAAAhV,OAAA,MAGA,GAAA8kB,GAAA,wHAAAzG,KAAArJ,EACA,IAAA8P,EAAA,CAGA,GAAAyG,GAAA5V,WAAAmP,EAAA,IACAtC,GAAAsC,EAAA,UAAAD,aACA,QAAArC,GACA,YACA,WACA,UACA,SACA,QACA,MAAA+I,GAAAS,CACA,YACA,UACA,QACA,MAAAT,GAAAd,CACA,aACA,WACA,UACA,SACA,QACA,MAAAc,GAAA6f,CACA,eACA,aACA,WACA,UACA,QACA,MAAA7f,GAAAjuB,CACA,eACA,aACA,WACA,UACA,QACA,MAAAiuB,GAAAhB,CACA,oBACA,kBACA,YACA,WACA,SACA,MAAAgB,EACA,SACA,UAYA,QAAA8f,GAAAC,GACA,MAAAA,IAAA7gB,EACAnhB,KAAAiiC,MAAAD,EAAA7gB,GAAA,IAEA6gB,GAAAF,EACA9hC,KAAAiiC,MAAAD,EAAAF,GAAA,IAEAE,GAAAhuC,EACAgM,KAAAiiC,MAAAD,EAAAhuC,GAAA,IAEAguC,GAAA/gB,EACAjhB,KAAAiiC,MAAAD,EAAA/gB,GAAA,IAEA+gB,EAAA,KAWA,QAAAE,GAAAF,GACA,MAAAG,GAAAH,EAAA7gB,EAAA,QACAghB,EAAAH,EAAAF,EAAA,SACAK,EAAAH,EAAAhuC,EAAA,WACAmuC,EAAAH,EAAA/gB,EAAA,WACA+gB,EAAA,MAOA,QAAAG,GAAAH,EAAA/f,EAAA3lB,GACA,KAAA0lC,EAAA/f,GAGA,MAAA+f,GAAA,IAAA/f,EACAjiB,KAAA2S,MAAAqvB,EAAA/f,GAAA,IAAA3lB,EAEA0D,KAAA6a,KAAAmnB,EAAA/f,GAAA,IAAA3lB,EAAA,IA/IA,GAAA2kB,GAAA,IACAjtB,EAAA,GAAAitB,EACA6gB,EAAA,GAAA9tC,EACAmtB,EAAA,GAAA2gB,EACApf,EAAA,OAAAvB,CAgBA9tB,GAAAD,QAAA,SAAAgb,EAAA5X,GACAA,OACA,IAAA0iB,SAAA9K,EACA,eAAA8K,GAAA9K,EAAA1X,OAAA,EACA,MAAA2uB,GAAAjX,EACG,eAAA8K,GAAAlL,MAAAI,MAAA,EACH,MAAA5X,GAAA4rC,KACAF,EAAA9zB,GACA2zB,EAAA3zB,EAEA,UAAApU,OAAA,wDAAAd,KAAAC,UAAAiV,MzEorOM,SAAS/a,EAAQD,EAASM,G0E3qOhC,QAAA2uC,GAAAzmB,GACA,GAAAznB,GAAAsK,EAAA,CAEA,KAAAtK,IAAAynB,GACAnd,MAAA,GAAAA,EAAAmd,EAAA8F,WAAAvtB,GACAsK,GAAA,CAGA,OAAArL,GAAAqpB,OAAAzc,KAAAuG,IAAA9H,GAAArL,EAAAqpB,OAAA/lB,QAWA,QAAA4rC,GAAA1mB,GAEA,QAAAO,KAEA,GAAAA,EAAAomB,QAAA,CAEA,GAAA/sC,GAAA2mB,EAGAqmB,GAAA,GAAAt0B,MACA8zB,EAAAQ,GAAAC,GAAAD,EACAhtC,GAAAsmB,KAAAkmB,EACAxsC,EAAA6hC,KAAAoL,EACAjtC,EAAAgtC,OACAC,EAAAD,CAIA,QADAhuC,GAAA,GAAAsH,OAAArF,UAAAC,QACAvC,EAAA,EAAmBA,EAAAK,EAAAkC,OAAiBvC,IACpCK,EAAAL,GAAAsC,UAAAtC,EAGAK,GAAA,GAAApB,EAAAsvC,OAAAluC,EAAA,IAEA,gBAAAA,GAAA,IAEAA,EAAAmuC,QAAA,KAIA,IAAA58B,GAAA,CACAvR,GAAA,GAAAA,EAAA,GAAAiG,QAAA,yBAAA+gB,EAAAonB,GAEA,UAAApnB,EAAA,MAAAA,EACAzV,IACA,IAAA88B,GAAAzvC,EAAAspB,WAAAkmB,EACA,sBAAAC,GAAA,CACA,GAAAz0B,GAAA5Z,EAAAuR,EACAyV,GAAAqnB,EAAA9uC,KAAAyB,EAAA4Y,GAGA5Z,EAAA8L,OAAAyF,EAAA,GACAA,IAEA,MAAAyV,KAIApoB,EAAAuoB,WAAA5nB,KAAAyB,EAAAhB,EAEA,IAAAsuC,GAAA3mB,EAAAhb,KAAA/N,EAAA+N,KAAArG,QAAAqG,IAAA4hC,KAAAjoC,QACAgoC,GAAAjuC,MAAAW,EAAAhB,IAaA,MAVA2nB,GAAAP,YACAO,EAAAomB,QAAAnvC,EAAAmvC,QAAA3mB,GACAO,EAAAlB,UAAA7nB,EAAA6nB,YACAkB,EAAAJ,MAAAsmB,EAAAzmB,GAGA,kBAAAxoB,GAAAw9B,MACAx9B,EAAAw9B,KAAAzU,GAGAA,EAWA,QAAAS,GAAAX,GACA7oB,EAAAoe,KAAAyK,EAKA,QAHArY,IAAAqY,GAAA,IAAArY,MAAA,UACA5G,EAAA4G,EAAAlN,OAEAvC,EAAA,EAAiBA,EAAA6I,EAAS7I,IAC1ByP,EAAAzP,KACA8nB,EAAArY,EAAAzP,GAAAsG,QAAA,aACA,MAAAwhB,EAAA,GACA7oB,EAAA4vC,MAAAnnC,KAAA,GAAA4f,QAAA,IAAAQ,EAAAmH,OAAA,SAEAhwB,EAAA0tC,MAAAjlC,KAAA,GAAA4f,QAAA,IAAAQ,EAAA,OAWA,QAAAgnB,KACA7vC,EAAAwpB,OAAA,IAWA,QAAA2lB,GAAAjmC,GACA,GAAAnI,GAAA6I,CACA,KAAA7I,EAAA,EAAA6I,EAAA5J,EAAA4vC,MAAAtsC,OAAyCvC,EAAA6I,EAAS7I,IAClD,GAAAf,EAAA4vC,MAAA7uC,GAAA0rB,KAAAvjB,GACA,QAGA,KAAAnI,EAAA,EAAA6I,EAAA5J,EAAA0tC,MAAApqC,OAAyCvC,EAAA6I,EAAS7I,IAClD,GAAAf,EAAA0tC,MAAA3sC,GAAA0rB,KAAAvjB,GACA,QAGA,UAWA,QAAAomC,GAAAt0B,GACA,MAAAA,aAAApU,OAAAoU,EAAA9B,OAAA8B,EAAA7R,QACA6R,EA7LAhb,EAAAC,EAAAD,QAAAkvC,EAAAnmB,MAAAmmB,EAAAptC,QAAAotC,EACAlvC,EAAAsvC,SACAtvC,EAAA6vC,UACA7vC,EAAAwpB,SACAxpB,EAAAmvC,UACAnvC,EAAAyoB,SAAAnoB,EAAA,IAMAN,EAAA0tC,SACA1tC,EAAA4vC,SAQA5vC,EAAAspB,aAMA,IAAA+lB,I1Ei4OM,SAASpvC,EAAQD,G2E94OvB,QAAA8vC,KACA1vC,KAAA2vC,QAAA3vC,KAAA2vC,YACA3vC,KAAA4vC,cAAA5vC,KAAA4vC,eAAAzsC,OAwQA,QAAAyoB,GAAAoU,GACA,wBAAAA,GAGA,QAAA6P,GAAA7P,GACA,sBAAAA,GAGA,QAAAqK,GAAArK,GACA,sBAAAA,IAAA,OAAAA,EAGA,QAAA8P,GAAA9P,GACA,gBAAAA,EAnRAngC,EAAAD,QAAA8vC,EAGAA,iBAEAA,EAAA7uC,UAAA8uC,QAAAxsC,OACAusC,EAAA7uC,UAAA+uC,cAAAzsC,OAIAusC,EAAAK,oBAAA,GAIAL,EAAA7uC,UAAAmvC,gBAAA,SAAAvhB,GACA,IAAAohB,EAAAphB,MAAA,GAAAjU,MAAAiU,GACA,KAAA3sB,WAAA,8BAEA,OADA9B,MAAA4vC,cAAAnhB,EACAzuB,MAGA0vC,EAAA7uC,UAAA0V,KAAA,SAAAmP,GACA,GAAAuqB,GAAAC,EAAA1mC,EAAAxI,EAAAL,EAAAwvC,CAMA,IAJAnwC,KAAA2vC,UACA3vC,KAAA2vC,YAGA,UAAAjqB,KACA1lB,KAAA2vC,QAAAtpC,OACAgkC,EAAArqC,KAAA2vC,QAAAtpC,SAAArG,KAAA2vC,QAAAtpC,MAAAnD,QAAA,CAEA,GADA+sC,EAAAhtC,UAAA,GACAgtC,YAAAzpC,OACA,KAAAypC,EAGA,IAAA7pC,GAAA,GAAAI,OAAA,yCAAAypC,EAAA,IAEA,MADA7pC,GAAAi0B,QAAA4V,EACA7pC,EAOA,GAFA8pC,EAAAlwC,KAAA2vC,QAAAjqB,GAEAoqB,EAAAI,GACA,QAEA,IAAAtkB,EAAAskB,GACA,OAAAjtC,UAAAC,QAEA,OACAgtC,EAAA3vC,KAAAP,KACA,MACA,QACAkwC,EAAA3vC,KAAAP,KAAAiD,UAAA,GACA,MACA,QACAitC,EAAA3vC,KAAAP,KAAAiD,UAAA,GAAAA,UAAA,GACA,MAEA,SACAjC,EAAAsH,MAAAzH,UAAAI,MAAAV,KAAA0C,UAAA,GACAitC,EAAA7uC,MAAArB,KAAAgB,OAEG,IAAAqpC,EAAA6F,GAIH,IAHAlvC,EAAAsH,MAAAzH,UAAAI,MAAAV,KAAA0C,UAAA,GACAktC,EAAAD,EAAAjvC,QACAuI,EAAA2mC,EAAAjtC,OACAvC,EAAA,EAAeA,EAAA6I,EAAS7I,IACxBwvC,EAAAxvC,GAAAU,MAAArB,KAAAgB,EAGA,WAGA0uC,EAAA7uC,UAAAsV,YAAA,SAAAuP,EAAA0qB,GACA,GAAA5vC,EAEA,KAAAorB,EAAAwkB,GACA,KAAAtuC,WAAA,8BA2CA,OAzCA9B,MAAA2vC,UACA3vC,KAAA2vC,YAIA3vC,KAAA2vC,QAAAU,aACArwC,KAAAuW,KAAA,cAAAmP,EACAkG,EAAAwkB,YACAA,cAEApwC,KAAA2vC,QAAAjqB,GAGA2kB,EAAArqC,KAAA2vC,QAAAjqB,IAEA1lB,KAAA2vC,QAAAjqB,GAAArd,KAAA+nC,GAGApwC,KAAA2vC,QAAAjqB,IAAA1lB,KAAA2vC,QAAAjqB,GAAA0qB,GANApwC,KAAA2vC,QAAAjqB,GAAA0qB,EASA/F,EAAArqC,KAAA2vC,QAAAjqB,MAAA1lB,KAAA2vC,QAAAjqB,GAAAnV,SAIA/P,EAHAsvC,EAAA9vC,KAAA4vC,eAGAF,EAAAK,oBAFA/vC,KAAA4vC,cAKApvC,KAAA,GAAAR,KAAA2vC,QAAAjqB,GAAAxiB,OAAA1C,IACAR,KAAA2vC,QAAAjqB,GAAAnV,QAAA,EACAjJ,QAAAjB,MAAA,mIAGArG,KAAA2vC,QAAAjqB,GAAAxiB,QACA,kBAAAoE,SAAAiC,OAEAjC,QAAAiC,UAKAvJ,MAGA0vC,EAAA7uC,UAAAqV,GAAAw5B,EAAA7uC,UAAAsV,YAEAu5B,EAAA7uC,UAAAsI,KAAA,SAAAuc,EAAA0qB,GAMA,QAAAE,KACAtwC,KAAAqW,eAAAqP,EAAA4qB,GAEAC,IACAA,GAAA,EACAH,EAAA/uC,MAAArB,KAAAiD,YAVA,IAAA2oB,EAAAwkB,GACA,KAAAtuC,WAAA,8BAEA,IAAAyuC,IAAA,CAcA,OAHAD,GAAAF,WACApwC,KAAAkW,GAAAwP,EAAA4qB,GAEAtwC,MAIA0vC,EAAA7uC,UAAAwV,eAAA,SAAAqP,EAAA0qB,GACA,GAAAI,GAAAC,EAAAvtC,EAAAvC,CAEA,KAAAirB,EAAAwkB,GACA,KAAAtuC,WAAA,8BAEA,KAAA9B,KAAA2vC,UAAA3vC,KAAA2vC,QAAAjqB,GACA,MAAA1lB,KAMA,IAJAwwC,EAAAxwC,KAAA2vC,QAAAjqB,GACAxiB,EAAAstC,EAAAttC,OACAutC,GAAA,EAEAD,IAAAJ,GACAxkB,EAAA4kB,EAAAJ,WAAAI,EAAAJ,mBACApwC,MAAA2vC,QAAAjqB,GACA1lB,KAAA2vC,QAAAt5B,gBACArW,KAAAuW,KAAA,iBAAAmP,EAAA0qB,OAEG,IAAA/F,EAAAmG,GAAA,CACH,IAAA7vC,EAAAuC,EAAoBvC,KAAA,GACpB,GAAA6vC,EAAA7vC,KAAAyvC,GACAI,EAAA7vC,GAAAyvC,UAAAI,EAAA7vC,GAAAyvC,aAAA,CACAK,EAAA9vC,CACA,OAIA,GAAA8vC,EAAA,EACA,MAAAzwC,KAEA,KAAAwwC,EAAAttC,QACAstC,EAAAttC,OAAA,QACAlD,MAAA2vC,QAAAjqB,IAEA8qB,EAAA1jC,OAAA2jC,EAAA,GAGAzwC,KAAA2vC,QAAAt5B,gBACArW,KAAAuW,KAAA,iBAAAmP,EAAA0qB,GAGA,MAAApwC,OAGA0vC,EAAA7uC,UAAAyV,mBAAA,SAAAoP,GACA,GAAA/Z,GAAAwkC,CAEA,KAAAnwC,KAAA2vC,QACA,MAAA3vC,KAGA,KAAAA,KAAA2vC,QAAAt5B,eAKA,MAJA,KAAApT,UAAAC,OACAlD,KAAA2vC,WACA3vC,KAAA2vC,QAAAjqB,UACA1lB,MAAA2vC,QAAAjqB,GACA1lB,IAIA,QAAAiD,UAAAC,OAAA,CACA,IAAAyI,IAAA3L,MAAA2vC,QACA,mBAAAhkC,GACA3L,KAAAsW,mBAAA3K,EAIA,OAFA3L,MAAAsW,mBAAA,kBACAtW,KAAA2vC,WACA3vC,KAKA,GAFAmwC,EAAAnwC,KAAA2vC,QAAAjqB,GAEAkG,EAAAukB,GACAnwC,KAAAqW,eAAAqP,EAAAyqB,OACG,IAAAA,EAEH,KAAAA,EAAAjtC,QACAlD,KAAAqW,eAAAqP,EAAAyqB,IAAAjtC,OAAA,GAIA,cAFAlD,MAAA2vC,QAAAjqB,GAEA1lB,MAGA0vC,EAAA7uC,UAAAsvC,UAAA,SAAAzqB,GACA,GAAAqK,EAOA,OAHAA,GAHA/vB,KAAA2vC,SAAA3vC,KAAA2vC,QAAAjqB,GAEAkG,EAAA5rB,KAAA2vC,QAAAjqB,KACA1lB,KAAA2vC,QAAAjqB,IAEA1lB,KAAA2vC,QAAAjqB,GAAAzkB,YAIAyuC,EAAA7uC,UAAA6vC,cAAA,SAAAhrB,GACA,GAAA1lB,KAAA2vC,QAAA,CACA,GAAAgB,GAAA3wC,KAAA2vC,QAAAjqB,EAEA,IAAAkG,EAAA+kB,GACA,QACA,IAAAA,EACA,MAAAA,GAAAztC,OAEA,UAGAwsC,EAAAgB,cAAA,SAAAE,EAAAlrB,GACA,MAAAkrB,GAAAF,cAAAhrB,K3E27OM,SAAS7lB,EAAQD,G4EltPvB,GAAA2I,GAAAD,MAAAC,QAMA2P,EAAAtX,OAAAC,UAAAkZ,QAmBAla,GAAAD,QAAA2I,GAAA,SAAAqS,GACA,QAAAA,GAAA,kBAAA1C,EAAA3X,KAAAqa,K5E+tPM,SAAS/a,EAAQD,EAASM,G6E1vPhCA,EAAA,IACAL,EAAAD,QAAAoC,KAAAwB,MAAA+rC,KAAAvtC,O7EqwPM,SAASnC,EAAQD,G8E1wPvB,YAEA,SAAAixC,GAAA34B,EAAA44B,EAAAC,GAGA,IAFA,GAAAC,GAAA,GACAC,EAAAF,EAAA74B,EAAAhV,OACA8tC,EAAA9tC,OAAA+tC,GACAD,GAAAF,CAEA,OAAAE,GAGApxC,EAAAka,QAAA,SAAA5B,EAAA44B,EAAAC,GACA,GAAAC,GAAAH,EAAA34B,EAAA44B,EAAAC,EACA,OAAAC,GAAA94B,GAGAtY,EAAAsxC,SAAA,SAAAh5B,EAAA44B,EAAAC,GACA,GAAAC,GAAAH,EAAA34B,EAAA44B,EAAAC,EACA,OAAA74B,GAAA84B,GAGApxC,EAAAuxC,iBAAA,SAAAhwC,EAAAC,GAEA,GAGAT,GAHAisC,EAAAzrC,EAAA+B,OACAkuC,EAAAhwC,EAAA8B,MAGA,KAAAvC,EAAA,EAAaA,EAAAisC,EAAUjsC,IAAA,CACvB,GAAAA,IAAAywC,EAEA,QAEA,IAAAC,GAAAlwC,EAAAglC,OAAAxlC,GACA2wC,EAAAlwC,EAAA+kC,OAAAxlC,EACA,IAAA0wC,IAAAC,EACA,MAAAD,GAAAC,GAAA,IAIA,MAAA1E,GAAAwE,GAEA,EAGA,GAOAxxC,EAAA2xC,iBAAA,SAAAC,GAEA,GAAAC,GAAAD,EAAA,EACApnC,EAAA,EAEA,IACA,GAAAsnC,GAAAD,GAAAjlC,KAAA6a,KAAAmqB,EAAA,IAAAhlC,KAAA2S,MAAAqyB,EAAA,GAEApnC,GAAAsnC,EAAAtnC,EACAonC,EAAAC,EAAAjlC,KAAA6a,KAAAmqB,EAAA,IAAAhlC,KAAA2S,MAAAqyB,EAAA,UACGA,EAOH,OAJAC,IAAA,MAAArnC,IACAA,EAAA,IAAAA,GAGAA,I9EixPM,SAASvK,EAAQD,EAASM,G+Er1PhC,YAMA,SAAAyF,GAAAsM,GACA,IAAAA,EACA,iBAIA,cAAAA;AACA,eAEA,MAAAA,GAAA8H,UACA,cAEA,MAAA9H,GAAA8H,UACA,SAEA,MAAArU,MAAAC,UAAAsM,IAnBA,GAAAua,GAAAtsB,EAAA,IACAgS,EAAAhS,EAAA,IACAiE,EAAA+N,EAAA/N,OAqBAtE,GAAAD,QAAA,SAAAsT,GACA,GAAAy+B,GAAAz+B,EAAAuZ,GACAxH,EAAA/R,EAAA+R,SACA2sB,EAAA1+B,EAAAxF,IACAmkC,EAAA3+B,EAAAyjB,OACAmb,EAAA5+B,EAAA4+B,UACAC,EAAA7+B,EAAA6+B,WAGAC,EAAArsC,EAAAisC,GAAAjsC,EAAAksC,GACA,WAEA,KAAAC,GAAAH,EAAAM,aAAA,CACA,GAAAC,GAAAP,EAAAM,aAAAD,EACA,IAAAE,EACA,MAAA/tC,GAAAoK,QAAA2jC,GAIA,MAAAP,GAAA1R,OAAA58B,KAAA,SAAA48B,GAOA,QAAAkS,GAAA1mC,GACAA,EAAA0Z,MAAA1Z,EAAA0Z,SACA,IAAAitB,GAAAntB,CACAmtB,GAAAnsC,QAAA,YACAmsC,EAAAntB,EAAA,IAAAA,EAEA,IAAAotB,GAAA5mC,EAAA0Z,MAAAitB,GAAA3mC,EAAA0Z,MAAAitB,MAEA,KAAAC,EAAAC,GAIA,MADAD,GAAAC,IAAA,EACA7mC,EAjBA,GAAA6mC,GAAArS,EAAAsS,QAAA,YACAT,EAAA,OAAA5/B,EAAApH,IAAAknC,GAkBA,OAAAxlB,GAAAmlB,EAAA,UAAAI,EAAAI,GAAA9uC,KAAA,WACA,MAAAsuC,GAAAa,0BAAAF,GAAAjvC,KAAA,SAAAQ,GACA,GAAA4oB,GAAA5oB,EAAA4oB,EACAA,GAAAgmB,iBAAA,CACA,IAAAvtB,IACApc,KAAAwpC,EACA7lB,KACAklB,WACAe,QAAAf,EAAAe,QACAd,SACAC,YAEA,OAAA3sB,GAAAuH,GAAAzmB,IAAA,kBAAA8I,MAAA,SAAA1I,GAEA,SAAAA,EAAA3B,OACA,KAAA2B,KAES/C,KAAA,SAAAsvC,GAST,MARAztB,GAAA0tB,IAAAD,IAAAC,IAAA,EACAd,IACAH,EAAAM,aAAAN,EAAAM,iBACAN,EAAAM,aAAAD,GAAA9sB,EACAA,EAAAuH,GAAAvW,GAAA,6BACAy7B,GAAAM,aAAAD,MAGA9sB,Y/Ei2PM,SAASrlB,EAAQD,EAASM,IgF57PhC,SAAAgJ,GAAA,YAqBA,SAAA2pC,GAAA9pC,GACA/I,KAAAyE,OAAA,IACAzE,KAAA8I,KAAA,oBACA9I,KAAA+I,UACA/I,KAAAqG,OAAA,CACA,KACAG,MAAAqC,kBAAA7I,KAAA6yC,GACG,MAAAxrC,KAKH,QAAAyrC,GAAA/pC,GACA/I,KAAAyE,OAAA,IACAzE,KAAA8I,KAAA,YACA9I,KAAA+I,UACA/I,KAAAqG,OAAA,CACA,KACAG,MAAAqC,kBAAA7I,KAAA8yC,GACG,MAAAzrC,KAKH,QAAA0rC,GAAAjqC,GAGA,MAAAA,GAAA7C,QAAA,WAAA6C,OAAAsH,MAAA,KAGA,QAAA4iC,GAAA3e,GAGA,WAAAA,EAAAnxB,QAAA,MAAAmpB,KAAAgI,EAAA,GAAAhO,KAGA,QAAA4sB,GAAAz5B,EAAA0V,GACA,GAAAgkB,GAAAlgC,EAAAwG,EAAA7N,IAAAujB,EAAAvjB,IACA,YAAAunC,IAAAlgC,EAAAwG,EAAAjX,MAAA2sB,EAAA3sB,OAGA,QAAA4wC,GAAAC,EAAArN,EAAAC,GAEA,MADAA,MAAA,EACA,gBAAAD,GACAqN,EAAAnyC,MAAA+kC,EAAAD,EAAAC,GACGA,EAAA,EACHoN,EAAAnyC,MAAA+kC,GAEAoN,EAGA,QAAAC,GAAAxgC,GACA,GAAA+H,GAAA/H,EAAAtQ,MAGAsuB,EAAAjW,GAAA,gBAAAA,MAAAwK,KAAAvS,EAAAxS,EACA,OAAAwwB,GAGA,QAAAyiB,GAAA7mB,EAAAplB,GACA,IACAolB,EAAAlW,KAAA,QAAAlP,GACG,MAAAjB,GACHkB,QAAAjB,MACA,qMAIAiB,QAAAjB,MAAAgB,IAIA,QAAAksC,GAAA9mB,EAAArjB,EAAApI,GAGA,IACA,OACA+iB,OAAA3a,EAAA/H,MAAA,KAAAL,IAEG,MAAAqG,GAEH,MADAisC,GAAA7mB,EAAAplB,IACYhB,MAAAgB,IAIZ,QAAAmsC,GAAAxwC,EAAAoG,GACA,GAAAqqC,GAAAzwC,EAAAkjC,WAAA,oBACAwN,EAAA1wC,EAAAkjC,WAAA,mBAEA,uBAAAljC,GAAAywC,IACA,mBAAAzwC,GAAA0wC,IACA1gC,EAAAhQ,EAAAywC,GAAAzwC,EAAA0wC,IAAA,EACA,SAAAb,GAAA,kGAEG,IAAAzpC,EAAAutB,QAAA3zB,EAAA2zB,UAAA,GACH,GAAA3zB,EAAA6pB,aACA,SAAAgmB,GAAA,4CACK,IAAA7vC,EAAAyK,MAAAzK,EAAAyK,KAAAvK,OAAA,IACLF,EAAA2wC,QAAA3wC,EAAA4wC,YACA,SAAAf,GAAA,6DAGA,GAAA7vC,EAAA4wC,YAAA,CACA,mBAAA5wC,GAAA4wC,YACA,SAAAf,GAAA,+BAAA7vC,EAAA4wC,YAAA,IAEA,IAAA5wC,EAAA4wC,YAAA,EACA,SAAAf,GAAA,wCACA7vC,EAAA4wC,YAAA,MAKA,QAAAC,GAAAtxC,GACA,gBAAAmG,GAEA,SAAAA,EAAAjE,OACA,MAAAlC,EAEA,MAAAmG,IAKA,QAAAorC,GAAAthC,GAWA,QAAAuhC,GAAAljB,EAAA3L,EAAA8uB,GAOA,QAAAC,KACA,MAAAjB,GAAA3e,GAGAlwB,EAAAoK,QAAA2lC,GAEAhvB,EAAAuH,GAAAzmB,IAAAmuC,GAAArlC,MAAA+kC,EAAAK,IAGA,QAAAE,GAAAC,GACA,MAAAA,GAAA5mC,KAAAvK,OAIAgiB,EAAAuH,GAAAG,SACAnf,KAAA4mC,EAAA5mC,KACAof,cAAA,IAJA1oB,EAAAoK,SAAgCmE,UAQhC,QAAA4hC,GAAAD,EAAAE,GAIA,OAHAC,MACAC,KAEA9zC,EAAA,EAAA6I,EAAA+qC,EAAA7hC,KAAAxP,OAAkDvC,EAAA6I,EAAS7I,IAAA,CAC3D,GAAAkS,GAAA0hC,EAAA7hC,KAAA/R,GACA8K,EAAAoH,EAAApH,GACA,IAAAA,IAGA+oC,EAAAnsC,KAAAoD,GACAgpC,EAAAhpC,EAAA2Z,MAAA,EACA3Z,EAAAipC,UAAAC,EAAAlpC,EAAA2Z,MACA3Z,EAAAipC,UAAA,CACA,GAAAE,GAAAD,EAAAlpC,EAAA2Z,IACA,UAAAwvB,KACAnpC,EAAAlJ,MAAAqyC,EAAAryC,QAKA,GAAAsyC,GAAAj0C,OAAA6M,KAAAknC,EAiBA,OAhBAE,GAAAhjC,QAAA,SAAAlG,GACA,IAAA8oC,EAAA9oC,GAAA,CAEA,GAAAmpC,IACA1vB,IAAAzZ,GAEAipC,EAAAD,EAAAhpC,EACA,UAAAipC,KACAE,EAAAvyC,MAAAqyC,EAAAryC,OAEAiyC,EAAAnsC,KAAAysC,MAGAT,EAAA5mC,KAAAyE,EAAA1E,KAAAqnC,EAAAvzC,OAAA+yC,EAAA5mC,OACA+mC,EAAAnsC,KAAAgsC,GAEAG,EAhEA,GAAAL,GAAA,cAAAtjB,EACAqjB,GAA0B9uB,IAAA+uB,EAAA1mC,SAC1BsnC,EAAAf,EAAAnjB,GACA8jB,EAAAI,EAAAJ,yBACAtgB,EAAA0gB,EAAA1gB,OA+DA,OAAA4f,KAAA5wC,KAAA,SAAAgxC,GACA,MAAAD,GAAAC,GAAAhxC,KAAA,SAAAkxC,GACA,MAAAD,GAAAD,EAAAE,OAOA,QAAAS,GAAA9vB,EAAA8uB,EAAApB,GACA,GAAAqC,GAAA,gBACA,OAAA/vB,GAAAuH,GAAAzmB,IAAAivC,GACAnmC,MAAA+kC,GAAuBzuB,IAAA6vB,EAAArC,IAAA,KACvBvvC,KAAA,SAAAsvC,GACA,GAAAuC,GAAAt0C,OAAA6M,KAAAumC,EACA,OAAA7vC,GAAAC,IAAA8wC,EAAAxnC,IAAA,SAAAmjB,GACA,MAAAkjB,GAAAljB,EAAA3L,EAAA8uB,MACO3wC,KAAA,SAAA8xC,GACP,GAAAC,GAAAljC,EAAA7G,QAAA8pC,EAIA,OAHAxC,GAAAC,MACAwC,EAAA/sC,KAAAsqC,GAEAztB,EAAAuH,GAAA4oB,UAAiCniB,KAAAkiB,QAKjC,QAAAE,GAAApwB,GACA,GAAAD,GAAA,gBAAAC,OAAApc,KACAuM,EAAAkgC,EAAAtwB,EAIA,OAHA5P,KACAA,EAAAkgC,EAAAtwB,GAAA,GAAAuwB,IAEAngC,EAGA,QAAAogC,GAAAvwB,GACA,MAAAhT,GAAAwR,cAAA4xB,EAAApwB,GAAA,WACA,MAAAwwB,GAAAxwB,OAIA,QAAAwwB,GAAAxwB,GAKA,QAAA3O,GAAA5K,EAAApJ,GACA,GAAAwhB,IAAoB1jB,GAAAoL,EAAA2Z,IAAAzZ,IAAAyO,EAAAzO,GAGpB,oBAAApJ,IAAA,OAAAA,IACAwhB,EAAAxhB,MAAA6X,EAAA7X,IAEAozC,EAAAttC,KAAA0b,GAOA,QAAA6xB,GAAA5B,EAAApB,GACA,kBACA,MAAAoC,GAAA9vB,EAAA8uB,EAAApB,IAnBA,GAAA+C,GACAlqC,EAYAmmC,EAAAhtB,EAAAM,EAAA0sB,OAAAr7B,GAEAs/B,EAAA3wB,EAAA0tB,KAAA,EAQAv9B,EAAA,GAAAmgC,EAEA,WAAArxC,GAAA,SAAAoK,EAAAtE,GAEA,QAAA6rC,KACAzgC,EAAA0gC,SAAA1yC,KAAA,WACA6hB,EAAA0tB,IAAAiD,EACAtnC,MAIA,QAAAynC,KAkDA,QAAAxrB,GAAApkB,GACA6D,EAAA7D,GAlDA8e,EAAAysB,SAAAtd,SACA4hB,WAAA,EACAppB,cAAA,EACAnF,MAAA,WACAue,MAAA4P,EACA9P,MAAAmQ,IACShgC,GAAA,oBAAA3Q,GACT,GAAA6tC,GAAA7tC,EAAA6tC,OACA,KAAAA,EAAAlwC,OACA,MAAA4yC,IAGA,QADA9B,MACArzC,EAAA,EAAAqN,EAAAolC,EAAAlwC,OAA6CvC,EAAAqN,EAAOrN,IAAA,CACpD,GAAAw1C,GAAA/C,EAAAzyC,EACA,UAAAw1C,EAAA1qC,IAAA2Z,IAAA,IACAuwB,KACAlqC,EAAA0qC,EAAA1qC,IAEAA,EAAAipC,UACAnB,EAAAruB,EAAAysB,SAAAC,GAAAnmC,IAEAkqC,EAAAhlC,KAAAsiC,EAIA,QADAmD,GADAzB,KAEAxwB,EAAA,EAAAkyB,EAAAV,EAAAzyC,OAAqDihB,EAAAkyB,EAAQlyB,IAAA,CAC7D,GAAA3iB,GAAAm0C,EAAAxxB,GACAmyB,GAAA90C,EAAAmK,IAAAnK,EAAAnB,GACA,KAAA2S,EAAAxR,EAAAmK,IAAAyqC,IACAE,EAAAjuC,KAAA8b,EAEA,IAAAoyB,GAAAx+B,EAAAu+B,EACA3B,GAAA4B,GAAA/0C,EACA40C,EAAA50C,EAAAmK,IAEAqoC,EAAAmC,EAAA1qC,IAAA2Z,MACAuvB,2BACAtgB,QAAA8hB,EAAA9hB,SAGAwhB,EAAAM,EAAAvD,IAGA,MADAv9B,GAAAwO,IAAA+xB,EAAA5B,EAAA6B,IACAzC,EAAAlwC,OAAAgzC,EACAJ,IAEAE,MACS9/B,GAAA,QAAAsU,GAOTwrB,MAIA,QAAAQ,GAAAtxB,EAAAkuB,EAAApwC,GACA,IAAAA,EAAA4wC,mBACA5wC,GAAA4wC,WAGA,IAAA6C,GAAAzzC,EAAA2wC,OAAA3wC,EAAA4wC,YAEA/B,EAAA/sB,EAAAI,EAAA2sB,WAEA6E,KACAC,EAAA3zC,EAAA4wC,WACAR,GAAAvhC,QAAA,SAAAxK,GACA,GAAAuvC,GAAAF,IAAAxzC,OAAA,GACAyI,EAAA8qC,EAAApvC,EAAAsE,IAAA,IAOA,OAJA8qC,IAAAnuC,MAAAC,QAAAoD,IAAA,gBAAAgrC,KACAhrC,IAAAzI,OAAAyzC,EAAAhrC,EAAA1K,MAAA,EAAA01C,GAAAhrC,GAGAirC,GAAA,IAAA5jC,EAAA4jC,EAAAjrC,IAAA,MAAAA,IACAirC,EAAAjrC,IAAAtD,MAAAsD,EAAAtE,EAAAhH,SACAu2C,GAAAr0C,MAAA8F,KAAAhB,EAAA9E,YAGAm0C,GAAAruC,MAAmBsD,MACnBA,EAAAtE,EAAAhH,KACAkC,OAAA8E,EAAA9E,UAEA,QAAA5B,GAAA,EAAA6I,EAAAktC,EAAAxzC,OAAwCvC,EAAA6I,EAAS7I,IAAA,CACjD,GAAA0G,GAAAqvC,EAAA/1C,GACAk2C,EAAAtD,EAAAruB,EAAAysB,SAAAE,GAAAxqC,EAAAsE,IAAAtE,EAAA9E,OAAA,GAGA,IAAAs0C,EAAAxwC,OAAA,eAAAgmB,KAAAwqB,EAAAxwC,MAAA/D,aAEA,KAAAu0C,GAAAxwC,KAGAgB,GAAA9E,MAAAs0C,EAAAxwC,MAAA,KAAAwwC,EAAA9yB,OACA1c,EAAAsE,IAAAtE,EAAAsE,IAAA,MAGA,OAAY+G,KAAAygC,EAAAuD,EAAA1zC,EAAA+iC,MAAA/iC,EAAAgjC,OAGZ,QAAA8Q,GAAA5xB,EAAAhS,GACA,MAAAhB,GAAAwR,cAAA4xB,EAAApwB,GAAA,WACA,MAAA6xB,GAAA7xB,EAAAhS,OAIA,QAAA6jC,GAAA7xB,EAAAhS,GAUA,QAAA8jC,GAAAC,GAEA,MADAA,GAAApqB,cAAA,EACA3H,EAAAuH,GAAAG,QAAAqqB,GAAA5zC,KAAA,SAAAQ,GAEA,MADAqzC,GAAArzC,EAAAqpB,WACArpB,EAAA6O,KAAAhF,IAAA,SAAAtD,GAMA,YAAAA,GAAAqB,KAAA,gBAAArB,GAAAqB,IAAAlJ,OACA,OAAA6H,EAAAqB,IAAAlJ,MAAA,CACA,GAAAkL,GAAA7M,OAAA6M,KAAArD,EAAAqB,IAAAlJ,OAAAoO,OAGAwmC,GAAA,mBACA,MAAA1pC,EAAA0pC,GAAA1pC,EAAA0pC,GACA,MAAA/sC,GAAAqB,IAAAlJ,MAIA,GAAA60C,GAAAC,EAAAx8B,qBAAAzQ,EAAAqB,IAAA2Z,IACA,QACAzZ,IAAAyrC,EAAA,GACA/2C,GAAA+2C,EAAA,GACA70C,MAAA,SAAA6H,GAAAqB,IAAArB,EAAAqB,IAAAlJ,MAAA,UAMA,QAAA+0C,GAAA5kC,GACA,GAAA6kC,EAUA,IARAA,EADAC,EACAhB,EAAAtxB,EAAAxS,EAAAQ,IAGAga,WAAAgqB,EACAO,OAAAzR,EACAtzB,QAGAQ,EAAA2Z,aAAA,CACA,GAAAqoB,GAAAhjC,EAAA1E,KAAAkF,EAAAhF,IAAA2lC,GAEA,OAAAnuB,GAAAysB,SAAA/kB,SACAnf,KAAAynC,EACAroB,cAAA,EACAopB,UAAA/iC,EAAA+iC,UACAyB,YAAAxkC,EAAAwkC,YACAC,OAAAzkC,EAAAykC,SACSt0C,KAAA,SAAAypB,GACT,GAAA8qB,KAaA,OAZA9qB,GAAApa,KAAAb,QAAA,SAAAgB,GACAA,EAAApH,MACAmsC,EAAA,IAAA/kC,EAAAxS,IAAAwS,EAAApH,OAGAiH,EAAAb,QAAA,SAAAgB,GACA,GAAAge,GAAAwiB,EAAAxgC,GACApH,EAAAmsC,EAAA,IAAA/mB,EACAplB,KACAoH,EAAApH,SAGA8rC,IAGA,MAAAA,GA7EA,GAAAL,GACAM,EAAAtyB,EAAA2sB,WAAA3+B,EAAAyjB,UAAA,EACAqP,EAAA9yB,EAAA8yB,MAAA,CACA,oBAAA9yB,GAAAzF,MAAAyF,EAAAzF,KAAAvK,SAEAgQ,EAAA6yB,MAAA,QACA7yB,GAAAzF,KA2EA,IAAApC,GAAA,SAAAsK,GACA,MAAAA,GAAAghB,OAAA,SAAAkN,EAAAgU,GACA,MAAAhU,GAAAviC,OAAAu2C,KAIA,uBAAA3kC,GAAAzF,KAAA,CACA,GAAAA,GAAAyF,EAAAzF,KACAqqC,EAAArqC,EAAAC,IAAA,SAAA/B,GACA,GAAAsrC,IACA7jC,SAAA2E,GAAApM,IACA0H,OAAA0E,GAAApM,OAEA,OAAAqrC,GAAAC,IAEA,OAAA9yC,GAAAC,IAAA0zC,GAAAz0C,KAAAgI,GAAAhI,KAAAi0C,GAEA,GAAAL,IACA/Q,WAAAhzB,EAAAgzB,WAOA,IALA,mBAAAhzB,GAAAE,WACA6jC,EAAA7jC,SACA2E,EADA7E,EAAAgzB,YACAhzB,EAAAE,cACAF,EAAAE,YAEA,mBAAAF,GAAAG,OAAA,CACA,GAAA8zB,GAAAj0B,EAAAK,iBAAA,CACAL,GAAAgzB,aACAiB,MAGA8P,EAAA5jC,OAAA0E,EAAAovB,GAAAj0B,EAAAG,YAA2EH,EAAAG,SAE3E,sBAAAH,GAAAvH,IAAA,CACA,GAAAosC,GAAAhgC,GAAA7E,EAAAvH,MACAqsC,EAAAjgC,GAAA7E,EAAAvH,QACAsrC,GAAA/Q,YACA+Q,EAAA5jC,OAAA0kC,EACAd,EAAA7jC,SAAA4kC,IAEAf,EAAA7jC,SAAA2kC,EACAd,EAAA5jC,OAAA2kC,GASA,MANAR,KACA,gBAAAtkC,GAAA6yB,QACAkR,EAAAlR,MAAA7yB,EAAA6yB,OAEAkR,EAAAjR,QAEAgR,EAAAC,GAAA5zC,KAAAi0C,GAIA,QAAAW,GAAAxrB,GACA,MAAAA,GAAAzmB,IAAA,UAAA+rC,GAAA1uC,KAAA,SAAAgxC,GACA,GAAA6D,KACAt3C,QAAA6M,KAAA4mC,EAAAlvB,OAAAtT,QAAA,SAAAugC,GACA,GAAAjiC,GAAA4iC,EAAAX,GACA+F,EAAA,WAAAhoC,EAAA,GACA8U,EAAA9U,EAAA,EACA+nC,GAAAC,GAAAD,EAAAC,OACAD,EAAAC,GAAAlzB,IAAA,GAEA,IAAA/R,IACAzF,KAAA7M,OAAA6M,KAAAyqC,GACArrB,cAAA,EAEA,OAAAJ,GAAAG,QAAA1Z,GAAA7P,KAAA,SAAAQ,GACA,GAAAu0C,KACAv0C,GAAA6O,KAAAb,QAAA,SAAAgB,GACA,GAAAwlC,GAAAxlC,EAAAlH,IAAAQ,UAAA,EACAvL,QAAA6M,KAAAyqC,EAAArlC,EAAAlH,MAAAkG,QAAA,SAAAoT,GACA,GAAAmtB,GAAAiG,EAAA,IAAApzB,CAEAovB,GAAAlvB,MAAAitB,KAGAA,EAAAntB,EAEA,IAAAqzB,GAAA13C,OAAA6M,KAAA4mC,EAAAlvB,MAAAitB,IAEAmG,EAAA1lC,EAAApH,KAAAoH,EAAApH,IAAA0Z,OAAAtS,EAAApH,IAAA0Z,MAAAF,EACAqzB,GAAAzmC,QAAA,SAAA2mC,GACAJ,EAAAI,GAAAJ,EAAAI,IAAAD,OAIA,IAAAE,GAAA73C,OAAA6M,KAAA2qC,GAAA1kC,OAAA,SAAA8kC,GACA,OAAAJ,EAAAI,KAEAE,EAAAD,EAAA/qC,IAAA,SAAA8qC,GACA,MAAAtmC,GAAAwR,cAAA4xB,EAAAkD,GAAA,WACA,UAAA/rB,GAAAnqB,YAAAk2C,EAAA/rB,EAAAksB,QAAAzoB,eAGA,OAAA/rB,GAAAC,IAAAs0C,GAAAr1C,KAAA,WACA,OAAkBwC,IAAA,QAGbguC,GAAchuC,IAAA,KAGnB,QAAA+yC,GAAAnsB,EAAArjB,EAAA8J,GACA,mBAAA9J,GAAA,CAEAoqC,EAAAtgC,EAAA9J,EAEA,IAAAyvC,IACApsB,KACAxH,SAAA,sBACAvX,IAAAtE,EAAAsE,IACAipB,OAAAvtB,EAAAutB,OACAmb,WAAA,EACAC,aAYA,OAVA+G,GAAAj1B,IAAA,WACA,MAAAk1B,GAAAF,GAAAx1C,KAAA,SAAA6hB,GACA,QAAA8zB,KACA,MAAA9zB,GAAAuH,GAAAyD,UAEA,MAAAhe,GAAAsR,IAAAiyB,EAAAvwB,GAAA7hB,KAAA,WACA,MAAAyzC,GAAA5xB,EAAAhS,KACW8lC,OAGXF,EAAA/C,SAGA,GAAA3D,GAAAhpC,EACA+G,EAAA4iC,EAAAX,GACA+F,EAAAhoC,EAAA,GACA8U,EAAA9U,EAAA,EACA,OAAAsc,GAAAzmB,IAAA,WAAAmyC,GAAA90C,KAAA,SAAAoI,GACA,GAAArC,GAAAqC,EAAA0Z,OAAA1Z,EAAA0Z,MAAAF,EAEA,KAAA7b,EAEA,SAAA0pC,GAAA,QAAArnC,EAAA2Z,IAAA,sBACAH,EAGAF,GAAAtZ,EAAAwZ,GACAuuB,EAAAtgC,EAAA9J,EAEA,IAAAyvC,IACApsB,KACAxH,SAAAmtB,EACA1kC,IAAAtE,EAAAsE,IACAipB,OAAAvtB,EAAAutB,OACAob,aAEA,OAAAgH,GAAAF,GAAAx1C,KAAA,SAAA6hB,GACA,aAAAhS,EAAA+lC,OAAA,iBAAA/lC,EAAA+lC,OACA,iBAAA/lC,EAAA+lC,OACA/vC,EAAAY,SAAA,WACA2rC,EAAAvwB,KAGA4xB,EAAA5xB,EAAAhS,IAEAuiC,EAAAvwB,GAAA7hB,KAAA,WACA,MAAAyzC,GAAA5xB,EAAAhS,SA9fA,GAAA6+B,GAAAv/B,EAAA1J,KACA8b,EAAApS,EAAAoS,OACAE,EAAAtS,EAAAsS,QACAC,EAAAvS,EAAAuS,cAmgBAtV,EAAA,SAAArG,EAAA8J,EAAAhJ,GACA,GAAAuiB,GAAAzsB,IACA,mBAAAkT,KACAhJ,EAAAgJ,EACAA,MAEAA,EAAAhB,EAAA1H,QAAA,KAAgC0I,GAEhC,kBAAA9J,KACAA,GAAasE,IAAAtE,GAGb,IAAAW,GAAA5F,EAAAoK,UAAAlL,KAAA,WACA,MAAAu1C,GAAAnsB,EAAArjB,EAAA8J,IAGA,OADAhB,GAAAvH,iBAAAZ,EAAAG,GACAH,GAGAmvC,EAAAhnC,EAAAzH,YAAA,WACA,GAAAgiB,GAAAzsB,IACA,OAAAi4C,GAAAxrB,IAGA,QACAhd,QACAypC,eAjrBA,GAMAvrC,GANA0pC,EAAAn3C,EAAA,GACAs1C,EAAAt1C,EAAA,IACA8S,EAAAqkC,EAAArkC,QACA+E,EAAAs/B,EAAAt/B,kBACAqC,EAAAi9B,EAAAj9B,aACA2+B,EAAA74C,EAAA,GAIAyN,GADA,mBAAArG,UAAA,kBAAAA,SAAAqG,IACAgK,SAAA9W,UAAA0uC,KAAAhvC,KAAA+G,QAAAqG,IAAArG,SAEA,YAEA,IAAA4K,GAAAhS,EAAA,IACAiE,EAAA+N,EAAA/N,QACAoxC,KACAuD,EAAA,GAAAtD,GACAU,EAAA,EAYAhkC,GAAA5H,SAAAuoC,EAAArsC,OAYA0L,EAAA5H,SAAAwoC,EAAAtsC,OA4oBA3G,EAAAD,QAAAk0C,IhFg8P8BvzC,KAAKX,EAASM,EAAoB,KAI1D,SAASL,EAAQD,EAASM,GiF3nRhC,YAOA,SAAAs1C,KACAx1C,KAAA+J,QAAA,GAAA5F,GAAA,SAAA6F,GAAiDA,MAHjD,GAAA7F,GAAAjE,EAAA,IAAAiE,OAKAqxC,GAAA30C,UAAAgjB,IAAA,SAAAF,GAMA,MALA3jB,MAAA+J,QAAA/J,KAAA+J,QAAA+E,MAAA,cAEGzL,KAAA,WACH,MAAAsgB,OAEA3jB,KAAA+J,SAEAyrC,EAAA30C,UAAAk1C,OAAA,WACA,MAAA/1C,MAAA+J,SAGAlK,EAAAD,QAAA41C,GjFkoRM,SAAS31C,EAAQD,EAASM,GkFxpRhC,YAIA,SAAAooC,GAAA7b,EAAA7Y,EAAA1J,GACA0J,EAAAulC,EAAAvlC,GAEA6Y,EAAA2sB,SACAj0C,OAAA,OACA6B,IAAA,SACA5B,KAAAwO,GACG1J,GAGH,QAAA4oB,GAAArG,EAAA7Y,EAAA1J,GACAuiB,EAAA2sB,SACAj0C,OAAA,OACA6B,IAAA,QACA5B,KAAAwO,GACG1J,GAGH,QAAAyiB,GAAAF,EAAAviB,GACAuiB,EAAA2sB,SACAj0C,OAAA,MACA6B,IAAA,UACGkD,GAGH,QAAAmvC,GAAA5sB,EAAApa,EAAAnI,GAGA,GAAA8a,GAAA3S,EAAA2S,KACAU,EAAArT,EAAAqT,MAAA,OACA5c,EAAAuJ,EAAAvJ,IAEA,KAAAkc,EACA,MAAA9a,GAAA,GAAA1D,OAAA,oCAGA,KAAAsC,EACA,MAAAoB,GAAA,GAAA1D,OAAA,oCAGA,IAAAQ,GAAA,WAAAge,EAAAU,EAAA5c,GAAA4E,IAAAiC,oBAAAqE,KAAA,IAEAyY,GAAA2sB,SACAj0C,OAAA,SACA6B,OACGkD,GA/CH,GAAAivC,GAAAj5C,EAAA,GAkDAN,GAAA0oC,cACA1oC,EAAAkzB,OACAlzB,EAAA+sB,aACA/sB,EAAAy5C,elF8pRM,SAASx5C,EAAQD,EAASM,GmFrtRhC,YAYA,SAAAssB,GAAAC,EAAAoE,EAAAnE,GACA,MAAA4sB,GAAA9sB,OAAAjsB,KAAAksB,EAAAoE,EAAAnE,GAGA,QAAA4b,GAAA7b,EAAA7Y,GAiBA,QAAA2lC,GAAA9tC,GASA,MARAA,GAAA0a,MAAA,UAAA1a,EAAAuhB,WACAwsB,GAAA,GAEA/tC,EAAAuhB,SAAA,QACAvhB,EAAA0Z,MAAA1Z,EAAA0Z,YAEAs0B,IAAAhuC,EAAA0Z,MAAAF,MAMAxZ,EAAA0Z,MAAAF,IACAvX,KACA1B,OAAAkG,EAAA3G,aAAAqI,EAAArB,MAAAvG,SAEA2qB,OAAA,SACA3zB,SACAwP,IAAAknC,IAIAjuC,GAvCAmI,EAAAulC,EAAAvlC,EACA,IAAA8lC,GAAAxnC,EAAA3H,MAAAqJ,EAAArB,MACAqB,GAAArB,MAAAH,EAAAwB,EAAArB,OAEAiB,EAAAI,EAAArB,MAEA,IAAAwc,GAAA7c,EAAApH,IAAApF,KAAAC,UAAAiO,IAEAqR,EAAArR,EAAA9K,MAAA,OAAAimB,EAEAspB,EAAAzkC,EAAAoR,MAAA,OAAA+J,EACA4qB,EAAA,WAAAtB,EAEAmB,GAAA,EACAC,GAAA,CA8BA,OAFA9rC,GAAA,iBAAAgsC,GAEAntB,EAAAC,EAAAktB,EAAAJ,GAAAl2C,KAAA,WACA,GAAAm2C,EACA,SAAAhzC,OAAA,sCACAmzC,EACA,2BAEGt2C,KAAA,WAIH,GAAAu2C,GAAAvB,EAAA,IAAApzB,CACA,OAAAM,GAAA9V,MAAAlP,KAAAksB,EAAAmtB,GACA7T,MAAA,EACApP,QAAA,IACKtzB,KAAA,WACL,OACAhD,GAAAs5C,EACA7wC,KAAAmc,EACA7a,OAAAqvC,EAAA,wBA7EA,GAAAvnC,GAAAhS,EAAA,GACAyN,EAAAuE,EAAAvE,IAEA2rC,EAAAp5C,EAAA,IACAqlB,EAAArlB,EAAA,IACAmlB,EAAAnlB,EAAA,GACAsT,EAAA6R,EAAA7R,cACApB,EAAAiT,EAAAjT,gBACA+mC,EAAAj5C,EAAA,GA2EAL,GAAAD,QAAA0oC,GnF4tRM,SAASzoC,EAAQD,EAASM,GoFjzRhC,YAKA,SAAAm5C,GAAA5sB,EAAAla,GAaA,QAAAsnC,GAAApuC,GACA,WAAA7K,OAAA6M,KAAAhC,EAAA0Z,OAAAjiB,QAAAuI,EAAA0Z,MAAAF,IAEcG,IAAAyL,EAAA6jB,UAAA,UAGdjpC,GAAA0Z,MAAAF,GACAxZ,GAlBA,IAAA8G,EAAAyS,KACA,SAAAxe,OAAA,8CAGA,KAAA+L,EAAAzJ,KACA,SAAAtC,OAAA,8CAGA,IAAAqqB,GAAAte,EAAAyS,KACAC,EAAA1S,EAAAzJ,IAYA,OAAA0jB,GAAAC,EAAAoE,EAAAgpB,GAAAx2C,KAAA,WACA,MAAAkiB,GAAA2zB,YAAA73C,MAAAorB,KACGppB,KAAA,WACH,OAAYwC,IAAA,KA7BZ,GAAA0f,GAAArlB,EAAA,IACAssB,EAAAtsB,EAAA,GAgCAL,GAAAD,QAAAy5C,GpFuzRM,SAASx5C,EAAQD,EAASM,GqF11RhC,YAoBA,SAAA45C,GAAAnpC,GAEA,QAAAopC,GAAAtuC,GACA,MAAAkF,GAAAjD,IAAA,SAAAkD,GACA,GAAA7E,GAAAyE,EAAAI,GACAlF,EAAAI,EAAAC,GACAiuC,EAAAxuC,EAAAC,EAAAC,EACA,OAAAsuC,KAIA,gBAAAC,EAAAC,GACA,GAAAC,GAAAJ,EAAAE,EAAAxuC,KACA2uC,EAAAL,EAAAG,EAAAzuC,KACA4uC,EAAArnC,EAAAmnC,EAAAC,EACA,YAAAC,EACAA,EAGAnoC,EAAAnF,QAAAktC,EAAAxuC,IAAA2Z,IAAA80B,EAAAzuC,IAAA2Z,MAIA,QAAAk1B,GAAA5nC,EAAAkB,EAAA2mC,GAKA,GAJA7nC,IAAAgB,OAAA,SAAAb,GACA,MAAA2nC,GAAA3nC,EAAApH,IAAAmI,EAAA9B,SAAAyoC,KAGA3mC,EAAAjD,KAAA,CAEA,GAAA8pC,GAAAX,EAAAlmC,EAAAjD,KACA+B,KAAA/B,KAAA8pC,GACA,gBAAA7mC,GAAAjD,KAAA,IACA,SAAAF,EAAAmD,EAAAjD,KAAA,MACA+B,IAAAgoC,WAIA,YAAA9mC,IAAA,QAAAA,GAAA,CAEA,GAAAoyB,GAAApyB,EAAAoyB,MAAA,EACAD,GAAA,SAAAnyB,KAAAmyB,MAAArzB,EAAAxP,QAAA8iC,CACAtzB,KAAAzR,MAAA+kC,EAAAD,GAEA,MAAArzB,GAGA,QAAA8nC,GAAA/uC,EAAAqG,EAAAyoC,GACA,MAAAA,GAAAI,MAAA,SAAA/tC,GACA,GAAAmF,GAAAD,EAAAlF,GACAlB,EAAAI,EAAAc,GACAotC,EAAAxuC,EAAAC,EAAAC,EACA,OAAAmF,GAAAjE,GACAguC,EAAAhuC,EAAAmF,EAAAtG,GAGAovC,EAAA9oC,EAAAtG,EAAAC,EAAAsuC,KAIA,QAAAa,GAAA9oC,EAAAtG,EAAAC,EAAAsuC,GACA,OAAAjoC,GAKAnR,OAAA6M,KAAAsE,GAAA4oC,MAAA,SAAAG,GACA,GAAAC,GAAAhpC,EAAA+oC,EACA,OAAA9yB,GAAA8yB,EAAArvC,EAAAsvC,EAAArvC,EAAAsuC,KAIA,QAAAY,GAAAhuC,EAAAmF,EAAAtG,GAEA,cAAAmB,EACAmF,EAAAipC,KAAA,SAAAC,GACA,MAAAT,GAAA/uC,EAAAwvC,EAAAr6C,OAAA6M,KAAAwtC,MAIA,SAAAruC,GACA4tC,EAAA/uC,EAAAsG,EAAAnR,OAAA6M,KAAAsE,KAIAA,EAAA+gB,KAAA,SAAAmoB,GACA,MAAAT,GAAA/uC,EAAAwvC,EAAAr6C,OAAA6M,KAAAwtC,MAKA,QAAAjzB,GAAA8yB,EAAArvC,EAAAsvC,EAAArvC,EAAAsuC,GACA,IAAAkB,EAAAJ,GACA,SAAAt0C,OAAA,qBAAAs0C,EACA,0HAGA,OAAAI,GAAAJ,GAAArvC,EAAAsvC,EAAArvC,EAAAsuC,GAGA,QAAAmB,GAAAnB,GACA,yBAAAA,IAAA,OAAAA,EAGA,QAAAoB,GAAApB,GACA,yBAAAA,GAGA,QAAAqB,GAAArB,EAAAe,GACA,GAAAO,GAAAP,EAAA,GACAQ,EAAAR,EAAA,EACA,QAAAO,EACA,SAAA90C,OAAA,qCAGA,IAAAmS,SAAA2iC,EAAA,MAAAA,EACA,SAAA90C,OAAA,4BAGA,IAAAmS,SAAA4iC,EAAA,MAAAA,EACA,SAAA/0C,OAAA,4BAGA,OAAAmS,UAAAqhC,EAAA,MAAAA,GAIAA,EAAAsB,IAAAC,EAGA,QAAAC,GAAAxB,EAAAe,GACA,MAAAA,GAAAC,KAAA,SAAApgC,GACA,MAAAo/B,aAAA1xC,OACA0xC,EAAA/zC,QAAA2U,IAAA,EAGAo/B,IAAAp/B,IAIA,QAAA6gC,GAAAzB,EAAAe,GACA,MAAAA,GAAAJ,MAAA,SAAA//B,GACA,MAAAo/B,GAAA/zC,QAAA2U,IAAA,IAIA,QAAA8gC,GAAA1B,EAAAe,GACA,MAAAf,GAAA92C,SAAA63C,EAGA,QAAAY,GAAA3B,EAAAe,GACA,GAAAa,GAAA,GAAA3zB,QAAA8yB,EAEA,OAAAa,GAAAvvB,KAAA2tB,GAGA,QAAA6B,GAAA7B,EAAAe,GAEA,OAAAA,GACA,WACA,cAAAf,CACA,eACA,yBACA,cACA,wBACA,cACA,wBACA,aACA,MAAAA,aAAA1xC,MACA,cACA,MAAgB,uBAAAyR,SAAAxZ,KAAAy5C,GAGhB,SAAAxzC,OAAAu0C,EAAA,8FAxLA,GAAAxyC,GAAArI,EAAA,IACA8S,EAAA9S,EAAA,GAAA8S,QACAqS,EAAAnlB,EAAA,GACA2Q,EAAAwU,EAAAxU,qBACAL,EAAA6U,EAAA7U,OACAC,EAAA4U,EAAA5U,SACA3E,EAAAuZ,EAAAvZ,WACAoG,EAAAhS,EAAA,GACAsL,EAAA0G,EAAA1G,gBAqLA0vC,GAEAY,WAAA,SAAArwC,EAAAsvC,EAAArvC,EAAAsuC,GACA,QAAAzxC,EAAAyxC,KAIA,IAAAA,EAAA92C,SAIA,gBAAA82C,GAAA,GACAA,EAAAgB,KAAA,SAAApgC,GACA,MAAA4/B,GAAA5/B,EAAAmgC,EAAAn6C,OAAA6M,KAAAstC,MAIAf,EAAAgB,KAAA,SAAApgC,GACA,MAAAigC,GAAAE,EAAAtvC,EAAAC,EAAAkP,QAIA1J,IAAA,SAAAzF,EAAAsvC,EAAArvC,EAAAsuC,GACA,MAAAoB,GAAApB,IAAA,IAAAhnC,EAAAgnC,EAAAe,IAGA5pC,KAAA,SAAA1F,EAAAsvC,EAAArvC,EAAAsuC,GACA,MAAAoB,GAAApB,IAAAhnC,EAAAgnC,EAAAe,IAAA,GAGA3pC,IAAA,SAAA3F,EAAAsvC,EAAArvC,EAAAsuC,GACA,MAAAoB,GAAApB,IAAAhnC,EAAAgnC,EAAAe,GAAA,GAGAzpC,KAAA,SAAA7F,EAAAsvC,EAAArvC,EAAAsuC,GACA,MAAAoB,GAAApB,IAAAhnC,EAAAgnC,EAAAe,IAAA,GAGAxpC,IAAA,SAAA9F,EAAAsvC,EAAArvC,EAAAsuC,GACA,MAAAoB,GAAApB,IAAAhnC,EAAAgnC,EAAAe,GAAA,GAGAgB,QAAA,SAAAtwC,EAAAsvC,EAAArvC,EAAAsuC,GAEA,MAAAe,GACAK,EAAApB,IAGAoB,EAAApB,IAGAgC,KAAA,SAAAvwC,EAAAsvC,EAAArvC,EAAAsuC,GACA,MAAAmB,GAAAnB,IAAAqB,EAAArB,EAAAe,IAGAtpC,IAAA,SAAAhG,EAAAsvC,EAAArvC,EAAAsuC,GACA,MAAAe,GAAAJ,MAAA,SAAAsB,GACA,WAAAjpC,EAAAgnC,EAAAiC,MAGAC,IAAA,SAAAzwC,EAAAsvC,EAAArvC,EAAAsuC,GACA,MAAAmB,GAAAnB,IAAAwB,EAAAxB,EAAAe,IAGAoB,KAAA,SAAA1wC,EAAAsvC,EAAArvC,EAAAsuC,GACA,MAAAmB,GAAAnB,KAAAwB,EAAAxB,EAAAe,IAGAqB,MAAA,SAAA3wC,EAAAsvC,EAAArvC,EAAAsuC,GACA,MAAAmB,GAAAnB,IAAA0B,EAAA1B,EAAAe,IAGAsB,KAAA,SAAA5wC,EAAAsvC,EAAArvC,EAAAsuC,GACA,MAAAzxC,GAAAyxC,IAAAyB,EAAAzB,EAAAe,IAGAuB,OAAA,SAAA7wC,EAAAsvC,EAAArvC,EAAAsuC,GACA,MAAAmB,GAAAnB,IAAA2B,EAAA3B,EAAAe,IAGAwB,MAAA,SAAA9wC,EAAAsvC,EAAArvC,EAAAsuC,GACA,MAAA6B,GAAA7B,EAAAe,IAIAl7C,GAAAD,QAAA06C,GrFi2RM,SAASz6C,EAAQD,EAASM,GsF5nShC,YAmBA,SAAAs8C,GAAAjqC,GAEA,MAAAA,GAAAyS,KAAA7Y,UAAA,OAAAoG,EAAAzJ,KAGA,QAAA2zC,GAAAhwB,EAAAiwB,GACA,GAAAxpC,GAAA3I,EAAAmyC,EAwBA,OAnBAxpC,GAAAgzB,YACA,UAAAhzB,IAAA,gBAAAA,GAAAG,SACAH,EAAAG,OAAA,IAEA,YAAAH,IAAA,gBAAAA,GAAAE,WACAF,EAAA6yB,MAAA,KAGA,YAAA7yB,IAAA,gBAAAA,GAAAE,WACAF,EAAAE,SAAA,IAEA,UAAAF,IAAA,gBAAAA,GAAAG,SACAH,EAAA6yB,MAAA,IAGA,OAAA7yB,IAAA,gBAAAA,GAAAvH,MACAuH,EAAA6yB,MAAA,GAGAtZ,EAAAG,QAAA1Z,GAGA,QAAA4f,GAAArG,EAAA7Y,GAWA,MATAA,GAAA9B,WACA8B,EAAA9B,SAAAE,EAAA4B,EAAA9B,WAEA8B,EAAAjD,OACAiD,EAAAjD,KAAAD,EAAAkD,EAAAjD,OAGAsD,EAAAL,GAEA+Y,EAAAF,GAAAppB,KAAA,SAAAs5C,GAEA,GAAAC,GAAAC,EAAAjpC,EAAA+oC,EAAA5vB,SAEA+vB,EAAAF,EAAArqC,KAEAoB,GAAAC,EAAAkpC,EAEA,IAAA5pC,GAAAhB,EAAA1H,QAAA,GACAqiB,cAAA,EACA8J,QAAA,GACKimB,EAAAG,UAEL,gBAAA7pC,IAAA,UAAAA,IACAF,EAAAE,EAAAE,SAAAF,EAAAG,QAAA,EAEA,OAAc6f,QAGd,IAAA8pB,GAAAppC,EAAAjD,MACA,gBAAAiD,GAAAjD,KAAA,IACA,SAAAF,EAAAmD,EAAAjD,KAAA,GAmBA,OAjBAqsC,KAEA9pC,EAAAgzB,YAAA,EACAhzB,EAAAD,EAAAC,IAGA0pC,EAAArC,eAAAr3C,SAGA,SAAA0Q,KACAV,EAAA6yB,MAAAnyB,EAAAmyB,OAEA,QAAAnyB,KACAV,EAAA8yB,KAAApyB,EAAAoyB,OAIA7hC,EAAAoK,UAAAlL,KAAA,WACA,iBAAAy5C,EAAAh0C,KACA,MAAA2zC,GAAAhwB,EAAAvZ,EAEA,IAAA0mC,GAAA4C,EAAAM,EACA,OAAAv3B,GAAA9V,MAAAlP,KAAAksB,EAAAmtB,EAAA1mC,KAEK7P,KAAA,SAAAQ,GAELqP,EAAAI,mBAAA,IAGAzP,EAAA6O,KAAAD,EAAA5O,EAAA6O,KAAAQ,EAAAE,SAAA0pC,IAGAF,EAAArC,eAAAr3C,SAEAW,EAAA6O,KAAA4nC,EAAAz2C,EAAA6O,KAAAkB,EAAAgpC,EAAArC,gBAGA,IAAAj3C,IACA4vB,KAAArvB,EAAA6O,KAAAhF,IAAA,SAAAmF,GACA,GAAApH,GAAAoH,EAAApH,GACA,OAAAmI,GAAA5H,OACAkG,EAAA9F,KAAAX,EAAAmI,EAAA5H,QAEAP,IAQA,OAJAqxC,GAAAjpC,cACAvQ,EAAA25C,QAAA,mEAGA35C,MAvIA,GAAA4O,GAAAhS,EAAA,GACAqK,EAAA2H,EAAA3H,MACAoiB,EAAAzsB,EAAA,IACA8S,EAAA9S,EAAA,GAAA8S,QACAuS,EAAArlB,EAAA,IACA28C,EAAA38C,EAAA,IACAmlB,EAAAnlB,EAAA,GACAo6C,EAAAp6C,EAAA,IACA8R,EAAAqT,EAAArT,gBACAtB,EAAA2U,EAAA3U,YACAD,EAAA4U,EAAA5U,SACAwD,EAAAoR,EAAApR,oBACAN,EAAA0R,EAAA1R,aACAV,EAAAoS,EAAApS,eACAR,EAAA4S,EAAA5S,qBACAtO,EAAA+N,EAAA/N,OA6HAtE,GAAAD,QAAAkzB,GtFmoSM,SAASjzB,EAAQD,EAASM,GuFjxShC,YAgBA,SAAAg9C,GAAA3qC,EAAA3F,GAEA,OADAgG,GAAAL,EAAAC,IAAAxG,OAAA0B,IAAA8C,GACA7P,EAAA,EAAA6I,EAAAoJ,EAAA1P,OAA2CvC,EAAA6I,EAAS7I,IAAA,CACpD,GAAAw8C,GAAAvqC,EAAAjS,EACA,IAAAiM,IAAAuwC,EACA,SAGA,SAQA,QAAAC,GAAAtrC,EAAAlF,GACA,GAAAmF,GAAAD,EAAAlF,GACAkuC,EAAAtqC,EAAAuB,EAEA,eAAA+oC,EAKA,QAAAuC,GAAAlpC,EAAA5B,GACA,GAAAK,GAAAL,EAAAC,IAAAxG,OAAA0B,IAAA8C,EAEA,OAAA2D,GAAAlT,QAAA0P,KAAA,SAAAxP,EAAAC,GACA,GAAAk8C,GAAA1qC,EAAA3M,QAAA9E,GACAo8C,EAAA3qC,EAAA3M,QAAA7E,EAOA,OANAk8C,MAAA,IACAA,EAAAhpC,OAAAC,WAEAgpC,KAAA,IACAA,EAAAjpC,OAAAC,WAEArC,EAAAnF,QAAAuwC,EAAAC,KAKA,QAAAC,GAAAjrC,EAAAT,EAAAqC,GAEAA,EAAAkpC,EAAAlpC,EAAA5B,EAIA,QADAkrC,IAAA,EACA98C,EAAA,EAAA6I,EAAA2K,EAAAjR,OAA0CvC,EAAA6I,EAAS7I,IAAA,CACnD,GAAAiM,GAAAuH,EAAAxT,EACA,IAAA88C,IAAAP,EAAA3qC,EAAA3F,GACA,MAAAuH,GAAAlT,MAAAN,EAEAA,GAAA6I,EAAA,GAAA4zC,EAAAtrC,EAAAlF,KACA6wC,GAAA,GAGA,SAGA,QAAAC,GAAA5rC,GACA,GAAA9F,KASA,OARApL,QAAA6M,KAAAqE,GAAAD,QAAA,SAAAjF,GACA,GAAAmF,GAAAD,EAAAlF,EACAhM,QAAA6M,KAAAsE,GAAAF,QAAA,SAAAb,GACA,QAAAA,GACAhF,EAAA3D,KAAAuE,OAIAZ,EAGA,QAAA2xC,GAAAC,EAAArrC,EAAAT,EAAAqC,GACA,GAAA/J,GAAA8H,EAAA7G,QAEAuyC,EAEAJ,EAAAjrC,EAAAT,EAAAqC,GAEAupC,EAAA5rC,GAGA,OAAAurC,GAAAnrC,EAAA1E,KAAApD,GAAAmI,GAKA,QAAAsrC,GAAAjrC,EAAA6B,EAAAzI,GACA,GAAAyI,EAAA,CAGA,GAAAqpC,GAAA5rC,EAAAxF,gCAAA+H,EAAA7B,GACAmrC,EAAA7rC,EAAA7F,0BAAAL,EAAA4G,EAEA,OAAAkrC,IAAAC,EAMA,MAAA7rC,GAAAvF,wBAAAX,EAAA4G,GAIA,QAAAorC,GAAAjsC,GACA,MAAAksC,GAAAh4C,QAAA8L,MAAA,EAOA,QAAAmsC,GAAAtrC,EAAAd,GACA,GAAAqsC,GAAAvrC,EAAA,GACAb,EAAAD,EAAAqsC,GAEAC,EAAAx9C,OAAA6M,KAAAsE,GAAAipC,KAAA,SAAAqD,GACA,OAAAL,EAAAK,IAGA,KAAAD,EACA,QAGA,IAAAE,GAAA,IAAA19C,OAAA6M,KAAAsE,GAAA7O,QACA,QAAAsN,EAAAuB,EAEA,QAAAusC,EAGA,QAAAC,GAAAhsC,EAAAkC,EAAAzI,EAAA8F,GAEA,GAAAc,GAAAL,EAAAC,IAAAxG,OAAA0B,IAAA8C,GAEAguC,EAAAX,EAAAjrC,EAAA6B,EAAAzI,EAEA,SAAAwyC,GAIAN,EAAAtrC,EAAAd,GAUA,QAAA2sC,GAAA3sC,EAAAqC,EAAAM,EAAAsY,GAEA,MAAAA,GAAA4J,OAAA,SAAA9yB,EAAA0O,GACA,GAAAmsC,GAAAH,EAAAhsC,EAAAkC,EAAAN,EAAArC,EAIA,OAHA4sC,IACA76C,EAAAwE,KAAAkK,GAEA1O,OAMA,QAAA86C,GAAA7sC,EAAAqC,EAAAM,EAAAsY,GAiBA,QAAA6xB,GAAArsC,GAGA,OAFAK,GAAAL,EAAAC,IAAAxG,OAAA0B,IAAA8C,GACApD,EAAA,EACAzM,EAAA,EAAA6I,EAAAoJ,EAAA1P,OAA6CvC,EAAA6I,EAAS7I,IAAA,CACtD,GAAAw8C,GAAAvqC,EAAAjS,EACAk+C,GAAA1B,IACA/vC,IAGA,MAAAA,GAxBA,GAAA0xC,GAAAL,EAAA3sC,EAAAqC,EAAAM,EAAAsY,EAEA,QAAA+xB,EAAA57C,OAAA,CAGA,GAAA67C,GAAAhyB,EAAA,EAEA,OADAgyB,GAAAlrC,aAAA,EACAkrC,EAEA,OAAAD,EAAA57C,OACA,MAAA47C,GAAA,EAGA,IAAAD,GAAA3sC,EAAAlF,cAAAmH,EAcA,OAAAjC,GAAAjF,IAAA6xC,EAAAF,GAGA,QAAAI,GAAAlE,EAAAC,GACA,OAAAD,GACA,UACA,OAAcnvC,IAAAovC,EACd,YACA,OAAc1nC,OAAA0nC,EACd,YACA,OAAc3nC,SAAA2nC,EACd,WACA,OACA1nC,OAAA0nC,EACAxnC,eAAA,EAEA,WACA,OACAH,SAAA2nC,EACAznC,iBAAA,IAKA,QAAA2rC,GAAAntC,EAAAS,GACA,GAMA2sC,GANAtyC,EAAA4D,EAAA+B,EAAAC,IAAAxG,OAAA,IACA+F,EAAAD,EAAAlF,GACA2tC,KAEA4E,EAAAv+C,OAAA6M,KAAAsE,EAsBA,OAlBAotC,GAAAttC,QAAA,SAAAipC,GAEA,GAAAkD,EAAAlD,GAEA,WADAP,GAAAlyC,KAAAuE,EAIA,IAAAmuC,GAAAhpC,EAAA+oC,GAEAsE,EAAAJ,EAAAlE,EAAAC,EAGAmE,GADAA,EACAhtC,EAAA3G,cAAA2zC,EAAAE,IAEAA,KAKArC,UAAAmC,EACA3E,kBAIA,QAAA8E,GAAAvE,EAAAC,GACA,OAAAD,GACA,UACA,OACA1nC,SAAA2nC,EACA1nC,OAAA0nC,EAEA,YACA,OACA1nC,OAAA0nC,EAEA,YACA,OACA3nC,SAAA2nC,EAEA,WACA,OACA1nC,OAAA0nC,EACAxnC,eAAA,EAEA,WACA,OACAH,SAAA2nC,EACAznC,iBAAA,IAKA,QAAAgsC,GAAAxtC,EAAAS,GAWA,QAAAwjC,GAAAp1C,GAEA4+C,KAAA,GACAnsC,EAAA/K,KAAAm3C,GAEArY,KAAA,GACA9zB,EAAAhL,KAAAo3C,GAIAlF,EAAA3nC,EAAA3R,MAAAN,GAGA,OAjBA4+C,GACApY,EANAv0B,EAAAL,EAAAC,IAAAxG,OAAA0B,IAAA8C,GAEA+pC,KACAnnC,KACAC,KAkBA1S,EAAA,EAAA6I,EAAAoJ,EAAA1P,OAA2CvC,EAAA6I,EAAS7I,IAAA,CACpD,GAAAw8C,GAAAvqC,EAAAjS,GAEAoR,EAAAD,EAAAqrC,EAEA,KAAAprC,EAAA,CACAgkC,EAAAp1C,EACA,OACK,GAAAA,EAAA,GACL,UAAAoR,GAAA,CACAgkC,EAAAp1C,EACA,OAEA,GAAA++C,GACA,OAAA3tC,IAAA,QAAAA,IACA,OAAAA,IAAA,QAAAA,GACA4tC,EAAA/+C,OAAA6M,KAAAqE,EAAAc,EAAAjS,EAAA,KACAi/C,EAAA1tC,EAAA7E,YAAAsyC,GAAA,QACAE,EAAA3tC,EAAA7E,YAAAsyC,EAAA/+C,OAAA6M,KAAAsE,IACA+tC,EAAAJ,IAAAE,IAAAC,CACA,IAAAC,EAAA,CACA/J,EAAAp1C,EACA,QAQA,OAJAw+C,GAAAv+C,OAAA6M,KAAAsE,GAEAmtC,EAAA,KAEA/6B,EAAA,EAAmBA,EAAAg7B,EAAAj8C,OAA0BihB,IAAA,CAC7C,GAAA22B,GAAAqE,EAAAh7B,GACA42B,EAAAhpC,EAAA+oC,GAEA3nC,EAAAksC,EAAAvE,EAAAC,EAGAmE,GADAA,EACAhtC,EAAA3G,cAAA2zC,EAAA/rC,IAEAA,EAIAC,EAAA/K,KAAA,YAAA62C,KAAA9rC,SAAAosC,GACAnsC,EAAAhL,KAAA,UAAA62C,KAAA7rC,OAAAosC,GACA,mBAAAP,KACAK,EAAAL,EAAA5rC,iBAEA,iBAAA4rC,KACA/X,EAAA+X,EAAA3rC,eAIA,GAAA1P,IACAuP,WACAC,SAUA,OAPA,mBAAAksC,KACA17C,EAAAyP,gBAAAisC,GAEA,mBAAApY,KACAtjC,EAAA0P,cAAA4zB,IAIA4V,UAAAl5C,EACA02C,kBAIA,QAAAwF,KACA,OACAhD,WAAgB3pC,SAAA,MAEhBmnC,mBAIA,QAAAyF,GAAAluC,EAAAS,GACA,MAAAA,GAAAsB,YACAksC,EAAAjuC,EAAAS,GAGA,IAAAA,EAAAC,IAAAxG,OAAA9I,OAEA+7C,EAAAntC,EAAAS,GAGA+sC,EAAAxtC,EAAAS,GAGA,QAAAsqC,GAAAzD,EAAArsB,GAEApf,EAAA,iBAAAyrC,EAEA,IAAAtnC,GAAAsnC,EAAAtnC,SACAnB,EAAAyoC,EAAAzoC,KAEAsvC,EAAA/rC,EAAApC,EAAAnB,GAEAwD,EAAA8rC,EAAAj0C,OACAyI,EAAAwrC,EAAAxrC,UACAlC,EAAAosC,EAAA7sC,EAAAqC,EAAAM,EAAAsY,GAEAmzB,EAAAF,EAAAluC,EAAAS,GACAwqC,EAAAmD,EAAAnD,UACAa,EAAAsC,EAAA3F,eAEAA,EAAAoD,EAAAC,EAAArrC,EAAAT,EAAAqC,GAEAtQ,GACAk5C,YACAxqC,QACAgoC,iBAGA,OADA5sC,GAAA,aAAA9J,GACAA,EAjbA,GAAAqO,GAAAhS,EAAA,GACAyN,EAAAuE,EAAAvE,IACA0X,EAAAnlB,EAAA,GACAsQ,EAAA6U,EAAA7U,OACA0D,EAAAmR,EAAAnR,cAGAsrC,EAAA,KAGAC,GAAkB/X,QA4GlBuW,GAAA,gCA8TAp+C,GAAAD,QAAAi9C,GvFwxSM,SAASh9C,EAAQD,EAASM,GwF9sThC,YAEA,IAAAgS,GAAAhS,EAAA,GACAuK,EAAAyH,EAAAzH,WAEA7K,GAAA0oC,YAAA79B,EAAAvK,EAAA,KACAN,EAAAkzB,KAAAroB,EAAAvK,EAAA,KACAN,EAAA+sB,WAAAliB,EAAAvK,EAAA,KACAN,EAAAy5C,YAAA5uC,EAAAvK,EAAA,MxFotTM,SAASL,EAAQD,EAASM,GyF5tThC,YAEA,IAAAgS,GAAAhS,EAAA,GAEAigD,EAAAjgD,EAAA,IACAkgD,EAAAlgD,EAAA,IAEAoxB,IACAA,GAAAgX,YAAAp2B,EAAAzI,UAAA,SAAAmK,EAAA1J,GAEA,mBAAA0J,GACA,MAAA1J,GAAA,GAAA1D,OAAA,uCAGA,IAAAksC,GAAA,SAAA1yC,KAAA0lB,OAAAy6B,EAAAC,CAEA1N,GAAApK,YAAAtoC,KAAA4T,EAAA1J,KAGAonB,EAAAwB,KAAA5gB,EAAAzI,UAAA,SAAAmK,EAAA1J,GAOA,GALA,mBAAAA,KACAA,EAAA0J,EACAA,EAAAzQ,QAGA,gBAAAyQ,GACA,MAAA1J,GAAA,GAAA1D,OAAA,gDAGA,IAAAksC,GAAA,SAAA1yC,KAAA0lB,OAAAy6B,EAAAC,CAEA1N,GAAA5f,KAAA9yB,KAAA4T,EAAA1J,KAGAonB,EAAA3E,WAAAza,EAAAzI,UAAA,SAAAS,GAEA,GAAAwoC,GAAA,SAAA1yC,KAAA0lB,OAAAy6B,EAAAC,CAEA1N,GAAA/lB,WAAA3sB,KAAAkK,KAGAonB,EAAA+nB,YAAAnnC,EAAAzI,UAAA,SAAA4I,EAAAnI,GAEA,mBAAAmI,GACA,MAAAnI,GAAA,GAAA1D,OAAA,uCAGA,IAAAksC,GAAA,SAAA1yC,KAAA0lB,OAAAy6B,EAAAC,CAEA1N,GAAA2G,YAAAr5C,KAAAqS,EAAAnI,KAGArK,EAAAD,QAAA0xB,EAGA,mBAAA1qB,gBAAAyqB,SACAzqB,OAAAyqB,QAAAC,WzFouTA,GAEM,SAASzxB,EAAQD,EAASM,I0F/xThC,SAAAwX,GAAA,YAEA,SAAAyV,GAAAC,GAA+B,MAAAA,IAAA,gBAAAA,IAAA,WAAAA,KAAA,QAAAA,EAe/B,QAAAizB,GAAAp5B,GACA,yBAAAoJ,cAAApJ,YAAAoJ,cACA,mBAAA4E,OAAAhO,YAAAgO,MAGA,QAAAqrB,GAAAtwB,GACA,qBAAAA,GAAA/uB,MACA,MAAA+uB,GAAA/uB,MAAA,EAGA,IAAAye,GAAA,GAAA2Q,aAAAL,EAAAO,YACAgwB,EAAA,GAAAvhC,YAAAU,GACA8gC,EAAA,GAAAxhC,YAAAgR,EAEA,OADAuwB,GAAA5vB,IAAA6vB,GACA9gC,EAGA,QAAA+gC,GAAAx5B,GACA,GAAAA,YAAAoJ,aACA,MAAAiwB,GAAAr5B,EAEA,IAAAy5B,GAAAz5B,EAAAy5B,KACAh7B,EAAAuB,EAAAvB,IAEA,yBAAAuB,GAAAhmB,MACAgmB,EAAAhmB,MAAA,EAAAy/C,EAAAh7B,GAGAuB,EAAA05B,YAAA,EAAAD,EAAAh7B,GAUA,QAAA+F,GAAAlpB,GACA,GAAAi4B,GAAA55B,OAAAgI,eAAArG,EAEA,WAAAi4B,EACA,QAEA,IAAAomB,GAAApmB,EAAAl4B,WACA,yBAAAs+C,IACAA,gBAAAC,GAAAtgD,KAAAqgD,IAAAE,GAGA,QAAAv2C,GAAA0c,GACA,GAAA85B,GACApgD,EACA6I,CAEA,KAAAyd,GAAA,gBAAAA,GACA,MAAAA,EAGA,IAAA3e,MAAAC,QAAA0e,GAAA,CAEA,IADA85B,KACApgD,EAAA,EAAA6I,EAAAyd,EAAA/jB,OAAoCvC,EAAA6I,EAAS7I,IAC7CogD,EAAApgD,GAAA4J,EAAA0c,EAAAtmB,GAEA,OAAAogD,GAKA,GAAA95B,YAAAvM,MACA,MAAAuM,GAAA+5B,aAGA,IAAAX,EAAAp5B,GACA,MAAAw5B,GAAAx5B,EAGA,KAAAwE,EAAAxE,GACA,MAAAA,EAGA85B,KACA,KAAApgD,IAAAsmB,GAEA,GAAArmB,OAAAC,UAAAC,eAAAP,KAAA0mB,EAAAtmB,GAAA,CACA,GAAA4B,GAAAgI,EAAA0c,EAAAtmB,GACA,oBAAA4B,KACAw+C,EAAApgD,GAAA4B,GAIA,MAAAw+C,GAGA,QAAA53C,GAAAC,GACA,GAAAC,IAAA,CACA,OAAAC,IAAA,SAAAtI,GAEA,GAAAqI,EAEA,SAAA7C,OAAA,6BAEA6C,IAAA,EACAD,EAAA/H,MAAArB,KAAAgB,KAKA,QAAAyI,GAAAC,GAEA,MAAAJ,IAAA,SAAAtI,GAEAA,EAAAuJ,EAAAvJ,EACA,IAAAgB,GAAAhC,KAEA2J,EAAA,kBAAA3I,KAAAkC,OAAA,IAAAlC,EAAA6I,MACAE,EAAA,GAAAk3C,IAAA,SAAAj3C,EAAAC,GACA,GAAA3G,EACA,KACA,GAAA4G,GAAAf,EAAA,SAAA/C,EAAA+D,GACA/D,EACA6D,EAAA7D,GAEA4D,EAAAG,IAKAnJ,GAAAqH,KAAA6B,GACA5G,EAAAoG,EAAArI,MAAAW,EAAAhB,GACAsC,GAAA,kBAAAA,GAAAD,MACA2G,EAAA1G,GAEO,MAAA+D,GACP4C,EAAA5C,KASA,OALAsC,IACAI,EAAA1G,KAAA,SAAA+G,GACAT,EAAA,KAAAS,IACOT,GAEPI,IAMA,QAAAm3C,GAAAp4C,EAAAoB,GACA,QAAAi3C,GAAAn/C,EAAA8G,EAAA9H,GAEA,GAAA2M,GAAAohC,QAAA,CAEA,OADAqS,IAAAp/C,EAAA8G,QACAnI,EAAA,EAAqBA,EAAAK,EAAAkC,OAAA,EAAqBvC,IAC1CygD,EAAA/4C,KAAArH,EAAAL,GAEAgN,IAAAtM,MAAA,KAAA+/C,EAGA,IAAAC,GAAArgD,IAAAkC,OAAA,EACAlC,KAAAkC,OAAA,YAAAkD,EAAAvC,GACA,GAAAy9C,IAAAt/C,EAAA8G,OACAw4C,KAAAhgD,OACA8E,GAAA,QAAAA,IAAA,UAAAvC,IAEA8J,GAAAtM,MAAA,KAAAigD,GACAD,EAAAj7C,EAAAvC,KAKA,MAAA4F,GAAAH,GAAA,SAAAtI,GACA,GAAAhB,KAAAuhD,QACA,MAAAN,IAAAh3C,OAAA,GAAAzD,OAAA,sBAEA,IAAAxG,KAAAwhD,WACA,MAAAP,IAAAh3C,OAAA,GAAAzD,OAAA,yBAEA,IAAAxE,GAAAhC,IAEA,OADAmhD,GAAAn/C,EAAA8G,EAAA9H,GACAhB,KAAAyhD,UAAAC,QAWAx3C,EAAA7I,MAAArB,KAAAgB,GAVA,GAAAigD,IAAA,SAAAj3C,EAAAC,GACAjI,EAAAy/C,UAAAE,QAAA,SAAAC,GACAA,EACA33C,EAAA23C,GAEA53C,EAAAhI,EAAA8G,GAAAzH,MAAAW,EAAAhB,WAUA,QAAAoL,GAAA5K,EAAAkG,GAEA,OADA7D,MACAlD,EAAA,EAAA6I,EAAA9B,EAAAxE,OAAmCvC,EAAA6I,EAAS7I,IAAA,CAC5C,GAAAsgC,GAAAv5B,EAAA/G,EACAsgC,KAAAz/B,KACAqC,EAAAo9B,GAAAz/B,EAAAy/B,IAGA,MAAAp9B,GAGA,QAAAg+C,GAAAl2C,GACA,UAAAA,EAEA,QAAAm2C,GAAAn2C,GACA,MAAAA,GAAAQ,UAAA,GAEA,QAAA41C,KACA/hD,KAAAgiD,UAoCA,QAAAC,GAAAtsC,GAIA,GAHA3V,KAAAgiD,OAAA,GAAAD,GAGApsC,GAAArN,MAAAC,QAAAoN,GACA,OAAAhV,GAAA,EAAA6I,EAAAmM,EAAAzS,OAAuCvC,EAAA6I,EAAS7I,IAChDX,KAAA6jB,IAAAlO,EAAAhV,IAyBA,QAAAuhD,KACA,sBAAAj6C,SAAA,mBAAAk6C,MAAA,mBAAAC,KACA,QAEA,IAAAnhB,GAAArgC,OAAAyhD,yBAAAF,IAAAl6C,OAAAq6C,QACA,OAAArhB,IAAA,OAAAA,IAAAkhB,IAAAl6C,OAAAq6C,WAAAH,IAwBA,QAAAI,GAAA/oC,GACA,MAAAA,GAGA,QAAAgpC,GAAAp4C,GACA,QACAvE,GAAAuE,IAKA,QAAAq4C,GAAAh2B,EAAAvZ,EAAAhJ,GAiBA,QAAAw4C,KACA,GAAAtP,KACAuP,GAAA9wC,QAAA,SAAAhO,GACAA,EAAAqvB,KAAArhB,QAAA,SAAAouB,GACAmT,EAAA/qC,MACAhI,GAAAwD,EAAAxD,GACA6yB,MAAA+M,SAIA/1B,EAAA,MAAoBkpC,YAGpB,QAAAwP,OACAC,IAAAC,GACAJ,IAIA,QAAAK,GAAAC,EAAA3iD,EAAA6yB,GACAyvB,EAAAK,IAA+B3iD,KAAA6yB,QAC/B0vB,IAUA,QAAAK,KAEA,KAAAtiD,GAAAuiD,EAAAhgD,QAAA,CAIA,GAAAigD,GAAA32C,KAAAC,IAAA9L,EAAAyiD,GAAAF,EAAAhgD,QACAmgD,EAAAH,EAAAjiD,MAAAN,EAAAwiD,EACAG,GAAAD,EAAA1iD,GACAA,GAAA0iD,EAAAngD,QAGA,QAAAogD,GAAAD,EAAA5L,GACA4L,EAAAxxC,QAAA,SAAAgf,EAAA1M,GACA,GAAAo/B,GAAA9L,EAAAtzB,EACAq/B,EAAAC,EAAAz9C,IAAA6qB,GAQA6yB,EAAAt3C,EAAAo3C,EAAA,gCACAE,GAAAC,UAAAH,EAAA91C,IAAA,SAAA0rC,GAEA,MAAAA,GAAA/yB,MAIAq9B,EAAAC,UAAAD,EAAAC,UAAAjwC,OAAA6uC,EAEA,IAAAqB,GAAArB,CAEA,KAAAmB,EAAAC,UAAAzgD,eACAwgD,GAAAC,UAKAC,EAAApB,IAIA,+CAAA3wC,QAAA,SAAAgyC,GACAA,IAAA3wC,KACAwwC,EAAAG,GAAA3wC,EAAA2wC,MAGAp3B,EAAAzmB,IAAA6qB,EAAA6yB,EAAA,SAAAt9C,EAAAvC,GACA,GAAAuG,EAGAA,GADAhE,IACqBC,MAAAD,IAErBw9C,EAAA//C,GAEAk/C,EAAAQ,EAAA1yB,EAAAzmB,GACA64C,QAzGA,GAAAa,GAAA5wC,EAAAggB,KAGAuwB,EAAA,GAAAM,GACAD,GAAAjyC,QAAA,SAAAunC,GACAqK,EAAA7kB,IAAAwa,EAAA/4C,IACAojD,EAAAz9C,IAAAozC,EAAA/4C,IAAAgI,KAAA+wC,GAEAqK,EAAA9yB,IAAAyoB,EAAA/4C,IAAA+4C,KAIA,IAAA0J,GAAAW,EAAA/C,KACAmC,EAAA,EACAF,EAAA,GAAAr6C,OAAAw6C,GA0BAI,IACAO,GAAA5xC,QAAA,SAAAtP,EAAAoJ,GACAu3C,EAAA76C,KAAAsD,IAGA,IAAAhL,GAAA,CAiEAsiD,KAIA,QAAAe,KACA,yBAAAj7B,SACA,mBAAAA,QAAAtL,SACA,mBAAAsL,QAAAtL,QAAAuL,MAgBA,QAAAi7B,KACA,MAAAC,IAMA,QAAAC,GAAAniD,GACAgiD,IACAj7B,OAAAtL,QAAA2mC,UAAAjuC,YAAA,SAAA9O,GAEA,MAAAA,EAAAkrC,SAEAvwC,EAAAuU,KAAAlP,EAAAg9C,OAAAC,YAGGL,MACH,mBAAAxxB,kBACAA,iBAAA,mBAAAprB,GACArF,EAAAuU,KAAAlP,EAAAsE,OAGA/E,OAAA29C,YAAA,mBAAAl9C,GACArF,EAAAuU,KAAAlP,EAAAsE,QAMA,QAAA64C,KACAC,GAAA/U,aAAAnvC,KAAAP,MACAA,KAAA0kD,cAEAP,EAAAnkD,MAwEA,QAAA2kD,GAAAx/C,GAEA,iBAAAmC,SAAAnC,IAAAmC,SAAA,CACA,GAAAtG,GAAAsH,MAAAzH,UAAAI,MAAAV,KAAA0C,UAAA,EACAqE,SAAAnC,GAAA9D,MAAAiG,QAAAtG,IAIA,QAAA4jD,GAAAn4C,EAAAQ,GACA,GAAA43C,GAAA,GACAp4C,GAAAkM,SAAAlM,EAAA,OACAQ,EAAA0L,SAAA1L,EAAA,IACAA,UAAAR,EACAQ,GAAAR,GAAA,MAEAQ,GAAA,EAGAA,EAAA43C,IACAp4C,EAAAo4C,GAAA,EACA53C,EAAA43C,EAEA,IAAAC,GAAAt4C,KAAA2C,SACA41C,EAAA93C,EAAAR,CAEA,UAAAs4C,EAAAD,EAAAr4C,GAGA,QAAAu4C,GAAAv4C,GACA,GAAAQ,GAAA,CAIA,OAHAR,KACAQ,EAAA,KAEA23C,EAAAn4C,EAAAQ,GAKA,QAAAg4C,GAAAxgD,EAAAyT,GACAysC,EAAA,oBAAAlgD,EAAA,uBAAAyT,GAkCA,QAAAgtC,GAAAzgD,EAAA4B,EAAAqC,GACAlC,MAAAjG,KAAAP,KAAA0I,GACA1I,KAAAyE,SACAzE,KAAA8I,KAAAzC,EACArG,KAAA+I,QAAAL,EACA1I,KAAAqG,OAAA,EAqCA,QAAA8+C,GAAA9+C,EAAAqC,GACA,QAAA08C,GAAA18C,GAIA,OAAAhI,KAAA2F,GACA,kBAAAA,GAAA3F,KACAV,KAAAU,GAAA2F,EAAA3F,GAIAyC,UAAAuF,IACA1I,KAAA0I,UAIA,MADA08C,GAAAvkD,UAAAqkD,EAAArkD,UACA,GAAAukD,GAAA18C,GAGA,QAAA28C,GAAAj/C,GAEA,mBAAAA,GAAA,CACA,GAAAN,GAAAM,CACAA,GAAAk/C,GACAl/C,EAAAN,OAoBA,MAjBA,SAAAM,IAAA,aAAAA,EAAAC,QACAD,EAAA0C,KAAA,WACA1C,EAAA3B,OAAA,KAGA,QAAA2B,KACAA,EAAA0C,KAAA1C,EAAAC,OAAA,WAGA,UAAAD,KACAA,EAAA3B,OAAA,KAGA,WAAA2B,KACAA,EAAA2C,QAAA3C,EAAA2C,SAAA3C,EAAAsC,QAGAtC,EAGA,QAAAm/C,GAAA7xC,EAAAjI,EAAA+5C,GACA,IACA,OAAA9xC,EAAAjI,EAAA+5C,GACG,MAAAp/C,GACH,GAAAq/C,GAAA,0BAAAr/C,EAAA2T,UACA,OAAAorC,GAAAO,GAAAD,IAIA,QAAAE,GAAAzyC,GACA,GAAAsyC,MACAI,EAAA1yC,EAAAQ,QAAA,kBAAAR,GAAAQ,MAGA,OAFA8xC,GAAA/1C,MAAAyD,EAAA2yC,aAEA,SAAA1P,GACAA,EAAA1qC,MAGA0qC,EAAA1qC,OAGA,IAAAq6C,GAAAF,GAAAL,EAAAryC,EAAAQ,OAAAyiC,EAAA1qC,IAAA+5C,EAEA,oBAAAM,GACA,MAAAA,EAGA,IAAAA,EACA,QAGA,IAAA5yC,EAAA2Z,cAEK,IAAA3Z,EAAAwkC,YACL,OAAAqO,KAAA5P,GAAA1qC,IAAAu6C,aAEA7P,EAAA1qC,IAAAu6C,aAAAllD,eAAAilD,KACA5P,EAAA1qC,IAAAu6C,aAAAD,GAAAE,MAAA,cALA9P,GAAA1qC,GASA,WAIA,QAAAJ,GAAAyY,GAEA,OADAjgB,MACAlD,EAAA,EAAA6I,EAAAsa,EAAA5gB,OAAoCvC,EAAA6I,EAAS7I,IAC7CkD,IAAAvC,OAAAwiB,EAAAnjB,GAEA,OAAAkD,GAOA,QAAAqjB,MAsBA,QAAAg/B,GAAA7lD,GACA,GAAA+F,EAQA,IAPA/F,EAEG,gBAAAA,GACH+F,EAAA++C,EAAAgB,IACG,KAAA95B,KAAAhsB,KAAA,mBAAAgsB,KAAAhsB,KACH+F,EAAA++C,EAAAiB,KAJAhgD,EAAA++C,EAAAkB,IAMAjgD,EACA,KAAAA,GAIA,QAAAsqC,GAAA4V,EAAA5gC,GACA,uBAAA4gC,KAAA5V,cAAAhrB,GACA++B,GAAA/U,aAAAgB,cAAA4V,EAAA5gC,GAeA,QAAA6gC,GAAA94B,GACA,IAAAA,EACA,WAEA,IAAAtd,GAAAsd,EAAArd,MAAA,IACA,YAAAD,EAAAjN,OACAiN,EAEA,IAAAA,EAAAjN,QACAuqB,KAEA,KAGA,QAAA+4B,GAAA/4B,GACA,GAAAg5B,GAAAF,EAAA94B,EACA,OAAAg5B,KAAAzyC,KAAA,UAeA,QAAA0yC,GAAAxuC,GAKA,IAJA,GAAA1X,GAAAmmD,GAAAplC,KAAArJ,GACA0uC,KACAjmD,EAAA,GAEAA,KAAA,CACA,GAAAgL,GAAA8B,GAAA9M,GACA4B,EAAA/B,EAAAG,IAAA,GACAkmD,GAAA,mBAAA5gD,QAAA0F,MAAA,CACAi7C,GAAAj7C,GAAAk7C,EAAAv2C,mBAAA/N,KAUA,MAPAqkD,GAAAE,OACAF,EAAAn5C,GAAA,KAAAxG,QAAA8/C,GAAA,SAAAC,EAAA9+B,EAAA++B,GACA/+B,IACA0+B,EAAAE,IAAA5+B,GAAA++B,KAIAL,EAMA,QAAAp6B,GAAAC,EAAAoE,EAAAnE,GACA,UAAAu0B,IAAA,SAAAj3C,EAAAC,GACAwiB,EAAAzmB,IAAA6qB,EAAA,SAAAzqB,EAAAqF,GACA,GAAArF,EAAA,CAEA,SAAAA,EAAA3B,OACA,MAAAwF,GAAA7D,EAEAqF,MAIA,GAAAqlB,GAAArlB,EAAA0a,KACA4K,EAAArE,EAAAjhB,EAEA,OAAAslB,IAQAA,EAAA3L,IAAAyL,EACAE,EAAA5K,KAAA2K,MACA9mB,GAAAgnB,EAAAvE,EAAAsE,EAAArE,KAPA1iB,GAAwBinB,SAAA,EAAA5K,IAAAyK,QAYxB,QAAAE,GAAAvE,EAAAhhB,EAAAihB,GACA,MAAAD,GAAAyE,IAAAzlB,GAAApI,KAAA,SAAAQ,GACA,OACAotB,SAAA,EACA5K,IAAAxiB,EAAAwiB,MAEG,SAAAjgB,GAEH,SAAAA,EAAA3B,OACA,KAAA2B,EAEA,OAAAomB,GAAAC,EAAAhhB,EAAA2Z,IAAAsH,KA4CA,QAAAjc,GAAAy2C,GACA,SAAA16C,KAAA2C,SAAA+3C,EAEA,QAAAC,GAAA39C,EAAA09C,GACAA,KAAAE,GAAAlkD,MACA,IAAA0nB,GAAA,GACAjqB,GAAA,CAEA,IAAA6I,EAAA,CAEA,OAAA7I,EAAA6I,GACAohB,GAAAw8B,GAAA32C,EAAAy2C,GAEA,OAAAt8B,GAKA,OAAAjqB,EAAA,IACA,OAAAA,GACA,OACA,QACA,QACA,QACAiqB,GAAA,GACA,MACA,SACAA,GAAAw8B,GAAA,EAAA32C,EAAA,MACA,MACA,SACAma,GAAAw8B,GAAA32C,EAAA,KAIA,MAAAma,GAQA,QAAAy8B,GAAAC,GAMA,IALA,GAAAC,GACAC,EACAC,EAEAC,EADAC,EAAAL,EAAAM,SAAA3mD,QAEAymD,EAAAC,EAAA99C,OAAA,CACA,GAAAg+C,GAAAH,EAAAz0B,IACA60B,EAAAD,EAAA,GACAE,EAAAL,EAAAK,GACA,IAAAD,EAAA5kD,OACA,OAAAvC,GAAA,EAAA6I,EAAAs+C,EAAA5kD,OAA4CvC,EAAA6I,EAAS7I,IACrDgnD,EAAAt/C,MAAsB0/C,MAAA,EAAA90B,IAAA60B,EAAAnnD,SAFtB,CAMA,GAAAsxB,KAAA41B,EAAA,GAAA51B,QACA5xB,EAAAwnD,EAAA,EAEAN,MAAAE,IAAAx1B,EAAAw1B,EACAD,IAAAO,EAAAP,EAAAO,EAAAR,EAAAlnD,KACAknD,EAAAlnD,EACAmnD,EAAAO,EACAN,EAAAx1B,IAIA,MAAAu1B,GAAA,IAAAD,EAOA,QAAAS,GAAAC,EAAA/9C,GAIA,IAHA,GAEAw9C,GAFAC,EAAAM,EAAAhnD,QAGAymD,EAAAC,EAAA99C,OAMA,OALAk+C,GAAAL,EAAAK,IACAF,EAAAH,EAAAz0B,IACA60B,EAAAD,EAAA,GACAK,EACAh+C,EAAA,IAAA49C,EAAA5kD,OAAA6kD,EAAAF,EAAA,GAAAH,EAAAntB,IAAAstB,EAAA,IACAlnD,EAAA,EAAA6I,EAAAs+C,EAAA5kD,OAA0CvC,EAAA6I,EAAS7I,IACnDgnD,EAAAt/C,MAAoB0/C,MAAA,EAAA90B,IAAA60B,EAAAnnD,GAAA45B,IAAA2tB,IAKpB,QAAAC,GAAAhnD,EAAAC,GACA,MAAAD,GAAA4mD,IAAA3mD,EAAA2mD,IAGA,QAAAK,GAAAH,GACA,GAAAI,KACAL,GAAAC,EAAA,SAAAK,EAAAP,EAAA1nD,EAAAkmC,EAAArzB,GACAo1C,GACAD,EAAAhgD,MAAmBge,IAAA0hC,EAAA,IAAA1nD,EAAA0nD,MAAA70C,WAGnBm1C,EAAA13C,KAAAw3C,GAAAzN,SACA,QAAA/5C,GAAA,EAAA6I,EAAA6+C,EAAAnlD,OAAsCvC,EAAA6I,EAAS7I,UAC/C0nD,GAAA1nD,GAAAonD,GAEA,OAAAM,GAMA,QAAAE,GAAAjB,GAIA,OAHAkB,GAAAnB,EAAAC,GACAe,EAAAD,EAAAd,EAAAM,UACA3R,KACAt1C,EAAA,EAAA6I,EAAA6+C,EAAAnlD,OAAsCvC,EAAA6I,EAAS7I,IAAA,CAC/C,GAAA8nD,GAAAJ,EAAA1nD,EACA8nD,GAAApiC,MAAAmiC,GAAAC,EAAAv1C,KAAA+e,SACAgkB,EAAA5tC,KAAAogD,EAAApiC,KAGA,MAAA4vB,GAKA,QAAAyS,GAAApB,GACA,GAAAW,KAQA,OAPAD,GAAAV,EAAAM,SAAA,SAAAU,EAAAP,EACAY,EAAApuB,EAAArnB,GACA,cAAAA,EAAAzO,QAAA6jD,IACAL,EAAA5/C,KAAA0/C,EAAA,IAAAY,GACAz1C,EAAAzO,OAAA,aAGAwjD,EAIA,QAAAW,GAAAX,GAIA,IAHA,GAEAP,GAFAruB,KACAsuB,EAAAM,EAAAhnD,QAEAymD,EAAAC,EAAA99C,OAAA,CACA,GAAAk+C,GAAAL,EAAAK,IACAF,EAAAH,EAAAz0B,IACA5yB,EAAAwnD,EAAA,GACA30C,EAAA20C,EAAA,GACAC,EAAAD,EAAA,GACAS,EAAA,IAAAR,EAAA5kD,OAEA2lD,EAAAnB,EAAAmB,QAAAnB,EAAAmB,QAAA5nD,UACA4nD,GAAAxgD,MAAkBhI,KAAA6S,SAClBo1C,GACAjvB,EAAAhxB,MAAkB0/C,MAAA,EAAAc,EAAA3lD,OAAA+vB,IAAA41B,GAElB,QAAAloD,GAAA,EAAA6I,EAAAs+C,EAAA5kD,OAA0CvC,EAAA6I,EAAS7I,IACnDgnD,EAAAt/C,MAAoB0/C,MAAA,EAAA90B,IAAA60B,EAAAnnD,GAAAkoD,YAGpB,MAAAxvB,GAAAqhB,UAcA,QAAAoO,GAAA3nD,EAAAC,GACA,MAAAD,GAAA4mD,IAAA3mD,EAAA2mD,IAIA,QAAAgB,GAAArhD,EAAAiqB,EAAAq3B,GAIA,IAHA,GAEAC,GAFAC,EAAA,EACAC,EAAAzhD,EAAAxE,OAEAgmD,EAAAC,GACAF,EAAAC,EAAAC,IAAA,EACAH,EAAAthD,EAAAuhD,GAAAt3B,GAAA,EACAu3B,EAAAD,EAAA,EAEAE,EAAAF,CAGA,OAAAC,GAIA,QAAAE,IAAA1hD,EAAAiqB,EAAAq3B,GACA,GAAAvvC,GAAAsvC,EAAArhD,EAAAiqB,EAAAq3B,EACAthD,GAAAoF,OAAA2M,EAAA,EAAAkY,GAMA,QAAA03B,IAAAtmD,EAAAumD,GAGA,OAFA5pD,GACA+oD,EACA9nD,EAAA2oD,EAAA9/C,EAAAzG,EAAAG,OAA6CvC,EAAA6I,EAAS7I,IAAA,CACtD,GAAA+mD,GAAA3kD,EAAApC,GACA4oD,GAAA7B,EAAArnD,GAAAqnD,EAAAx0C,QACAu1C,IACAA,EAAA,GAAApgD,KAAAkhD,GACAd,EAAAc,GAEA7pD,EAAA+oD,EAAAc,EAGA,MAAA7pD,GAIA,QAAA8pD,IAAAroD,EAAAC,GACA,MAAAD,GAAA,GAAAC,EAAA,QAKA,QAAAqoD,IAAAC,EAAAC,GAGA,IAFA,GAAAt0C,KAAgBu0C,MAAAF,EAAAG,MAAAF,IAChB1T,GAAA,EACA5gC,EAAAnS,OAAA,IACA,GAAAyuB,GAAAtc,EAAAxL,MACA+/C,EAAAj4B,EAAAi4B,MACAC,EAAAl4B,EAAAk4B,OAEAD,EAAA,GAAAnlD,QAAAolD,EAAA,GAAAplD,UACAmlD,EAAA,GAAAnlD,OACA,cAAAmlD,EAAA,GAAAnlD,QACA,cAAAolD,EAAA,GAAAplD,OAAA,sBAGA,QAAA9D,GAAA,EAAmBA,EAAAkpD,EAAA,GAAA3mD,OAAqBvC,IACxC,GAAAipD,EAAA,OAOA,OADAE,IAAA,EACA3lC,EAAA,EAAqBA,EAAAylC,EAAA,GAAA1mD,OAAqBihB,IAC1CylC,EAAA,GAAAzlC,GAAA,KAAA0lC,EAAA,GAAAlpD,GAAA,KACA0U,EAAAhN,MAAsBuhD,QAAA,GAAAzlC,GAAA0lC,QAAA,GAAAlpD,KACtBmpD,GAAA,EAGAA,KACA7T,EAAA,aACAmT,GAAAQ,EAAA,GAAAC,EAAA,GAAAlpD,GAAA6oD,SAdAvT,GAAA,WACA2T,EAAA,MAAAC,EAAA,GAAAlpD,GAiBA,OAAUs1C,YAAA4R,KAAA6B,GAGV,QAAAK,IAAAlC,EAAA9kD,EAAAinD,GACA,GAGAnmD,GAHAomD,KACAhU,GAAA,EACA6T,GAAA,CAGA,KAAAjC,EAAA3kD,OACA,OAAY2kD,MAAA9kD,GAAAkzC,UAAA,WAGZ,QAAAt1C,GAAA,EAAA6I,EAAAq+C,EAAA3kD,OAAoCvC,EAAA6I,EAAS7I,IAAA,CAC7C,GAAAupD,GAAArC,EAAAlnD,EACA,IAAAupD,EAAAnC,MAAAhlD,EAAAglD,KAAAmC,EAAAj3B,IAAA,KAAAlwB,EAAAkwB,IAAA,GAGApvB,EAAA4lD,GAAAS,EAAAj3B,IAAAlwB,EAAAkwB,KACAg3B,EAAA5hD,MAAoB0/C,IAAAmC,EAAAnC,IAAA90B,IAAApvB,EAAAgkD,OACpB5R,KAAApyC,EAAAoyC,UACA6T,GAAA,MACK,IAAAE,KAAA,GAML,GAAAG,GAAAD,EAAAnC,IAAAhlD,EAAAglD,IAAAmC,EAAAnnD,EACAqnD,EAAAF,EAAAnC,IAAAhlD,EAAAglD,IAAAhlD,EAAAmnD,EACA5hC,EAAA8hC,EAAArC,IAAAoC,EAAApC,IAEAsC,KAEAC,IAEA,KADAA,EAAAjiD,MAAkB4qB,IAAAk3B,EAAAl3B,IAAA3K,OAAA6J,OAAA,KAAAo4B,UAAA,OAClBD,EAAApnD,OAAA,IACA,GAAAyuB,GAAA24B,EAAAzgD,KACA,QAAA8nB,EAAArJ,KAOA,OADAkiC,GAAA74B,EAAAsB,IAAA,GACA9O,EAAA,EAAAsmC,EAAAD,EAAAtnD,OAAsDihB,EAAAsmC,EAAiBtmC,IACvEmmC,EAAAjiD,MACA4qB,IAAAu3B,EAAArmC,GACAmE,KAAAqJ,EAAArJ,KAAA,EACA6J,OAAAR,EAAAsB,IACAs3B,UAAApmC,QAXAwN,GAAAsB,IAAA,KAAAm3B,EAAAn3B,IAAA,IACAo3B,EAAAhiD,KAAAspB,GAeA,GAAAgZ,GAAA0f,EAAA,EAEA1f,IAGA9mC,EAAA4lD,GAAA9e,EAAA1X,IAAAm3B,EAAAn3B,KACA0X,EAAAxY,OAAA,GAAAwY,EAAA4f,WAAA1mD,EAAAgkD,KACAoC,EAAA5hD,MAAsB0/C,IAAAoC,EAAApC,IAAA90B,IAAAk3B,EAAAl3B,MACtBgjB,KAAApyC,EAAAoyC,UACA6T,GAAA,GANAG,EAAA5hD,KAAA6hD,OASAD,GAAA5hD,KAAA6hD,GAWA,MANAJ,IACAG,EAAA5hD,KAAAtF,GAGAknD,EAAAt5C,KAAAm4C,IAGAjB,KAAAoC,EACAhU,aAAA,iBAKA,QAAAyU,IAAA7C,EAAA8C,GAMA,OADAvgD,GAHAivB,EAAAuvB,EAAAf,GACA+C,KAGAjqD,EAAA,EAAA6I,EAAA6vB,EAAAn2B,OAAqCvC,EAAA6I,EAAS7I,IAAA,CAW9C,OARAoC,GAAAs2B,EAAA14B,GACAkqD,EAAA9nD,EAAAkwB,IACAq2B,EAAA98C,KAAAS,IAAA,EAAA49C,EAAA3nD,OAAAynD,GACAG,GACA/C,IAAAhlD,EAAAglD,IAAAuB,EACAr2B,IAAAo2B,GAAAwB,EAAAvB,IAGA77B,EAAA,EAAmBA,EAAA67B,EAAgB77B,IAAA,CACnC,GAAApH,GAAAtjB,EAAAglD,IAAAt6B,EAAA,IAAAo9B,EAAAp9B,GAAAptB,EACAuqD,GAAAvkC,IAAA,EAMAjc,EADAA,EACA2/C,GAAA3/C,EAAA0gD,GAAA,GAAAjD,MAEAiD,GASA,MALA9C,GAAA59C,EAAA,SAAAk+C,EAAAP,EAAAY,SAEAiC,GAAA7C,EAAA,IAAAY,MAIAd,KAAAz9C,EACA69C,KAAArnD,OAAA6M,KAAAm9C,IAIA,QAAAG,IAAAlD,EAAA9kD,EAAA4nD,GACA,GAAAK,GAAAjB,GAAAlC,EAAA9kD,GACA8nD,EAAAH,GAAAM,EAAAnD,KAAA8C,EACA,QACA9C,KAAAgD,EAAAhD,KACAoD,YAAAJ,EAAA5C,KACAhS,UAAA+U,EAAA/U,WAKA,QAAAiV,IAAAjD,EAAA5hC,GAOA,IANA,GAKAqhC,GALAC,EAAAM,EAAAhnD,QACAkqD,EAAA9kC,EAAAjW,MAAA,KACAg7C,EAAAzyC,SAAAwyC,EAAA,OACAE,EAAAF,EAAA,GAGAzD,EAAAC,EAAA99C,OAAA,CACA,GAAA69C,EAAAK,MAAAqD,GAAA1D,EAAAz0B,IAAA,KAAAo4B,EACA,QAGA,QADAvD,GAAAJ,EAAAz0B,IAAA,GACAtyB,EAAA,EAAA6I,EAAAs+C,EAAA5kD,OAA0CvC,EAAA6I,EAAS7I,IACnDgnD,EAAAt/C,MAAoB0/C,IAAAL,EAAAK,IAAA,EAAA90B,IAAA60B,EAAAnnD,KAGpB,SAGA,QAAA2qD,IAAA5D,GACA,MAAAA,GAAAz0B,IAMA,QAAAs4B,IAAAjE,EAAAjhC,GACAA,IACAA,EAAAghC,EAAAC,GAMA,KAJA,GAGAO,GAHAxnD,EAAAgmB,EAAAla,UAAAka,EAAApgB,QAAA,QACA0hD,EAAAL,EAAAM,SAAAl6C,IAAA49C,IAGAzD,EAAAF,EAAA99C,OAAA,CACA,GAAAg+C,EAAA,KAAAxnD,EACA,QAAAwnD,EAAA,GAAA51B,OAEA01B,KAAArmD,OAAAumD,EAAA,KAIA,QAAA2D,IAAAnrD,GACA,gBAAAgsB,KAAAhsB,GAIA,QAAAorD,IAAAplC,EAAAihC,GAGA,IAFA,GACAI,GADAC,EAAAL,EAAAM,SAAA3mD,QAEAymD,EAAAC,EAAA99C,OAAA,CACA,GAAAk+C,GAAAL,EAAAK,IACAF,EAAAH,EAAAz0B,IACA5yB,EAAAwnD,EAAA,GACA30C,EAAA20C,EAAA,GACAC,EAAAD,EAAA,GACAS,EAAA,IAAAR,EAAA5kD,OAEA2lD,EAAAnB,EAAAmB,QAAAnB,EAAAmB,QAAA5nD,UAGA,IAFA4nD,EAAAxgD,MAAkBhI,KAAA0nD,MAAA70C,SAElBo1C,EACA,OAAA3nD,GAAA,EAAA6I,EAAAq/C,EAAA3lD,OAA2CvC,EAAA6I,EAAS7I,IAAA,CACpD,GAAA+qD,GAAA7C,EAAAloD,GACAgrD,EAAAD,EAAA3D,IAAA,IAAA2D,EAAArrD,EAEA,IAAAsrD,IAAAtlC,EAEA,MAAA0hC,GAAA,IAAA1nD,EAKA,OAAA8jB,GAAA,EAAAnW,EAAA85C,EAAA5kD,OAAwCihB,EAAAnW,EAAOmW,IAC/CwjC,EAAAt/C,MAAoB0/C,MAAA,EAAA90B,IAAA60B,EAAA3jC,GAAA0kC,YAKpB,SAAAriD,OAAA,4CAAA8gD,EAAAjnD,GAAA,SAAAgmB,GAGA,QAAAulC,IAAA35C,GACA,MAAA45C,IAAA,yBAAkC55C,EAAA,QAGlC,QAAA65C,IAAA75C,GACA,GAAAqL,IACA,yBACA,kBACA,yBACA,iCACA,sBACA,OACA,gBAAArL,EAAA,IACA,eACA,mBACA,mBACA,MACA,MACA+B,KAAA,KAEA,OAAA63C,IAAAvuC,MAKA,QAAAyuC,IAAA/pD,EAAAm0C,GAEA,IACAn0C,EAAAuU,KAAA,SAAA4/B,GACG,MAAA9uC,GACHs9C,EAAA,4CAAAt9C,IAIA,QAAA2kD,IAAAv/B,EAAAvZ,EAAAhJ,GAsBA,QAAA+hD,KACAjqD,EAAAqI,SAtBAo6C,GAAA/U,aAAAnvC,KAAAP,KACA,IAAAgC,GAAAhC,IACAA,MAAAysB,KACAvZ,IAAA3I,EAAA2I,KACA,IAAA4iC,GAAA5iC,EAAA4iC,SAAA3sC,EAAA,SAAA/C,EAAA9C,GACA8C,EACAsqC,EAAA1uC,EAAA,YACAA,EAAAuU,KAAA,QAAAnQ,GAGApE,EAAAuU,KAAA,WAAAjT,GAEAtB,EAAAsU,qBACAmW,EAAApW,eAAA,YAAA41C,IAEA/hD,KACAlI,EAAAkU,GAAA,oBAAA5S,GACA4G,EAAA,KAAA5G,KAEAtB,EAAAkU,GAAA,QAAAhM,IAKAuiB,EAAAtjB,KAAA,YAAA8iD,GAEA/4C,EAAAg5C,SAAA,SAAA/V,GAEAn0C,EAAAmqD,aAGAJ,GAAA/pD,EAAAm0C,GAGA,IAAApsC,GAAA,GAAAk3C,IAAA,SAAAj3C,EAAAC,GACAiJ,EAAA4iC,SAAA,SAAA1vC,EAAAvC,GACAuC,EACA6D,EAAA7D,GAEA4D,EAAAnG,KAIA7B,GAAAmH,KAAA,oBACAsjB,EAAApW,eAAA,YAAA41C,GACA/4C,EAAA4iC,SAAA,MAAyBrxC,OAAA,gBAEzBzE,KAAAqD,KAAA0G,EAAA1G,KAAAksC,KAAAxlC,GACA/J,KAAA,MAAA+J,EAAA,MAAAwlC,KAAAxlC,GACA/J,KAAAqD,KAAA,SAAA+G,GACA0rC,EAAA,KAAA1rC,IACG0rC,GAIHrpB,EAAAg1B,UAAAC,QAWA1/C,EAAAoqD,UAAAl5C,GAVAuZ,EAAAg1B,UAAAE,QAAA,SAAAC,GACAA,EACA1uC,EAAA4iC,SAAA8L,GACO5/C,EAAAmqD,YACPnqD,EAAAuU,KAAA,UAEAvU,EAAAoqD,UAAAl5C,KAaA,QAAA0iC,IAAAnqC,EAAA67C,EAAAp0C,GACA,GAAAm5C,KAAqBhmC,IAAA5a,EAAA0a,MACrB,cAAAjT,EAAAwU,QACA2kC,EAAAjE,EAAAd,EAAAM,UACAl6C,IAAA,SAAA8L;AAAuB,OAAS6M,IAAA7M,EAAA6M,OAEhC,IAAA8vB,IACA91C,GAAAinD,EAAAjnD,GACAg0B,QAAAg4B,EACA5gD,MAYA,OATA8/C,IAAAjE,EAAA77C,EAAA0a,QACAgwB,EAAAlkB,SAAA,GAEA/e,EAAA+iC,YACAE,EAAA1qC,IAAA6gD,WAAA/D,EAAAjB,GACAnR,EAAA1qC,IAAA6gD,WAAAppD,cACAizC,GAAA1qC,IAAA6gD,YAGAnW,EAgIA,QAAAppC,IAAAT,EAAAC,GACA,MAAAD,GAAAC,GAAA,EAAAD,EAAAC,EAAA,IAKA,QAAAggD,IAAAriD,GACA,gBAAA9D,EAAAgtC,GACAhtC,GAAAgtC,EAAA,IAAAA,EAAA,GAAA/sC,MACA6D,EAAA9D,GAAAgtC,EAAA,IAEAlpC,EAAA,KAAAkpC,EAAAlwC,OAAAkwC,EAAA,GAAAA,IAMA,QAAAoZ,IAAAt5B,GACA,OAAAvyB,GAAA,EAAiBA,EAAAuyB,EAAAhwB,OAAiBvC,IAAA,CAClC,GAAA8K,GAAAynB,EAAAvyB,EACA,IAAA8K,EAAAipC,eACAjpC,GAAAu6C,iBACK,IAAAv6C,EAAAu6C,aAGL,OADAyG,GAAA7rD,OAAA6M,KAAAhC,EAAAu6C,cACA7hC,EAAA,EAAqBA,EAAAsoC,EAAAvpD,OAAiBihB,IAAA,CACtC,GAAA4hC,GAAA0G,EAAAtoC,EACA1Y,GAAAu6C,aAAAD,GAAA35C,EAAAX,EAAAu6C,aAAAD,IACA,4DAOA,QAAA2G,IAAAvrD,EAAAC,GACA,GAAAurD,GAAA5/C,GAAA5L,EAAAikB,IAAAhkB,EAAAgkB,IACA,QAAAunC,EACA,MAAAA,EAEA,IAAAC,GAAAzrD,EAAA0rD,WAAA1rD,EAAA0rD,WAAAjrB,MAAA,EACAkrB,EAAA1rD,EAAAyrD,WAAAzrD,EAAAyrD,WAAAjrB,MAAA,CACA,OAAA70B,IAAA6/C,EAAAE,GAKA,QAAAC,IAAA9E,GACA,GAAA+E,MACAC,IAoBA,OAnBAjF,GAAAC,EAAA,SAAAK,EAAAP,EAAA1nD,EAAA6sD,GACA,GAAA7mC,GAAA0hC,EAAA,IAAA1nD,CAOA,OANAioD,KACA0E,EAAA3mC,GAAA,GAEAljB,SAAA+pD,GACAD,EAAA5kD,MAAkBs8B,KAAAuoB,EAAAtoB,GAAAve,IAElBA,IAGA4mC,EAAAvS,UACAuS,EAAAp7C,QAAA,SAAAs7C,GACAhqD,SAAA6pD,EAAAG,EAAAxoB,MACAqoB,EAAAG,EAAAxoB,MAAA,EAAAqoB,EAAAG,EAAAvoB,IAEAooB,EAAAG,EAAAxoB,MAAAn4B,KAAAC,IAAAugD,EAAAG,EAAAxoB,MAAA,EAAAqoB,EAAAG,EAAAvoB,OAGAooB,EAGA,QAAAI,IAAAC,EAAAn6C,EAAAhJ,GACA,GAAAuD,GAAA,SAAAyF,GACAA,EAAAzF,KAAAxM,MAAAiS,EAAA8yB,KAAA9yB,EAAA6yB,MAAA7yB,EAAA8yB,MACA9yB,EAAA8yB,KAAA,EAAA9yB,EAAAzF,KAAAxM,MAAAiS,EAAA8yB,MAAA9yB,EAAAzF,IAIA,IAHAyF,EAAAgzB,YACAz4B,EAAAitC,WAEAjtC,EAAAvK,OACA,MAAAmqD,GAAAC,UAAyBvnB,MAAA,GAAS77B,EAElC,IAAAqtC,IACAE,OAAAvkC,EAAA8yB,KAEA,OAAAib,IAAA78C,IAAAqJ,EAAAC,IAAA,SAAA/B,GACA,GAAA4hD,GAAAC,IAA4B7hD,MAAAsmB,QAAA,MAAwB/e,EAIpD,QAHA,uBAAArB,QAAA,SAAA47C,SACAF,GAAAE,KAEA,GAAAxM,IAAA,SAAA1yC,EAAAtE,GACAojD,EAAAC,SAAAC,EAAA,SAAAnnD,EAAAvC,GAEA,MAAAuC,GACA6D,EAAA7D,IAEAmxC,EAAArqB,WAAArpB,EAAAqpB,eACA3e,GAAA1K,EAAA6O,KAAA,KAAgC/G,MAAAtF,MAAA,sBAG7BhD,KAAA,SAAA+vC,GAEH,MADAmE,GAAA7kC,KAAA0gC,EACAmE,IAMA,QAAAmW,IAAA1rD,GACA,GAAA2f,GAAA3f,EAAA2rD,iBAAA,GACAz6C,EAAAyO,EAAAzO,KACAhJ,EAAAyX,EAAAzX,QACAlI,GAAAgE,IAAA,qBAAA8I,MAAA,WACA,WACGzL,KAAA,SAAAoI,GACHA,KAAAmiD,WACA16C,EAAA06C,SAAAniD,EAAAmiD,UAEA5rD,EAAA6rD,SAAA36C,EAAA,SAAA9M,EAAAvC,GAEAuC,EACA8D,EAAA9D,GAEA8D,EAAA,KAAArG,GAEAiG,GAAA,WACA9H,EAAA2rD,iBAAAG,QACA9rD,EAAA2rD,iBAAAzqD,QACAwqD,GAAA1rD,SAOA,QAAA+rD,IAAAjlD,GACA,YAAAA,EAAAq9B,OAAA,IACAr9B,EAAA,yEAQA,QAAAklD,MACAvJ,GAAA/U,aAAAnvC,KAAAP,MA0uBA,QAAAiuD,MACAjuD,KAAA0hD,SAAA,EACA1hD,KAAA4hD,QAAA,EACA5hD,KAAAqV,SAkCA,QAAA64C,IAAAplD,EAAAoK,GACA,GAAA8U,GAAAlf,EAAAkf,MAAA,sBACA,IAAAA,EAEA,OACAlf,KAAA,SAAAujB,KAAArE,EAAA,IAAAA,EAAA,SAAAA,EAAA,GAAAA,EAAA,GACA0qB,QAAA1qB,EAAA,GAIA,IAAAmmC,GAAAC,GAAAD,SACAE,EAAAD,GAAAC,kBACA78B,EAAA48B,GAAA58B,OACA88B,EAAAp7C,EAAAw/B,OAEA,KAAA4b,EACA,OAAA3tD,GAAA,EAAmBA,EAAA0tD,EAAAnrD,SAA8BvC,EAAA,CACjD2tD,EAAAD,EAAA1tD,EAGA,eAAA2tD,GAAA,UAAAH,IACAlK,KAAAn7B,aAAA,oBAAA0I,EAAA1oB,IAMA,KAJA67C,GAAA,iCAAA77C,EAAA,+EAQA,GAAA4pC,GAAAyb,EAAAG,GAGAC,IAAA7b,GAAA,cAAAA,KACAA,EAAA8b,UAEA,QACA1lD,KAAAylD,EAAA/8B,EAAA1oB,IACA4pC,QAAA4b,GAcA,QAAAG,IAAAzsD,GAIA,QAAA0sD,KACA1sD,EAAAqU,eAAA,SAAAs4C,GACA3sD,EAAAM,YAAAiU,KAAA,YAAAvU,EAAA8G,MAGA,QAAA8lD,KACA5sD,EAAAqU,eAAA,YAAAq4C,GACA1sD,EAAAqU,eAAA,SAAAs4C,GACA3sD,EAAAuU,KAAA,aAGA,QAAAo4C,KACA3sD,EAAAqU,eAAA,YAAAq4C,GACAG,EAAApwC,OAAAzc,EAAA8G,MAfA,GAAA+lD,GAAA7sD,EAAAM,YAAAwsD,qBAkBA9sD,GAAAmH,KAAA,YAAAulD,GACA1sD,EAAAmH,KAAA,SAAAwlD,GAGAE,EAAAjwB,IAAA58B,EAAA8G,OACA+lD,EAAAl+B,IAAA3uB,EAAA8G,SAEA+lD,EAAA7oD,IAAAhE,EAAA8G,MAAAT,KAAAumD,GAIA,QAAAR,IAAAtlD,EAAAoK,GAGA,KAAAlT,eAAAouD,KACA,UAAAA,IAAAtlD,EAAAoK,EAGA,IAAAlR,GAAAhC,IAcA,IAbAkT,QAEApK,GAAA,gBAAAA,KACAoK,EAAApK,EACAA,EAAAoK,EAAApK,WACAoK,GAAApK,MAGA9I,KAAA24C,OAAAzlC,EAAA3I,EAAA2I,GAEAlR,EAAAywC,gBAAAv/B,EAAAu/B,gBACAzwC,EAAAwvB,OAAA48B,GAAA58B,OAEA,gBAAA1oB,GACA,SAAAtC,OAAA,0BAGA,IAAAuoD,IAAA77C,EAAAse,QAAA,IAAA1oB,EACAkmD,EAAAd,GAAAa,EAAA77C,EASA,IAPAA,EAAApK,KAAAkmD,EAAAlmD,KACAoK,EAAAw/B,QAAAx/B,EAAAw/B,SAAAsc,EAAAtc,QAEA1wC,EAAA8G,OACA9G,EAAAitD,SAAA/7C,EAAAw/B,QACA/pB,GAAA,sCAAAzV,EAAAw/B,UAEA0b,GAAAD,SAAAj7C,EAAAw/B,WACA0b,GAAAD,SAAAj7C,EAAAw/B,SAAAwc,QACA,SAAA1oD,OAAA,oBAAA0M,EAAAw/B,QAGAsb,IAAAztD,KAAAyB,GACAA,EAAAy/C,UAAA,GAAAwM,IAEAjsD,EAAA0wC,QAAAx/B,EAAAw/B,QAEA0b,GAAAD,SAAAj7C,EAAAw/B,SAAAnyC,KAAAyB,EAAAkR,EAAA,SAAA9M,GACA,MAAAA,GACApE,EAAAy/C,UAAA0N,KAAA/oD,IAEAqoD,GAAAzsD,GAEAA,EAAAuU,KAAA,UAAAvU,GACAosD,GAAA73C,KAAA,UAAAvU,EAAA8G,UACA9G,GAAAy/C,UAAA2N,MAAAptD,MAcA,QAAAqtD,IAAAC,GACA1uD,OAAA6M,KAAAg3C,GAAA/U,aAAA7uC,WAAAgR,QAAA,SAAAlG,GACA,kBAAA84C,IAAA/U,aAAA7uC,UAAA8K,KACA2jD,EAAA3jD,GAAA4jD,GAAA5jD,GAAA4jC,KAAAggB,MAMA,IAAAC,GAAAF,EAAAR,sBAAA,GAAA/K,GACAuL,GAAAp5C,GAAA,qBAAApN,GACA0mD,EAAAxpD,IAAA8C,GAAA+I,QAAA,SAAA3H,GACAA,MAEAslD,EAAA/wC,OAAA3V,KAoEA,QAAAyjC,IAAA52B,GACA,MAAAA,GAAAghB,OAAA,SAAAn1B,EAAAmwB,GAEA,MADAnwB,GAAAmwB,IAAA,EACAnwB,OAoCA,QAAAiuD,IAAAppC,GACA,cAAAgG,KAAAhG,GACA,MAAA8+B,GAAAuK,GAEA,IAAAj2C,GAAA4M,EAAApgB,QAAA,KACAqG,EAAA+Z,EAAAla,UAAA,EAAAsN,GACAlN,EAAA8Z,EAAAla,UAAAsN,EAAA,EACA,QACA+X,OAAA7Y,SAAArM,EAAA,IACAjM,GAAAkM,GAIA,QAAAojD,IAAAC,EAAA18C,GAMA,OALA60C,GAAA6H,EAAAhuB,MAAAguB,EAAA38B,IAAA/vB,OAAA,EAEA2sD,EAAAD,EAAA38B,IACAA,GAAA48B,EAAA,GAAA38C,MAEAvS,EAAA,EAAA6I,EAAAqmD,EAAA3sD,OAA2CvC,EAAA6I,EAAS7I,IACpDsyB,GAAA48B,EAAAlvD,IAA4B8D,OAAA,YAAkBwuB,GAG9C,SACA80B,MACA90B,QAMA,QAAA68B,IAAArkD,EAAAskD,GAEA,GAAAC,GACAC,EACAC,EACAh9C,GAAczO,OAAA,YAKd,IAJAgH,EAAAipC,WACAxhC,EAAA+e,SAAA,GAGA89B,EAKA,GAJAtkD,EAAA2Z,MACA3Z,EAAA2Z,IAAA+hC,KAEA8I,EAAA9I,EAAA,OAAAp/B,cACAtc,EAAA0a,KAAA,CAEA,GADA+pC,EAAAT,GAAAhkD,EAAA0a,MACA+pC,EAAA7pD,MACA,MAAA6pD,EAEAzkD,GAAA0kD,YACApI,IAAAmI,EAAA1+B,OACAyB,KAAAi9B,EAAA7vD,IAA2BoE,OAAA,aAAkBwrD,EAAA/8C,UAE7C88C,EAAAE,EAAA1+B,OAAA,MAEA/lB,GAAA0kD,YACApI,IAAA,EACA90B,KAAAg9B,EAAA/8C,QAEA88C,EAAA,MAQA,IALAvkD,EAAAohD,aACAphD,EAAA0kD,UAAAR,GAAAlkD,EAAAohD,WAAA35C,GACA88C,EAAAvkD,EAAAohD,WAAAjrB,MACAquB,EAAAxkD,EAAAohD,WAAA55B,IAAA,KAEAxnB,EAAA0kD,UAAA,CAEA,GADAD,EAAAT,GAAAhkD,EAAA0a,MACA+pC,EAAA7pD,MACA,MAAA6pD,EAEAF,GAAAE,EAAA1+B,OACAy+B,EAAAC,EAAA7vD,GACAoL,EAAA0kD,YACApI,IAAAiI,EACA/8B,KAAAg9B,EAAA/8C,QAKAgzC,EAAAz6C,EAAA2Z,KAEA3Z,EAAA0a,KAAA6pC,EAAA,IAAAC,CAEA,IAAA7lD,IAAgBk9C,YAAaxhD,QAC7B,QAAA6F,KAAAF,GAEA,GAAA7K,OAAAC,UAAAC,eAAAP,KAAAkL,EAAAE,GAAA,CACA,GAAAykD,GAAA,MAAAzkD,EAAA,EACA,IAAAykD,IAAAC,GAAA1kD,GAAA,CACA,GAAAtF,GAAA8+C,EAAAmL,GAAA3kD,EAEA,MADAtF,GAAA0C,QAAAunD,GAAAvnD,QAAA,KAAA4C,EACAtF,EACO+pD,IAAAG,GAAA5kD,GACPvB,EAAAk9C,SAAA37C,EAAA1K,MAAA,IAAAwK,EAAAE,GAEAvB,EAAAtE,KAAA6F,GAAAF,EAAAE,GAIA,MAAAvB,GAcA,QAAAomD,IAAArgD,EAAAsgD,GAEAtgD,QACAsgD,OACA,KACA,UAAAx7B,MAAA9kB,EAAAsgD,GACG,MAAAppD,GACH,iBAAAA,EAAAyB,KACA,KAAAzB,EAOA,QALAqpD,GAAA,mBAAAC,yBACA,mBAAAC,6BACA,mBAAAC,+BACAC,kBACAC,EAAA,GAAAL,GACA/vD,EAAA,EAAmBA,EAAAwP,EAAAjN,OAAkBvC,GAAA,EACrCowD,EAAA1hC,OAAAlf,EAAAxP,GAEA,OAAAowD,GAAAC,QAAAP,EAAA/qC,OAMA,QAAAurC,IAAAC,GAIA,OAHAhuD,GAAAguD,EAAAhuD,OACAiuD,EAAA,GAAA9gC,aAAAntB,GACAwE,EAAA,GAAAsX,YAAAmyC,GACAxwD,EAAA,EAAiBA,EAAAuC,EAAYvC,IAC7B+G,EAAA/G,GAAAuwD,EAAAhjC,WAAAvtB,EAEA,OAAAwwD,GAGA,QAAAC,IAAAC,EAAA3rC,GACA,MAAA8qC,KAAAS,GAAAI,KAA6D3rC,SAG7D,QAAA4rC,IAAAC,EAAA7rC,GACA,MAAA0rC,IAAAI,GAAAD,GAAA7rC,GAMA,QAAA+rC,IAAA3yC,GAIA,OAHA64B,GAAA,GACA+Z,EAAA,GAAA1yC,YAAAF,GACA5b,EAAAwuD,EAAAnhC,WACA5vB,EAAA,EAAiBA,EAAAuC,EAAYvC,IAC7Bg3C,GAAAt4B,OAAAC,aAAAoyC,EAAA/wD,GAEA,OAAAg3C,GAIA,QAAAga,IAAAC,EAAA1nD,GACA,sBAAA2nD,YAGA,MAAA3nD,GAAAunD,IACA,GAAAK,iBAAAC,kBAAAH,IAGA,IAAAI,GAAA,GAAAH,YACAI,EAAA,kBAAAD,GAAAL,kBACAK,GAAAE,UAAA,SAAA7qD,GACA,GAAA+C,GAAA/C,EAAAqY,OAAAtV,QAAA,EACA,OAAA6nD,GACA/nD,EAAAE,OAEAF,GAAAunD,GAAArnD,KAEA6nD,EACAD,EAAAL,mBAAAC,GAEAI,EAAAD,kBAAAH,GAIA,QAAAO,IAAAC,EAAAloD,GACAynD,GAAAS,EAAA,SAAAlB,GACAhnD,EAAAgnD,KAIA,QAAAmB,IAAAD,EAAAloD,GACAioD,GAAAC,EAAA,SAAAE,GACApoD,EAAAqoD,GAAAD,MAKA,QAAAP,IAAAH,EAAA1nD,GACA,sBAAA2nD,YAGA,MAAA3nD,IAAA,GAAA4nD,iBAAAC,kBAAAH,GAGA,IAAAI,GAAA,GAAAH,WACAG,GAAAE,UAAA,SAAA7qD,GACA,GAAA+C,GAAA/C,EAAAqY,OAAAtV,QAAA,GAAAimB,aAAA,EACAnmB,GAAAE,IAEA4nD,EAAAD,kBAAAH,GAQA,QAAAY,IAAA1iC,GACA,MAAAyiC,IAAAziC,GAGA,QAAA2iC,IAAAC,EAAA9wB,EAAA/R,GACA,MAAA6iC,GAAA/R,YACA+R,EAAA/R,YAAA/e,EAAA/R,GAEA6iC,EAAAzxD,MAAA2gC,EAAA/R,GAGA,QAAA8iC,IAAA7zC,EAAA4zC,EAAA9wB,EAAA/R,EAAA3lB,IACA03B,EAAA,GAAA/R,EAAA6iC,EAAAhS,QAEAgS,EAAAD,GAAAC,EAAA9wB,EAAA/R,IAEAkiC,GAAAW,EAAA,SAAAE,GACA9zC,EAAAuQ,OAAAujC,GACA1oD,MAIA,QAAA2oD,IAAA/zC,EAAA/T,EAAA62B,EAAA/R,EAAA3lB,IACA03B,EAAA,GAAA/R,EAAA9kB,EAAA7H,UAEA6H,IAAAoB,UAAAy1B,EAAA/R,IAEA/Q,EAAAyQ,aAAAxkB,GACAb,IAGA,QAAA4oD,IAAAhtD,EAAAoE,GAUA,QAAA/B,KACA4qD,GAAAC,GAGA,QAAA5qD,KACA,GAAA0nB,GAAAhR,EAAA+Q,KAAA,GACAyiC,EAAAE,GAAA1iC,EACA5lB,GAAAooD,GACAxzC,EAAAoR,UAGA,QAAA8iC,KACA,GAAApxB,GAAAqxB,EAAAC,EACArjC,EAAA+R,EAAAsxB,CACAD,KACAA,EAAAE,EACA9jC,EAAAvQ,EAAAhZ,EAAA87B,EAAA/R,EAAA1nB,GAEAknB,EAAAvQ,EAAAhZ,EAAA87B,EAAA/R,EAAAznB,GA3BA,GAAAgrD,GAAA,gBAAAttD,GACA0D,EAAA4pD,EAAAttD,EAAA5C,OAAA4C,EAAA46C,KACAwS,EAAA1mD,KAAAC,IAAA4mD,GAAA7pD,GACA2pD,EAAA3mD,KAAA6a,KAAA7d,EAAA0pD,GACAD,EAAA,EACAn0C,EAAAs0C,EAAA,GAAAvoD,IAAA,GAAAA,IAAAwlB,YAEAhB,EAAA+jC,EAAAP,GAAAF,EAuBAK,KAGA,QAAAM,IAAAvoD,GACA,MAAAF,IAAAI,KAAAF,GAGA,QAAAwoD,IAAAztD,GACA,IACA,MAAA0rD,IAAA1rD,GACG,MAAAuB,GACH,GAAAjB,GAAA++C,EAAAqO,GACA,0CACA,QAAYntD,MAAAD,IAIZ,QAAAqtD,IAAA1N,EAAA2N,EAAAxpD,GACA,GAAAypD,GAAAJ,GAAAxN,EAAAjgD,KACA,OAAA6tD,GAAAttD,MACA6D,EAAAypD,EAAAttD,QAGA0/C,EAAA7iD,OAAAywD,EAAAzwD,OACA,SAAAwwD,EACA3N,EAAAjgD,KAAAsrD,GAAAuC,EAAA5N,EAAA6N,cACG,WAAAF,EACH3N,EAAAjgD,KAAAysD,GAAAoB,GAEA5N,EAAAjgD,KAAA6tD,MAEAb,IAAAa,EAAA,SAAAvpD,GACA27C,EAAA36C,OAAA,OAAAhB,EACAF,OAIA,QAAA2pD,IAAA9N,EAAA2N,EAAAxpD,GACA4oD,GAAA/M,EAAAjgD,KAAA,SAAAipB,GACAg3B,EAAA36C,OAAA,OAAA2jB,EAEAg3B,EAAA7iD,OAAA6iD,EAAAjgD,KAAA46C,MAAAqF,EAAAjgD,KAAA5C,QAAA,EACA,WAAAwwD,EACAvB,GAAApM,EAAAjgD,KAAA,SAAAurD,GACAtL,EAAAjgD,KAAAurD,EACAnnD,MAEK,WAAAwpD,EACLrB,GAAAtM,EAAAjgD,KAAA,SAAAyrD,GACAxL,EAAAjgD,KAAAyrD,EACArnD,MAGAA,MAKA,QAAA4pD,IAAA/N,EAAA2N,EAAAxpD,GACA,MAAA67C,GAAAE,KACA/7C,SAEA,gBAAA67C,GAAAjgD,KACA2tD,GAAA1N,EAAA2N,EAAAxpD,GAEA2pD,GAAA9N,EAAA2N,EAAAxpD,IAIA,QAAA6pD,IAAAC,EAAAN,EAAAxpD,GAkCA,QAAA9B,KACA6rD,IACAD,EAAA9wD,SAAA+wD,IACAC,EACAhqD,EAAAgqD,GAEAhqD,KAtCA,IAAA8pD,EAAA9wD,OACA,MAAAgH,IAGA,IACAgqD,GADAD,EAAA,CAGAD,GAAAniD,QAAA,SAAAsiD,GASA,QAAAC,GAAAhuD,GACA8tD,EAAA9tD,EACAiuD,IACAA,IAAA3c,EAAAx0C,QACAkF,IAZA,GAAAsvC,GAAAyc,EAAAruD,MAAAquD,EAAAruD,KAAAkgD,aACAplD,OAAA6M,KAAA0mD,EAAAruD,KAAAkgD,iBACAqO,EAAA,CAEA,KAAA3c,EAAAx0C,OACA,MAAAkF,IAWA,QAAAuD,KAAAwoD,GAAAruD,KAAAkgD,aACAmO,EAAAruD,KAAAkgD,aAAAllD,eAAA6K,IACAmoD,GAAAK,EAAAruD,KAAAkgD,aAAAr6C,GACA+nD,EAAAU,KAiBA,QAAAE,IAAAC,EAAA1wB,EAAAswB,EAAA/gB,EACAzyC,EAAA+J,EAAA8pD,EAAAzE,GAEA,GAAA7E,GAAArnB,EAAA+jB,SAAAuM,EAAA7M,SAAAjhC,KAEA,MADA+sB,GAAAzyC,GAAAwzD,EACAzpD,GAIA,IAAA+pD,GAAA5wB,EAAAwjB,cAAAxjB,GACA6wB,EAAA,WAAA7wB,KAAA5R,QACAs5B,GAAA1nB,EAAA4wB,GACAxiC,EAAA,WAAAkiC,GAAA7M,SAAA6M,EAAA7M,SAAAr1B,QACAs5B,GAAA4I,EAAA7M,UACAqN,EAAA,MAAAtoC,KAAA8nC,EAAA7M,SAAAjhC,IAEA,IAAAquC,IAAAziC,GAAA89B,GAAA4E,EAAA,CACA,GAAA5jC,GAAAojC,EAAAruD,IACAirB,GAAA5K,KAAAsuC,EACA1jC,EAAA3L,IAAA+uC,EAAA7M,SAAAjnD,GACA8zD,EAAArE,GAAA/+B,EAAAg/B,GAGA,GAAAjG,GAAAiB,GAAAlnB,EAAA+jB,SAAAuM,EAAA7M,SAAAM,SAAA,GAAA2M,GAEAK,EAAA7E,IAAA2E,GAAAziC,IACAyiC,GAAA,aAAA5K,EAAA7T,WACAye,IAAAziC,GAAA,eAAA63B,EAAA7T,UAEA,IAAA2e,EAAA,CACA,GAAAxuD,GAAA++C,EAAA0P,GAEA,OADAzhB,GAAAzyC,GAAAyF,EACAsE,IAGA,GAAAoqD,GAAAX,EAAA7M,SAAAjhC,GACA8tC,GAAA7M,SAAAM,SAAAkC,EAAAjC,KACAsM,EAAAlJ,YAAAnB,EAAAmB,gBAEApnB,EAAAkxB,UACAZ,EAAA7M,SAAAyN,QAAAlxB,EAAAkxB,QAIA,IAQAC,GARAC,EAAA5N,EAAA8M,EAAA7M,UACA4N,EAAA3J,GAAA4I,EAAA7M,SAAA2N,GAIAE,EAAAT,IAAAQ,EAAA,EACAR,EAAAQ,GAAA,GAKAF,GAFAF,IAAAG,EAEAC,EAGA3J,GAAA4I,EAAA7M,SAAAwN,GAGAN,EAAAL,EAAAc,EAAAC,EAAAF,GACA,EAAAG,EAAAx0D,EAAA+J,GAGA,QAAA0qD,IAAAjB,GACA,kBAAAA,EAAA7M,SAAAM,SAAA,GAAA30B,IAAA,GAAAxuB,OAGA,QAAA4wD,IAAAd,EAAAP,EAAA3G,EAAAiI,EAAAC,EAAAniB,EACAohB,EAAAthD,EAAAsiD,GAKA,QAAAC,GAAAtB,EAAAuB,EAAAxrD,GAEA,GAAA+qD,GAAA5N,EAAA8M,EAAA7M,UACAr1B,EAAAs5B,GAAA4I,EAAA7M,SAAA2N,EACA,kBAAA/hD,IAAA+e,EAEA,MADAmhB,GAAAsiB,GAAAvQ,EAAAwQ,GAAA,WACAzrD,GAIA,IAAA0qD,GAAA7E,GAAAqF,GAAAjB,EAEA,IAAAS,EAAA,CACA,GAAAxuD,GAAA++C,EAAA0P,GAEA,OADAzhB,GAAAsiB,GAAAtvD,EACA8D,IAGA,GAAAirD,GAAAljC,EAAA,GAEAuiC,GAAAL,EAAAc,EAAAhjC,KAAA,EACAkjC,EAAAO,EAAAxrD,GASA,QAAA0rD,OACAC,IAAAC,GAAAN,GACAA,IAlCAjB,KAAA,GA0BA,IAAAxE,GAAA78C,EAAA6iD,UACAC,EAAA,GAAAjS,IAEA8R,EAAA,EACAC,EAAA9B,EAAA9wD,MAQA8wD,GAAAniD,QAAA,SAAAokD,EAAAP,GAEA,GAAAO,EAAA7wC,KAAAomC,GAAAyK,EAAA7wC,KAAA,CACA,GAAAhc,GAAA6sD,EAAAvhB,SAAA,0BAKA,YAJA2Y,GAAAjkD,GAAA6sD,GAA4B17B,IAAAg7B,GAAQ,SAAAnvD,EAAAvC,GACpCuvC,EAAAsiB,GAAAtvD,GAAAvC,EACA+xD,MAKA,GAAAv1D,GAAA41D,EAAA3O,SAAAjnD,EACA21D,GAAAp3B,IAAAv+B,IACAy1D,IACAE,EAAAhwD,IAAA3F,GAAAgI,MAAA4tD,EAAAP,KAEAM,EAAArlC,IAAAtwB,IAAA41D,EAAAP,OAMAM,EAAAnkD,QAAA,SAAAqhB,EAAA7yB,GAGA,QAAA61D,OACArT,EAAA3vB,EAAAhwB,OACAizD,IAEAP,IAGA,QAAAO,KACA,GAAA5zD,GAAA2wB,EAAA2vB,GACAoT,EAAA1zD,EAAA,GACAmzD,EAAAnzD,EAAA,EAEA,IAAA+yD,EAAA12B,IAAAv+B,GACAi0D,GAAAC,EAAAe,EAAAtvD,IAAA3F,GAAA41D,EAAA7iB,EACAsiB,EAAAQ,EAAA1B,EAAAzE,OACO,CAEP,GAAAjG,GAAAiB,MAAAkL,EAAA3O,SAAAM,SAAA,GAAA2M,EACA0B,GAAA3O,SAAAM,SAAAkC,EAAAjC,KACAoO,EAAAhL,YAAAnB,EAAAmB,gBACAwK,EAAAQ,EAAAP,EAAAQ,IAtBA,GAAArT,GAAA,CAyBAsT,OA6BA,QAAAC,IAAAl+C,GAIA,IACA,MAAAxS,MAAAmsB,MAAA3Z,GACG,MAAA7Q,GAEH,MAAAgvD,IAAAxkC,MAAA3Z,IAIA,QAAAo+C,IAAApwD,GACA,IACA,MAAAR,MAAAC,UAAAO,GACG,MAAAmB,GAEH,MAAAgvD,IAAA1wD,UAAAO,IAIA,QAAAqwD,IAAArsD,GACA,gBAAAssD,GACA,GAAAztD,GAAA,eACAytD,GAAA92C,QAAA82C,EAAA92C,OAAArZ,QACA0C,EAAAytD,EAAA92C,OAAArZ,MAAAyC,MAAA0tD,EAAA92C,OAAArZ,MAAA0C,SAEAmB,EAAAi7C,EAAAsR,GAAA1tD,EAAAytD,EAAA9wC,QAWA,QAAAgxC,IAAApP,EAAAD,EAAAp1B,GACA,OACAnsB,KAAAwwD,GAAAhP,GACAD,aACAsP,eAAA1kC,EAAA,QACA2gB,IAAA0U,EAAA1U,IACAvyC,GAAAinD,EAAAjnD,IAIA,QAAAu2D,IAAAC,GACA,IAAAA,EACA,WAEA,IAAAvP,GAAA8O,GAAAS,EAAA/wD,KAIA,OAHAwhD,GAAAD,WAAAwP,EAAAxP,WACAC,EAAAr1B,QAAA,MAAA4kC,EAAAF,eACArP,EAAA1U,IAAAikB,EAAAjkB,IACA0U,EAKA,QAAAwP,IAAArrD,GACA,IAAAA,EACA,MAAAA,EAEA,IAAAgO,GAAAhO,EAAAsrD,YAAAC,YAAA,IAIA,OAHAvrD,GAAA2Z,IAAA3Z,EAAAsrD,YAAA5qD,UAAA,EAAAsN,EAAA,GACAhO,EAAA0a,KAAA1a,EAAAsrD,YAAA5qD,UAAAsN,EAAA,SACAhO,GAAAsrD,YACAtrD,EAMA,QAAAwrD,IAAA7xD,EAAAsgB,EAAAwxC,EAAAhtD,GACAgtD,EAIAhtD,EAHA9E,EAEK,gBAAAA,GACLA,EAEAksD,GAAAlsD,EAAAsgB,GAJA8qC,IAAA,KAAiC9qC,UAOjCtgB,EAEK,gBAAAA,GACLusD,GAAAvsD,EAAA,SAAAuyC,GACAztC,EAAAqoD,GAAA5a,MAGAztC,EAAA9E,GANA8E,EAAA,IAWA,QAAAitD,IAAA1rD,EAAAyH,EAAAkkD,EAAA1sD,GAOA,QAAAk4C,OACAC,IAAAnL,EAAAx0C,QAAAwH,GACAA,IAIA,QAAA2sD,GAAA5rD,EAAAs6C,GACA,GAAAuR,GAAA7rD,EAAAu6C,aAAAD,GACA36C,EAAAksD,EAAAlsD,OACAo6C,EAAA4R,EAAAG,YAAAC,IAAAxxD,IAAAoF,EACAo6C,GAAAiS,UAAA,SAAApwD,GACAiwD,EAAAlyD,KAAAiC,EAAAqY,OAAAtV,OAAAhF,KACAw9C,KAlBA,GAAAlL,GAAA92C,OAAA6M,KAAAhC,EAAAu6C,iBACA,KAAAtO,EAAAx0C,OACA,MAAAwH,OAEA,IAAAm4C,GAAA,CAkBAnL,GAAA7lC,QAAA,SAAAk0C,GACA7yC,EAAAwkC,aAAAxkC,EAAA2Z,aACAwqC,EAAA5rD,EAAAs6C,IAEAt6C,EAAAu6C,aAAAD,GAAAE,MAAA,EACArD,OASA,QAAA8U,IAAAtkB,EAAA8jB,GACA,MAAAjW,IAAA78C,IAAAgvC,EAAA1lC,IAAA,SAAAmF,GACA,GAAAA,EAAApH,KAAAoH,EAAApH,IAAAu6C,aAAA,CACA,GAAA2R,GAAA/2D,OAAA6M,KAAAoF,EAAApH,IAAAu6C,aACA,OAAA/E,IAAA78C,IAAAuzD,EAAAjqD,IAAA,SAAAq4C,GACA,GAAAuR,GAAAzkD,EAAApH,IAAAu6C,aAAAD,EACA,YAAAuR,GAAA,CAGA,GAAAlyD,GAAAkyD,EAAAlyD,KACAsgB,EAAA4xC,EAAA1D,YACA,WAAA3S,IAAA,SAAA1yC,GACA0oD,GAAA7xD,EAAAsgB,EAAAwxC,EAAA,SAAApxD,GACA+M,EAAApH,IAAAu6C,aAAAD,GAAAyH,GACAphD,EAAAkrD,GAAA,2BACexxD,SAEfyI,gBAQA,QAAAqpD,IAAA3P,EAAAp3B,EAAAumC,GAQA,QAAAxU,KACAn0C,IACAA,GACAopD,IAIA,QAAAA,KACAC,EAAA50D,QAGA40D,EAAAjmD,QAAA,SAAAzG,GACA,GAAA2sD,GAAAC,EAAAzlD,MAAA,aAAA9D,MACAwpD,YAAAC,MACA9sD,EAAA,KAAAA,EAAA,aACA2sD,GAAAN,UAAA,SAAApwD,GACA,GAAAoH,GAAApH,EAAAqY,OAAAtV,MACAqE,IAEA0pD,EAAA15C,OAAArT,MAzBA,GAAA0sD,MACAM,EAAAhB,EAAAG,YAAAc,IACAF,EAAAf,EAAAG,YAAAC,IACAQ,EAAAZ,EAAAG,YAAAe,IACA7pD,EAAAw5C,EAAA/kD,MA2BA+kD,GAAAp2C,QAAA,SAAAwU,GACA,GAAA9T,GAAA6lD,EAAA7lD,MAAA,eACA5G,EAAAklB,EAAA,KAAAxK,CACA9T,GAAA/B,OAAA7E,GAAA8rD,UAAA,SAAApwD,GACA,GAAAurC,GAAAvrC,EAAAqY,OAAAtV,MACA,oBAAAwoC,GACA,MAAAgQ,IAEAwV,GAAA35C,OAAAm0B,EAEA,IAAA2lB,GAAAP,EAAAzlD,MAAA,OACAimD,WAAAP,YAAAQ,KAAA7lB,GAEA2lB,GAAAd,UAAA,SAAAngD,GACA,GAAAihD,GAAAjhD,EAAAoI,OAAAtV,MACA,IAAAmuD,EAAA,CACA,GAAAntD,GAAAmtD,EAAAh2D,MAAAm2D,UAAAtoD,MAAA,QACA0nD,GAAAzvD,KAAA+C,GACA4sD,EAAAv5C,OAAA85C,EAAAI,YACAJ,EAAAK,eAEAhW,SAOA,QAAAiW,IAAAC,EAAAC,EAAAC,GACA,IACA,OACA5B,IAAA0B,EAAAG,YAAAF,EAAAC,IAEG,MAAA5yD,GACH,OACAC,MAAAD,IAOA,QAAA8yD,IAAAC,EAAA3T,EAAAtyC,EAAAm6C,EAAAyL,EAAA5uD,GAwCA,QAAAkvD,KAEA,GAAAL,IACAM,GAAAhB,GACAb,GACA8B,GAAAhB,GACAiB,IAEAC,EAAAX,GAAAC,EAAAC,EAAA,YACA,OAAAS,GAAAnzD,MACA6D,EAAAsvD,EAAAnzD,QAEA+wD,EAAAoC,EAAApC,IACAA,EAAAqC,QAAAlD,GAAArsD,GACAktD,EAAAsC,UAAAnD,GAAArsD,GACAktD,EAAAuC,WAAA7jB,EACA8jB,EAAAxC,EAAAG,YAAA8B,IACAQ,EAAAzC,EAAAG,YAAAc,IACAyB,EAAA1C,EAAAG,YAAAC,IACAuC,EAAA3C,EAAAG,YAAAe,IACA0B,EAAA5C,EAAAG,YAAAgC,IAEAS,EAAAh0D,IAAAuzD,IAAA9B,UAAA,SAAApwD,GACAgtC,EAAAhtC,EAAAqY,OAAAtV,OACA6vD,SAGAC,GAAA,SAAA9zD,GACA,MAAAA,IACA+zD,GAAA,EACAjwD,EAAA9D,QAEAg0D,QAIA,QAAAC,KACAC,GAAA,EACAL,IAGA,QAAAM,KACAlF,GAAA8D,EAAAqB,WAAAxG,EAAA3G,EAAAiI,EACA8B,EAAAhkB,EAAAohB,EAAAthD,EAAAmnD,GAGA,QAAAJ,KACA5lB,GAAAimB,IAKAjmB,EAAAomB,UAAAC,EACAV,EAAA9oC,IAAAmjB,IAGA,QAAA+lB,KAQA,QAAAxX,OACA+X,IAAA3G,EAAA9wD,QACAq3D,IAIA,QAAAK,GAAAtjD,GACA,GAAAgwC,GAAAsP,GAAAt/C,EAAAoI,OAAAtV,OAEAk9C,IACAgO,EAAA3kC,IAAA22B,EAAAjnD,GAAAinD,GAEA1E,IAlBA,GAAAoR,EAAA9wD,OAqBA,OAjBAy3D,GAAA,EAiBAh6D,EAAA,EAAA6I,EAAAwqD,EAAA9wD,OAA0CvC,EAAA6I,EAAS7I,IAAA,CACnD,GAAAwzD,GAAAH,EAAArzD,EACA,IAAAwzD,EAAA/uC,KAAAomC,GAAA2I,EAAA/uC,KACAw9B,QADA,CAIA,GAAA4C,GAAAoU,EAAA5zD,IAAAmuD,EAAA7M,SAAAjnD,GACAmlD,GAAAiS,UAAAmD,IAIA,QAAA9kB,KACAqkB,IAIAU,GAAAC,OAAAzN,EAAA0N,MAAAjyD,MACAoB,EAAA,KAAAkpC,IAGA,QAAA4nB,GAAA5vD,EAAAlB,GAEA,GAAAs7C,GAAAsU,EAAA9zD,IAAAoF,EACAo6C,GAAAiS,UAAA,SAAApwD,GACA,GAAAA,EAAAqY,OAAAtV,OAOAF,QAPA,CACA,GAAA9D,GAAA++C,EAAA8V,GACA,uCACA7vD,EACAhF,GAAA3B,OAAA,IACAyF,EAAA9D,KAOA,QAAA8zD,GAAAnkB,GAoBA,QAAA6M,OACAC,IAAAqY,EAAAh4D,QACA6yC,EAAA3vC,GAnBA,GAAA80D,KAWA,IAVAlH,EAAAniD,QAAA,SAAAsiD,GACAA,EAAAruD,MAAAquD,EAAAruD,KAAAkgD,cACAplD,OAAA6M,KAAA0mD,EAAAruD,KAAAkgD,cAAAn0C,QAAA,SAAAspD,GACA,GAAApV,GAAAoO,EAAAruD,KAAAkgD,aAAAmV,EACApV,GAAAE,MACAiV,EAAA7yD,KAAA09C,EAAA36C,aAKA8vD,EAAAh4D,OACA,MAAA6yC,IAEA,IACA3vC,GADAy8C,EAAA,CAQAqY,GAAArpD,QAAA,SAAAzG,GACA4vD,EAAA5vD,EAAA,SAAAgwD,GACAA,IAAAh1D,IACAA,EAAAg1D,GAEAxY,QAKA,QAAA4R,GAAAL,EAAAc,EAAAC,EAAAF,EACAqG,EAAAlG,EAAAO,EAAAxrD,GAEAiqD,EAAA7M,SAAAD,WAAA4N,EACAd,EAAA7M,SAAAr1B,QAAAijC,CAEA,IAAAzpD,GAAA0oD,EAAAruD,IACA2F,GAAA2Z,IAAA+uC,EAAA7M,SAAAjnD,GACAoL,EAAA0a,KAAAguC,EAAA7M,SAAAjhC,IAEA2uC,IACAvpD,EAAAipC,UAAA,EAGA,IAAA4mB,GAAA7vD,EAAAu6C,cACAplD,OAAA6M,KAAAhC,EAAAu6C,cAAA9iD,MACA,OAAAo4D,GACAC,EAAApH,EAAAc,EAAAC,EACAmG,EAAA3F,EAAAxrD,IAGAwwD,GAAAvF,EACA8E,QAEAuB,GAAArH,EAAAc,EAAAC,EACAmG,EAAA3F,EAAAxrD,IAGA,QAAAsxD,GAAArH,EAAAc,EAAAC,EACAmG,EAAA3F,EAAAxrD,GASA,QAAAuxD,GAAAp0D,GACA,GAAAq0D,GAAAvH,EAAAlJ,eAEAoQ,IAAAhO,EAAA5a,kBACAipB,IAAAp6D,OAAAonD,EAAAyL,EAAA7M,YAGAoU,KAAAx4D,QACA00D,GAAA8D,EAAAvH,EAAA7M,SAAAjnD,GAAA+2D,GAGA9P,EAAA1U,IAAAvrC,EAAAqY,OAAAtV,MAGA,IAAAuxD,GAAAjF,GAAApP,EAAA2N,EACAC,GACA0G,EAAAhC,EAAA1oC,IAAAyqC,EACAC,GAAAnE,UAAAoE,EAGA,QAAAC,GAAAz0D,GAEAA,EAAA00D,iBACA10D,EAAA20D,iBACA,IAAAzpD,GAAAsnD,EAAAtnD,MAAA,eACA0pD,EAAA1pD,EAAA/B,OAAA/E,EAAAsrD,YACAkF,GAAAxE,UAAA,SAAApwD,GACA,GAAA60D,GAAArC,EAAA3oC,IAAAzlB,EAAApE,EAAAqY,OAAAtV,OACA8xD,GAAAzE,UAAAgE,GAIA,QAAAI,KACAzoB,EAAAsiB,IACA7vD,IAAA,EACAxF,GAAAinD,EAAAjnD,GACAgmB,IAAAihC,EAAAjhC,KAEAivC,EAAA3kC,IAAAwjC,EAAA7M,SAAAjnD,GAAA8zD,EAAA7M,UACA6U,EAAAhI,EAAA7M,EAAA1U,IAAA1oC,GA9CA,GAAAuB,GAAA0oD,EAAAruD,KACAwhD,EAAA6M,EAAA7M,QAEA77C,GAAAsrD,YAAAzP,EAAAjnD,GAAA,KAAAinD,EAAAjhC,UACA5a,GAAA2Z,UACA3Z,GAAA0a,IA4CA,IAAA+1C,GAAArC,EAAA3oC,IAAAzlB,EAEAywD,GAAAzE,UAAAgE,EACAS,EAAAE,QAAAN,EAGA,QAAAP,GAAApH,EAAAc,EAAAC,EACAmG,EAAA3F,EAAAxrD,GAQA,QAAAmyD,KACAxZ,IAAAnL,EAAAx0C,QACAs4D,EAAArH,EAAAc,EAAAC,EACAmG,EAAA3F,EAAAxrD,GAIA,QAAAoyD,KACAzZ,IACAwZ,IAdA,GAAA5wD,GAAA0oD,EAAAruD,KAEA+8C,EAAA,EACAnL,EAAA92C,OAAA6M,KAAAhC,EAAAu6C,aAcAtO,GAAA7lC,QAAA,SAAAlG,GACA,GAAAo6C,GAAAoO,EAAAruD,KAAAkgD,aAAAr6C,EACA,IAAAo6C,EAAAE,KAOApD,IACAwZ,QARA,CACA,GAAAv2D,GAAAigD,EAAAjgD,WACAigD,GAAAjgD,KACAigD,EAAAwW,OAAA5jD,SAAAs8C,EAAA,GACA,IAAA7pD,GAAA26C,EAAA36C,MACAoxD,GAAApxD,EAAAtF,EAAAw2D,MAUA,QAAAH,GAAAhI,EAAAvhB,EAAA1oC,GASA,QAAA04C,OACA6Z,IAAAC,EAAAx5D,QACAgH,IAIA,QAAA2Z,GAAAkiC,GACA,GAAA36C,GAAA+oD,EAAAruD,KAAAkgD,aAAAD,GAAA36C,OACAo6C,EAAAuU,EAAA7oC,KACA0hB,MACA8lB,UAAAttD,EAAA,KAAAwnC,GAGA4S,GAAAiS,UAAA7U,EACA4C,EAAA4W,QAAA,SAAA/0D,GAIAA,EAAA00D,iBACA10D,EAAA20D,kBACApZ,KA3BA,GAAA6Z,GAAA,EACAC,EAAA97D,OAAA6M,KAAA0mD,EAAAruD,KAAAkgD,iBAEA,KAAA0W,EAAAx5D,OACA,MAAAgH,IA0BA,QAAAvJ,GAAA,EAAmBA,EAAA+7D,EAAAx5D,OAAsBvC,IACzCkjB,EAAA64C,EAAA/7D,IAIA,QAAA67D,GAAApxD,EAAAtF,EAAAoE,GAGA,GAAA+xD,GAAAnC,EAAArrD,MAAArD,EACA6wD,GAAAxE,UAAA,SAAApwD,GACA,GAAAoH,GAAApH,EAAAqY,OAAAtV,MACA,IAAAqE,EACA,MAAAvE,IAEA,IAAAyyD,IACAvxD,SACAhG,KAAAU,GAEAo2D,EAAApC,EAAA5oC,IAAAyrC,EACAT,GAAAzE,UAAAvtD,GAlWA,OATAktD,GACAwC,EACAC,EACAC,EACAC,EACAC,EACA4C,EACAvoB,EARA2f,EAAAxO,EAAAtyB,KAUAvyB,EAAA,EAAA6I,EAAAwqD,EAAA9wD,OAAwCvC,EAAA6I,EAAS7I,IAAA,CACjD,GAAA8K,GAAAuoD,EAAArzD,EACA8K,GAAA2Z,KAAAomC,GAAA//C,EAAA2Z,OAGA3Z,EAAAuoD,EAAArzD,GAAAmvD,GAAArkD,EAAAyH,EAAA6iD,WACAtqD,EAAApF,QAAAu2D,IACAA,EAAAnxD,IAIA,GAAAmxD,EACA,MAAA1yD,GAAA0yD,EAGA,IAAAtC,IAAA,EACAI,EAAA,EACAtnB,EAAA,GAAA9qC,OAAA0rD,EAAA9wD,QACAoyD,EAAA,GAAAvR,IACAoW,GAAA,EACAzG,EAAArG,EAAA0N,MAAA8B,YAAA,eAEA9I,IAAAC,EAAAN,EAAA,SAAAttD,GACA,MAAAA,GACA8D,EAAA9D,OAEAgzD,OAiVA,QAAA0D,IAAAvF,EAAAwF,EAAA72B,EAAA82B,EAAAC,GAiBA,QAAAC,GAAA71D,GACA81D,EAAA91D,EAAAqY,OAAAtV,OACAgzD,GACAH,EAAAG,EAAAD,EAAAE,GAIA,QAAAC,GAAAj2D,GACA+1D,EAAA/1D,EAAAqY,OAAAtV,OACA+yD,GACAF,EAAAG,EAAAD,EAAAE,GAIA,QAAAE,KACA,IAAAH,EAAAl6D,OACA,MAAA+5D,IAGA,IACAO,GADApnB,EAAAgnB,IAAAl6D,OAAA,EAEA,IAAA65D,KAAA91B,MACA,IACAu2B,EAAAvF,YAAAC,MAAA9hB,EAAA2mB,EAAA91B,OACA,EAAA81B,EAAAU,WACO,MAAAp2D,GACP,iBAAAA,EAAAyB,MAAA,IAAAzB,EAAAiW,KACA,MAAA2/C,SAIAO,GAAAvF,YAAAyF,WAAAtnB,GAAA,EAEA2mB,GAAAS,EACAJ,EAAA,KACAD,EAAA,KACA5F,EAAAoG,OAAAZ,EAAAC,GAAAvF,UAAAyF,EACA3F,EAAAqG,WAAAb,EAAAC,GAAAvF,UAAA6F,EAGA,QAAAO,GAAAx2D,GACA,GAAAkxD,GAAAlxD,EAAAqY,OAAAtV,MACA,OAAAmuD,OAIA0E,IAAA1E,EAAA5sD,MAAA4sD,EAAAh2D,OAAAg2D,GAHA0E,IAnDA,GAIAG,GACAD,EACAE,EANAS,EAAA,kBAAAvG,GAAAoG,QACA,kBAAApG,GAAAqG,YACAZ,EAAA,IAAA92B,CAuDA43B,IACAT,GAAoBzE,SAAA2E,GACpBhG,EAAAoG,OAAAZ,EAAAC,GAAAvF,UAAAyF,EACA3F,EAAAqG,WAAAb,EAAAC,GAAAvF,UAAA6F,GACGp3B,EACHqxB,EAAAiB,WAAAuE,EAAA,QAAAtF,UAAAoG,EAEAtG,EAAAiB,WAAAuE,GAAAtF,UAAAoG,EAKA,QAAAF,IAAApG,EAAAwF,EAAAtyC,GASA,QAAAozC,GAAAx2D,GACA,GAAAkxD,GAAAlxD,EAAAqY,OAAAtV,MACAmuD,IACAttC,EAAA5iB,KAAAkwD,EAAAh2D,OACAg2D,EAAAK,YAEAnuC,GACA/K,QACAtV,OAAA6gB,KAhBA,qBAAAssC,GAAAoG,OAGA,YADApG,EAAAoG,OAAAZ,GAAAtF,UAAAhtC,EAIA,IAAAQ,KAgBAssC,GAAAiB,WAAAuE,GAAAtF,UAAAoG,EAGA,QAAAE,IAAAn8B,EAAA/R,EAAAsX,EAAAx7B,EAAAu6B,GACA,IACA,GAAAtE,GAAA/R,EACA,MAAAqW,GACA+xB,YAAAC,MAAAroC,EAAA+R,GAAAuF,GAAA,GAEA8wB,YAAAC,MAAAt2B,EAAA/R,GAAA,GAAAsX,EAEK,IAAAvF,EACL,MAAAsE,GACA+xB,YAAA+F,WAAAp8B,GAEAq2B,YAAAyF,WAAA97B,EAEK,IAAA/R,EACL,MAAAqW,GACA+xB,YAAAyF,WAAA7tC,GAAAsX,GAEA8wB,YAAA+F,WAAAnuC,GAAAsX,EAEK,IAAAx7B,EACL,MAAAssD,aAAAQ,KAAA9sD,GAEG,MAAAtE,GACH,OAAYhB,MAAAgB,GAEZ,YAGA,QAAA42D,IAAA/qD,EAAA4lD,EAAA5uD,GA2CA,QAAAg0D,GAAA5W,EAAAz0C,EAAAoiD,GACA,GAAAtpD,GAAA27C,EAAAjnD,GAAA,KAAA40D,CACAkJ,GAAAn4D,IAAA2F,GAAA8rD,UAAA,SAAApwD,GAEA,GADAwL,EAAApH,IAAAqrD,GAAAzvD,EAAAqY,OAAAtV,QACA8I,EAAA+iC,UAAA,CACA,GAAAA,GAAAsS,EAAAjB,EACArR,GAAA/yC,SACA2P,EAAApH,IAAA6gD,WAAArW,GAGAkhB,GAAAtkD,EAAApH,IAAAyH,EAAAkkD,IAIA,QAAAgH,GAAAnJ,EAAA3N,GACA,GAAAz0C,IACAxS,GAAAinD,EAAAjnD,GACAsL,IAAA27C,EAAAjnD,GACAkC,OACA8jB,IAAA4uC,IAGAhjC,EAAAq1B,EAAAr1B,OACA,QAAA/e,EAAA+e,SACAmhB,EAAA/qC,KAAAwK,GAEAof,GACApf,EAAAtQ,MAAA0vB,SAAA,EACApf,EAAApH,IAAA,MACOyH,EAAA2Z,cACPqxC,EAAA5W,EAAAz0C,EAAAoiD,KAEKhjC,GAAA+T,KAAA,IACLoN,EAAA/qC,KAAAwK,GACAK,EAAA2Z,cACAqxC,EAAA5W,EAAAz0C,EAAAoiD,IAKA,QAAA3R,GAAA+a,GACA,OAAA19D,GAAA,EAAA6I,EAAA60D,EAAAn7D,OAA6CvC,EAAA6I,GAC7C4pC,EAAAlwC,SAAA6iC,EADsDplC,IAAA,CAItD,GAAA29D,GAAAD,EAAA19D,GACA2mD,EAAAsP,GAAA0H,GACArJ,EAAA3N,EAAAD,UACA+W,GAAAnJ,EAAA3N,IAIA,QAAA2V,GAAAsB,EAAAF,EAAA9F,GACAA,IAGAjV,EAAA+a,GACAjrB,EAAAlwC,OAAA6iC,GACAwyB,EAAAK,YAIA,QAAAsE,GAAA71D,GACA,GAAA4jB,GAAA5jB,EAAAqY,OAAAtV,MACA8I,GAAAgzB,aACAjb,IAAAyvB,WAEA4I,EAAAr4B,GAGA,QAAAuzC,KACAt0D,EAAA,MACAgjB,WAAAutC,EACAhjB,OAAAvkC,EAAA8yB,KACAtzB,KAAA0gC,IAIA,QAAAqrB,KACAvrD,EAAAwkC,YACAggB,GAAAtkB,EAAAlgC,EAAAykC,QAAAt0C,KAAAm7D,GAEAA,IA5HA,GAAA58B,GAAA,YAAA1uB,MAAAE,SACAyc,EAAA,UAAA3c,MAAAG,OACA1H,EAAA,OAAAuH,MAAAvH,IACAq6B,EAAA9yB,EAAA8yB,MAAA,EACAD,EAAA,gBAAA7yB,GAAA6yB,MAAA7yB,EAAA6yB,OAAA,EACAoB,EAAAj0B,EAAAK,iBAAA,EAEAwpD,EAAAgB,GAAAn8B,EAAA/R,EAAAsX,EAAAx7B,EAAAuH,EAAAgzB,YACAw4B,EAAA3B,KAAA12D,KACA,IAAAq4D,IAAA,cAAAA,EAAA51D,MACA,IAAA41D,EAAAphD,MAGA,MAAApT,GAAAi7C,EAAAsR,GACAiI,EAAA51D,KAAA41D,EAAA31D,SAGA,IAAAgwD,IAAAM,GAAAhB,GAAAkB,GAEArmD,GAAAwkC,aACAqhB,EAAA1wD,KAAAmvD,GAEA,IAAAgC,GAAAX,GAAAC,EAAAC,EAAA,WACA,IAAAS,EAAAnzD,MACA,MAAA6D,GAAAsvD,EAAAnzD,MAEA,IAAA+wD,GAAAoC,EAAApC,GACAA,GAAAuC,WAAA8E,EACArH,EAAAqC,QAAAlD,GAAArsD,EACA,IAKAuwD,GALAb,EAAAxC,EAAAG,YAAA8B,IACAjB,EAAAhB,EAAAG,YAAAc,IACA2B,EAAA5C,EAAAG,YAAAgC,IACA4E,EAAA/F,EAAA7lD,MAAA,eACA6gC,IAgGA,OA7FA4mB,GAAAh0D,IAAAuzD,IAAA9B,UAAA,SAAApwD,GACAozD,EAAApzD,EAAAqY,OAAAtV,OAAAqwD,UA4FAiE,GAAA,IAAA34B,EAAA,OAGAA,KAAA,EACA43B,GAAA/D,EAAAmD,EAAAG,OAIAJ,IAAAlD,EAAAmD,EAAA7pD,EAAAgzB,WAAAH,EAAAC,EAAAi3B,GAeA,QAAA0B,IAAAvH,GACA,UAAAnW,IAAA,SAAA1yC,GACA,GAAAmkD,GAAAlC,IAAA,KACAhL,EAAA4R,EAAAG,YAAAqH,IAAA1tC,IAAAwhC,EAAA,MAEAlN,GAAAiS,UAAA,WACA,GAAAoH,GAAA3wD,UAAA4Z,UAAAE,MAAA,iBACA82C,EAAA5wD,UAAA4Z,UAAAE,MAAA,SAGAzZ,GAAAuwD,IAAAD,GACAlmD,SAAAkmD,EAAA,aAGAzH,EAAAqC,QAAA,SAAApyD,GAGAA,EAAA00D,iBACA10D,EAAA20D,kBACAztD,GAAA,MAEGO,MAAA,WACH,WAIA,QAAAiwD,IAAA3H,EAAA1sD,GACA,GAAA6H,GAAA6kD,EAAAG,YAAA8B,IAAA9mD,MAAA,iBACAA,GAAA9D,MAAAwpD,YAAAQ,KAAA,MAAAhB,UAAA,SAAApwD,GACAqD,EAAArD,EAAAqY,OAAAtV,SAWA,QAAAmpC,IAAAnqC,EAAAhD,EAAAvC,EAAAwtB,GACA,IACAjoB,EAAAhD,EAAAvC,GACG,MAAAuC,GAIHirB,EAAA9a,KAAA,QAAAnQ,IAIA,QAAA44D,OACAC,IAAA5pD,GAAAnS,SAGA+7D,IAAA,EACA5pD,GAAAy4C,WAGA,QAAAoR,IAAA7sC,EAAAnoB,EAAAmnB,GACAhc,GAAAhN,KAAA,WACAgqB,EAAA,SAAAjsB,EAAAvC,GACA0vC,GAAArpC,EAAA9D,EAAAvC,EAAAwtB,GACA4tC,IAAA,EACAn1D,GAAA,WACAk1D,GAAA3tC,SAIA2tC,KAGA,QAAA3qC,IAAAnhB,EAAAm6C,EAAAhJ,EAAAyU,GA2CA,QAAAmE,GAAAsB,EAAAF,EAAA9F,GAQA,QAAA4G,GAAA7X,EAAA8X,GACA,GAAAjpB,GAAAjjC,EAAA0iC,cAAAwpB,EAAA9X,EAAAp0C,EACAmsD,GAAAlpB,EAAAvD,IAAA0U,EAAA1U,GAEA,IAAA0sB,GAAA5rD,EAAAyiC,EACA,uBAAAmpB,GACApsD,EAAA4iC,SAAAwpB,QAGAA,IACAC,IACAC,GACApsB,EAAA/qC,KAAA8tC,GAIAjjC,EAAAwkC,aAAAxkC,EAAA2Z,aACAsqC,GAAAiI,EAAAlsD,EAAAkkD,EAAA,WACAM,IAAAvhB,GAAAjjC,EAAAykC,QAAAt0C,KAAA,WACA6P,EAAAg5C,SAAA/V,OAIAjjC,EAAAg5C,SAAA/V,KAKA,QAAAspB,KACA,OAAA9+D,GAAA,EAAA6I,EAAAk2D,EAAAx8D,OAA+CvC,EAAA6I,GAC/C+1D,IAAAx5B,EADwDplC,IAAA,CAIxD,GAAAy+D,GAAAM,EAAA/+D,EACA,IAAAy+D,EAAA,CAGA,GAAA9X,GAAAqY,EAAAh/D,EACAw+D,GAAA7X,EAAA8X,IAGAG,IAAAx5B,GACAwyB,EAAAK,WAjDA,GAAAL,GAAAgG,EAAAr7D,OAAA,CAIA,GAAAw8D,GAAA,GAAAp3D,OAAAi2D,EAAAr7D,QACAy8D,EAAA,GAAAr3D,OAAAi2D,EAAAr7D,QAmDA2/C,EAAA,CACAwb,GAAAxsD,QAAA,SAAAtP,EAAA5B,GACA,GAAA8K,GAAAqrD,GAAAv0D,GACAqwC,EAAA2rB,EAAA59D,EACAi/D,GAAAn0D,EAAAmnC,EAAA,SAAA0U,EAAA8X,GACAO,EAAAh/D,GAAA2mD,EACAoY,EAAA/+D,GAAAy+D,IACAvc,IAAA0b,EAAAr7D,QACAu8D,SAMA,QAAAI,GAAAp0D,EAAAmnC,EAAA0U,EAAA58C,GACA,GAAA48C,EAAA1U,QAEA,MAAAloC,IAGA,IAAA48C,EAAAD,aAAA57C,EAAA0a,KAEA,MAAAzb,GAAA48C,EAAA77C,EAIA,IAAAq0D,GAAAr0D,EAAA2Z,IAAA,KAAAkiC,EAAAD,WACA7B,EAAA2Y,EAAAn4D,IAAA85D,EACAta,GAAAiS,UAAA,SAAApwD,GACAqD,EAAA48C,EAAAwP,GAAAzvD,EAAAqY,OAAAtV,UAIA,QAAAw1D,GAAAn0D,EAAAmnC,EAAAloC,GACA,GAAAwqC,MAAAtW,IAAAnzB,EAAA2Z,KACA,MAAA1a,IAGA,IAAA48C,GAAAyY,EAAA/5D,IAAAyF,EAAA2Z,IACA,OAAAkiC,GACAuY,EAAAp0D,EAAAmnC,EAAA0U,EAAA58C,QAGAkvD,EAAA5zD,IAAAyF,EAAA2Z,KAAAqyC,UAAA,SAAApwD,GACAigD,EAAAsP,GAAAvvD,EAAAqY,OAAAtV,QACA21D,EAAApvC,IAAAllB,EAAA2Z,IAAAkiC,GACAuY,EAAAp0D,EAAAmnC,EAAA0U,EAAA58C,KAIA,QAAAqrC,KACA7iC,EAAA4iC,SAAA,MACA1C,UACAwa,SAAAyR,IAIA,QAAAZ,MACAvrD,EAAA8sD,YAAA9sD,EAAAwkC,YAGAggB,GAAAtkB,GAAA/vC,KAAA0yC,GAEAA,IAhKA,GAFA7iC,EAAA3I,EAAA2I,GAEAA,EAAA8sD,WAAA,CACA,GAAA3/D,GAAAgkD,EAAA,IAAA8C,GAGA,OAFA0T,IAAA1kD,YAAAkuC,EAAAhkD,EAAAgtD,EAAAn6C,GACA2nD,GAAAC,OAAAzW,IAEAh6C,OAAA,WACAwwD,GAAAxkD,eAAAguC,EAAAhkD,KAKA,GAAA60C,GAAAhiC,EAAA+sD,SAAA,GAAAC,IAAAhtD,EAAA+sD,QAEA/sD,GAAA+yB,MAAA/yB,EAAA+yB,OAAA,CACA,IAAAo5B,GAAAnsD,EAAA+yB,MAEAF,EAAA,SAAA7yB,KAAA6yB,OAAA,CACA,KAAAA,IACAA,EAAA,EAEA,IAAAy5B,EAEAA,GADA,eAAAtsD,GACAA,EAAAitD,cACG,cAAAjtD,KAEHA,EAAAssD,UAKA,IAKApI,GACAyC,EACAD,EACAuE,EARA/qB,KACAmsB,EAAA,EACA7rD,EAAAiyC,EAAAzyC,GACA6sD,EAAA,GAAAhc,IAmIAqc,GAAA/G,GAAAhB,GACAnlD,GAAAwkC,aACA0oB,EAAA/3D,KAAAmvD,GAEA,IAAAgC,GAAAX,GAAAC,EAAAsH,EAAA,WACA,IAAA5G,EAAAnzD,MACA,MAAA6M,GAAA4iC,SAAA0jB,EAAAnzD,MAEA+wD,GAAAoC,EAAApC,IACAA,EAAAqC,QAAAlD,GAAArjD,EAAA4iC,UACAshB,EAAAuC,WAAA8E,EAEA5E,EAAAzC,EAAAG,YAAAc,IACAuB,EAAAxC,EAAAG,YAAA8B,IACA8E,EAAAtE,EAAAtnD,MAAA,cAEA,IAAAwqD,GAAA7pD,EAAA+yB,QAAA/yB,EAAAgzB,WACA+xB,YAAAyF,WAAAxqD,EAAA+yB,OAAA,OAEA62B,IAAAjD,EAAAkD,EAAA7pD,EAAAgzB,WAAAH,EAAAk3B,GAOA,QAAAoD,IAAAntD,EAAAhJ,GACA,GAAAmjD,GAAArtD,IAEAk/D,IAAA,SAAAoB,GACAljC,GAAAiwB,EAAAn6C,EAAAotD,IACGp2D,EAAAmjD,EAAA/qD,aAGH,QAAA86B,IAAAiwB,EAAAn6C,EAAAhJ,GAQA,QAAAq2D,GAAA9zC,GACA,GAAAmtC,GAAAntC,EAAA+zC,kBAAAnH,IAAoDoH,QAAA,MACpDh0C,GAAA+zC,kBAAAnI,IAAwCqI,eAAA,IACxCp4B,YAAA,6BAAkDq4B,QAAA,IAClDl0C,EAAA+zC,kBAAAhJ,IAAwCiJ,QAAA,WACxCh0C,EAAA+zC,kBAAAjH,IAAsCkH,QAAA,KAAAC,eAAA,IACtCj0C,EAAA+zC,kBAAA5B,IAGAhF,EAAAtxB,YAAA,mCAA8Dq4B,QAAA,IAG9Dl0C,EAAA+zC,kBAAAlH,IAAuCmH,QAAA,OAGvC,IAAAzI,GAAAvrC,EAAA+zC,kBAAAlI,IACOoI,eAAA,GACP1I,GAAA1vB,YAAA,aACA0vB,EAAA1vB,YAAA,yBAA0Dq4B,QAAA,IAM1D,QAAAC,GAAAxJ,EAAAltD,GACA,GAAA0vD,GAAAxC,EAAAG,YAAA8B,GACAO,GAAAtxB,YAAA,mCAA8Dq4B,QAAA,IAE9D/G,EAAApB,aAAAf,UAAA,SAAAngD,GACA,GAAAihD,GAAAjhD,EAAAoI,OAAAtV,MACA,IAAAmuD,EAAA,CACA,GAAAjR,GAAAiR,EAAAh2D,MACA0vB,EAAAs5B,GAAAjE,EACAA,GAAAqP,eAAA1kC,EAAA,QACA2nC,EAAA1oC,IAAAo2B,GACAiR,EAAAK,eAEA1uD,MAMA,QAAA22D,GAAAp0C,GACAA,EAAA+zC,kBAAAlH,IAAuCmH,QAAA,QACvCn4B,YAAA,6BAAkDq4B,QAAA,IAIlD,QAAAG,GAAA1J,EAAA1sD,GACA,GAAAq2D,GAAA3J,EAAAG,YAAA+B,IACAM,EAAAxC,EAAAG,YAAA8B,IACAjB,EAAAhB,EAAAG,YAAAc,IAEAE,EAAAqB,EAAApB,YACAD,GAAAd,UAAA,SAAAngD,GACA,GAAAihD,GAAAjhD,EAAAoI,OAAAtV,MACA,IAAAmuD,EAAA,CACA,GAAAjR,GAAAiR,EAAAh2D,MACAsuB,EAAAy2B,EAAAjnD,GACA2oB,EAAAwiC,GAAA36B,GACAxK,EAAAghC,EAAAC,EACA,IAAAt+B,EAAA,CACA,GAAA82C,GAAAjvC,EAAA,KAAAxK,EAGAub,EAAA/Q,EAAA,KACAhB,EAAAgB,EAAA,MACAte,EAAA6lD,EAAA7lD,MAAA,eACAwyC,EAAAkT,YAAAC,MAAAt2B,EAAA/R,GAAA,MACAmxC,EAAAzuD,EAAAimD,WAAAzT,EACAic,GAAAvJ,UAAA,SAAApwD,GAEA,GADA25D,EAAA35D,EAAAqY,OAAAtV,OAKa,CACb,GAAAtE,GAAAk7D,EAAAz+D,KACAuD,GAAAixD,cAAA+I,GACAiB,EAAA7vC,IAAAprB,GAEAsyD,EAAA35C,OAAAuiD,EAAArI,YACAqI,EAAApI,eARAgB,GAAAn7C,OAAA85C,EAAAI,YACAJ,EAAAK,gBAWAL,GAAAK,eAEOluD,IACPA,KAMA,QAAAu2D,GAAAx0C,GACA,GAAAurC,GAAAvrC,EAAA+zC,kBAAAlI,IACOoI,eAAA,GACP1I,GAAA1vB,YAAA,aACA0vB,EAAA1vB,YAAA,yBAA0Dq4B,QAAA,IAI1D,QAAAO,GAAA9J,EAAAltD,GACA,GAAAkuD,GAAAhB,EAAAG,YAAAc,IACAF,EAAAf,EAAAG,YAAAC,IACAQ,EAAAZ,EAAAG,YAAAe,IAKA9S,EAAA2S,EAAA1pD,OACA+2C,GAAAiS,UAAA,SAAApwD,GACA,GAAAoH,GAAApH,EAAAqY,OAAAtV,MACA,OAAAqE,QAIA2pD,EAAAI,aAAAf,UAAA,SAAApwD,GACA,GAAAkxD,GAAAlxD,EAAAqY,OAAAtV,MACA,KAAAmuD,EACA,MAAAruD,IAMA,QAJAuB,GAAA8sD,EAAAh2D,MACAqwC,EAAA2lB,EAAAI,WACAlM,EAAA7rD,OAAA6M,KAAAhC,EAAAu6C,kBACAmb,KACAh9C,EAAA,EAAuBA,EAAAsoC,EAAAvpD,OAAiBihB,IAAA,CACxC,GAAA4hC,GAAAt6C,EAAAu6C,aAAAyG,EAAAtoC,GACAg9C,GAAApb,EAAA36C,SAAA,EAEA,GAAA8vD,GAAAt6D,OAAA6M,KAAA0zD,EACA,KAAAh9C,EAAA,EAAmBA,EAAA+2C,EAAAh4D,OAAoBihB,IAAA,CACvC,GAAA/Y,GAAA8vD,EAAA/2C,EACA6zC,GAAA9mC,KACA0hB,MACA8lB,UAAAttD,EAAA,KAAAwnC,IAGA2lB,EAAAK,aAxBA1uD,KAmCA,QAAAk3D,GAAAhK,GAEA,QAAAiK,GAAAxK,GACA,MAAAA,GAAA/wD,KAKA8wD,GAAAC,IAHAA,EAAA5kC,QAAA,MAAA4kC,EAAAF,eACAE,GAOA,GAAAgD,GAAAzC,EAAAG,YAAAc,IACAuB,EAAAxC,EAAAG,YAAA8B,IACAd,EAAAqB,EAAApB,YACAD,GAAAd,UAAA,SAAApwD,GAUA,QAAAi6D,KAGA,GAAA1/B,GAAA0lB,EAAAjnD,GAAA,KACAwvB,EAAAy3B,EAAAjnD,GAAA,MACAmlD,EAAAqU,EAAAtnD,MAAA,eAAAimD,WACAP,YAAAC,MAAAt2B,EAAA/R,IAEA0xC,EAAA,CACA/b,GAAAiS,UAAA,SAAApwD,GACA,GAAAkxD,GAAAlxD,EAAAqY,OAAAtV,MACA,KAAAmuD,EAEA,MADAjR,GAAA1U,IAAA2uB,EACAC,GAEA,IAAA5uB,GAAA2lB,EAAAI,UACA/lB,GAAA2uB,IACAA,EAAA3uB,GAEA2lB,EAAAK,YAIA,QAAA4I,KACA,GAAA7F,GAAAjF,GAAApP,EACAA,EAAAD,WAAAC,EAAAr1B,SAEAuzB,EAAAoU,EAAA1oC,IAAAyqC,EACAnW,GAAAiS,UAAA,WACAc,EAAAK,YAtCA,GAAAL,GAAAlxD,EAAAqY,OAAAtV,MACA,IAAAmuD,EAAA,CAGA,GAAAjR,GAAA+Z,EAAA9I,EAAAh2D,MAsCA,OApCA+kD,GAAAD,WAAAC,EAAAD,YACAA,EAAAC,GAmCAA,EAAA1U,IACA4uB,QAGAF,OA5NA,GAAAjd,GAAAnxC,EAAApK,KAEAgwD,EAAA,IACAzL,GAAA0N,MAAA,KA8NA1N,EAAA3nC,KAAA,WACA,aAGA2nC,EAAAjoC,IAAA3b,EAAA,SAAAS,GACAA,EAAA,KAAAmjD,EAAA0N,MAAA0G,cAGApU,EAAAqU,UAAA,SAAAlc,EAAAmc,EAAAz3D,GACAgvD,GAAAhmD,EAAAsyC,EAAAmc,EAAAtU,EAAAyL,EAAA5uD,IAKAmjD,EAAAuU,KAAA,SAAAvhE,EAAA6S,EAAAhJ,GAcA,QAAA6rC,KACA7rC,EAAA9D,GAAqBqF,MAAA67C,WAAA/sB,IAAA68B,IAdrB,GAAA3rD,GACA67C,EACAlhD,EACAgxD,EAAAlkD,EAAAqnB,GACA,KAAA68B,EAAA,CACA,GAAAoC,GAAAX,GAAAC,GACAO,GAAAhB,GAAAb,IAAA,WACA,IAAAgC,EAAAnzD,MACA,MAAA6D,GAAAsvD,EAAAnzD,MAEA+wD,GAAAoC,EAAApC,IAOAA,EAAAG,YAAA8B,IAAArzD,IAAA3F,GAAAo3D,UAAA,SAAApwD,GAOA,GANAigD,EAAAsP,GAAAvvD,EAAAqY,OAAAtV,SAMAk9C,EAEA,MADAlhD,GAAA++C,EAAAwQ,GAAA,WACA5f,GAGA,IAAA1vB,EACA,IAAAnT,EAAAmT,IAQAA,EAAAnT,EAAAu4C,UAAAv4C,EAAAmT,IAAAihC,GAAAp0C,EAAAmT,QARA,CACAA,EAAAihC,EAAAD,UACA,IAAAp1B,GAAAs5B,GAAAjE,EACA,IAAAr1B,EAEA,MADA7rB,GAAA++C,EAAAwQ,GAAA,WACA5f,IAMA,GAAAwhB,GAAAH,EAAAG,YAAAc,IACA1sD,EAAA27C,EAAAjnD,GAAA,KAAAgmB,CAEAkxC,GAAAhlD,MAAA,eAAAvM,IAAA2F,GAAA8rD,UAAA,SAAApwD,GAKA,MAJAoE,GAAApE,EAAAqY,OAAAtV,OACAqB,IACAA,EAAAqrD,GAAArrD,IAEAA,MAIAsqC,MAHA3vC,EAAA++C,EAAAwQ,GAAA,WACA5f,QAOAsX,EAAAwU,eAAA,SAAAhxC,EAAAixC,EAAAC,EAAA7uD,EAAAhJ,GACA,GAAAktD,EACA,IAAAlkD,EAAAqnB,IACA68B,EAAAlkD,EAAAqnB,QACK,CACL,GAAAi/B,GAAAX,GAAAC,GACAO,GAAAhB,GAAAb,IAAA,WACA,IAAAgC,EAAAnzD,MACA,MAAA6D,GAAAsvD,EAAAnzD,MAEA+wD,GAAAoC,EAAApC,IAEA,GAAAhsD,GAAA22D,EAAA32D,OACAsa,EAAAq8C,EAAAnO,YAEAwD,GAAAG,YAAAC,IAAAxxD,IAAAoF,GAAAqsD,UAAA,SAAApwD,GACA,GAAAjC,GAAAiC,EAAAqY,OAAAtV,OAAAhF,IACA6xD,IAAA7xD,EAAAsgB,EAAAxS,EAAAykC,OAAA,SAAAqqB,GACA93D,EAAA,KAAA83D,OAKA3U,EAAA4U,MAAA,SAAA/3D,GACA,GAAAg4D,GACAzH,EAEAjB,EAAAX,GAAAC,GAAAS,GAAAlB,IAAA,WACA,IAAAmB,EAAAnzD,MACA,MAAA6D,GAAAsvD,EAAAnzD,MAEA,IAAA+wD,GAAAoC,EAAApC,GACAA,GAAAG,YAAAgC,IAAAvzD,IAAAuzD,IAAA9B,UAAA,SAAApwD,GACAozD,EAAApzD,EAAAqY,OAAAtV,OAAAqwD,UAEArD,EAAAG,YAAAc,IAAAG,WAAA,aAAAf,UAAA,SAAApwD,GACA,GAAAkxD,GAAAlxD,EAAAqY,OAAAtV,MACA83D,GAAA3J,IAAA5sD,IAAA,GAGAyrD,EAAAuC,WAAA,WACAzvD,EAAA,MACAi4D,UAAA1H,EACA2H,WAAAF,EAEAG,sBAAAhV,EAAA0N,MAAA8B,YAAA,sBAKAxP,EAAAC,SAAA,SAAAp6C,EAAAhJ,GACA+zD,GAAA/qD,EAAA4lD,EAAA5uD,IAGAmjD,EAAAiV,SAAA,SAAApvD,GACAmhB,GAAAnhB,EAAAm6C,EAAAhJ,EAAAyU,IAGAzL,EAAAkV,OAAA,SAAAr4D,GAGA4uD,EAAA0J,QACAC,GAAAhkD,OAAA4lC,GACAn6C,KAGAmjD,EAAAqV,iBAAA,SAAA7xC,EAAA3mB,GACA,GAAAsvD,GAAAX,GAAAC,GAAAO,IAAA,WACA,IAAAG,EAAAnzD,MACA,MAAA6D,GAAAsvD,EAAAnzD,MAEA,IAAA+wD,GAAAoC,EAAApC,IACA5R,EAAA4R,EAAAG,YAAA8B,IAAArzD,IAAA6qB,EACA20B,GAAAiS,UAAA,SAAAngD,GACA,GAAA7L,GAAAmrD,GAAAt/C,EAAAoI,OAAAtV,OACAqB,GAGAvB,EAAA,KAAAuB,EAAAm8C,UAFA19C,EAAAi7C,EAAAwQ,OAUAtI,EAAAsV,cAAA,SAAA9xC,EAAAo3B,EAAA/9C,GACA,GAAA6uD,IACAM,GACAhB,GACAb,GACAc,IAEAkB,EAAAX,GAAAC,EAAAC,EAAA,YACA,IAAAS,EAAAnzD,MACA,MAAA6D,GAAAsvD,EAAAnzD,MAEA,IAAA+wD,GAAAoC,EAAApC,IAEAwC,EAAAxC,EAAAG,YAAA8B,GAEAO,GAAA5zD,IAAA6qB,GAAA4mC,UAAA,SAAAngD,GACA,GAAAgwC,GAAAsP,GAAAt/C,EAAAoI,OAAAtV,OACA49C,GAAAV,EAAAM,SAAA,SAAAU,EAAAP,EACAY,EAAApuB,EAAArnB,GACA,GAAAmT,GAAA0hC,EAAA,IAAAY,CACAV,GAAAhiD,QAAAogB,MAAA,IACAnT,EAAAzO,OAAA,aAGAmzD,GAAA3P,EAAAp3B,EAAAumC,EACA,IAAAnC,GAAA3N,EAAAD,WACAp1B,EAAAq1B,EAAAr1B,OACAmlC,GAAAG,YAAA8B,IAAAnoC,IACAwlC,GAAApP,EAAA2N,EAAAhjC,KAEAmlC,EAAAqC,QAAAlD,GAAArsD,GACAktD,EAAAuC,WAAA,WACAzvD,MAKAmjD,EAAAuV,UAAA,SAAAviE,EAAA6J,GACA,GAAAsvD,GAAAX,GAAAC,GAAAQ,IAAA,WACA,IAAAE,EAAAnzD,MACA,MAAA6D,GAAAsvD,EAAAnzD,MAEA,IAAAkvD,GAAAiE,EAAApC,IACA5R,EAAA+P,EAAAgC,YAAA+B,IAAAtzD,IAAA3F,EAEAmlD,GAAA4W,QAAA7F,GAAArsD,GACAs7C,EAAAiS,UAAA,SAAApwD,GACA,GAAAoE,GAAApE,EAAAqY,OAAAtV,MACAqB,UAGAA,GAAA,YACAvB,EAAA,KAAAuB,IAHAvB,EAAAi7C,EAAAwQ,OAQAtI,EAAAwV,UAAA,SAAAp3D,EAAAyH,EAAAhJ,GACA,kBAAAgJ,KACAhJ,EAAAgJ,EACAA,YAEAzH,GAAAohD,UACA,IAAAiW,GAAAr3D,EAAA0a,KACA9lB,EAAAoL,EAAA2Z,GACA09C,GAGAr3D,EAAA0a,KAAA,MAAAxN,SAAAmqD,EAAA1yD,MAAA,eAFA3E,EAAA0a,KAAA,KAKA,IACA4J,GADAwlC,EAAAriD,EAAAqnB,GAEA,KAAAg7B,EAAA,CACA,GAAAiE,GAAAX,GAAAC,GAAAQ,IAAA,YACA,IAAAE,EAAAnzD,MACA,MAAA6D,GAAAsvD,EAAAnzD,MAEAkvD,GAAAiE,EAAApC,IACA7B,EAAA6G,QAAA7F,GAAArsD,GACAqrD,EAAAoE,WAAA,WACA5pC,GACA7lB,EAAA,KAAA6lB,IAKA,GACAy1B,GADAud,EAAAxN,EAAAgC,YAAA+B,GAEAwJ,IACAtd,EAAAud,EAAA/8D,IAAA3F,GACAmlD,EAAAiS,UAAA,SAAApwD,GACA,GAAA27D,GAAA37D,EAAAqY,OAAAtV,MACA,IAAA44D,KAAA78C,OAAA28C,EAES,CACT,GAAAtd,GAAAud,EAAA7xC,IAAAzlB,EACA+5C,GAAAiS,UAAA,WACA1nC,GAAmBlqB,IAAA,EAAAxF,GAAAoL,EAAA2Z,IAAAiB,IAAA5a,EAAA0a,MACnBjT,EAAAqnB,KACArwB,EAAA,KAAA6lB,QANA7lB,GAAAi7C,EAAA0P,QAYArP,EAAAud,EAAAl/C,IAAApY,GACA+5C,EAAA4W,QAAA,SAAA/0D,GAEA6C,EAAAi7C,EAAA0P,KACAxtD,EAAA00D,iBACA10D,EAAA20D,mBAEAxW,EAAAiS,UAAA,WACA1nC,GAAelqB,IAAA,EAAAxF,GAAAoL,EAAA2Z,IAAAiB,IAAA5a,EAAA0a,MACfjT,EAAAqnB,KACArwB,EAAA,KAAA6lB,MAMAs9B,EAAA4V,aAAA,SAAAx3D,EAAAyH,EAAAhJ,GACA,kBAAAgJ,KACAhJ,EAAAgJ,EACAA,KAEA,IAAAqiD,GAAAriD,EAAAqnB,GACA,KAAAg7B,EAAA,CACA,GAAAiE,GAAAX,GAAAC,GAAAQ,IAAA,YACA,IAAAE,EAAAnzD,MACA,MAAA6D,GAAAsvD,EAAAnzD,MAEAkvD,GAAAiE,EAAApC,IACA7B,EAAAoE,WAAA,WACA5pC,GACA7lB,EAAA,KAAA6lB,IAIA,GAAAA,GACA1vB,EAAAoL,EAAA2Z,IACA29C,EAAAxN,EAAAgC,YAAA+B,IACA9T,EAAAud,EAAA/8D,IAAA3F,EAEAmlD,GAAA4W,QAAA7F,GAAArsD,GACAs7C,EAAAiS,UAAA,SAAApwD,GACA,GAAA27D,GAAA37D,EAAAqY,OAAAtV,MACA44D,MAAA78C,OAAA1a,EAAA0a,MAGA48C,EAAAtkD,OAAApe,GACA0vB,GAAelqB,IAAA,EAAAxF,KAAAgmB,IAAA,OACfnT,EAAAqnB,KACArwB,EAAA,KAAA6lB,IALA7lB,EAAAi7C,EAAAwQ,OAWAtI,EAAA6V,SAAA,SAAAhwD,EAAAhJ,GACA2wD,GAAAvkD,mBAAA+tC,EAGA,IAAA8e,GAAAC,GAAAp9D,IAAAq+C,EACA8e,MAAA/4D,SACA+4D,EAAA/4D,OAAAo4D,QACAC,GAAAhkD,OAAA4lC,GAEA,IAAAmB,GAAA6d,UAAAC,eAAAjf,EAEAmB,GAAAiS,UAAA,WAEA2L,GAAA3kD,OAAA4lC,GACAJ,KAAAI,IAAAv7B,qBACAA,cAAAu7B,GAEAn6C,EAAA,MAAsBrE,IAAA,KAGtB2/C,EAAA4W,QAAA7F,GAAArsD,GAGA,IAAAq5D,GAAAd,GAAAz8D,IAAAq+C,EAEA,IAAAkf,EAGA,MAFAzK,GAAAyK,EAAAzK,IACAzL,EAAA0N,MAAAwI,EAAA7rD,OACA5N,GAAA,WACAI,EAAA,KAAAmjD,IAIA,IAAA7H,EAEAA,GADAtyC,EAAAuK,QACA+lD,GAAAnf,EAAAnxC,EAAAuK,SAEA4lD,UAAAI,KAAApf,EAAAqf,IAGAN,GAAAzyC,IAAA0zB,EAAAmB,GAEAA,EAAAme,gBAAA,SAAAt8D,GA2BA,QAAAc,KACA,GAAAy7D,GAAAC,EAAAljE,EAAA,EACAA,KACAijE,GACAA,EAAAxM,EAAAjvD,GA9BA,GAAAskB,GAAAplB,EAAAqY,OAAAtV,MACA,IAAA/C,EAAAy8D,WAAA,EACA,MAAAvD,GAAA9zC,EAIA,IAAA2qC,GAAA/vD,EAAA08D,cAAA9K,WAIA5xD,GAAAy8D,WAAA,GACAjD,EAAAp0C,GAEAplB,EAAAy8D,WAAA,GACA7C,EAAAx0C,EAGA,IAAAo3C,IACAjD,EACAE,EACAI,EACAE,GAGAzgE,EAAA0G,EAAAy8D,UAUA37D,MAGAq9C,EAAAiS,UAAA,SAAApwD,GAkCA,QAAA28D,KACA,mBAAAnH,IAAAoH,IAGA5W,EAAA0N,OACAjyD,KAAAu7C,EACAod,aACA5E,eAGA4F,GAAA9xC,IAAA0zB,GACAyU,MACAphD,OAAA21C,EAAA0N,QAEA7wD,EAAA,KAAAmjD,IAGA,QAAA6W,KACA,sBAAAzJ,IAAA,mBAAApmB,GAAA,CAGA,GAAA8vB,GAAA9f,EAAA,KACA8f,KAAA9vB,GACAotB,EAAAptB,EAAA8vB,GAEA9vB,EAAA8vB,GAAA1C,EAAAta,IAEA9S,EAAAomB,WACArD,EAAAG,YAAAgC,IAAAroC,IAAAmjB,IA5DAykB,EAAAzxD,EAAAqY,OAAAtV,OAEA0uD,EAAAsL,gBAAA,WACAtL,EAAA0J,QACAC,GAAAhkD,OAAA4lC,IAGAyU,EAAAW,QAAA,SAAApyD,GACAs9C,EAAA,wCAAAt9C,EAAAqY,OAAArZ,OACAyyD,EAAA0J,QACAC,GAAAhkD,OAAA4lC,GAUA,IAOAhQ,GACAomB,EACAoC,EACA4E,EAVArK,EAAA0B,EAAAG,aACAM,GACAqF,GACAvF,IACA,aAEA4K,GAAA,CAwCA7M,GAAAG,YAAAgC,IAAAvzD,IAAAuzD,IAAA9B,UAAA,SAAApwD,GACAgtC,EAAAhtC,EAAAqY,OAAAtV,SAAoC/J,GAAAk5D,IACpC2K,KAMAnF,GAAA3H,EAAA,SAAA3oD,GACAgsD,EAAAhsD,EACAy1D,MAMAG,KAEAA,GAAA1F,GAAAvH,IAGAiN,GAAAhhE,KAAA,SAAAuX,GACAiiD,EAAAjiD,EACAopD,MAKA5M,EAAAuC,WAAA,WACAsK,GAAA,EACAD,MAIAxe,EAAA4W,QAAA,WACA,GAAA3W,GAAA,6DACAd,GAAA,QAAAc,GACAv7C,EAAAi7C,EAAAsR,GAAAhR,KAmBA,QAAA+d,IAAAnf,EAAA5mC,GACA,IACA,MAAA4lD,WAAAI,KAAApf,GACAruC,QAAA0tD,GACAjmD,YAEG,MAAArX,GACH,MAAAi9D,WAAAI,KAAApf,EAAAqf,KAmBA,QAAAY,IAAApsD,GACA,MAAA5H,oBAAAi0D,OAAArsD,IAGA,QAAAssD,IAAAC,GAIA,MAAAA,GAAA,GAAAA,EAAA,GAAAA,EAAA,GAQA,QAAAC,IAAAxsD,EAAA0pB,EAAA/R,GAEA,IADA,GAAAzlB,GAAA,GACAw3B,EAAA/R,GACAzlB,GAAAiV,OAAAC,aACAklD,GAAAtsD,EAAAgW,WAAA0T,OAAA,EACA4iC,GAAAtsD,EAAAgW,WAAA0T,MAEA,OAAAx3B,GAQA,QAAAu6D,IAAAzsD,EAAA0pB,EAAA/R,GAEA,IADA,GAAAzlB,GAAA,GACAw3B,EAAA/R,GAEAzlB,GAAAiV,OAAAC,aACAklD,GAAAtsD,EAAAgW,WAAA0T,EAAA,QACA4iC,GAAAtsD,EAAAgW,WAAA0T,EAAA,OACA4iC,GAAAtsD,EAAAgW,WAAA0T,KAAA,EACA4iC,GAAAtsD,EAAAgW,WAAA0T,EAAA,KACAA,GAAA,CAEA,OAAAx3B,GAGA,QAAAw6D,IAAA1sD,EAAA2sD,GACA,gBAAAA,EACAP,GAAAI,GAAAxsD,EAAA,EAAAA,EAAAhV,SAEAyhE,GAAAzsD,EAAA,EAAAA,EAAAhV,QAIA,QAAA4hE,IAAA5sD,GACA,UAAAA,EAAA,IAwBA,QAAA6sD,IAAA7sD,GACA,MAAAA,GACAjR,QAAA,gBACAA,QAAA,gBACAA,QAAA,gBAGA,QAAA+9D,IAAA9sD,GACA,MAAAA,GACAjR,QAAA,sBACAA,QAAA,qBACAA,QAAA,qBAGA,QAAAg+D,IAAAx5D,GAKA,aAFAA,GAAA2Z,UACA3Z,GAAA0a,KACAzgB,KAAAC,UAAA8F,GAGA,QAAAy5D,IAAAz5D,EAAApL,EAAAgmB,GAIA,MAHA5a,GAAA/F,KAAAmsB,MAAApmB,GACAA,EAAA2Z,IAAA/kB,EACAoL,EAAA0a,KAAAE,EACA5a,EAIA,QAAA05D,IAAAhtD,GAEA,IADA,GAAAsV,GAAA,IACAtV,KACAsV,GAAA,IACAtV,IACAsV,GAAA,IAGA,OAAAA,GAAA,IAGA,QAAA23C,IAAAtzD,EAAA+V,EAAAw9C,EAAAC,EAAAC,GACA,gBAAAzzD,EAAA,UACA,gBAAA+V,OAAA7T,KAAA,YACAqxD,EAAA,OAAAA,EAAA,KACAC,EAAA,WACA,gBAAAA,OAAAtxD,KAAA,eACAuxD,EAAA,aAAAA,EAAA,IAGA,QAAAC,IAAAvd,EAAAp3B,EAAA0kC,GASA,QAAA3S,OACAC,IAAAoF,EAAA/kD,QACAuiE,IAIA,QAAAA,KAGA,GAAAC,EAAAxiE,OAAA,CAIA,GAAAyiE,GAAA,yCACAC,GAAA,iBAAAT,GAAAO,EAAAxiE,OAEAqyD,GAAAsQ,WAAAF,EAAAD,EAAA,SAAAnQ,EAAA1xD,GAGA,OADAiiE,MACAnlE,EAAA,EAAqBA,EAAAkD,EAAA6O,KAAAxP,OAAqBvC,IAC1CmlE,EAAAz9D,KAAAxE,EAAA6O,KAAAif,KAAAhxB,GAAAyK,OAEA,IAAA06D,EAAA5iE,OAAA,CAIA,GAAAyiE,GAAA,eAAAC,GACA,kBACAF,EAAAh4D,IAAA,WAA8B,YAAcsG,KAAA,KAC5C,GACAuhD,GAAAsQ,WAAAF,EAAAD,EAAA,SAAAnQ,GAEA,GAAAoQ,GAAA,sBAAAC,GACA,qBACAE,EAAAp4D,IAAA,WAA0C,YAAcsG,KAAA,KACxD,GACAuhD,GAAAsQ,WAAAF,EAAAG,EAAA,SAAAvQ,EAAA1xD,GAEA,OADAkiE,GAAA,GAAA7F,IACAv/D,EAAA,EAAyBA,EAAAkD,EAAA6O,KAAAxP,OAAqBvC,IAC9ColE,EAAAliD,IAAAhgB,EAAA6O,KAAAif,KAAAhxB,GAAAyK,OAEA06D,GAAAj0D,QAAA,SAAAzG,GACA26D,EAAAnnC,IAAAxzB,KAGAmqD,EAAAsQ,WACA,eAAAD,GAAA,mBACAx6D,IACAmqD,EAAAsQ,WACA,eAAAG,GAAA,mBAAA56D,eAxDA,GAAA68C,EAAA/kD,OAAA,CAIA,GAAA2/C,GAAA,EACA6iB,IA2DAzd,GAAAp2C,QAAA,SAAAwU,GACA,GAAAs/C,GAAA,mBAAAM,GACA,2BAEA1Q,GAAAsQ,WAAAF,GAAA90C,EAAAxK,GAAA,SAAAkvC,EAAA1xD,GACA,IAAAA,EAAA6O,KAAAxP,OACA,MAAA0/C,IAEA,IAAAhQ,GAAA/uC,EAAA6O,KAAAif,KAAA,GAAAihB,GACA8yB,GAAAr9D,KAAAuqC,GAEA2iB,EAAAsQ,WACA,eAAAI,GAAA,gBAAArzB,GAAAgQ,QAKA,QAAAsjB,IAAAh8D,GACA,gBAAAoN,GACAqtC,EAAA,gCAAArtC,EAEA,IAAA6uD,GAAA7uD,KAAAhV,YAAAyX,WACAiO,MAAA,qBACAo+C,EAAAD,KAAA,IAAA7uD,EAAAoO,KACA2gD,EAAA/uD,EAAAoI,QAAApI,EAAAvO,OACAmB,GAAAi7C,EAAAmhB,GAAAD,EAAAD,KAIA,QAAAG,IAAArzD,GACA,WAAAA,GAGA,WAAAA,EAAAwtC,IAQA,IAAA8lB,GAAA,mBAAAt4D,YACA,UAAAme,KAAAne,UAAA4Z,UACA,OAAA0+C,GAAA,MAGA,QAAAC,IAAAtN,EAAA3T,EAAAtyC,EAAAm6C,EAAA5gC,EAAAi6C,EAAAx8D,GAyBA,QAAA4rC,KACA,MAAAqkB,GACAjwD,EAAAiwD,IAEAuM,EAAA5L,OAAAzN,EAAAsZ,WACAz8D,GAAA,KAAAkpC,IAGA,QAAA4nB,GAAA5vD,EAAAlB,GACA,GAAAy7D,GAAA,+BAAAK,GACA,iBACAzQ,GAAAsQ,WAAAF,GAAAv6D,GAAA,SAAAmqD,EAAAnrD,GACA,OAAAA,EAAAsI,KAAAif,KAAA,GAAAi1C,IAAA,CACA,GAAAxgE,GAAA++C,EAAA8V,GACA,uCACA7vD,EACAlB,GAAA9D,OAEA8D,OAKA,QAAAgwD,GAAAnkB,GAkBA,QAAA6M,OACAC,IAAAqY,EAAAh4D,QACA6yC,EAAA3vC,GAnBA,GAAA80D,KAWA,IAVAlH,EAAAniD,QAAA,SAAAsiD,GACAA,EAAAruD,MAAAquD,EAAAruD,KAAAkgD,cACAplD,OAAA6M,KAAA0mD,EAAAruD,KAAAkgD,cAAAn0C,QAAA,SAAAspD,GACA,GAAApV,GAAAoO,EAAAruD,KAAAkgD,aAAAmV,EACApV,GAAAE,MACAiV,EAAA7yD,KAAA09C,EAAA36C,aAKA8vD,EAAAh4D,OACA,MAAA6yC,IAEA,IACA3vC,GADAy8C,EAAA,CAQAqY,GAAArpD,QAAA,SAAAzG,GACA4vD,EAAA5vD,EAAA,SAAAgwD,GACAA,IAAAh1D,IACAA,EAAAg1D,GAEAxY,QAKA,QAAA4R,GAAAL,EAAAc,EAAAC,EAAAF,EACAqG,EAAAlG,EAAAO,EAAAxrD,GAEA,QAAA6rC,KAaA,QAAAomB,GAAAvpB,EAAA1oC,GAOA,QAAA04C,KAIA,QAHA6Z,IAAAC,EAAAx5D,QACAgH,KAEA,EAEA,QAAA2Z,GAAAkiC,GACA,GAAA4f,GAAA,eAAAC,GACA,8BACAiB,GAAA/gE,EAAAkgD,aAAAD,GAAA36C,OAAAwnC,EACA2iB,GAAAsQ,WAAAF,EAAAkB,EAAAjkB,KAhBA,GAAA6Z,GAAA,EACAC,EAAA97D,OAAA6M,KAAA3H,EAAAkgD,iBAEA,KAAA0W,EAAAx5D,OACA,MAAAgH,IAiBA,QAAAvJ,GAAA,EAAuBA,EAAA+7D,EAAAx5D,OAAsBvC,IAC7CkjB,EAAA64C,EAAA/7D,IAnCA,GAAAmF,GAAAquD,EAAAruD,KACAghE,EAAA9R,EAAA,IAEA30D,EAAAyF,EAAAsf,IACAiB,EAAAvgB,EAAAqgB,KACAjgB,EAAA++D,GAAAn/D,GACA6/D,EAAA,eAAAM,GACA,qDACAY,GAAAxmE,EAAAgmB,EAAAngB,EAAA4gE,EA+BAvR,GAAAsQ,WAAAF,EAAAkB,EAAA,SAAAtR,EAAAnrD,GACA,GAAAwoC,GAAAxoC,EAAA28D,QACA5K,GAAAvpB,EAAA,WACAo0B,EAAAzR,EAAA3iB,MAEO,WAEP,GAAAq0B,GAAA7B,GAAA,MAAAa,GAAA,KACA,qBAYA,OAXA1Q,GAAAsQ,WAAAoB,GAAA5mE,EAAAgmB,GAAA,SAAAkvC,EAAA1xD,GACA,GAAA+uC,GAAA/uC,EAAA6O,KAAAif,KAAA,GAAAihB,IACA+yB,EAAA,UAAAM,GACA,mDACAY,GAAA3gE,EAAA4gE,EAAAzmE,EAAAgmB,EACAkvC,GAAAsQ,WAAAF,EAAAkB,EAAA,SAAAtR,GACA4G,EAAAvpB,EAAA,WACAo0B,EAAAzR,EAAA3iB,UAIA,IAIA,QAAAypB,GAAA6K,GACA9gE,IACA8gE,GACA9gE,EAAA8gE,EACAh9D,EAAA9D,IACSiuD,IAAA3c,EAAAx0C,QACT6yC,KAiBA,QAAAumB,GAAAl2D,GACAiuD,IACAgI,EAAAj2D,GAqBA,QAAA4gE,GAAAzR,EAAA3iB,GACA,GAAAvyC,GAAA8zD,EAAA7M,SAAAjnD,GAEA8mE,EAAAhT,EAAAlJ,eACAoQ,IAAAhO,EAAA5a,kBACA00B,EAAAze,EAAAyL,EAAA7M,UAAAhmD,OAAA6lE,IAEAA,EAAAjkE,QACAsiE,GAAA2B,EAAA9mE,EAAAk1D,GAGApB,EAAA7M,SAAA1U,KACA,IAAAvsB,GAAA8tC,EAAA7M,SAAAjhC,UACA8tC,GAAA7M,SAAAjhC,GAEA,IAAAs/C,GAAAtK,EACA,UAAA+L,GACA,uDACAnB,GACA,iBAAAmB,GAAA,4BACA,eAAAA,GACA,qDACAC,EAAA/Q,GAAAnC,EAAA7M,UACAtd,EAAAqxB,GACAgM,EAAAz0B,EAAAqiB,EAAA50D,IACAA,EAAAuyC,IAAAy0B,EACA9R,GAAAsQ,WAAAF,EAAA37B,EAAA,WACAoJ,EAAAsiB,IACA7vD,IAAA,EACAxF,GAAA8zD,EAAA7M,SAAAjnD,GACAgmB,OAEAivC,EAAA3kC,IAAAtwB,EAAA8zD,EAAA7M,UACAp9C,MApEA,GAAA9D,GAAA,KACAiuD,EAAA,CAEAF,GAAAruD,KAAAsf,IAAA+uC,EAAA7M,SAAAjnD,GACA8zD,EAAAruD,KAAAqgB,KAAAguC,EAAA7M,SAAAjhC,GACA,IAAAqxB,GAAA92C,OAAA6M,KAAA0mD,EAAAruD,KAAAkgD,iBAGAgP,KACAb,EAAAruD,KAAA4uC,UAAA,GAQAgD,EAAA7lC,QAAA,SAAAlG,GACA,GAAAo6C,GAAAoO,EAAAruD,KAAAkgD,aAAAr6C,EACA,IAAAo6C,EAAAE,KAOAoO,IACAgI,QARA,CACA,GAAAv2D,GAAAigD,EAAAjgD,WACAigD,GAAAjgD,KACAigD,EAAAwW,OAAA5jD,SAAAs8C,EAAA,GACA,IAAA7pD,GAAA26C,EAAA36C,MACAoxD,GAAApxD,EAAAtF,EAAAw2D;AAOA5kB,EAAAx0C,QACA6yC,IAyCA,QAAAuxB,KACAjS,GAAA8D,EAAAqB,WAAAxG,EAAA3G,EAAAiI,EAAAC,EACAniB,EAAAohB,EAAAthD,GAGA,QAAAknD,GAAAlwD,GAOA,QAAA04C,OACA+X,IAAA3G,EAAA9wD,QACAgH,IARA,IAAA8pD,EAAA9wD,OACA,MAAAgH,IAGA,IAAAywD,GAAA,CAQA3G,GAAAniD,QAAA,SAAAsiD,GACA,GAAAA,EAAA/uC,KAAAomC,GAAA2I,EAAA/uC,KACA,MAAAw9B,IAEA,IAAAviD,GAAA8zD,EAAA7M,SAAAjnD,EACAk1D,GAAAsQ,WAAA,oBAAAuB,GACA,iBAAA/mE,GAAA,SAAAk1D,EAAAnrD,GACA,GAAAA,EAAAsI,KAAAxP,OAAA,CACA,GAAAokD,GAAA8O,GAAAhsD,EAAAsI,KAAAif,KAAA,GAAAzrB,KACAovD,GAAA3kC,IAAAtwB,EAAAinD,GAEA1E,QAKA,QAAA4Z,GAAApxD,EAAAtF,EAAAoE,GACA,GAAAy7D,GAAA,sBAAAK,GAAA,iBACAzQ,GAAAsQ,WAAAF,GAAAv6D,GAAA,SAAAmqD,EAAAnrD,GACA,MAAAA,GAAAsI,KAAAxP,OACAgH,KAKAy7D,EAAA,eAAAK,GACA,8CACAzQ,GAAAsQ,WAAAF,GAAAv6D,EAAA25D,GAAAj/D,IAAA,WACAoE,KACO,WAGP,MADAA,MACA,OAzRA,GAAA6lD,GAAA78C,EAAA6iD,UACAwR,EAAA/hB,EAAAtyB,KAGA8gC,EAAAuT,EAAA75D,IAAA,SAAAjC,GACA,GAAAA,EAAA2Z,KAAAomC,GAAA//C,EAAA2Z,KACA,MAAA3Z,EAEA,IAAAslB,GAAA++B,GAAArkD,EAAAskD,EACA,OAAAh/B,KAGAy2C,EAAAxT,EAAAtgD,OAAA,SAAAygD,GACA,MAAAA,GAAA9tD,OAEA,IAAAmhE,EAAAtkE,OACA,MAAAgH,GAAAs9D,EAAA,GAGA,IAAAjS,GAIA4E,EAHA/mB,EAAA,GAAA9qC,OAAA0rD,EAAA9wD,QACAoyD,EAAA,GAAAvR,GAyQAgQ,IAAAC,EAAA,kBAAA5tD,GACA,MAAAA,GACA8D,EAAA9D,OAEAqmB,GAAAwsC,YAAA,SAAA7B,GACA7B,EAAA6B,EACA8C,EAAA,SAAA9zD,GACAA,EACA+zD,EAAA/zD,EAEAg0D,EAAAkN,MAGKpB,GAAAh8D,GAAA4rC,KAOL,QAAA2xB,IAAAv0D,GACA,MAAAA,GAAAw0D,OAAAx0D,EAAApK,KAAAoK,EAAA8C,QAAA9C,EAAAy0D,YAAAz0D,EAAAwtC,MAGA,QAAAknB,IAAA10D,GACA,IACA,OACAuZ,GAAAg7C,GAAAv0D,IAEG,MAAA9M,GACH,OACAC,MAAAD,IAKA,QAAAyhE,IAAA30D,GACA,GAAA40D,GAAAC,GAAA/hE,IAAAkN,EAAApK,KAKA,OAJAg/D,KACAA,EAAAF,GAAA10D,GACA60D,GAAAp3C,IAAAzd,EAAApK,KAAAg/D,IAEAA,EAKA,QAAAE,IAAAv8D,EAAAyH,EAAAm6C,EAAA+J,EAAA1sD,GAOA,QAAAk4C,OACAC,IAAAnL,EAAAx0C,QAAAwH,GACAA,IAIA,QAAA2sD,GAAA5rD,EAAAs6C,GACA,GAAAuR,GAAA7rD,EAAAu6C,aAAAD,GACAkiB,GAAmBtwB,OAAAzkC,EAAAykC,OAAApd,IAAA68B,EACnB/J,GAAAwU,eAAAp2D,EAAA2Z,IAAA2gC,EAAAuR,EAAA2Q,EAAA,SAAAC,EAAApiE,GACA2F,EAAAu6C,aAAAD,GAAAyH,GACAphD,EAAAkrD,GAAA,2BACSxxD,SAET88C,MApBA,GAAAlL,GAAA92C,OAAA6M,KAAAhC,EAAAu6C,iBACA,KAAAtO,EAAAx0C,OACA,MAAAwH,OAEA,IAAAm4C,GAAA,CAoBAnL,GAAA7lC,QAAA,SAAAk0C,GACA7yC,EAAAwkC,aAAAxkC,EAAA2Z,aACAwqC,EAAA5rD,EAAAs6C,IAEAt6C,EAAAu6C,aAAAD,GAAAE,MAAA,EACArD,OAiCA,QAAAulB,IAAAj1D,EAAAhJ,GA0BA,QAAAk+D,KAEAnkB,MACAr9C,OAAAkiB,aAAA,oBAAAukC,EAAAsZ,QAAA,GAEAz8D,EAAA,KAAAmjD,GAQA,QAAAgb,GAAA9S,EAAArrD,GAEAqrD,EAAAsQ,WAAAyC,IAEA/S,EAAAsQ,WAAA,eAAAI,GACA,yDACA1Q,EAAAsQ,WAAA0C,IACAhT,EAAAsQ,WAAA,eAAAuB,GACA,uDACA7R,EAAAsQ,WAAA,uDACAuB,GAAA,eAEA,IAAAzB,GAAA,UAAAyB,GAAA,uBAAAA,GACA,0BAAAnB,GAAA,SAAAmB,GACA,OAAAnB,GAAA,UAAAmB,GAAA,aAEA7R,GAAAsQ,WAAAF,KAAA,SAAApQ,EAAAnrD,GAKA,OAHA6nB,MACAjJ,KAEAroB,EAAA,EAAyBA,EAAAyJ,EAAAsI,KAAAxP,OAAwBvC,IAAA,CACjD,GAAAgxB,GAAAvnB,EAAAsI,KAAAif,KAAAhxB,GACAiyC,EAAAjhB,EAAAihB,IACA0U,EAAA5hD,KAAAmsB,MAAAF,EAAA21B,SACAiE,IAAAjE,IACAr1B,EAAA5pB,KAAAuqC,GAEA4Y,GAAAlE,EAAAjnD,KACA2oB,EAAA3gB,KAAAi/C,EAAAjnD,IAGAk1D,EAAAsQ,WAAA,UAAAuB,GAAA,6BACAjC,GAAAn8C,EAAA9lB,QAAA8lB,EAAA,WACAusC,EAAAsQ,WAAA,UAAAI,GACA,iCACAd,GAAAlzC,EAAA/uB,QAAA+uB,EAAA/nB,WAQA,QAAAs+D,GAAAjT,EAAArrD,GACA,GAAA8e,GAAA,8BAAAy/C,GACA,yBACAlT,GAAAsQ,WAAA78C,KAAA,WACA,GAAA28C,GAAA,UAAAyB,GAAA,cACAnB,GAAA,sBACAA,GAAA,SACAmB,GAAA,OAAAnB,GAAA,UACAmB,GAAA,6BACA7R,GAAAsQ,WAAAF,KAAA,SAAApQ,EAAA1xD,GAKA,QAAA6kE,KACA,IAAAh2D,EAAAxP,OACA,MAAAgH,GAAAqrD,EAEA,IAAA1iD,GAAAH,EAAAo7C,QACAznC,EAAA3gB,KAAAmsB,MAAAhf,EAAA/M,MAAAqgB,IACAovC,GAAAsQ,WAAA,eAAA4C,GACA,mCACA51D,EAAAxS,GAAAgmB,EAAAxT,EAAA/M,MAAA,SAAAyvD,GACAA,EAAAsQ,WAAA,eAAAuB,GAAA,eACAv0D,EAAAxS,IAAA,SAAAk1D,GACAA,EAAAsQ,WAAA,eAAAI,GAAA,gBACApzD,EAAA+/B,KAAA,WACA81B,UAhBA,OADAh2D,MACA/R,EAAA,EAAuBA,EAAAkD,EAAA6O,KAAAxP,OAAqBvC,IAC5C+R,EAAArK,KAAAxE,EAAA6O,KAAAif,KAAAhxB,GAoBA+nE,SAMA,QAAAC,GAAApT,EAAArrD,GAEA,QAAA0+D,GAAAl2D,GACA,QAAAg2D,KACA,IAAAh2D,EAAAxP,OACA,MAAAgH,GAAAqrD,EAEA,IAAA1iD,GAAAH,EAAAo7C,QACA+a,EAAAjE,GAAA/xD,EAAAic,IAAA+1C,GACAprD,EAAAovD,EAAA7R,YAAA,MACA8R,EAAAD,EAAA18D,UAAA,EAAAsN,GACA4M,EAAAwiD,EAAA18D,UAAAsN,EAAA,GACAksD,EAAA,UAAAM,GACA,yCACA1Q,GAAAsQ,WAAAF,GAAAmD,EAAAziD,EAAAwiD,GAAA,WACAH,MAGAA,IAGA,GAAA/C,GAAA,eAAAM,GAAA,oBACA1Q,GAAAsQ,WAAAF,KAAA,SAAApQ,GACA,GAAAoQ,GAAA,eAAAM,GAAA,iBACA1Q,GAAAsQ,WAAAF,KAAA,SAAApQ,GACAA,EAAAsQ,WAAAkD,MAAA,SAAAxT,GACA,GAAAoQ,GAAA,sCAAAM,EACA1Q,GAAAsQ,WAAAF,KAAA,SAAApQ,EAAA1xD,GAEA,OADA6O,MACA/R,EAAA,EAA2BA,EAAAkD,EAAA6O,KAAAxP,OAAqBvC,IAChD+R,EAAArK,KAAAxE,EAAA6O,KAAAif,KAAAhxB,GAEAioE,GAAAl2D,WASA,QAAAs2D,GAAAzT,EAAArrD,GAEA,QAAAg3D,GAAA3L,GAIA,GAAAoQ,GAAA,+BAAAK,EACAzQ,GAAAsQ,WAAAF,KAAA,SAAApQ,EAAA1xD,GAQA,QAAAolE,KACA,GAAAtD,GAAAP,GACA8D,GAAA,KAAA9B,GAAA,aACAA,GAAAnB,IACAkD,GACA,KACA/B,GAAA,OAEAzB,IAAA,UAAAyD,EAAA,WAAA3xB,EACAA,GAAA2xB,EACA7T,EAAAsQ,WAAAF,KAAA,SAAApQ,EAAA1xD,GAKA,QAAAwlE,GAAAj+D,EAAAwnC,GAEA,GAAA8yB,GAAA4D,EAAAl+D,GAAAk+D,EAAAl+D,MACAs6D,GAAAz/D,QAAA2sC,MAAA,GACA8yB,EAAAr9D,KAAAuqC,GARA,IAAA/uC,EAAA6O,KAAAxP,OACA,MAAAgH,GAAAqrD,EAUA,QARA+T,MAQA3oE,EAAA,EAA2BA,EAAAkD,EAAA6O,KAAAxP,OAAqBvC,IAIhD,OAHAkS,GAAAhP,EAAA6O,KAAAif,KAAAhxB,GACA8K,EAAAy5D,GAAAryD,EAAA/M,KAAA+M,EAAAxS,GAAAwS,EAAAwT,KACAomC,EAAA7rD,OAAA6M,KAAAhC,EAAAu6C,kBACA7hC,EAAA,EAA6BA,EAAAsoC,EAAAvpD,OAAiBihB,IAAA,CAC9C,GAAA4hC,GAAAt6C,EAAAu6C,aAAAyG,EAAAtoC,GACAklD,GAAAtjB,EAAA36C,OAAAyH,EAAA+/B,KAGA,GAAA22B,KAOA,IANA3oE,OAAA6M,KAAA67D,GAAAz3D,QAAA,SAAAzG,GACA,GAAAs6D,GAAA4D,EAAAl+D,EACAs6D,GAAA7zD,QAAA,SAAA+gC,GACA22B,EAAAlhE,MAAA+C,EAAAwnC,SAGA22B,EAAArmE,OACA,MAAA+lE,IAEA,IAAApmB,GAAA,CACA0mB,GAAA13D,QAAA,SAAAxB,GACA,GAAAs1D,GAAA,eAAAC,GACA,6BACArQ,GAAAsQ,WAAAF,EAAAt1D,EAAA,aACAwyC,IAAA0mB,EAAArmE,QACA+lE,UAtDA,GAAAx6D,GAAA5K,EAAA6O,KAAAif,KAAA,GAAAi1C,GACA,KAAAn4D,EACA,MAAAvE,GAAAqrD,EAGA,IAAA9d,GAAA,EACA2xB,EAAA,EAsDAH,OAIA,GAAAO,GAAA,8BACA5D,GAAA,wBACArQ,GAAAsQ,WAAA2D,KAAA,SAAAjU,GACAA,EAAAsQ,WACA4D,MAAA,SAAAlU,GACAA,EAAAsQ,WACA6D,MACAxI,OAOA,QAAAyI,GAAApU,EAAArrD,GACA,GAAAy7D,GAAA,eAAAK,GACA,0CACAzQ,GAAAsQ,WAAAF,KAAAz7D,GAKA,QAAA0/D,GAAArU,EAAArrD,GACA,GAAAy7D,GAAA,eAAAyB,GACA,6BACA7R,GAAAsQ,WAAAF,KAAA,SAAApQ,GACA,GAAAoQ,GAAA,UAAAyB,GAAA,sCACAnB,GAAA,mBACA1Q,GAAAsQ,WAAAF,KAAA,SAAApQ,GAGA,GAAAoQ,GACA,0DACAyB,GAAA,YACA7R,GAAAsQ,WAAAF,KAAAz7D,OAKA,QAAA2/D,GAAAtU,EAAA7qD,GAEA6qD,EAAAsQ,WAAA,qCAAAtQ,EAAA1xD,GACA,GAAAirB,GAAAjrB,EAAA6O,KAAAif,KAAA,GAAA7C,GACA+1C,GAAA,IAAA/1C,EAAA5rB,OAAA,iBACAwH,MAKA,QAAAo/D,KACA,KAAAC,EAAA7mE,OAAA,IACA,GAAA8mE,GAAAD,EAAAlgE,KACAmgE,GAAA,KAAAvI,IAIA,QAAAwI,GAAA1U,EAAA2U,GACA,OAAAA,EAAA,CAGA,GAAA9jD,GAAA,8BAAA+jD,GACA,8BACAC,EAAA,8BAAApE,GACA,kDACAwD,EAAA,8BACA5D,GAAA,yBAEAn6D,EAAA,8BAAA27D,GACA,yDACAx0B,EAAA,8BAAAqzB,GACA,2FAEAj9C,EAAA,8BAAAy/C,GACA,yBAGAlT,GAAAsQ,WAAAuE,GACA7U,EAAAsQ,WAAA78C,GACAusC,EAAAsQ,WAAA2D,KAAA,WACAjU,EAAAsQ,WAAA6D,IACAnU,EAAAsQ,WAAA4D,MAEAlU,EAAAsQ,WAAAp6D,KAAA,WACA8pD,EAAAsQ,WAAAyC,IACA/S,EAAAsQ,WAAAjzB,KAAA,WACA2iB,EAAAsQ,WAAA0C,IACAhT,EAAAsQ,WAAAkD,IACAxT,EAAAsQ,WAAAz/C,KAAA,WAEA,GAAAikD,GAAA,eAAAF,GACA,kCACA1I,GAAAta,GACA,IAAAmjB,IAAAC,GAAA9I,EACAlM,GAAAsQ,WAAAwE,EAAAC,EAAA,WACAR,gBAKK,CAEL,GAAAU,GAAA,WACA,GAAAC,GAAAP,EAAAK,EACAE,IAEAlV,EAAAsQ,WAAA,UAAAsE,GAAA,qBACAI,GAGA,IAAA5E,GAAA,oBAAAwE,EACA5U,GAAAsQ,WAAAF,KAAA,SAAApQ,EAAAnrD,GACAq3D,EAAAr3D,EAAAsI,KAAAif,KAAA,GAAA+4C,KACAZ,OAMAa,GACAtC,EACAG,EACAG,EACAK,EACAW,EACAC,EACAY,GAIA7pE,EAAAupE,EACAU,EAAA,SAAArV,GACAoV,EAAAhqE,EAAA,GAAA40D,EAAAqV,GACAjqE,IAEAiqE,GAAArV,IAIA,QAAAsV,KACAp+C,EAAAwsC,YAAA,SAAA1D,GAEAsU,EAAAtU,EAAA,WAEAuV,EAAAvV,MAEK2Q,GAAAh8D,GAAAk+D,GAGL,QAAA0C,GAAAvV,GACA,GAAAoQ,GAAA,kDAAAwE,EACA5U,GAAAsQ,WAAAF,KAAA,SAAApQ,EAAAnrD,GACAA,EAAAsI,KAAAxP,OAGO,aAAAmpB,KAAAjiB,EAAAsI,KAAAif,KAAA,GAAAg0C,KASPpQ,EAAAsQ,WAAA,0BAAAsE,MACA,SAAA5U,EAAAnrD,GACA,GAAA8/D,GAAA9/D,EAAAsI,KAAAif,KAAA,GAAAo5C,UACAd,GAAA1U,EAAA2U,KATA3U,EAAAsQ,WAAA,eAAAsE,GACA,+CAEAF,EAAA1U,EAAA,KAPA0U,EAAA1U,EAAA,KAqBA,QAAAyV,GAAAzV,EAAArrD,GACA,GAAAy7D,GAAA,+BAAAM,EACA1Q,GAAAsQ,WAAAF,KAAA,SAAApQ,EAAA1xD,GACA,GAAAq+D,GAAAr+D,EAAA6O,KAAAif,KAAA,GAAAihB,KAAA,CACA1oC,GAAAg4D,KAIA,QAAAnD,GAAAxJ,EAAArrD,GAEA,GAAAy7D,GAAAP,GACA,SAAAgC,GAAA,iBACAA,GAAAnB,IACAkD,GACAlD,GAAA,aAEA1Q,GAAAsQ,WAAAF,KAAA,SAAApQ,EAAAnrD,GACAF,EAAAE,EAAAsI,KAAAif,KAAA,GAAAxZ,OAmCA,QAAA8yD,GAAA1V,EAAAl1D,EAAAgmB,EAAAnc,EAAA6rC,GACA,GAAA4vB,GAAAP,GACA8D,IACA9B,GAAAnB,IACAkD,GACA/B,GAAA,SACAP,GAAAxmE,EAEAk1D,GAAAsQ,WAAAF,EAAAkB,EAAA,SAAA1lE,EAAAiyC,GACA,IAAAA,EAAA1gC,KAAAxP,OAAA,CACA,GAAAkD,GAAA++C,EAAAwQ,GAAA,UACA,OAAA5f,GAAA3vC,GAEA,GAAAurB,GAAAyhB,EAAA1gC,KAAAif,KAAA,GACA21B,EAAA8O,GAAAzkC,EAAA21B,SACAp9C,GAAAuhD,GAAAplC,EAAAihC,MA1dA,GAIAud,GAJAxX,EAAArtD,KACAyhE,EAAA,KACA/gB,EAAA6lB,GAAArzD,GACA62D,IAGA1c,GAAAsZ,MAAAzzD,EAAApK,IAIA,IAAAoiE,GAAA1d,MAA8Bt6C,GAC9B8C,QAAAm1D,GACAxD,YAAAz0D,EAAApK,KACA43C,SAEA0qB,EAAAvD,GAAAqD,EACA,IAAAE,EAAA/kE,MACA,MAAA6/D,IAAAh8D,GAAAkhE,EAAA/kE,MAEA,IAAAomB,GAAA2+C,EAAA3+C,EACA,mBAAAA,GAAA4+C,kBAEA5+C,EAAA4+C,gBAAA5+C,EAAAwsC,aA+XA4R,IAuBAxd,EAAA3nC,KAAA,WACA,gBAGA2nC,EAAAjoC,IAAA3b,EAAA,SAAAS,GACAA,EAAA,KAAAu3D,KAGApU,EAAA4U,MAAA,SAAA/3D,GACA,GAAA0oC,GACA6nB,CACAhuC,GAAA4+C,gBAAA,SAAA9V,GACAyV,EAAAzV,EAAA,SAAA+V,GACA14B,EAAA04B,IAEAvM,EAAAxJ,EAAA,SAAAgW,GACA9Q,EAAA8Q,KAEKrF,GAAAh8D,GAAA,WACLA,EAAA,MACAi4D,UAAA1H,EACA2H,WAAAxvB,EACA44B,gBAAA3G,OAKAxX,EAAAqU,UAAA,SAAAlc,EAAAmc,EAAAz3D,GACAu8D,GAAAvzD,EAAAsyC,EAAAmc,EAAAtU,EAAA5gC,EAAAi6C,GAAAx8D,IAsBAmjD,EAAAuU,KAAA,SAAAvhE,EAAA6S,EAAAhJ,GAUA,QAAA6rC,GAAA3vC,GACA8D,EAAA9D,GAAqBqF,MAAA67C,WAAA/sB,IAAAg7B,IAVrB,GAAA9pD,GACA67C,EACAiO,EAAAriD,EAAAqnB,GACA,KAAAg7B,EACA,MAAA9oC,GAAA4+C,gBAAA,SAAAjU,GACA/J,EAAAuU,KAAAvhE,EAAAmtD,IAA+BjzB,IAAA68B,GAASlkD,GAAAhJ,IAQxC,IAAAy7D,GACAkB,CAEA,IAAA3zD,EAAAmT,IAOK,IAAAnT,EAAAu4C,OAML,WALAwf,GAAA1V,EAAAl1D,EAAA6S,EAAAmT,IAAA,SAAAolD,GACAv4D,EAAAu4C,QAAA,EACAv4C,EAAAmT,IAAAolD,EACApe,EAAAuU,KAAAvhE,EAAA6S,EAAAhJ,IACO6rC,EAGP4vB,GAAAP,GACA8D,IACA9B,GAAAnB,IACAmB,GAAA,OAAAnB,GAAA,WACAA,GAAA,YAAAA,GAAA,WACAY,GAAAxmE,EAAA6S,EAAAmT,SAnBAs/C,GAAAP,GACA8D,IACA9B,GAAAnB,IACAkD,GACA/B,GAAA,SACAP,GAAAxmE,EAiBAk1D,GAAAsQ,WAAAF,EAAAkB,EAAA,SAAA1lE,EAAAiyC,GACA,IAAAA,EAAA1gC,KAAAxP,OAAA,CACA,GAAAwoE,GAAAvmB,EAAAwQ,GAAA,UACA,OAAA5f,GAAA21B,GAEA,GAAA/5C,GAAAyhB,EAAA1gC,KAAAif,KAAA,EAEA,IADA21B,EAAA8O,GAAAzkC,EAAA21B,UACA31B,EAAAM,UAAA/e,EAAAmT,IAAA,CACA,GAAAslD,GAAAxmB,EAAAwQ,GAAA,UACA,OAAA5f,GAAA41B,GAEAlgE,EAAAy5D,GAAAvzC,EAAA7rB,KAAAwhD,EAAAjnD,GAAAsxB,EAAAtL,KACA0vB,OAIAsX,EAAAC,SAAA,SAAAp6C,EAAAhJ,GACA,GACAgtC,GADA9D,KAGAxR,EAAA,YAAA1uB,MAAAE,SACAyc,EAAA,UAAA3c,MAAAG,OACA1H,EAAA,OAAAuH,MAAAvH,IACAu6B,EAAA,cAAAhzB,MAAAgzB,WACAH,EAAA,SAAA7yB,KAAA6yB,OAAA,EACA0R,EAAA,QAAAvkC,KAAA8yB,KAAA,EACAmB,EAAAj0B,EAAAK,iBAAA,EAEAszD,KACA+E,IAEA,IAAAjgE,KAAA,EACAigE,EAAAvjE,KAAA++D,GAAA,WACAP,EAAAx+D,KAAAsD,OACK,IAAAi2B,KAAA,GAAA/R,KAAA,GAKL,GAJA+R,KAAA,IACAgqC,EAAAvjE,KAAA++D,GAAA,QAAAlhC,EAAA,iBACA2gC,EAAAx+D,KAAAu5B,IAEA/R,KAAA,GACA,GAAAm5B,GAAA9iB,EAAA,OACAiB,KACA6hB,GAAA,KAEA4iB,EAAAvjE,KAAA++D,GAAA,OAAApe,EAAA,MACA6d,EAAAx+D,KAAAwnB,GAEAlkB,KAAA,IACAigE,EAAAvjE,KAAA++D,GAAA,WACAP,EAAAx+D,KAAAsD,IAIA,OAAAuH,EAAA+e,SAEA25C,EAAAvjE,KAAA49D,GAAA,gBAGAx5C,EAAA4+C,gBAAA,SAAA9V,GAMA,GAJAwJ,EAAAxJ,EAAA,SAAAkF,GACAvjB,EAAAujB,IAGA,IAAA10B,EAAA,CAKA,GAAA4/B,GAAAP,GACA8D,IACA9B,GAAAnB,IACAkD,GACAyC,EACAxE,GAAA,QAAAlhC,EAAA,cAEAy/B,IAAA,UAAA5/B,EAAA,WAAA0R,EAEA8d,EAAAsQ,WAAAF,EAAAkB,EAAA,SAAAtR,EAAAnrD,GACA,OAAAzJ,GAAA,EAAAqN,EAAA5D,EAAAsI,KAAAxP,OAA+CvC,EAAAqN,EAAOrN,IAAA,CACtD,GAAAgxB,GAAAvnB,EAAAsI,KAAAif,KAAAhxB,GACA2mD,EAAA8O,GAAAzkC,EAAA21B,UACAjnD,EAAAinD,EAAAjnD,GACAyF,EAAAo/D,GAAAvzC,EAAA7rB,KAAAzF,EAAAsxB,EAAAtL,KACA4uC,EAAAnvD,EAAAqgB,KACA1a,GACApL,KACAsL,IAAAtL,EACAkC,OAAoB8jB,IAAA4uC,GAEpB,IAAA/hD,EAAA2Z,aAAA,CAGA,GAFAphB,MAAA3F,EACA2F,MAAA0a,KAAA8uC,EACA/hD,EAAA+iC,UAAA,CACA,GAAAA,GAAAsS,EAAAjB,EACArR,GAAA/yC,SACAuI,MAAA6gD,WAAArW,GAGA+xB,GAAAv8D,MAAAyH,EAAAm6C,EAAAkI,GAEA,GAAA5jC,EAAAM,QAAA,CACA,UAAA/e,EAAA+e,QAIA,QAHAxmB,GAAAlJ,MAAA0vB,SAAA,EACAxmB,MAAA,KAKA2nC,EAAA/qC,KAAAoD,QAGKy6D,GAAAh8D,GAAA,WACLA,EAAA,MACAgjB,WAAAgqB,EACAO,OAAAvkC,EAAA8yB,KACAtzB,KAAA0gC,OAKAia,EAAAiV,SAAA,SAAApvD,GAoCA,QAAA24D,KAEA,GAAAC,GACA1E,GAAA,sBACAA,GAAA,uBACAnB,GAAA,wBACAA,GAAA,sBAEAthC,EAAAyiC,GAAA,SAAAnB,GAEAZ,EAAA+B,GAAA,OAAAnB,GAAA,eACAmB,GAAA,eAAAnB,GAAA,OAEA2F,GAAA,cACA/E,GAAA3zD,EAAA+yB,MAEA/yB,GAAA+sD,UACA2L,EAAAvjE,KAAA++D,GAAA,UAAAjC,GAAAjyD,EAAA+sD,QAAA/8D,SACA2jE,IAAAvlE,OAAA4R,EAAA+sD,SAGA,IAAAsF,GAAA,WAAAr/B,EAAA,cAEAy/B,EAAAP,GAAA0G,EAAAnnC,EAAA0gC,EAAAuG,EAAArG,GAEA7xD,EAAAiyC,EAAAzyC,EACAA,GAAAgS,MAAAhS,EAAAQ,SAEAiyD,GAAA,UAAA5/B,EAGA,IAAAs5B,GAAAnsD,EAAA+yB,OAAA,CACAxZ,GAAA4+C,gBAAA,SAAA9V,GACAA,EAAAsQ,WAAAF,EAAAkB,EAAA,SAAAtR,EAAAnrD,GACA,QAAA2hE,GAAA51B,GACA,kBACAjjC,EAAAg5C,SAAA/V,IAGA,OAAAx1C,GAAA,EAAAqN,EAAA5D,EAAAsI,KAAAxP,OAAiDvC,EAAAqN,EAAOrN,IAAA,CACxD,GAAAgxB,GAAAvnB,EAAAsI,KAAAif,KAAAhxB,GACA2mD,EAAA8O,GAAAzkC,EAAA21B,SACA+X,GAAA1tC,EAAAq6C,MAEA,IAAAvgE,GAAAy5D,GAAAvzC,EAAAytC,WAAA9X,EAAAjnD,GACAsxB,EAAA01B,YACAlR,EAAAjjC,EAAA0iC,cAAAnqC,EAAA67C,EAAAp0C,EACAijC,GAAAvD,IAAAjhB,EAAAq6C,MAEA,IAAA1M,GAAA5rD,EAAAyiC,EACA,oBAAAmpB,GACA,MAAApsD,GAAA4iC,SAAAwpB,EAiBA,IAdAA,IACAC,IACAC,GACApsB,EAAA/qC,KAAA8tC,GAIAjjC,EAAAwkC,aAAAxkC,EAAA2Z,aACAm7C,GAAAv8D,EAAAyH,EAAAm6C,EAAAkI,EACAwW,EAAA51B,IAEA41B,EAAA51B,MAGAopB,IAAAx5B,EACA,UAIOmgC,GAAAhzD,EAAA4iC,UAAA,WACP5iC,EAAA8sD,YACA9sD,EAAA4iC,SAAA,MACA1C,UACAwa,SAAAyR,MA9GA,GAFAnsD,EAAA3I,EAAA2I,GAEAA,EAAA8sD,WAAA,CACA,GAAA3/D,GAAAgtD,EAAAsZ,MAAA,IAAAxf,GAGA,OAFAuf,IAAAvwD,YAAAk3C,EAAAsZ,MAAAtmE,EAAAgtD,EAAAn6C,GACAwzD,GAAA5L,OAAAzN,EAAAsZ,QAEAt8D,OAAA,WACAq8D,GAAArwD,eAAAg3C,EAAAsZ,MAAAtmE,KAKA,GAAA6lC,GAAAhzB,EAAAgzB,UAGAhzB,GAAA+yB,MAAA/yB,EAAA+yB,QAAAC,EAAAhzB,EAAA+yB,MAAA,CAEA,IAAAF,GAAA,SAAA7yB,KAAA6yB,OAAA,CACA,KAAAA,IACAA,EAAA,EAGA,IAAAy5B,EAEAA,GADA,eAAAtsD,GACAA,EAAAitD,cACK,cAAAjtD,KAELA,EAAAssD,UAIA,IAAApsB,MACAmsB,EAAA,CAqFAsM,MAGAxe,EAAAkV,OAAA,SAAAr4D,GAEAA,KAGAmjD,EAAAwU,eAAA,SAAAhxC,EAAAixC,EAAAC,EAAA7uD,EAAAhJ,GACA,GAAArG,GACA0xD,EAAAriD,EAAAqnB,IACAnvB,EAAA22D,EAAA32D,OACAsa,EAAAq8C,EAAAnO,aACA+R,EAAA,mFAEAK,GAAA,iBACAzQ,GAAAsQ,WAAAF,GAAAv6D,GAAA,SAAAmqD,EAAAnrD,GAKA,GAAAunB,GAAAvnB,EAAAsI,KAAAif,KAAA,GACA7rB,EAAA6rB,EAAAs6C,QAAAjH,GAAArzC,EAAAvsB,MACAw/D,GAAAjzC,EAAAvsB,KAAAy/D,EAEAhhE,GADAqP,EAAAykC,OACAyZ,GAAAtrD,EAAA4f,GAEA6sC,GAAAzsD,GAEAoE,EAAA,KAAArG,MAIAwpD,EAAAqV,iBAAA,SAAA7xC,EAAA3mB,GACAuiB,EAAA4+C,gBAAA,SAAA9V,GACA,GAAAoQ,GAAA,gCAAAyB,GAAA,eACA7R,GAAAsQ,WAAAF,GAAA90C,GAAA,SAAA0kC,EAAAnrD,GACA,GAAAA,EAAAsI,KAAAxP,OAES,CACT,GAAA4C,GAAAswD,GAAAhsD,EAAAsI,KAAAif,KAAA,GAAA21B,SACAp9C,GAAA,KAAApE,EAAA8hD,cAHA19C,GAAAi7C,EAAAwQ,UASAtI,EAAAsV,cAAA,SAAA9xC,EAAAo3B,EAAA/9C,GACA,MAAA+9C,GAAA/kD,WAGAupB,GAAAwsC,YAAA,SAAA1D,GAGA,GAAAoQ,GAAA,gCAAAyB,GAAA,eACA7R,GAAAsQ,WAAAF,GAAA90C,GAAA,SAAA0kC,EAAAnrD,GACA,GAAAk9C,GAAA8O,GAAAhsD,EAAAsI,KAAAif,KAAA,GAAA21B,SACAU,GAAAV,EAAAM,SAAA,SAAAU,EAAAP,EACAY,EAAApuB,EAAArnB,GACA,GAAAmT,GAAA0hC,EAAA,IAAAY,CACAV,GAAAhiD,QAAAogB,MAAA,IACAnT,EAAAzO,OAAA,YAIA,IAAAkhE,GAAA,UAAAyB,GAAA,4BACA7R,GAAAsQ,WAAAF,GAAArP,GAAAhP,GAAAz2B,MAGA20C,GAAAvd,EAAAp3B,EAAA0kC,IACK2Q,GAAAh8D,GAAA,WACLA,MAtBAA,KA0BAmjD,EAAAuV,UAAA,SAAAviE,EAAA6J,GACAuiB,EAAA4+C,gBAAA,SAAA9V,GACA,GAAAoQ,GAAA,yBAAA8C,GAAA,aACAlT,GAAAsQ,WAAAF,GAAAtlE,GAAA,SAAAk1D,EAAA1xD,GACA,GAAAA,EAAA6O,KAAAxP,OAAA,CACA,GAAAyuB,GAAA9tB,EAAA6O,KAAAif,KAAA,GACAlmB,EAAAy5D,GAAAvzC,EAAAzrB,KAAA7F,EAAAsxB,EAAAtL,IACAnc,GAAA,KAAAuB,OAEAvB,GAAAi7C,EAAAwQ,UAMAtI,EAAAwV,UAAA,SAAAp3D,EAAAyH,EAAAhJ,GAiBA,QAAAgiE,GAAA3W,GACA,GAAAoQ,GACA16C,CACA63C,IACA6C,EAAA,UAAA8C,GAAA,0CAEAx9C,GAAA6pC,EAAA5uD,EAAA7F,EAAAyiE,KAEA6C,EAAA,eAAA8C,GAAA,kCACAx9C,GAAA5qB,EAAAy0D,EAAA5uD,IAEAqvD,EAAAsQ,WAAAF,EAAA16C,EAAA,SAAAsqC,EAAA1xD,GACAA,EAAAsoE,cACAp8C,GAAiBlqB,IAAA,EAAAxF,KAAAgmB,IAAAyuC,GACjB5hD,EAAAqnB,KACArwB,EAAA,KAAA6lB,IAGA7lB,EAAAi7C,EAAA0P,MAEO,WAEP,MADA3qD,GAAAi7C,EAAA0P,MACA,IAtCA,kBAAA3hD,KACAhJ,EAAAgJ,EACAA,YAEAzH,GAAAohD,UACA,IAEAiI,GAFAgO,EAAAr3D,EAAA0a,KACA9lB,EAAAoL,EAAA2Z,GAKA0vC,GAHAgO,EAGAr3D,EAAA0a,KAAA,MAAAxN,SAAAmqD,EAAA1yD,MAAA,eAFA3E,EAAA0a,KAAA,KAIA,IAEA4J,GAFA7pB,EAAA++D,GAAAx5D,EA6BAyH,GAAAqnB,IACA2xC,EAAAh5D,EAAAqnB,KAEA9N,EAAAwsC,YAAAiT,EAAAhG,GAAAh8D,GAAA,WACA6lB,GACA7lB,EAAA,KAAA6lB,MAMAs9B,EAAA4V,aAAA,SAAAx3D,EAAAyH,EAAAhJ,GAOA,QAAAkiE,GAAA7W,GACA,GAAAoQ,GAAA,eAAA8C,GAAA,wBACAz+B,GAAAv+B,EAAA2Z,IAAA3Z,EAAA0a,KACAovC,GAAAsQ,WAAAF,EAAA37B,EAAA,SAAAurB,EAAA1xD,GACA,MAAAA,GAAAsoE,cAGAp8C,GAAelqB,IAAA,EAAAxF,GAAAoL,EAAA2Z,IAAAiB,IAAA,YACfnT,EAAAqnB,KACArwB,EAAA,KAAA6lB,KAJA7lB,EAAAi7C,EAAAwQ,OAXA,kBAAAziD,KACAhJ,EAAAgJ,EACAA,KAEA,IAAA6c,EAgBA7c,GAAAqnB,IACA6xC,EAAAl5D,EAAAqnB,KAEA9N,EAAAwsC,YAAAmT,EAAAlG,GAAAh8D,GAAA,WACA6lB,GACA7lB,EAAA,KAAA6lB,MAMAs9B,EAAA6V,SAAA,SAAAhwD,EAAAhJ,GACAw8D,GAAApwD,mBAAA+2C,EAAAsZ,OACAl6C,EAAAwsC,YAAA,SAAA1D,GACA,GAAAwD,IAAAqO,GAAAnB,GAAAD,GAAAmE,GACA1B,GAAA7C,GACA7M,GAAAlnD,QAAA,SAAAs8B,GACAonB,EAAAsQ,WAAA,wBAAA13B,SAEK+3B,GAAAh8D,GAAA,WACL+5C,YACAr9C,QAAAkiB,aAAA,oBAAAukC,EAAAsZ,aACA//D,QAAAkiB,aAAAukC,EAAAsZ,QAEAz8D,EAAA,MAAsBrE,IAAA,OAKtB,QAAAwmE,MACA,IAEA,MADAC,cAAA,kCACA,EACG,MAAAlmE,GACH,UAQA,QAAAmmE,MAcA,sBAAAlJ,YAAA,OAAAA,YACA,iBAAAh3C,KAAAne,UAAA4Z,WAEA,QAKA,IAAA0kD,GAAAvoB,IAGAwoB,EAAA,0BAAAv+D,UAAA4Z,SACA,IAAA0kD,GAAA1jD,aAAA2jD,GACA,YAAA3jD,aAAA2jD,EAEA,IAAAC,GAAAL,IAIA,OAHAG,KACA1jD,aAAA2jD,GAAAC,EAAA,SAEAA,EAGA,QAAAxd,MACA,wBAAAod,eAGAC,KAGA,QAAAI,IAAA7jE,EAAAkN,EAAA2xD,EAAAjnB,GAEA,MAAA4rB,cAAAxjE,EAAAkN,EAAA2xD,EAAAjnB,GAGA,QAAAksB,IAAA15D,EAAAhJ,GACA,GAAA2iE,GAAArf,IACAka,OAAAiF,IACGz5D,EAEHi1D,IAAA5nE,KAAAP,KAAA6sE,EAAA3iE,GAaA,QAAA4iE,MAUA,OATAC,MAEAhjE,EAAA,GAAAk3C,IAAA,SAAA1yC,EAAAtE,GACA8iE,EAAAx+D,UACAw+D,EAAA9iE,WAGAjJ,EAAA,GAAAsH,OAAArF,UAAAC,QAEAvC,EAAA,EAAiBA,EAAAK,EAAAkC,OAAiBvC,IAClCK,EAAAL,GAAAsC,UAAAtC,EAaA,OAVAosE,GAAAhjE,UAEAk3C,GAAA1yC,UAAAlL,KAAA,WACA,MAAAG,OAAAnC,MAAA,KAAAL,KACGqC,KAAA,SAAAkC,GACHwnE,EAAAx+D,QAAAhJ,KACGuJ,MAAA,SAAAzI,GACH0mE,EAAA9iE,OAAA5D,KAGA0mE,EAGA,QAAAC,IAAAhqE,EAAAkH,GACA,GAAA6iE,GAAAxjC,EAAAhkC,EAEAvB,EAAA,GAAAipE,SAEAC,GACA/nE,OAAAnC,EAAAmC,OACAvB,YAAA,UACAI,UA+DA,OA5DAhB,GAAAkD,OACAlC,EAAA2sB,IAAA,6BACA3sB,EAAA2sB,IAAA,eAAA3tB,EAAAgB,QAAA,iBACA,qBAGAhB,EAAAoC,MACApC,EAAAmqE,aACA,gBAAAnqE,GAAAoC,KACA8nE,EAAA9nE,KAAAM,KAAAC,UAAA3C,EAAAoC,MACG,QAAApC,GACHkqE,EAAA9nE,KAAApC,EAAAoC,KAEA8nE,EAAA9nE,KAAA,KAGAxE,OAAA6M,KAAAzK,EAAAgB,SAAA6N,QAAA,SAAAlG,GACA3I,EAAAgB,QAAAlD,eAAA6K,IACA3H,EAAA2sB,IAAAhlB,EAAA3I,EAAAgB,QAAA2H,MAIAohE,EAAAD,GAAA9pE,EAAAgE,IAAAkmE,GAEAlqE,EAAAwS,QAAA,IACA+zB,EAAA/6B,WAAA,WACAu+D,EAAA9iE,OAAA,GAAAzD,OAAA,8BACAxD,EAAAgE,OACKhE,EAAAwS,UAGLu3D,EAAAhjE,QAAA1G,KAAA,SAAA+pE,GASA,MARA7nE,IACA8nE,WAAAD,EAAA3oE,QAGAzB,EAAAwS,QAAA,GACAP,aAAAs0B,GAGAhkC,EAAA8nE,YAAA,KAAA9nE,EAAA8nE,WAAA,IACArqE,EAAA20C,OAAAy1B,EAAAxb,OAAAwb,EAAAjnE,OAGAinE,EAAAlnE,SACG7C,KAAA,SAAA+G,GACH7E,EAAA8nE,YAAA,KAAA9nE,EAAA8nE,WAAA,IACAnjE,EAAA,KAAA3E,EAAA6E,IAEAA,EAAA3F,OAAAc,EAAA8nE,WACAnjE,EAAAE,MAEG0E,MAAA,SAAAzI,GACHA,IAEAA,EAAA,GAAAG,OAAA,aAEA0D,EAAA7D,MAGUinE,MAAAP,EAAA9iE,QAGV,QAAAsjE,IAAAvqE,EAAAkH,GAEA,GAAAsjE,GAAAjkC,EACAkkC,GAAA,EAEAC,EAAA,WACAF,EAAAF,QACAK,KAGAC,EAAA,WACAH,GAAA,EACAD,EAAAF,QACAK,KAGA59C,GAAau9C,MAAAI,GAEbC,EAAA,WACA14D,aAAAs0B,GACAxZ,EAAAu9C,MAAA,aACAE,IACAA,EAAAK,WAAA1qE,OACAqqE,EAAAM,SACAN,EAAAM,OAAAD,WAAA1qE,QAEAqqE,EAAA/qD,mBAAAtf,OACAqqE,EAAArqE,QAKAqqE,GADAxqE,EAAAwqE,IACA,GAAAxqE,GAAAwqE,IAEA,GAAAO,eAGA,KACAP,EAAA/J,KAAAzgE,EAAAmC,OAAAnC,EAAAgE,KACG,MAAA4gB,GACH,MAAA1d,GAAA,GAAA1D,OAAAohB,EAAA9e,MAAA,mBAGA0kE,EAAAQ,kBAAA,mBAAAhrE,KACAA,EAAAgrE,gBAEA,QAAAhrE,EAAAmC,aACAnC,GAAAgB,QAAA,gBACGhB,EAAAkD,OACHlD,EAAAgB,QAAAiqE,OAAA,mBACAjrE,EAAAgB,QAAA,gBAAAhB,EAAAgB,QAAA,iBACA,mBACAhB,EAAAoC,MACApC,EAAAmqE,aACA,gBAAAnqE,GAAAoC,OACApC,EAAAoC,KAAAM,KAAAC,UAAA3C,EAAAoC,QAIApC,EAAA20C,SACA61B,EAAAU,aAAA,eAGA,QAAAlrE,KACAA,EAAAoC,KAAA,KAGA,QAAAuG,KAAA3I,GAAAgB,QACAhB,EAAAgB,QAAAlD,eAAA6K,IACA6hE,EAAAW,iBAAAxiE,EAAA3I,EAAAgB,QAAA2H,GA4DA,OAxDA3I,GAAAwS,QAAA,IACA+zB,EAAA/6B,WAAAo/D,EAAA5qE,EAAAwS,SACAg4D,EAAAK,WAAA,WACA54D,aAAAs0B,GACA,IAAAikC,EAAAY,aACA7kC,EAAA/6B,WAAAo/D,EAAA5qE,EAAAwS,WAGA,mBAAAg4D,GAAAM,SACAN,EAAAM,OAAAD,WAAAL,EAAAK,aAIAL,EAAA/qD,mBAAA,WACA,OAAA+qD,EAAAY,WAAA,CAIA,GAAA7oE,IACA8nE,WAAAG,EAAA/oE,OAGA,IAAA+oE,EAAA/oE,QAAA,KAAA+oE,EAAA/oE,OAAA,KACA,GAAAqB,EAEAA,GADA9C,EAAA20C,OACA6Y,IAAAgd,EAAAjoE,UAAA,KACAmgB,KAAA8nD,EAAAa,kBAAA,kBAGAb,EAAAc,aAEApkE,EAAA,KAAA3E,EAAAO,OACK,CACL,GAAAM,KACA,IAAAqnE,EACArnE,EAAA,GAAAI,OAAA,aACAJ,EAAAkX,KAAA,gBACO,oBAAAkwD,GAAAjoE,SACP,IACAa,EAAAV,KAAAmsB,MAAA27C,EAAAjoE,UACS,MAAA8B,IAETjB,EAAA3B,OAAA+oE,EAAA/oE,OACAyF,EAAA9D,GAEAunE,MAGA3qE,EAAAoC,MAAApC,EAAAoC,eAAA6vB,MACA88B,GAAA/uD,EAAAoC,KAAA,SAAAwtD,GACA4a,EAAAe,KAAA3b,KAGA4a,EAAAe,KAAAvrE,EAAAoC,MAGA2qB,EAGA,QAAAy+C,MACA,IAEA,MADA,IAAAT,iBACA,EACG,MAAA3nE,GACH,UAMA,QAAAqoE,IAAAzrE,EAAAkH,GACA,MAAAwkE,KAAA1rE,EAAAwqE,IACAD,GAAAvqE,EAAAkH,GAEA8iE,GAAAhqE,EAAAkH,GAOA,QAAAykE,MACA,SAGA,QAAAC,IAAA5rE,EAAAkH,GAeA,QAAAugB,GAAAjpB,EAAA8B,EAAAoH,GACA,IAAA1H,EAAA20C,QAAA30C,EAAAkD,MAAA,gBAAA1E,GAEA,IACAA,EAAAkE,KAAAmsB,MAAArwB,GACO,MAAA6F,GAEP,MAAAqD,GAAArD,GAGAiB,MAAAC,QAAA/G,KACAA,IAAAkM,IAAA,SAAAyb,GACA,MAAAA,GAAA9iB,OAAA8iB,EAAA0lD,QACAxpB,EAAAl8B,GAEAA,KAIAnmB,EAAA20C,QACAm3B,GAAAttE,EAAA8B,GAEAoH,EAAA,KAAAlJ,EAAA8B,GAnCAN,EAAAuH,EAAAvH,EAEA,IAAA+rE,IACA5pE,OAAA,MACAnB,WACAkC,MAAA,EACAinE,aAAA,EACA33D,QAAA,IACAw5D,OAAA,EA+CA,OA5CAhsE,GAAAwqD,GAAAuhB,EAAA/rE,GA2BAA,EAAAkD,OACAlD,EAAA20C,SACA30C,EAAAgB,QAAAiqE,OAAA,oBAEAjrE,EAAAgB,QAAA,gBAAAhB,EAAAgB,QAAA,iBACA,oBAGAhB,EAAA20C,SACA30C,EAAA6hE,SAAA,KACA7hE,EAAAkD,MAAA,GAGAlD,EAAAmqE,cACAnqE,EAAAkD,MAAA,GAGAuoE,GAAAzrE,EAAA,SAAAoD,EAAAb,EAAAH,GAEA,GAAAgB,EACA,MAAA8D,GAAAm7C,EAAAj/C,GAGA,IAAAC,GACAutD,EAAAruD,EAAAvB,SAAAuB,EAAAvB,QAAA,gBACA8B,EAAAV,GAAAupE,IAIA,KAAA3rE,EAAA20C,SAAA30C,EAAAkD,OAAAlD,EAAAmqE,cACA,gBAAArnE,KACA,OAAAumB,KAAAunC,IACA,WAAmBvnC,KAAAvmB,IAAA,WAAmBumB,KAAAvmB,IACtC,IACAA,EAAAJ,KAAAmsB,MAAA/rB,EAAAiU,YACO,MAAA1S,IAGP9B,EAAA8nE,YAAA,KAAA9nE,EAAA8nE,WAAA,IACA5iD,EAAA3kB,EAAAP,EAAA2E,IAEA7D,EAAAg/C,EAAAv/C,GACAO,EAAA5B,OAAAc,EAAA8nE,WACAnjE,EAAA7D,MAKA,QAAA4oE,IAAA/7D,EAAAhJ,GAKA,GAAAglE,GAAAhhE,qBAAA4Z,UACA5Z,UAAA4Z,UAAAC,cAAA,GAEAonD,EAAAD,EAAAjpE,QAAA,gBAAAipE,EAAAjpE,QAAA,eACAmpE,EAAAF,EAAAjpE,QAAA,aACAopE,EAAAH,EAAAjpE,QAAA,aAIAqpE,EAAAH,IACAC,GAAAC,IAAA,QAAAn8D,EAAA/N,OAEA6pE,IAAA,SAAA97D,OAAA87D,MAEAO,EAAA,SAAAljD,KAAAnZ,EAAAlM,IAEA,KAAAuoE,IAAAD,IAAAN,GAAA,CACA,GAAAQ,GAAAt8D,EAAAlM,IAAAf,QAAA,SACAiN,GAAAlM,MAAAwoE,EAAA,mBAAA90D,KAAA+0D,MAGA,MAAAb,IAAA17D,EAAAhJ,GAMA,QAAAwlE,IAAAC,EAAA5pC,GACA,UAAAkb,IAAA,SAAA1yC,EAAAtE,GAOA,QAAA2lE,KACA3Q,IACA0Q,EAAA1jE,OAAA5I,KAAAonB,EAAAD,GAGA,QAAAk+C,OACAtgE,IAAAoB,EAEApD,EACA6D,EAAA7D,GAEAmI,IAGAshE,IAIA,QAAAplD,KACAw0C,IACAyJ,IAIA,QAAAl+C,GAAAslD,GACA7Q,IACA74D,KAAA0pE,EACApH,IAGA,QAAAmH,KACA,KAAA5Q,EAAAl5B,GAAA95B,EAAAzC,GACAomE,IAtCA,GAIAxpE,GAJA64D,EAAA,EACAhzD,EAAA,EACA7D,EAAA,EACAoB,EAAAmmE,EAAAzsE,MAuCA2sE,OAWA,QAAAE,IAAAl9D,GACA,GAAA45C,GAAA55C,EAAApH,KAAAoH,EAAApH,IAAAu6C,YACAyG,IAGA7rD,OAAA6M,KAAAg/C,GAAA56C,QAAA,SAAAspD,GACA,GAAApV,GAAA0G,EAAA0O,EACApV,GAAAjgD,KAAAwrD,GAAAvL,EAAAjgD,KAAAigD,EAAA6N,gBAIA,QAAAoc,IAAA3vE,GACA,iBAAAgsB,KAAAhsB,GACA,WAAAsP,mBAAAtP,EAAAY,MAAA,IAEA,UAAAorB,KAAAhsB,GACA,UAAAsP,mBAAAtP,EAAAY,MAAA,IAEA0O,mBAAAtP,GAGA,QAAA4vE,IAAAxkE,GACA,MAAAA,GAAAu6C,cAAAplD,OAAA6M,KAAAhC,EAAAu6C,cAIA/E,GAAA78C,IAAAxD,OAAA6M,KAAAhC,EAAAu6C,cAAAt4C,IAAA,SAAA/B,GACA,GAAAo2D,GAAAt2D,EAAAu6C,aAAAr6C,EACA,IAAAo2D,EAAAj8D,MAAA,gBAAAi8D,GAAAj8D,KACA,UAAAm7C,IAAA,SAAA1yC,GACA8jD,GAAA0P,EAAAj8D,KAAAyI,KACOlL,KAAA,SAAAkuD,GACPwQ,EAAAj8D,KAAAyrD,OATAtQ,GAAA1yC,UAeA,QAAA2hE,IAAAh9D,GACA,IAAAA,EAAAse,OACA,QAGA,IAAA2+C,GAAAzpB,EAAAxzC,EAAAse,QAAA2+C,QAEA,gBAAAA,GAAA,UAAAA,EAKA,QAAAC,IAAAtnE,EAAAoK,GAGA,GAAAg9D,GAAAh9D,GAAA,CACA,GAAAmxC,GAAAnxC,EAAApK,KAAA8mB,OAAA1c,EAAAse,OAAAtuB,OACA4F,GAAAoK,EAAAse,OAAA7hB,mBAAA00C,GAIA,GAAAuC,GAAAF,EAAA59C,IAGA89C,EAAAypB,MAAAzpB,EAAA0pB,YACA1pB,EAAA/rB,MAAgB01C,SAAA3pB,EAAAypB,KAAAC,SAAA1pB,EAAA0pB,UAKhB,IAAAngE,GAAAy2C,EAAA7jD,KAAAkE,QAAA,iBAAAmJ,MAAA,IAcA,OAVAw2C,GAAAn6B,GAAAtc,EAAAtG,MAEA+8C,EAAAn6B,GAAAxmB,QAAA,YACA2gD,EAAAn6B,GAAA9c,mBAAAi3C,EAAAn6B,KAKAm6B,EAAA7jD,KAAAoN,EAAA6D,KAAA,KAEA4yC,EAIA,QAAA4pB,IAAAt9D,EAAAnQ,GACA,MAAA0tE,IAAAv9D,IAAAuZ,GAAA,IAAA1pB,GAIA,QAAA0tE,IAAAv9D,EAAAnQ,GAGA,GAAA2tE,GAAAx9D,EAAAnQ,KAAA,MAIA,OAAAmQ,GAAAi9D,SAAA,MAAAj9D,EAAAy9D,MACAz9D,EAAA09D,KAAA,IAAA19D,EAAA09D,KAAA,IACA,IAAA19D,EAAAnQ,KAAA2tE,EAAA3tE,EAGA,QAAA8tE,IAAA7mC,GACA,UAAAppC,OAAA6M,KAAAu8B,GAAAt8B,IAAA,SAAA+J,GACA,MAAAA,GAAA,IAAA9H,mBAAAq6B,EAAAvyB,MACGzD,KAAA,KAIH,QAAA88D,IAAA59D,EAAAhJ,GAuBA,QAAA6mE,GAAAC,EAAAhuE,EAAAkH,GACA,GAAA+mE,GAAAD,EAAA/B,SACAtN,EAAAnU,GAAAjjD,EAAA2mE,GAAAD,EAAAjuE,EAEA,OADAmuE,IAAAxP,EAAAx8D,OAAA,IAAAw8D,EAAA36D,KACAqmD,EAAA+jB,MAAAzP,EAAAz3D,GAGA,QAAAmnE,GAAAL,EAAA99D,GACA,UAAA+tC,IAAA,SAAA1yC,EAAAtE,GACA8mE,EAAAC,EAAA99D,EAAA,SAAA9M,EAAAvC,GAEA,MAAAuC,GACA6D,EAAA7D,OAEAmI,GAAA1K,OAKA,QAAAytE,GAAAxoE,EAAAM,GACA,MAAA83C,GAAAp4C,EAAAQ,GAAA,SAAAtI,GACA6pE,IAAAxnE,KAAA,WACA,MAAA+F,GAAA/H,MAAArB,KAAAgB,KACO8N,MAAA,SAAAzH,GACP,GAAA6C,GAAAlJ,EAAA6I,KACAK,GAAA7C,QAOA,QAAAwjE,KAEA,GAAA33D,EAAAq+D,WAAAr+D,EAAAs+D,WACA,MAAAvwB,IAAA1yC,SAMA,IAAAkjE,EACA,MAAAA,EAGA,IAAAC,IAAuBvsE,OAAA,MAAA6B,IAAA2qE,EAuBvB,OAtBAF,GAAAJ,KAAiCK,GAAA5iE,MAAA,SAAA1I,GACjC,MAAAA,MAAA3B,QAAA,MAAA2B,EAAA3B,QAEAwgD,EAAA,uDACAosB,MAAgClsE,OAAA,MAAA6B,IAAA2qE,KAEhC1wB,GAAAh3C,OAAA7D,KAEK0I,MAAA,SAAA1I,GAIL,SAAAA,MAAA3B,QAAA,MAAA2B,EAAA3B,SAGAw8C,GAAAh3C,OAAA7D,KAGAqrE,EAAA3iE,MAAA,WACA2iE,EAAA,OAGAA,EAuSA,QAAAG,GAAAC,GACA,MAAAA,GAAAzhE,MAAA,KAAA1C,IAAAiC,oBAAAqE,KAAA,KAhYA,GAAAq5C,GAAArtD,KAEA2wE,EAAAP,GAAAl9D,EAAApK,KAAAoK,GACAy+D,EAAAnB,GAAAG,EAAA,GAEAz9D,GAAA3I,EAAA2I,EACA,IAAAg+D,GAAAh+D,EAAA+7D,QAEA,IAAA/7D,EAAA2nB,MAAA81C,EAAA91C,KAAA,CACA,GAAAi3C,GAAA5+D,EAAA2nB,MAAA81C,EAAA91C,KACA3iB,EAAA45D,EAAAvB,SAAA,IAAAuB,EAAAxB,SACArsE,EAAAsuD,GAAAjjC,SAAA3f,mBAAAuI,IACAg5D,GAAAltE,QAAAktE,EAAAltE,YACAktE,EAAAltE,QAAA+tE,cAAA,SAAA9tE,EAKAopD,EAAA+jB,MAAAnC,EAgCA,IAAAwC,EAyCA3nE,IAAA,WACAI,EAAA,KAAAmjD,KAGAA,EAAA3nC,KAAA,WACA,cAGA2nC,EAAAhtD,GAAAixE,EAAA,cAAApnE,GACA6mE,MAAiB5rE,OAAA,MAAA6B,IAAAypE,GAAAE,EAAA,KAAqC,SAAAvqE,EAAAgE,GACtD,GAAA4nE,GAAA5nE,KAAA+8C,KACA/8C,EAAA+8C,KAAAwpB,EAAAlkD,GAAA+jD,GAAAG,EAAA,GACAzmE,GAAA,KAAA8nE,OAIA3kB,EAAAjU,QAAAk4B,EAAA,mBAAAtuE,EAAAkH,GACAlH,EAAAgE,IAAAwpE,GAAAG,EAAA3tE,EAAAgE,KACA+pE,KAAc/tE,EAAAkH,KAKdmjD,EAAA4kB,QAAAX,EAAA,mBAAAp+D,EAAAhJ,GACA,kBAAAgJ,KACAhJ,EAAAgJ,EACAA,MAEAA,EAAA3I,EAAA2I,GACA69D,EAAA79D,GACAlM,IAAAwpE,GAAAG,EAAA,YACAxrE,OAAA,QACK,WACL,QAAA+sE,KACA7kB,EAAAptB,KAAA,SAAA75B,EAAAvC,GACAA,MAAAsuE,gBACAjoE,EAAA,MAA4BrE,IAAA,IAE5B2I,WAAA0jE,EAAAh/D,EAAAm2B,UAAA,OAKA6oC,QAIA7kB,EAAA5K,QAAAvB,EAAA,mBAAAhuC,EAAAhJ,GAGA,QAAAkoE,GAAA1nE,GACA,GAAAs/B,KACA92B,GAAA+0C,OACAje,EAAAie,MAAA,GAEA/0C,EAAAwkC,cAEA1N,EAAA0N,aAAA,GAEAxkC,EAAAu4C,SACAzhB,EAAAyhB,QAAA,GAEAslB,EAAA79D,GACAlM,IAAAwpE,GAAAG,EAAA,YAAAE,GAAA7mC,IACA7kC,OAAA,OACAC,MAAe8tB,KAAAhgB,EAAAggB,OACRxoB,GAGP,QAAA2nE,KAOA,QAAAC,GAAAC,GACA,gBAAAnsE,EAAAvC,GAEAuvC,EAAAm/B,GAAA1uE,EAAAuvC,UACAyP,IAAA2vB,GACAtoE,EAAA,MAA4BkpC,QAAA/nC,EAAA+nC,MAK5B,OAfA4pB,GAAAyV,GACAD,EAAAhmE,KAAA6a,KAAAnU,EAAAggB,KAAAhwB,OAAA85D,GACAna,EAAA,EACAzP,EAAA,GAAA9qC,OAAAkqE,GAYA7xE,EAAA,EAAqBA,EAAA6xE,EAAgB7xE,IAAA,CACrC,GAAA4sD,GAAAnhD,EAAA8G,GAAA,+BACAq6C,GAAA0hB,KAAAiC,EACA3jB,EAAAr6B,KAAAhgB,EAAAggB,KAAAjyB,MAAAN,EAAAq8D,EACAxwD,KAAAC,IAAAyG,EAAAggB,KAAAhwB,QAAAvC,EAAA,GAAAq8D,IACAva,EAAAzgD,EAAAurD,EAAA+kB,EAAA3xE,KA3CA,GAAAqB,GAAAhC,KAgDA2xE,EAAAlB,GAAAE,EAAA,IACA+B,EAAAC,GAAAhB,EAEA,kBAAAe,GAEAN,EAAA,SAAAhsE,EAAAvC,GAEAuC,GACAusE,GAAAhB,IAAA,EACA1sB,EACA7+C,EAAA3B,OACA,uEAGA4tE,MAEAM,GAAAhB,IAAA,EACAznE,EAAA,KAAArG,MAGK6uE,EAELN,EAAAloE,GAEAmoE,MAOAhlB,EAAA4U,MAAA,SAAA/3D,GACA2gE,IAAAxnE,KAAA,WACA0tE,MACA5rE,OAAA,MACA6B,IAAAwpE,GAAAG,EAAA,KACO,SAAAvqE,EAAAvC,GAEP,MAAAuC,GACA8D,EAAA9D,IAEAvC,EAAA8sE,KAAAH,GAAAG,EAAA,QACAzmE,GAAA,KAAArG,QAEKiL,MAAA5E,IAMLmjD,EAAArnD,IAAAsrE,EAAA,eAAAjxE,EAAA6S,EAAAhJ,GA8CA,QAAA0oE,GAAAnnE,GAUA,QAAAjI,GAAA23D,GACA,GAAApV,GAAA0G,EAAA0O,GACAp4D,EAAAitE,GAAAvkE,EAAA2Z,KAAA,IAAAwsD,EAAAzW,GACA,QAAA1vD,EAAA0a,IACA,OAAAkrD,GAAAn+D,GACA/N,OAAA,MACA6B,IAAAwpE,GAAAG,EAAA5tE,GACA40C,QAAA,IACSt0C,KAAA,SAAAqvD,GACT,MAAAx/C,GAAAykC,OACA+a,EAEA,GAAAzR,IAAA,SAAA1yC,GACA8jD,GAAAK,EAAAnkD,OAESlL,KAAA,SAAAyC,SACTigD,GAAAE,WACAF,GAAA7iD,OACA6iD,EAAAjgD,SA3BA,GAAA2mD,GAAAhhD,EAAAu6C,aACA6sB,EAAApmB,GAAA7rD,OAAA6M,KAAAg/C,EACA,IAAAA,GAAAomB,EAAA3vE,OAAA,CA6BA,GAAAysE,GAAAkD,EAAAnlE,IAAA,SAAAytD,GACA,kBACA,MAAA33D,GAAA23D,KAMA,OAAAuU,IAAAC,EAAA,IAGA,QAAAmD,GAAAC,GACA,MAAAzqE,OAAAC,QAAAwqE,GACA9xB,GAAA78C,IAAA2uE,EAAArlE,IAAA,SAAAjC,GACA,GAAAA,EAAA5F,GACA,MAAA+sE,GAAAnnE,EAAA5F,OAIA+sE,EAAAG,GA/FA,kBAAA7/D,KACAhJ,EAAAgJ,EACAA,MAEAA,EAAA3I,EAAA2I,EAGA,IAAA82B,KAEA92B,GAAA+0C,OACAje,EAAAie,MAAA,GAGA/0C,EAAA8/D,YACAhpC,EAAAgpC,WAAA,GAGA9/D,EAAAu4C,SACAzhB,EAAAyhB,QAAA,GAGAv4C,EAAAywC,YACA,QAAAzwC,EAAAywC,YACAzwC,EAAAywC,UAAAj+C,KAAAC,UAAAuN,EAAAywC,YAEA3Z,EAAA2Z,UAAAzwC,EAAAywC,WAGAzwC,EAAAmT,MACA2jB,EAAA3jB,IAAAnT,EAAAmT,KAGAnT,EAAA+iC,YACAjM,EAAAiM,UAAA/iC,EAAA+iC,WAGA51C,EAAA2vE,GAAA3vE,EAGA,IAAA2C,IACAmC,OAAA,MACA6B,IAAAwpE,GAAAG,EAAAtwE,EAAAwwE,GAAA7mC,IAyDAqnC,GAAAn+D,EAAAlQ,GAAAK,KAAA,SAAAQ,GACA,MAAAo9C,IAAA1yC,UAAAlL,KAAA,WACA,GAAA6P,EAAAwkC,YACA,MAAAo7B,GAAAjvE,KAEOR,KAAA,WACP6G,EAAA,KAAArG,OAEKiL,MAAA5E,KAILmjD,EAAA4lB,OAAA3B,EAAA,SACA,SAAA4B,EAAAC,EAAAjgE,EAAAhJ,GACA,GAAAuB,EACA,iBAAA0nE,IAEA1nE,GACA2Z,IAAA8tD,EACA/sD,KAAAgtD,GAEA,kBAAAjgE,KACAhJ,EAAAgJ,EACAA,QAIAzH,EAAAynE,EACA,kBAAAC,IACAjpE,EAAAipE,EACAjgE,OAEAhJ,EAAAgJ,EACAA,EAAAigE,GAIA,IAAA9sD,GAAA5a,EAAA0a,MAAAjT,EAAAmT,GAGA0qD,GAAA79D,GACA/N,OAAA,SACA6B,IAAAwpE,GAAAG,EAAAX,GAAAvkE,EAAA2Z,MAAA,QAAAiB,GACKnc,KAQLmjD,EAAA+lB,cACA9B,EAAA,yBAAAzgD,EAAAghD,EAAA3+D,EACAhJ,GACA,kBAAAgJ,KACAhJ,EAAAgJ,EACAA,KAEA,IAAA82B,GAAA92B,EAAAmT,IAAA,QAAAnT,EAAAmT,IAAA,GACArf,EAAAwpE,GAAAG,EAAAX,GAAAn/C,IAAA,IACA+gD,EAAAC,GAAA7nC,CACA+mC,GAAA79D,GACA/N,OAAA,MACA6B,MACA2wC,QAAA,GACKztC,KAILmjD,EAAAgmB,iBACA/B,EAAA,4BAAAzgD,EAAAghD,EAAAxrD,EACAnc,GAEA,GAAAlD,GAAAwpE,GAAAG,EAAAX,GAAAn/C,GAAA,IACA+gD,EAAAC,IAAA,QAAAxrD,CAEA0qD,OACA5rE,OAAA,SACA6B,OACKkD,KAMLmjD,EAAAimB,cACAhC,EAAA,yBAAAzgD,EAAAghD,EAAAxrD,EAAAqsC,EACAhtC,EAAAxb,GACA,kBAAAwb,KACAxb,EAAAwb,EACAA,EAAAgtC,EACAA,EAAArsC,EACAA,EAAA,KAEA,IAAAhmB,GAAA2vE,GAAAn/C,GAAA,IAAA+gD,EAAAC,GACA7qE,EAAAwpE,GAAAG,EAAAtwE,EAKA,IAJAgmB,IACArf,GAAA,QAAAqf,GAGA,gBAAAqsC,GAAA,CAEA,GAAA/a,EACA,KACAA,EAAA6Z,GAAAkB,GACO,MAAAtsD,GACP,MAAA8D,GAAAi7C,EAAAqO,GACA,4CAEAd,EAAA/a,EAAAyZ,GAAAzZ,EAAAjyB,GAAA,GAGA,GAAAxS,IACAlP,SAAgB4a,eAAA8G,GAChBvgB,OAAA,MACA6B,MACAmmE,aAAA,EACA/nE,KAAAstD,EACAl9C,QAAA07D,EAAA17D,SAAA,IAGAu7D,MAAc79D,EAAAhJ,KAKdmjD,EAAAqU,UAAA,SAAAlc,EAAAtyC,EAAAhJ,GAIAs7C,EAAAuQ,UAAA7iD,EAAA6iD,UAEA8U,IAAAxnE,KAAA,WACA,MAAA49C,IAAA78C,IAAAohD,EAAAtyB,KAAAxlB,IAAAuiE,OACK5sE,KAAA,WAEL0tE,EAAA79D,GACA/N,OAAA,OACA6B,IAAAwpE,GAAAG,EAAA,cACAn7D,QAAAtC,EAAAsC,QACApQ,KAAAogD,GACO,SAAAp/C,EAAAgtC,GACP,MAAAhtC,GACA8D,EAAA9D,IAEAgtC,EAAAvhC,QAAA,SAAAzH,GACAA,EAAAvE,IAAA,QAEAqE,GAAA,KAAAkpC,QAEKtkC,MAAA5E,IAKLmjD,EAAAkmB,KAAA,SAAA9nE,EAAAyH,EAAAhJ,GACA2gE,IAAAxnE,KAAA,WACA,MAAA4sE,IAAAxkE,KACKpI,KAAA,WAEL0tE,EAAA79D,GACA/N,OAAA,MACA6B,IAAAwpE,GAAAG,EAAAX,GAAAvkE,EAAA2Z,MACAhgB,KAAAqG,GACO,SAAArF,EAAAgE,GACP,MAAAhE,GACA8D,EAAA9D,OAEA8D,GAAA,KAAAE,OAEK0E,MAAA5E,IAMLmjD,EAAAzgC,QAAA0kD,EAAA,mBAAAp+D,EAAAhJ,GACA,kBAAAgJ,KACAhJ,EAAAgJ,EACAA,MAEAA,EAAA3I,EAAA2I,EAGA,IACA9N,GADA4kC,KAEA7kC,EAAA,KAEA+N,GAAA+iC,YACAjM,EAAAiM,WAAA,GAGA/iC,EAAAgzB,aACA8D,EAAA9D,YAAA,GAGAhzB,EAAA2Z,eACAmd,EAAAnd,cAAA,GAIA3Z,EAAAwkC,cACA1N,EAAA0N,aAAA,GAGAxkC,EAAAvH,MACAq+B,EAAAr+B,IAAAjG,KAAAC,UAAAuN,EAAAvH,MAGAuH,EAAAsgE,YACAtgE,EAAAE,SAAAF,EAAAsgE,WAGAtgE,EAAAE,WACA42B,EAAA52B,SAAA1N,KAAAC,UAAAuN,EAAAE,WAGAF,EAAAugE,UACAvgE,EAAAG,OAAAH,EAAAugE,SAGAvgE,EAAAG,SACA22B,EAAA32B,OAAA3N,KAAAC,UAAAuN,EAAAG,SAGA,mBAAAH,GAAAK,gBACAy2B,EAAAz2B,gBAAAL,EAAAK,eAGA,mBAAAL,GAAA6yB,QACAiE,EAAAjE,MAAA7yB,EAAA6yB,OAGA,mBAAA7yB,GAAA8yB,OACAgE,EAAAhE,KAAA9yB,EAAA8yB,KAGA,IAAA0tC,GAAA7C,GAAA7mC,EAEA,oBAAA92B,GAAAzF,OACAtI,EAAA,OACAC,GAAcqI,KAAAyF,EAAAzF,OAId4jE,EAAAn+D,GACA/N,SACA6B,IAAAwpE,GAAAG,EAAA,YAAA+C,GACAtuE,SACK/B,KAAA,SAAAQ,GACLqP,EAAA2Z,cAAA3Z,EAAAwkC,aAAAxkC,EAAAykC,QACA9zC,EAAA6O,KAAAb,QAAAk+D,IAEA7lE,EAAA,KAAArG,KACKiL,MAAA5E,KAMLmjD,EAAAiV,SAAA,SAAApvD,GAMA,GAAA8pD,GAAA,cAAA9pD,KAAAygE,WAAAz9B,EAEAhjC,GAAA3I,EAAA2I,GACAA,EAAAsC,QAAA,WAAAtC,KAAAsC,QACA,WAAA07D,KAAA17D,QACA,GAIA,IAEAgqD,GAFAx1B,EAAA92B,EAAAsC,SAAiCA,QAAAtC,EAAAsC,QAAA,QACjCuwB,EAAA,mBAAA7yB,GAAA6yB,OAAA7yB,EAAA6yB,KAGAy5B,GADA,eAAAtsD,GACAA,EAAAitD,cACK,cAAAjtD,KAELA,EAAAssD,UAKA,IAAAoU,GAAA7tC,CA+CA,IA7CA7yB,EAAAwU,QACAsiB,EAAAtiB,MAAAxU,EAAAwU,QAGAxU,EAAA2Z,cAAA3Z,EAAAQ,QAAA,kBAAAR,GAAAQ,UACAs2B,EAAAnd,cAAA,GAGA3Z,EAAAwkC,cACA1N,EAAA0N,aAAA,GAGAxkC,EAAA8sD,aACAh2B,EAAA6pC,KAAA,YAGA3gE,EAAA+iC,YACAjM,EAAAiM,WAAA,GAGA/iC,EAAAgzB,aACA8D,EAAA9D,YAAA,GAGA,aAAAhzB,GAEAA,EAAA4gE,YACA9pC,EAAA8pC,UAAA5gE,EAAA4gE,WAEK5gE,EAAA8sD,aAELh2B,EAAA8pC,UAAA,KAGA5gE,EAAAQ,QAAA,gBAAAR,GAAAQ,SACAs2B,EAAAt2B,OAAAR,EAAAQ,QAGAR,EAAAgS,MAAA,gBAAAhS,GAAAgS,OACA8kB,EAAAt2B,OAAA,QACAs2B,EAAA9kB,KAAAhS,EAAAgS,MAKAhS,EAAA2yC,cAAA,gBAAA3yC,GAAA2yC,aACA,OAAAkuB,KAAA7gE,GAAA2yC,aAEA3yC,EAAA2yC,aAAA/kD,eAAAizE,KACA/pC,EAAA+pC,GAAA7gE,EAAA2yC,aAAAkuB,GAKA,IACA3uE,GADAD,EAAA,KAGA+N,GAAA+sD,UAGAj2B,EAAAt2B,OAAA,WACAvO,EAAA,OACAC,GAAc66D,QAAA/sD,EAAA+sD,SAGd,IAAAuN,GACAwG,EAIAxwE,EAAA,SAAAyiC,EAAA/7B,GACA,IAAAgJ,EAAA+gE,QAAA,CAGAjqC,EAAA/D,QAGA,gBAAA+D,GAAA/D,QACA+D,EAAA/D,MAAAvgC,KAAAC,UAAAqkC,EAAA/D,QAGA/yB,EAAAgzB,WACAH,IACAiE,EAAAjE,MAAA6tC,GAGA5pC,EAAAjE,UAAA6tC,EAAA5W,EACAA,EAAA4W,CAIA,IAAAM,IACA/uE,SACA6B,IAAAwpE,GAAAG,EAAA,WAAAE,GAAA7mC,IACAx0B,QAAAtC,EAAAsC,QACApQ,OAEA4uE,GAAA/tC,EAGA/yB,EAAA+gE,SAKApJ,IAAAxnE,KAAA,WACAmqE,EAAAuD,EAAA79D,EAAAghE,EAAAhqE,KACO4E,MAAA5E,KAMPkpC,GAAmBA,YAEnB+gC,EAAA,SAAA/tE,EAAAvC,GACA,IAAAqP,EAAA+gE,QAAA,CAGA,GAAAG,GAAA,CAEA,IAAAvwE,KAAAuvC,QAAA,CACAghC,EAAAvwE,EAAAuvC,QAAAlwC,OACAkwC,EAAAwa,SAAA/pD,EAAA+pD,QAEA,IAAApI,KACAA,GAAA/1C,MAAAyD,EAAA2yC,aACAhiD,EAAAuvC,QAAAvvC,EAAAuvC,QAAA1/B,OAAA,SAAAjT,GACAmzE,GACA,IAAA7jD,GAAA41B,EAAAzyC,GAAAzS,EAUA,OATAsvB,KACA7c,EAAA2Z,cAAA3Z,EAAAwkC,aAAAxkC,EAAAykC,QACAo4B,GAAAtvE,GAEA++D,GACApsB,UAAA/qC,KAAA5H,GAEAyS,EAAAg5C,SAAAzrD,IAEAsvB,QAEO,IAAA3pB,EAKP,MAFA8M,GAAA+gE,SAAA,MACA/gE,GAAA4iC,SAAA1vC,EAMAvC,MAAA+pD,WACAomB,EAAAnwE,EAAA+pD,SAGA,IAAAymB,GAAAtuC,GAAA6tC,GAAA,GACA/vE,GAAAuwE,EAAApX,GACA9pD,EAAA,aAEAA,EAAA8sD,YAAAj6B,GAAA6tC,GAAA,IAAAS,EAKAnhE,EAAA4iC,SAAA,KAAA1C,GAHAtpC,GAAA,WAA8BtG,EAAAwwE,EAAAG,MAU9B,OAHA3wE,GAAA0P,EAAA+yB,OAAA,EAAAkuC,IAIA9pE,OAAA,WACA6I,EAAA+gE,SAAA,EACAzG,GACAA,EAAAF,WASAjgB,EAAAinB,SAAAhD,EAAA,oBAAA9rB,EAAAtyC,EAAAhJ,GAEA,kBAAAgJ,KACAhJ,EAAAgJ,EACAA,MAIA69D,EAAA79D,GACA/N,OAAA,OACA6B,IAAAwpE,GAAAG,EAAA,cACAvrE,KAAAogD,GACKt7C,KAGLmjD,EAAAkV,OAAA,SAAAr4D,GACAA,KAGAmjD,EAAA6V,SAAA,SAAAlgE,EAAAkH,GACA6mE,EAAA/tE,GACAgE,IAAAwpE,GAAAG,EAAA,IACAxrE,OAAA,UACK,SAAAiB,EAAA9C,GACL,MAAA8C,MAAA3B,QAAA,MAAA2B,EAAA3B,OACAyF,EAAA9D,OAEA8D,GAAA,KAAA5G,MAeA,QAAAutC,IAAA34B,EAAA44B,EAAAC,GAIA,IAHA,GAAAC,GAAA,GACAC,EAAAF,EAAA74B,EAAAhV,OAEA8tC,EAAA9tC,OAAA+tC,GACAD,GAAAF,CAEA,OAAAE,GAGA,QAAAl3B,IAAA5B,EAAA44B,EAAAC,GACA,GAAAC,GAAAH,GAAA34B,EAAA44B,EAAAC,EACA,OAAAC,GAAA94B,EAOA,QAAAlF,IAAA7R,EAAAC,GAEA,GAAAD,IAAAC,EACA,QAGAD,GAAAiZ,GAAAjZ,GACAC,EAAAgZ,GAAAhZ,EAEA,IAAAiZ,GAAAd,GAAApY,GACAmZ,EAAAf,GAAAnY,EACA,IAAAiZ,EAAAC,IAAA,EACA,MAAAD,GAAAC,CAEA,cAAAnZ,IACA,aACA,MAAAA,GAAAC,CACA,eACA,MAAAD,GAAAC,GAAA,GACA,cACA,MAAA+X,IAAAhY,EAAAC,GAEA,MAAAkH,OAAAC,QAAApH,GAAA+X,GAAA/X,EAAAC,GAAAgY,GAAAjY,EAAAC,GAKA,QAAAgZ,IAAAzO,GACA,aAAAA,IACA,gBACA,WACA,cACA,MAAAA,KAAA4O,KAAA5O,MAAA4O,MAAAC,MAAA7O,GACA,KAEAA,CACA,cACA,GAAA8O,GAAA9O,CACA,IAAArD,MAAAC,QAAAoD,GAAA,CACA,GAAAnC,GAAAmC,EAAAzI,MACAyI,GAAA,GAAArD,OAAAkB,EACA,QAAA7I,GAAA,EAAuBA,EAAA6I,EAAS7I,IAChCgL,EAAAhL,GAAAyZ,GAAAK,EAAA9Z,QAGO,IAAAgL,YAAA+O,MACP,MAAA/O,GAAAgP,QACO,WAAAhP,EAAA,CACPA,IACA,QAAA8L,KAAAgD,GACA,GAAAA,EAAA3Z,eAAA2W,GAAA,CACA,GAAAmD,GAAAH,EAAAhD,EACA,oBAAAmD,KACAjP,EAAA8L,GAAA2C,GAAAQ,OAMA,MAAAjP,GAGA,QAAAkM,IAAAlM,GACA,UAAAA,EACA,aAAAA,IACA,cACA,MAAAA,GAAA,GACA,cACA,MAAAmM,IAAAnM,EACA,cAMA,MAAAA,GACA1E,QAAA,gBACAA,QAAA,gBACAA,QAAA,eACA,cACA,GAAAsB,GAAAD,MAAAC,QAAAoD,GACAjE,EAAAa,EAAAoD,EAAA/K,OAAA6M,KAAA9B,GACAhL,GAAA,EACA6I,EAAA9B,EAAAxE,OACAkH,EAAA,EACA,IAAA7B,EACA,OAAA5H,EAAA6I,GACAY,GAAA2N,GAAArQ,EAAA/G,QAGA,QAAAA,EAAA6I,GAAA,CACA,GAAAwO,GAAAtQ,EAAA/G,EACAyJ,IAAA2N,GAAAC,GACAD,GAAApM,EAAAqM,IAGA,MAAA5N,GAGA,SAMA,QAAA2N,IAAApM,GACA,GAAA0M,GAAA,IAEA,OADA1M,GAAAyO,GAAAzO,GACA4N,GAAA5N,GAAAqO,GAAAnC,GAAAlM,GAAA0M,EAGA,QAAAJ,IAAAC,EAAAvX,GACA,GACAwX,GADAC,EAAAzX,EAEA0X,EAAA,MAAAH,EAAAvX,EACA,IAAA0X,EACAF,EAAA,EACAxX,QACG,CACH,GAAA2X,GAAA,MAAAJ,EAAAvX,EACAA,IACA,IAAA4X,GAAA,GACAC,EAAAN,EAAA/L,UAAAxL,IAAA8X,IACAC,EAAAC,SAAAH,EAAA,IAAAI,EAMA,KAJAN,IACAI,MAEA/X,GAAA8X,KACA,CACA,GAAAvM,GAAAgM,EAAAvX,EACA,WAAAuL,EACA,KAEAqM,IAAArM,EAEAvL,IAEA4X,IAAAnI,MAAA,KAEA+H,EADA,IAAAI,EAAArV,OACAyV,SAAAJ,EAAA,IAGAM,WAAAN,EAAA,OAAAA,EAAA,IAGAD,IACAH,GAAA,IAGA,IAAAO,IAIAP,EAAAU,WAAAV,EAAA,IAAAO,IAGA,OAAUP,MAAAjV,OAAAvC,EAAAyX,GAKV,QAAAvO,IAAAiP,EAAAC,GACA,GAAAvX,GAAAsX,EAAAjP,KAEA,IAAAkP,EAAA7V,OAAA,CACA,GAAA8V,GAAAD,IAAA7V,OAAA,EACA1B,KAAAwX,EAAA7L,UAEA4L,EAAAlP,MACAmP,EAAAD,IAAA7V,OAAA,GAEA,IAAAiK,GAAA6L,EAAA7L,QACA8L,EAAAD,EAAAzG,KACA,IAAAjK,MAAAC,QAAA4E,GACAA,EAAA9E,KAAA7G,OACK,IAAAyX,IAAAH,EAAA5V,OAAA,GACL,GAAAyI,GAAAmN,EAAAjP,KACAsD,GAAAxB,GAAAnK,MAEAsX,GAAAzQ,KAAA7G,IAKA,QAAAqZ,IAAA3C,GAMA,IALA,GAAAY,MACAC,KACApY,EAAA,IAGA,CACA,GAAA4Y,GAAArB,EAAAvX,IACA,WAAA4Y,EAQA,OAAAA,GACA,QACAT,EAAAzQ,KAAA,KACA,MACA,SACAyQ,EAAAzQ,KAAA,MAAA6P,EAAAvX,IACAA,GACA,MACA,SACA,GAAAma,GAAA7C,GAAAC,EAAAvX,EACAmY,GAAAzQ,KAAAyS,EAAA3C,KACAxX,GAAAma,EAAA5X,MACA,MACA,SAGA,IAFA,GAAA6X,GAAA,KAEA,CACA,GAAA7O,GAAAgM,EAAAvX,EACA,WAAAuL,EACA,KAEA6O,IAAA7O,EACAvL,IAIAoa,IAAA9T,QAAA,sBACAA,QAAA,qBACAA,QAAA,qBACA6R,EAAAzQ,KAAA0S,EACA,MACA,SACA,GAAAC,IAA4B7N,WAAAoF,MAAAuG,EAAA5V,OAC5B4V,GAAAzQ,KAAA2S,EAAA7N,SACA4L,EAAA1Q,KAAA2S,EACA,MACA,SACA,GAAAC,IAA0B9N,WAAYoF,MAAAuG,EAAA5V,OACtC4V,GAAAzQ,KAAA4S,EAAA9N,SACA4L,EAAA1Q,KAAA4S,EACA,MAEA,SACA,SAAAzU,OACA,4DACA+S,OArDA,CACA,OAAAT,EAAA5V,OACA,MAAA4V,GAAAjP,KAEAA,IAAAiP,EAAAC,KAsDA,QAAAG,IAAA/X,EAAAC,GAEA,OADAoI,GAAAgD,KAAAC,IAAAtL,EAAA+B,OAAA9B,EAAA8B,QACAvC,EAAA,EAAiBA,EAAA6I,EAAS7I,IAAA,CAC1B,GAAAgQ,GAAAqC,GAAA7R,EAAAR,GAAAS,EAAAT,GACA,QAAAgQ,EACA,MAAAA,GAGA,MAAAxP,GAAA+B,SAAA9B,EAAA8B,OAAA,EACA/B,EAAA+B,OAAA9B,EAAA8B,OAAA,KAEA,QAAAiW,IAAAhY,EAAAC,GAIA,MAAAD,KAAAC,EAAA,EAAAD,EAAAC,EAAA,KAEA,QAAAgY,IAAAjY,EAAAC,GAGA,OAFAiY,GAAAzY,OAAA6M,KAAAtM,GAAAmY,EAAA1Y,OAAA6M,KAAArM,GACAoI,EAAAgD,KAAAC,IAAA4M,EAAAnW,OAAAoW,EAAApW,QACAvC,EAAA,EAAiBA,EAAA6I,EAAS7I,IAAA,CAE1B,GAAAgQ,GAAAqC,GAAAqG,EAAA1Y,GAAA2Y,EAAA3Y,GACA,QAAAgQ,EACA,MAAAA,EAIA,IADAA,EAAAqC,GAAA7R,EAAAkY,EAAA1Y,IAAAS,EAAAkY,EAAA3Y,KACA,IAAAgQ,EACA,MAAAA,GAIA,MAAA0I,GAAAnW,SAAAoW,EAAApW,OAAA,EACAmW,EAAAnW,OAAAoW,EAAApW,OAAA,KAMA,QAAAqW,IAAAC,GACA,GAAAnZ,IAAA,sCACAoZ,EAAApZ,EAAA4F,cAAAuT,GAEA,QAAAC,EACA,OAAAD,EACA,EAEAlR,MAAAC,QAAAiR,GACA,EAEAC,EAAA,EAAAA,EAAA,EAAAA,EAAA,EAGAnR,MAAAC,QAAAiR,GACA,EADA,OAUA,QAAA1B,IAAAK,GAEA,OAAAA,EACA,SAKA,IAAAuB,GAAAvB,EAAAwB,gBAAAvJ,MAAA,QACAsI,EAAAC,SAAAe,EAAA,OAEApB,EAAAH,EAAA,EAEA/N,EAAAkO,EAAA,QAIAsB,GAAAtB,GAAAI,KAAAE,GACAiB,EAAAC,GAAA,EAAAC,WAAA,IAAAtB,GAEArO,IAAA4P,GAAAH,CAGA,IAAAI,GAAAzN,KAAAuG,IAAA8F,WAAAa,EAAA,IAEApB,KACA2B,EAAA,GAAAA,EAGA,IAAAC,GAAAD,EAAAE,QAAA,GAOA,OAJAD,KAAAjT,QAAA,aAEAmD,GAAA4P,GAAAE,EAUA,QAAAq6D,MACAv0E,KAAA+J,QAAA,GAAAk3C,IAAA,SAAAj3C,GAAwDA,MAcxD,QAAA+uC,IAAA7lC,GACA,GAUAshE,GAVA7iC,EAAAz+B,EAAAuZ,GACAxH,EAAA/R,EAAA+R,SACA2sB,EAAA1+B,EAAAxF,IACAmkC,EAAA3+B,EAAAyjB,OACAmb,EAAA5+B,EAAA4+B,UAGAE,EAAAJ,EAAA73B,YAAA83B,KAAA93B,YACA,WAGA,KAAA+3B,IAEA0iC,EAAA7iC,EAAAM,aAAAN,EAAAM,iBACAuiC,EAAAxiC,IACA,MAAAwiC,GAAAxiC,EAIA,IAAAyiC,GAAA9iC,EAAA1R,OAAA58B,KAAA,SAAA48B,GAOA,QAAAkS,GAAA1mC,GACAA,EAAA0Z,MAAA1Z,EAAA0Z,SACA,IAAAitB,GAAAntB,CACAmtB,GAAAnsC,QAAA,YACAmsC,EAAAntB,EAAA,IAAAA,EAEA,IAAAotB,GAAA5mC,EAAA0Z,MAAAitB,GAAA3mC,EAAA0Z,MAAAitB,MAEA,KAAAC,EAAAC,GAIA,MADAD,GAAAC,IAAA,EACA7mC,EAjBA,GAAA6mC,GAAArS,EAAAsS,QAAA,YACAT,EAAA,OAAAwhB,GAAAthB,GAkBA,OAAAxlB,GAAAmlB,EAAA,iBAAAQ,GAAA9uC,KAAA,WACA,MAAAsuC,GAAAa,0BAAAF,GAAAjvC,KAAA,SAAAQ,GACA,GAAA4oB,GAAA5oB,EAAA4oB,EACAA,GAAAgmB,iBAAA,CACA,IAAAvtB,IACApc,KAAAwpC,EACA7lB,KACAklB,WACAe,QAAAf,EAAAe,QACAd,SACAC,YAEA,OAAA3sB,GAAAuH,GAAAzmB,IAAA,kBAAA8I,MAAA,SAAA1I,GAEA,SAAAA,EAAA3B,OACA,KAAA2B,KAES/C,KAAA,SAAAsvC,GAOT,MANAztB,GAAA0tB,IAAAD,IAAAC,IAAA,EACA4hC,GACAtvD,EAAAuH,GAAAtjB,KAAA,6BACAqrE,GAAAxiC,KAGA9sB,SASA,OAHAsvD,KACAA,EAAAxiC,GAAAyiC,GAEAA,EAGA,QAAA5hC,IAAA9pC,GACA/I,KAAAyE,OAAA,IACAzE,KAAA8I,KAAA,oBACA9I,KAAA+I,UACA/I,KAAAqG,OAAA,CACA,KACAG,MAAAqC,kBAAA7I,KAAA6yC,IACG,MAAAxrC,KAKH,QAAAyrC,IAAA/pC,GACA/I,KAAAyE,OAAA,IACAzE,KAAA8I,KAAA,YACA9I,KAAA+I,UACA/I,KAAAqG,OAAA,CACA,KACAG,MAAAqC,kBAAA7I,KAAA8yC,IACG,MAAAzrC,KAKH,QAAAqtE,IAAA3rE,GACA/I,KAAAyE,OAAA,IACAzE,KAAA8I,KAAA,gBACA9I,KAAA+I,UACA/I,KAAAqG,OAAA,CACA,KACAG,MAAAqC,kBAAA7I,KAAA00E,IACG,MAAArtE,KAKH,QAAAstE,IAAA7rE,GACA,GAAAC,GAAA,WAAAD,EACA,8DAEA,WAAA4rE,IAAA3rE,GAGA,QAAA6rE,IAAA3pD,GAEA,OADA7gB,GAAA,EACAzJ,EAAA,EAAA6I,EAAAyhB,EAAA/nB,OAAsCvC,EAAA6I,EAAS7I,IAAA,CAC/C,GAAAwX,GAAA8S,EAAAtqB,EACA,oBAAAwX,GAAA,CACA,IAAA7P,MAAAC,QAAA4P,GAcA,KAAAw8D,IAAA,OAZAvqE,GAAA,gBAAAA,QACA,QAAA+Z,GAAA,EAAAC,EAAAjM,EAAAjV,OAA0CihB,EAAAC,EAAUD,IAAA,CACpD,GAAA0wD,GAAA18D,EAAAgM,EACA,oBAAA0wD,GACA,KAAAF,IAAA,OACW,oBAAAvqE,GAAA+Z,GACX/Z,EAAA/B,KAAAwsE,GAEAzqE,EAAA+Z,IAAA0wD,OAMK,gBAAAzqE,GACLA,GAAA+N,EAEA/N,EAAA,IAAA+N,EAGA,MAAA/N,GAOA,QAAA0qE,IAAAprE,EAAA6M,GACA,MAAAs1C,IACA,WAAAniD,EAAAzC,QAAA,QAAgC,UAEhCsP,OACAq+D,OACAjnE,IAAAonE,GACAxsE,WACAoS,YAKA,QAAAhQ,IAAAZ,EAAAG,GAYA,MAXAA,IACAH,EAAA1G,KAAA,SAAAQ,GACAiG,GAAA,WACAI,EAAA,KAAArG,MAEK,SAAA6E,GACLoB,GAAA,WACAI,EAAAxB,OAIAqB,EAGA,QAAAU,IAAArB,GACA,MAAAE,IAAA,SAAAtI,GACA,GAAA0J,GAAA1J,EAAA6I,MACAE,EAAAX,EAAA/H,MAAArB,KAAAgB,EAIA,OAHA,kBAAA0J,IACAC,GAAAZ,EAAAW,GAEAX,IAKA,QAAAyZ,IAAAzZ,EAAAirE,GACA,MAAAjrE,GAAA1G,KAAA,SAAAQ,GACA,MAAAmxE,KAAA3xE,KAAA;AACA,MAAAQ,MAEG,SAAA6E,GACH,MAAAssE,KAAA3xE,KAAA,WACA,KAAAqF,OAKA,QAAAgb,IAAArO,EAAAsO,GACA,kBACA,GAAA3iB,GAAAiC,UACA2gB,EAAA5jB,IACA,OAAAqV,GAAAwO,IAAA,WACA,MAAAF,GAAAtiB,MAAAuiB,EAAA5iB,MAOA,QAAAwM,IAAA9F,GACA,GAAAutE,GAAA,GAAA/U,IAAAx4D,GACA0C,EAAA,GAAA9B,OAAA2sE,EAAAv0B,MACAnuC,GAAA,CAIA,OAHA0iE,GAAApjE,QAAA,SAAAtP,GACA6H,IAAAmI,GAAAhQ,IAEA6H,EAGA,QAAA8qE,IAAAxnE,GACA,GAAAtD,GAAA,GAAA9B,OAAAoF,EAAAgzC,MACAnuC,GAAA,CAIA,OAHA7E,GAAAmE,QAAA,SAAAtP,EAAAoJ,GACAvB,IAAAmI,GAAA5G,IAEAvB,EAOA,QAAA2oC,IAAAjqC,GAGA,MAAAA,GAAA7C,QAAA,WAAA6C,OAAAsH,MAAA,KAGA,QAAA4iC,IAAA3e,GAGA,WAAAA,EAAAnxB,QAAA,MAAAmpB,KAAAgI,EAAA,GAAAhO,KAGA,QAAAitB,IAAA7mB,EAAAplB,GACA,IACAolB,EAAAlW,KAAA,QAAAlP,GACG,MAAAjB,GACHu+C,EAAA,QACA,qMAIAA,EAAA,QAAAt9C,IAGA,QAAA8tE,IAAA1oD,EAAArjB,EAAAqC,GAGA,IACArC,EAAAqC,GACG,MAAApE,GACHisC,GAAA7mB,EAAAplB,IAIA,QAAA+tE,IAAA3oD,EAAArjB,EAAAqE,EAAAwd,EAAAoqD,GAKA,IACA,OAAYtxD,OAAA3a,EAAAqE,EAAAwd,EAAAoqD,IACT,MAAAhuE,GAEH,MADAisC,IAAA7mB,EAAAplB,IACYhB,MAAAgB,IAIZ,QAAA4rC,IAAAz5B,EAAA0V,GACA,GAAAgkB,GAAAlgC,GAAAwG,EAAA7N,IAAAujB,EAAAvjB,IACA,YAAAunC,IAAAlgC,GAAAwG,EAAAjX,MAAA2sB,EAAA3sB,OAGA,QAAA4wC,IAAAC,EAAArN,EAAAC,GAEA,MADAA,MAAA,EACA,gBAAAD,GACAqN,EAAAnyC,MAAA+kC,EAAAD,EAAAC,GACGA,EAAA,EACHoN,EAAAnyC,MAAA+kC,GAEAoN,EAGA,QAAAC,IAAAxgC,GACA,GAAA+H,GAAA/H,EAAAtQ,MAGAsuB,EAAAjW,GAAA,gBAAAA,MAAAwK,KAAAvS,EAAAxS,EACA,OAAAwwB,GAGA,QAAAykD,IAAAzxE,GACAA,EAAA6O,KAAAb,QAAA,SAAAgB,GACA,GAAA45C,GAAA55C,EAAApH,KAAAoH,EAAApH,IAAAu6C,YACAyG,IAGA7rD,OAAA6M,KAAAg/C,GAAA56C,QAAA,SAAAspD,GACA,GAAApV,GAAA0G,EAAA0O,EACA1O,GAAA0O,GAAAr1D,KAAAwrD,GAAAvL,EAAAjgD,KAAAigD,EAAA6N,kBAKA,QAAA2hB,IAAAriE,GACA,gBAAArP,GAIA,MAHAqP,GAAA2Z,cAAA3Z,EAAAwkC,aAAAxkC,EAAAykC,QACA29B,GAAAzxE,GAEAA,GAkCA,QAAA2xE,IAAAC,EAAAviE,EAAA82B,EAAA0rC,GAEA,GAAA96D,GAAA1H,EAAAuiE,EACA,oBAAA76D,KACA86D,IACA96D,EAAAjL,mBAAAjK,KAAAC,UAAAiV,KAEAovB,EAAA3hC,KAAAotE,EAAA,IAAA76D,IAIA,QAAA+6D,IAAAC,GACA,sBAAAA,GAAA,CACA,GAAAC,GAAAvhE,OAAAshE,EAEA,OAAAp7D,OAAAq7D,QAAAl9D,SAAAi9D,EAAA,IAGAA,EAFAC,GAOA,QAAAC,IAAA5iE,GAIA,MAHAA,GAAA0gC,YAAA+hC,GAAAziE,EAAA0gC,aACA1gC,EAAA6yB,MAAA4vC,GAAAziE,EAAA6yB,OACA7yB,EAAA8yB,KAAA2vC,GAAAziE,EAAA8yB,MACA9yB,EAGA,QAAA6iE,IAAAC,GACA,GAAAA,EAAA,CACA,mBAAAA,GACA,UAAAnjC,IAAA,+BACAmjC,EAAA,IAEA,IAAAA,EAAA,EACA,UAAAnjC,IAAA,wCACAmjC,EAAA,MAKA,QAAAxiC,IAAAxwC,EAAAoG,GACA,GAAAqqC,GAAAzwC,EAAAkjC,WAAA,oBACAwN,EAAA1wC,EAAAkjC,WAAA,mBAEA,uBAAAljC,GAAAywC,IACA,mBAAAzwC,GAAA0wC,IACA1gC,GAAAhQ,EAAAywC,GAAAzwC,EAAA0wC,IAAA,EACA,SAAAb,IAAA,kGAEG,IAAAzpC,EAAAutB,QAAA3zB,EAAA2zB,UAAA,GACH,GAAA3zB,EAAA6pB,aACA,SAAAgmB,IAAA,4CACK,IAAA7vC,EAAAyK,MAAAzK,EAAAyK,KAAAvK,OAAA,IACLF,EAAA2wC,QAAA3wC,EAAA4wC,YACA,SAAAf,IAAA,8DAIA,8BAAAhhC,QAAA,SAAAokE,GACA,GAAA5vE,GAAA0vE,GAAA/yE,EAAAizE,GACA,IAAA5vE,EACA,KAAAA,KAKA,QAAA6vE,IAAAzpD,EAAArjB,EAAA8J,GAEA,GACA9N,GADA4kC,KAEA7kC,EAAA,KA6BA,IAvBAqwE,GAAA,SAAAtiE,EAAA82B,GACAwrC,GAAA,eAAAtiE,EAAA82B,GACAwrC,GAAA,cAAAtiE,EAAA82B,GACAwrC,GAAA,QAAAtiE,EAAA82B,GACAwrC,GAAA,aAAAtiE,EAAA82B,GACAwrC,GAAA,QAAAtiE,EAAA82B,GACAwrC,GAAA,cAAAtiE,EAAA82B,GACAwrC,GAAA,OAAAtiE,EAAA82B,GACAwrC,GAAA,QAAAtiE,EAAA82B,GACAwrC,GAAA,YAAAtiE,EAAA82B,GACAwrC,GAAA,WAAAtiE,EAAA82B,GAAA,GACAwrC,GAAA,YAAAtiE,EAAA82B,GAAA,GACAwrC,GAAA,SAAAtiE,EAAA82B,GAAA,GACAwrC,GAAA,UAAAtiE,EAAA82B,GAAA,GACAwrC,GAAA,gBAAAtiE,EAAA82B,GACAwrC,GAAA,MAAAtiE,EAAA82B,GAAA,GAGAA,IAAAh2B,KAAA,KACAg2B,EAAA,KAAAA,EAAA,OAAAA,EAIA,mBAAA92B,GAAAzF,KAAA,CACA,GAAA0oE,GAAA,IAIAC,EACA,QAAAzmE,mBAAAjK,KAAAC,UAAAuN,EAAAzF,MACA2oE,GAAAlzE,OAAA8mC,EAAA9mC,OAAA,GAAAizE,EAGAnsC,IAAA,MAAAA,EAAA,YAAAosC,GAEAjxE,EAAA,OACA,gBAAAiE,GACAhE,GAAgBqI,KAAAyF,EAAAzF,MAEhBrE,EAAAqE,KAAAyF,EAAAzF,MAMA,mBAAArE,GAAA,CACA,GAAA+G,GAAA4iC,GAAA3pC,EACA,OAAAqjB,GAAA2sB,SACAj0C,SACA6B,IAAA,WAAAmJ,EAAA,aAAAA,EAAA,GAAA65B,EACA5kC,SACK/B,KAAAkyE,GAAAriE,IAYL,MARA9N,SACAxE,OAAA6M,KAAArE,GAAAyI,QAAA,SAAAlG,GACArD,MAAAC,QAAAa,EAAAuC,IACAvG,EAAAuG,GAAAvC,EAAAuC,GAEAvG,EAAAuG,GAAAvC,EAAAuC,GAAAoO,aAGA0S,EAAA2sB,SACAj0C,OAAA,OACA6B,IAAA,aAAAgjC,EACA5kC,SACG/B,KAAAkyE,GAAAriE,IAMH,QAAAmjE,IAAA5pD,EAAArjB,EAAA8J,GACA,UAAA+tC,IAAA,SAAA1yC,EAAAtE,GACAwiB,EAAA6pD,OAAAltE,EAAA8J,EAAA,SAAA9M,EAAAvC,GACA,MAAAuC,GACA6D,EAAA7D,OAEAmI,GAAA1K,OAQA,QAAA0yE,IAAA9pD,GACA,UAAAw0B,IAAA,SAAA1yC,EAAAtE,GACAwiB,EAAA+pD,aAAA,SAAApwE,EAAAvC,GACA,MAAAuC,GACA6D,EAAA7D,OAEAmI,GAAA1K,OAKA,QAAAgwC,IAAAtxC,GACA,gBAAAmG,GAEA,SAAAA,EAAAjE,OACA,MAAAlC,EAEA,MAAAmG,IAQA,QAAAqrC,IAAAljB,EAAA3L,EAAA8uB,GAOA,QAAAC,KACA,MAAAjB,IAAA3e,GAGA4sB,GAAA1yC,QAAA2lC,GAEAhvB,EAAAuH,GAAAzmB,IAAAmuC,GAAArlC,MAAA+kC,GAAAK,IAGA,QAAAE,GAAAC,GACA,MAAAA,GAAA5mC,KAAAvK,OAIAgiB,EAAAuH,GAAAG,SACAnf,KAAA4mC,EAAA5mC,KACAof,cAAA,IAJAo0B,GAAA1yC,SAAqCmE,UAQrC,QAAA+jE,GAAApiC,EAAAE,GAIA,OAHAC,MACAkiC,EAAA,GAAAxW,IAEAv/D,EAAA,EAAA6I,EAAA+qC,EAAA7hC,KAAAxP,OAAgDvC,EAAA6I,EAAS7I,IAAA,CACzD,GAAAkS,GAAA0hC,EAAA7hC,KAAA/R,GACA8K,EAAAoH,EAAApH,GACA,IAAAA,IAGA+oC,EAAAnsC,KAAAoD,GACAirE,EAAA7yD,IAAApY,EAAA2Z,KACA3Z,EAAAipC,UAAAC,EAAA/V,IAAAnzB,EAAA2Z,MACA3Z,EAAAipC,UAAA,CACA,GAAAE,GAAAD,EAAA3uC,IAAAyF,EAAA2Z,IACA,UAAAwvB,KACAnpC,EAAAlJ,MAAAqyC,EAAAryC,QAIA,GAAAsyC,GAAAqgC,GAAAvgC,EAiBA,OAhBAE,GAAAhjC,QAAA,SAAAlG,GACA,IAAA+qE,EAAA93C,IAAAjzB,GAAA,CAEA,GAAAmpC,IACA1vB,IAAAzZ,GAEAipC,EAAAD,EAAA3uC,IAAA2F,EACA,UAAAipC,KACAE,EAAAvyC,MAAAqyC,EAAAryC,OAEAiyC,EAAAnsC,KAAAysC,MAGAT,EAAA5mC,KAAAD,GAAAqnC,EAAAvzC,OAAA+yC,EAAA5mC,OACA+mC,EAAAnsC,KAAAgsC,GAEAG,EA/DA,GAAAL,GAAA,cAAAtjB,EACAqjB,GAAwB9uB,IAAA+uB,EAAA1mC,SACxBsnC,EAAAf,EAAAhuC,IAAA6qB,GACA8jB,EAAAI,EAAA,GACA1gB,EAAA0gB,EAAA,EA8DA,OAAAd,KAAA5wC,KAAA,SAAAgxC,GACA,MAAAD,GAAAC,GAAAhxC,KAAA,SAAAkxC,GACA,MAAAkiC,GAAApiC,EAAAE,OAOA,QAAAS,IAAA9vB,EAAA8uB,EAAApB,GACA,GAAAqC,GAAA,gBACA,OAAA/vB,GAAAuH,GAAAzmB,IAAAivC,GACAnmC,MAAA+kC,IAAqBzuB,IAAA6vB,EAAArC,IAAA,KACrBvvC,KAAA,SAAAsvC,GACA,GAAAuC,GAAAggC,GAAAlhC,EACA,OAAAiN,IAAA78C,IAAA8wC,EAAAxnC,IAAA,SAAAmjB,GACA,MAAAkjB,IAAAljB,EAAA3L,EAAA8uB,MACK3wC,KAAA,SAAA8xC,GACL,GAAAC,GAAA/pC,EAAA8pC,EAIA,OAHAxC,GAAAC,MACAwC,EAAA/sC,KAAAsqC,GAEAztB,EAAAuH,GAAA4oB,UAA+BniB,KAAAkiB,QAK/B,QAAAE,IAAApwB,GACA,GAAAD,GAAA,gBAAAC,OAAApc,KACAuM,EAAAkgC,GAAAtwB,EAIA,OAHA5P,KACAA,EAAAkgC,GAAAtwB,GAAA,GAAAsvD,KAEAl/D,EAGA,QAAAogC,IAAAvwB,GACA,MAAAxB,IAAA4xB,GAAApwB,GAAA,WACA,MAAAwwB,IAAAxwB,OAIA,QAAAwwB,IAAAxwB,GAKA,QAAA3O,GAAA5K,EAAApJ,GACA,GAAAwhB,IAAkB1jB,GAAAoL,EAAA2Z,IAAAzZ,IAAAyO,GAAAzO,GAGlB,oBAAApJ,IAAA,OAAAA,IACAwhB,EAAAxhB,MAAA6X,GAAA7X,IAEAozC,EAAAttC,KAAA0b,GAgBA,QAAA6xB,GAAA5B,EAAApB,GACA,kBACA,MAAAoC,IAAA9vB,EAAA8uB,EAAApB,IAMA,QAAAoD,KACA,MAAA9wB,GAAAysB,SAAAtd,SACA4hB,WAAA,EACAppB,cAAA,EACAnF,MAAA,WACAue,MAAA4P,EACA9P,MAAA4wC,KACKtzE,KAAAigD,GAGL,QAAAA,GAAA/9C,GACA,GAAA6tC,GAAA7tC,EAAA6tC,OACA,IAAAA,EAAAlwC,OAAA,CAGA,GAAA8wC,GAAA4iC,EAAAxjC,EAEA,IADA/9B,EAAAwO,IAAA+xB,EAAA5B,EAAA6B,MACAzC,EAAAlwC,OAAAyzE,IAGA,MAAA3gC,MAGA,QAAA4gC,GAAAxjC,GAEA,OADAY,GAAA,GAAA+P,IACApjD,EAAA,EAAA6I,EAAA4pC,EAAAlwC,OAAyCvC,EAAA6I,EAAS7I,IAAA,CAClD,GAAAw1C,GAAA/C,EAAAzyC,EACA,UAAAw1C,EAAA1qC,IAAA2Z,IAAA,IACAuwB,KACAlqC,EAAA0qC,EAAA1qC,IAEAA,EAAAipC,UACAygC,GAAAjwD,EAAAysB,SAAAC,EAAAnmC,GAEAkqC,EAAAhlC,KAAAsiC,GAEA,IAAA0B,GAAAkiC,EAAAlhC,EACA3B,GAAArjB,IAAAwlB,EAAA1qC,IAAA2Z,KACAuvB,EACAwB,EAAA9hB,UAGAwhB,EAAAM,EAAAvD,IAEA,MAAAoB,GAGA,QAAA6iC,GAAAlhC,GAGA,OADAS,GADAzB,EAAA,GAAAoP,IAEApjD,EAAA,EAAA6I,EAAAmsC,EAAAzyC,OAA4CvC,EAAA6I,EAAS7I,IAAA,CACrD,GAAAm2E,GAAAnhC,EAAAh1C,GACA21C,GAAAwgC,EAAAnrE,IAAAmrE,EAAAz2E,GACAM,GAAA,OAAAqS,GAAA8jE,EAAAnrE,IAAAyqC,IACAE,EAAAjuC,KAAA1H,GAEAg0C,EAAAhkB,IAAA5Y,GAAAu+B,GAAAwgC,GACA1gC,EAAA0gC,EAAAnrE,IAEA,MAAAgpC,GA7FA,GAAAgB,GACAlqC,EAYAmmC,CAEA,sBAAA1sB,GAAA0sB,QAAA,IAAA1sB,EAAA0sB,OAAA1uC,OAAA,CACA,GAAA6zE,GAAA7xD,EAAA0sB,MACAA,GAAA,SAAAnmC,GACA,MAAAsrE,GAAAtrE,EAAA8K,QAGAq7B,GAAAkjC,GAAA5vD,EAAA0sB,OAAA73B,WAAAxD,EAGA,IAAAs/B,GAAA3wB,EAAA0tB,KAAA,EAQAv9B,EAAA,GAAAk/D,GAgEA,OAAAv+B,KAAA3yC,KAAA,WACA,MAAAgS,GAAA0gC,WACG1yC,KAAA,WACH6hB,EAAA0tB,IAAAiD,IAIA,QAAAW,IAAAtxB,EAAAkuB,EAAApwC,GACA,IAAAA,EAAA4wC,mBACA5wC,GAAA4wC,WAGA,IAEA/B,GAFA4E,EAAAzzC,EAAA2wC,OAAA3wC,EAAA4wC,WAIA/B,GADAmlC,GAAA9xD,EAAA2sB,WACAmlC,GAAA9xD,EAAA2sB,WAEAijC,GAAA5vD,EAAA2sB,UAAA93B,WAGA,IAAA28B,MACAC,EAAAn8B,MAAAxX,EAAA4wC,aAAAt/B,OAAA2iE,kBACAj0E,EAAA4wC,WACAR,GAAAvhC,QAAA,SAAAxK,GACA,GAAAuvC,GAAAF,IAAAxzC,OAAA,GACAg0E,EAAAzgC,EAAApvC,EAAAsE,IAAA,IAOA,OAJA8qC,IAAAnuC,MAAAC,QAAA2uE,KACAA,IAAAj2E,MAAA,EAAA01C,IAGAC,GAAA,IAAA5jC,GAAA4jC,EAAAsgC,aACAtgC,EAAAnpC,KAAApF,MAAAhB,EAAAsE,IAAAtE,EAAAhH,SACAu2C,GAAA3rB,OAAA5iB,KAAAhB,EAAA9E,YAGAm0C,GAAAruC,MACAoF,OAAApG,EAAAsE,IAAAtE,EAAAhH,KACA4qB,QAAA5jB,EAAA9E,OACA20E,eAGA9jC,IACA,QAAAzyC,GAAA,EAAA6I,EAAAktC,EAAAxzC,OAAsCvC,EAAA6I,EAAS7I,IAAA,CAC/C,GAAA0G,GAAAqvC,EAAA/1C,GACAk2C,EAAAu+B,GAAAlwD,EAAAysB,SAAAE,EAAAxqC,EAAAoG,KAAApG,EAAA4jB,QAAA,EACA,IAAA4rB,EAAAxwC,OAAAwwC,EAAAxwC,gBAAAquE,IAEA,KAAA79B,GAAAxwC,KAEA+sC,GAAA/qC,MAEA9F,MAAAs0C,EAAAxwC,MAAA,KAAAwwC,EAAA9yB,OACApY,IAAAtE,EAAA6vE,WAIA,OAAUxkE,KAAAygC,GAAAC,EAAApwC,EAAA+iC,MAAA/iC,EAAAgjC,OAGV,QAAA8Q,IAAA5xB,EAAAhS,GACA,MAAAwQ,IAAA4xB,GAAApwB,GAAA,WACA,MAAA6xB,IAAA7xB,EAAAhS,OAIA,QAAA6jC,IAAA7xB,EAAAhS,GAUA,QAAA8jC,GAAAC,GAEA,MADAA,GAAApqB,cAAA,EACA3H,EAAAuH,GAAAG,QAAAqqB,GAAA5zC,KAAA,SAAAQ,GAEA,MADAqzC,GAAArzC,EAAAqpB,WACArpB,EAAA6O,KAAAhF,IAAA,SAAAtD,GAMA,YAAAA,GAAAqB,KAAA,gBAAArB,GAAAqB,IAAAlJ,OACA,OAAA6H,EAAAqB,IAAAlJ,MAAA,CACA,GAAAkL,GAAA7M,OAAA6M,KAAArD,EAAAqB,IAAAlJ,OAAAoO,OAGAwmC,GAAA,mBACA,MAAA1pC,EAAA0pC,GAAA1pC,EAAA0pC,GACA,MAAA/sC,GAAAqB,IAAAlJ,MAIA,GAAA60C,GAAAv8B,GAAAzQ,EAAAqB,IAAA2Z,IACA,QACAzZ,IAAAyrC,EAAA,GACA/2C,GAAA+2C,EAAA,GACA70C,MAAA,SAAA6H,GAAAqB,IAAArB,EAAAqB,IAAAlJ,MAAA,UAMA,QAAA+0C,GAAA5kC,GACA,GAAA6kC,EAUA,IARAA,EADAC,EACAhB,GAAAtxB,EAAAxS,EAAAQ,IAGAga,WAAAgqB,EACAO,OAAAzR,EACAtzB,QAGAQ,EAAA2Z,aAAA,CACA,GAAAqoB,GAAA1nC,GAAAkF,EAAAhF,IAAA2lC,IAEA,OAAAnuB,GAAAysB,SAAA/kB,SACAnf,KAAAynC,EACAroB,cAAA,EACAopB,UAAA/iC,EAAA+iC,UACAyB,YAAAxkC,EAAAwkC,YACAC,OAAAzkC,EAAAykC,SACOt0C,KAAA,SAAAypB,GACP,GAAA8qB,GAAA,GAAAmM,GAWA,OAVAj3B,GAAApa,KAAAb,QAAA,SAAAgB,GACA+kC,EAAAjnB,IAAA9d,EAAAxS,GAAAwS,EAAApH,OAEAiH,EAAAb,QAAA,SAAAgB,GACA,GAAAge,GAAAwiB,GAAAxgC,GACApH,EAAAmsC,EAAA5xC,IAAA6qB,EACAplB,KACAoH,EAAApH,SAGA8rC,IAGA,MAAAA,GA3EA,GAAAL,GACAM,EAAAtyB,EAAA2sB,WAAA3+B,EAAAyjB,UAAA,EACAqP,EAAA9yB,EAAA8yB,MAAA,CA6EA,IA5EA,mBAAA9yB,GAAAzF,MAAAyF,EAAAzF,KAAAvK,SAEAgQ,EAAA6yB,MAAA,QACA7yB,GAAAzF,MAyEA,mBAAAyF,GAAAzF,KAAA,CACA,GAAAA,GAAAyF,EAAAzF,KACAqqC,EAAArqC,EAAAC,IAAA,SAAA/B,GACA,GAAAsrC,IACA7jC,SAAA2E,IAAApM,IACA0H,OAAA0E,IAAApM,OAEA,OAAAqrC,GAAAC,IAEA,OAAAgK,IAAA78C,IAAA0zC,GAAAz0C,KAAAgI,GAAAhI,KAAAi0C,GAEA,GAAAL,IACA/Q,WAAAhzB,EAAAgzB,WAaA,IAXAhzB,EAAAsgE,YACAtgE,EAAAE,SAAAF,EAAAsgE,WAEAtgE,EAAAugE,UACAvgE,EAAAG,OAAAH,EAAAugE,SAEA,mBAAAvgE,GAAAE,WACA6jC,EAAA7jC,SACA2E,GADA7E,EAAAgzB,YACAhzB,EAAAE,cACAF,EAAAE,YAEA,mBAAAF,GAAAG,OAAA,CACA,GAAA8zB,GAAAj0B,EAAAK,iBAAA,CACAL,GAAAgzB,aACAiB,MAGA8P,EAAA5jC,OAAA0E,GACAovB,GAAAj0B,EAAAG,YAAuCH,EAAAG,SAEvC,sBAAAH,GAAAvH,IAAA,CACA,GAAAosC,GAAAhgC,IAAA7E,EAAAvH,MACAqsC,EAAAjgC,IAAA7E,EAAAvH,QACAsrC,GAAA/Q,YACA+Q,EAAA5jC,OAAA0kC,EACAd,EAAA7jC,SAAA4kC,IAEAf,EAAA7jC,SAAA2kC,EACAd,EAAA5jC,OAAA2kC,GASA,MANAR,KACA,gBAAAtkC,GAAA6yB,QACAkR,EAAAlR,MAAA7yB,EAAA6yB,OAEAkR,EAAAjR,QAEAgR,EAAAC,GAAA5zC,KAAAi0C,GAIA,QAAA6/B,IAAA1qD,GACA,MAAAA,GAAA2sB,SACAj0C,OAAA,OACA6B,IAAA,kBAIA,QAAAixC,IAAAxrB,GACA,MAAAA,GAAAzmB,IAAA,kBAAA3C,KAAA,SAAAgxC,GACA,GAAA6D,GAAA,GAAA6L,GACAnjD,QAAA6M,KAAA4mC,EAAAlvB,OAAAtT,QAAA,SAAAugC,GACA,GAAAjiC,GAAA4iC,GAAAX,GACA+F,EAAA,WAAAhoC,EAAA,GACA8U,EAAA9U,EAAA,GACAgV,EAAA+yB,EAAAlyC,IAAAmyC,EACAhzB,KACAA,EAAA,GAAA+6C,IACAhoB,EAAAvnB,IAAAwnB,EAAAhzB,IAEAA,EAAAtB,IAAAoB,IAEA,IAAA/R,IACAzF,KAAAynE,GAAAh9B,GACArrB,cAAA,EAEA,OAAAJ,GAAAG,QAAA1Z,GAAA7P,KAAA,SAAAQ,GACA,GAAAu0C,KACAv0C,GAAA6O,KAAAb,QAAA,SAAAgB,GACA,GAAAwlC,GAAAxlC,EAAAlH,IAAAQ,UAAA,EACA+rC,GAAAlyC,IAAA6M,EAAAlH,KAAAkG,QAAA,SAAAoT,GACA,GAAAmtB,GAAAiG,EAAA,IAAApzB,CAEAovB,GAAAlvB,MAAAitB,KAGAA,EAAAntB,EAEA,IAAAqzB,GAAA13C,OAAA6M,KAAA4mC,EAAAlvB,MAAAitB,IAEAmG,EAAA1lC,EAAApH,KAAAoH,EAAApH,IAAA0Z,OACAtS,EAAApH,IAAA0Z,MAAAF,EACAqzB,GAAAzmC,QAAA,SAAA2mC,GACAJ,EAAAI,GACAJ,EAAAI,IAAAD,OAIA,IAAAE,GAAA73C,OAAA6M,KAAA2qC,GAAA1kC,OACA,SAAA8kC,GAA+B,OAAAJ,EAAAI,KAC/BE,EAAAD,EAAA/qC,IAAA,SAAA8qC,GACA,MAAA90B,IAAA4xB,GAAAkD,GAAA,WACA,UAAA/rB,GAAAnqB,YAAAk2C,EAAA/rB,EAAAksB,QAAAzoB,eAGA,OAAA+wB,IAAA78C,IAAAs0C,GAAAr1C,KAAA,WACA,OAAgBwC,IAAA,QAGbguC,IAAchuC,IAAA,KAejB,QAAA+yC,IAAAnsB,EAAArjB,EAAA8J,GACA,YAAAuZ,EAAA/G,OACA,MAAAwwD,IAAAzpD,EAAArjB,EAAA8J,EAIA,sBAAAuZ,GAAA6pD,OACA,MAAAD,IAAA5pD,EAAArjB,EAAA8J,EAGA,oBAAA9J,GAAA,CAEAoqC,GAAAtgC,EAAA9J,EAEA,IAAAyvC,IACApsB,KACAxH,SAAA,sBACAvX,IAAAtE,EAAAsE,IACAipB,OAAAvtB,EAAAutB,OACAmb,WAAA,EAYA,OAVAgH,IAAAj1B,IAAA,WACA,MAAAk1B,IAAAF,GAAAx1C,KAAA,SAAA6hB,GACA,QAAA8zB,KACA,MAAA9zB,GAAAuH,GAAAyD,UAEA,MAAA1M,IAAAiyB,GAAAvwB,GAAA7hB,KAAA,WACA,MAAAyzC,IAAA5xB,EAAAhS,KACS8lC,OAGTF,GAAA/C,SAGA,GAAA3D,GAAAhpC,EACA+G,EAAA4iC,GAAAX,GACA+F,EAAAhoC,EAAA,GACA8U,EAAA9U,EAAA,EACA,OAAAsc,GAAAzmB,IAAA,WAAAmyC,GAAA90C,KAAA,SAAAoI,GACA,GAAArC,GAAAqC,EAAA0Z,OAAA1Z,EAAA0Z,MAAAF,EAEA,KAAA7b,GAAA,gBAAAA,GAAAsE,IACA,SAAAolC,IAAA,QAAAqF,EACA,sBAAAlzB,EAEAuuB,IAAAtgC,EAAA9J,EAEA,IAAAyvC,IACApsB,KACAxH,SAAAmtB,EACA1kC,IAAAtE,EAAAsE,IACAipB,OAAAvtB,EAAAutB,OAEA,OAAAoiB,IAAAF,GAAAx1C,KAAA,SAAA6hB,GACA,aAAAhS,EAAA+lC,OAAA,iBAAA/lC,EAAA+lC,OACA,iBAAA/lC,EAAA+lC,OACAnvC,GAAA,WACA2rC,GAAAvwB,KAGA4xB,GAAA5xB,EAAAhS,IAEAuiC,GAAAvwB,GAAA7hB,KAAA,WACA,MAAAyzC,IAAA5xB,EAAAhS,SAiCA,QAAAkkE,IAAA/wD,GACA,YAAAgG,KAAAhG,GAGA,QAAAgxD,IAAAC,EAAAC,EAAApc,GACA,OAAAmc,EAAAtxB,eACAsxB,EAAAtxB,aAAAmV,IACAmc,EAAAtxB,aAAAmV,GAAA/vD,SAAAmsE,EAAAvxB,aAAAmV,GAAA/vD,OAGA,QAAAosE,IAAA/qD,EAAAhhB,GACA,GAAAonE,GAAAjyE,OAAA6M,KAAAhC,EAAAu6C,aACA,OAAA/E,IAAA78C,IAAAyuE,EAAAnlE,IAAA,SAAAytD,GACA,MAAA1uC,GAAA2mD,cAAA3nE,EAAA2Z,IAAA+1C,GAAgD90C,IAAA5a,EAAA0a,UAIhD,QAAAsxD,IAAA/3D,EAAAqM,EAAAtgB,GACA,GAAAisE,GAAA,SAAA3rD,EAAArG,QAAA,SAAAhG,EAAAgG,OACAmtD,EAAAjyE,OAAA6M,KAAAhC,EAAAu6C,aAEA,OAAA0xB,GAIAh4D,EAAA1Z,IAAAyF,EAAA2Z,KAAA/hB,KAAA,SAAAi0E,GACA,MAAAr2B,IAAA78C,IAAAyuE,EAAAnlE,IAAA,SAAAytD,GACA,MAAAkc,IAAAC,EAAA7rE,EAAA0vD,GACApvC,EAAAqnD,cAAA3nE,EAAA2Z,IAAA+1C,GAGAz7C,EAAA0zD,cAAAkE,EAAAlyD,IAAA+1C,QAEGrsD,MAAA,SAAAzI,GAEH,SAAAA,EAAA5B,OACA,KAAA4B,EAGA,OAAAmxE,IAAAzrD,EAAAtgB,KAjBA+rE,GAAAzrD,EAAAtgB,GAqBA,QAAAksE,IAAAC,GACA,GAAA9zB,KAWA,OAVAljD,QAAA6M,KAAAmqE,GAAA/lE,QAAA,SAAAxR,GACA,GAAAw3E,GAAAD,EAAAv3E,GAAAwuE,OACAgJ,GAAAhmE,QAAA,SAAAimE,GACAh0B,EAAAz7C,MACAhI,KACAgmB,IAAAyxD,SAMA5kD,KAAA4wB,EACAmE,MAAA,EACAwD,QAAA,GAUA,QAAAssB,IAAAhsD,EAAArM,EAAAk4D,EAAAn7D,GAMA,QAAAu7D,KAEA,GAAAC,GAAAN,GAAAC,EAEA,IAAAK,EAAA/kD,KAAAhwB,OAIA,MAAA6oB,GAAA02B,QAAAw1B,GAAA50E,KAAA,SAAA60E,GAEA,GAAAz7D,EAAA07D,UACA,SAAA3xE,OAAA,YAEA,OAAAy6C,IAAA78C,IAAA8zE,EAAA9kC,QAAA1lC,IAAA,SAAA0qE,GACA,MAAAn3B,IAAA78C,IAAAg0E,EAAAllD,KAAAxlB,IAAA,SAAAjC,GACA,GAAA8rE,GAAA9rE,EAAA5F,EAQA,OANA4F,GAAApF,QAGAR,GAAA,GAGA0xE,KAAAvxB,aAIAyxB,GAAA/3D,EAAAqM,EAAAwrD,GAAAl0E,KAAA,SAAAq0C,GACA,GAAAm7B,GAAAjyE,OAAA6M,KAAA8pE,EAAAvxB,aAQA,OAPAtO,GAAA7lC,QAAA,SAAAkwD,EAAAphE,GACA,GAAAolD,GAAAwxB,EAAAvxB,aAAA6sB,EAAAlyE,UACAolD,GAAAE,WACAF,GAAA7iD,OACA6iD,EAAAjgD,KAAAi8D,IAGAwV,IAZAA,QAiBAl0E,KAAA,SAAA+vC,GACAilC,IAAA/2E,OAAA+J,EAAA+nC,GAAA1/B,OAAA4kE,cAKA,QAAAhd,GAAA7vD,GACA,MAAAA,GAAAu6C,cAAAplD,OAAA6M,KAAAhC,EAAAu6C,cAAA9iD,OAAA,EAGA,QAAAq1E,GAAA9sE,GACA,MAAAA,GAAA6gD,YAAA7gD,EAAA6gD,WAAAppD,OAAA,EAGA,QAAAs1E,GAAAvlD,GAGA,MAAAlH,GAAAa,SACAnf,KAAAwlB,EACApG,cAAA,EACAopB,WAAA,IACK5yC,KAAA,SAAAQ,GACL,GAAA4Y,EAAA07D,UACA,SAAA3xE,OAAA,YAEA3C,GAAA6O,KAAAb,QAAA,SAAAgB,GACAA,EAAAof,UAAApf,EAAApH,MAAA2rE,GAAAvkE,EAAAtQ,MAAA8jB,MACAi1C,EAAAzoD,EAAApH,MAAA8sE,EAAA1lE,EAAApH,OAOAoH,EAAApH,IAAA6gD,kBACAz5C,GAAApH,IAAA6gD,WAIA+rB,EAAAhwE,KAAAwK,EAAApH,WACAmsE,GAAA/kE,EAAAxS,SAKA,QAAAo4E,KAGA,GAAAxlD,GAAAryB,OAAA6M,KAAAmqE,GAAAlkE,OAAA,SAAArT,GACA,GAAAwuE,GAAA+I,EAAAv3E,GAAAwuE,OACA,YAAAA,EAAA3rE,QAAAk0E,GAAAvI,EAAA,KAEA,IAAA57C,EAAA/vB,OAAA,EACA,MAAAs1E,GAAAvlD,GAIA,QAAAylD,KACA,OAAY7yE,KAAAqtB,KAAAmlD,GAxGZT,EAAArtE,EAAAqtE,EAEA,IAAAS,MACAxyE,GAAA,CAwGA,OAAAo7C,IAAA1yC,UACAlL,KAAAo1E,GACAp1E,KAAA20E,GACA30E,KAAAq1E,GAeA,QAAAC,IAAAlsD,EAAApsB,EAAAu4E,EAAAC,EAAAzuD,GACA,MAAAqC,GAAAzmB,IAAA3F,GAAAyO,MAAA,SAAA1I,GACA,SAAAA,EAAA3B,OAMA,MALA,SAAAgoB,EAAA/G,QACAu/B,EACA,gEAIA6zB,WAAAD,EACAzzD,IAAA/kB,EACAwoD,WACAkwB,WAAAC,GACAhjE,QAAAijE,GAGA,MAAA7yE,KACG/C,KAAA,SAAAoI,GACH,IAAA2e,EAAA+tD,WAKA1sE,EAAAmiD,WAAAgrB,EA0BA,MArBAntE,GAAAo9C,SAAAp9C,EAAAo9C,aAAAn1C,OAAA,SAAAie,GACA,MAAAA,GAAAmnD,aAAAD,IAIAptE,EAAAo9C,QAAA1Z,SACAye,SAAAgrB,EACAE,WAAAD,IAMAptE,EAAAo9C,QAAAp9C,EAAAo9C,QAAA5nD,MAAA,EAAAi4E,IAEAztE,EAAAuK,QAAAijE,GACAxtE,EAAAstE,WAAAC,GAEAvtE,EAAAqtE,WAAAD,EACAptE,EAAAmiD,SAAAgrB,EAEAnsD,EAAAyE,IAAAzlB,GAAAqD,MAAA,SAAA1I,GACA,SAAAA,EAAA3B,OAEA,MAAAk0E,IAAAlsD,EAAApsB,EAAAu4E,EAAAC,EAAAzuD,EAEA,MAAAhkB,OAKA,QAAA+yE,IAAAptD,EAAArM,EAAArf,EAAA+pB,GACApqB,KAAA+rB,MACA/rB,KAAA0f,SACA1f,KAAAK,KACAL,KAAAoqB,cAsGA,QAAAgvD,IAAAC,EAAAC,GACA,MAAAD,GAAAP,aAAAQ,EAAAR,YAEAlrB,SAAAyrB,EAAAzrB,SACA/E,QAAAwwB,EAAAxwB,SAIA0wB,GAAAF,EAAAxwB,QAAAywB,EAAAzwB,SAGA,QAAA0wB,IAAAC,EAAAC,GAGA,GAAA9tC,GAAA6tC,EAAA,GACAE,EAAAF,EAAAv4E,MAAA,GACA0rC,EAAA8sC,EAAA,GACAE,EAAAF,EAAAx4E,MAAA,EAEA,KAAA0qC,GAAA,IAAA8tC,EAAAv2E,OACA,OACA0qD,SAAAgsB,GACA/wB,WAIA,IAAAgxB,GAAAluC,EAAAmtC,UAEA,IAAAgB,GAAAD,EAAAJ,GACA,OACA7rB,SAAAjiB,EAAAiiB,SACA/E,QAAA2wB,EAIA,IAAAnuB,GAAA1e,EAAAmsC,UACA,OAAAgB,IAAAzuB,EAAAquB,IAEA9rB,SAAAjhB,EAAAihB,SACA/E,QAAA8wB,GAIAJ,GAAAG,EAAAC,GAGA,QAAAG,IAAAC,EAAAlxB,GACA,GAAAlpC,GAAAkpC,EAAA,GACAmxB,EAAAnxB,EAAA5nD,MAAA,EAEA,UAAA84E,GAAA,IAAAlxB,EAAA3lD,UAIA62E,IAAAp6D,EAAAm5D,YAIAgB,GAAAC,EAAAC,IAGA,QAAAC,IAAA7zE,GACA,sBAAAA,GAAA3B,QAAA,IAAA+H,KAAA2S,MAAA/Y,EAAA3B,OAAA,KAKA,QAAAy1E,IAAAhnE,EAAAkX,EAAA/jB,EAAA6D,GACA,GAAAgJ,EAAArO,SAAA,EAGA,MAFAulB,GAAA7T,KAAA,QAAAlQ,OACA+jB,GAAA9T,oBAOA,IAJA,kBAAApD,GAAAinE,oBACAjnE,EAAAinE,kBAAAn1B,GAEA56B,EAAA7T,KAAA,eAAAlQ,GACA,WAAA+jB,EAAA3N,OAAA,YAAA2N,EAAA3N,MAAA,CACA2N,EAAA7T,KAAA,SAAAlQ,GACA+jB,EAAA3N,MAAA,SACA,IAAA29D,GAAA,WACAlnE,EAAAmnE,iBAAAC,IAEAC,EAAA,WACAnwD,EAAA/T,eAAA,SAAA+jE,GAEAhwD,GAAAjhB,KAAA,SAAAoxE,GACAnwD,EAAAjhB,KAAA,SAAAixE,GAGAlnE,EAAAmnE,iBAAAnnE,EAAAmnE,kBAAAC,GACApnE,EAAAmnE,iBAAAnnE,EAAAinE,kBAAAjnE,EAAAmnE,kBACA7rE,WAAAtE,EAAAgJ,EAAAmnE,kBAGA,QAAAG,IAAAC,GACA,MAAA75E,QAAA6M,KAAAgtE,GAAA9pE,KAAAqC,IAAA2jB,OAAA,SAAAvsB,EAAAuB,GAEA,MADAvB,GAAAuB,GAAA8uE,EAAA9uE,GACAvB,OAMA,QAAAswE,IAAA3uD,EAAArM,EAAAxM,GACA,GAAAgiC,GAAAhiC,EAAA+sD,QAAA/sD,EAAA+sD,QAAAtvD,KAAAqC,IAAA,GACA2nE,EAAAznE,EAAAQ,OAAAR,EAAAQ,OAAAqG,WAAA,GACA0gE,EAAA,GACAG,EAAA,EAUA,OARA1nE,GAAAQ,QAAAR,EAAA2yC,eACA40B,EAAA/0E,KAAAC,UAAA60E,GAAAtnE,EAAA2yC,gBAGA3yC,EAAAQ,QAAA,UAAAR,EAAAQ,SACAknE,EAAA1nE,EAAAgS,KAAAnL,YAGAknC,GAAA78C,KAAA2nB,EAAA1rB,KAAAqf,EAAArf,OAAAgD,KAAA,SAAAQ,GACA,GAAAg3E,GAAAh3E,EAAA,GAAAA,EAAA,GAAA82E,EAAAC,EACAH,EAAAvlC,CACA,WAAA+L,IAAA,SAAA1yC,GACAukD,GAAA+nB,EAAAtsE,OAEGlL,KAAA,SAAAy3E,GAKH,MADAA,KAAA7zE,QAAA,WAAAA,QAAA,WACA,UAAA6zE,IAIA,QAAA5xC,IAAAnd,EAAArM,EAAAxM,EAAAkX,EAAAhgB,GAmCA,QAAA2wE,KACA,MAAAC,GACA/5B,GAAA1yC,UAEAmsE,GAAA3uD,EAAArM,EAAAxM,GAAA7P,KAAA,SAAAQ,GACAo3E,EAAAp3E,EACAm3E,EAAA,GAAA7B,IAAAptD,EAAArM,EAAAu7D,EAAA7wD,KAIA,QAAA8wD,KAGA,GAFAC,KAEA,IAAAC,EAAAloD,KAAAhwB,OAAA,CAGA,GAAAgwB,GAAAkoD,EAAAloD,KACAmoD,GAAoB7lE,QAAAtC,EAAAsC,QACpB,OAAAkK,GAAA21B,UAA4BniB,OAAA6iC,WAAA,GAA6BslB,GAAAh4E,KAAA,SAAAQ,GAEzD,GAAAumB,EAAA+tD,UAEA,KADAmD,KACA,GAAA90E,OAAA,YAKA,IAAA+0E,GAAA36E,OAAAyB,OAAA,KACAwB,GAAAgO,QAAA,SAAAhO,GACAA,EAAAwC,QACAk1E,EAAA13E,EAAAxD,IAAAwD,IAIA,IAAA23E,GAAA56E,OAAA6M,KAAA8tE,GAAAr4E,MACAkH,GAAAqxE,oBAAAD,EACApxE,EAAAsxE,cAAAxoD,EAAAhwB,OAAAs4E,EAEAtoD,EAAArhB,QAAA,SAAApG,GACA,GAAApF,GAAAk1E,EAAA9vE,EAAA2Z,IACA,IAAA/e,EAAA,CAEA,GADA+D,EAAAisB,OAAAhuB,KAAAhC,GACA,iBAAAA,EAAAyC,MAAA,cAAAzC,EAAAyC,KAGA,KAAAzC,EAFA+jB,GAAA7T,KAAA,SAAAhM,EAAAlE,QAKA80E,GAAA9yE,KAAAoD,MAIK,SAAArF,GAEL,KADAgE,GAAAqxE,oBAAAvoD,EAAAhwB,OACAkD,KAIA,QAAAu1E,KACA,GAAAP,EAAA/0E,MACA,SAAAG,OAAA,oCAEA4D,GAAAwjD,WAAAwtB,EAAAxoC,GACA,IAAAgpC,GAAArxE,EAAAH,EAMA,OALA+wE,GAAAj4E,SACA04E,EAAA1oD,KAAAioD,EACA/wD,EAAA7T,KAAA,SAAAqlE,IAEAC,GAAA,EACAb,EAAAc,gBAAAV,EAAAxoC,IACAimC,GAAAx1E,KAAA,WAGA,GAFAw4E,GAAA,EAEAzxD,EAAA+tD,UAEA,KADAmD,KACA,GAAA90E,OAAA,YAEA40E,GAAAj4E,OACA44E,MACKjtE,MAAA,SAAA1I,GAEL,KADA41E,GAAA51E,GACAA,IAIA,QAAA61E,KACA,GAAA3zD,KAWA,OAVA8yD,GAAA/mD,QAAAxiB,QAAA,SAAAskC,GAGA,WAAAA,EAAA91C,KAGAioB,EAAA6tB,EAAA91C,IAAA81C,EAAA9hB,QAAA3mB,IAAA,SAAA8L,GACA,MAAAA,GAAA6M,SAGA3G,EAAA40D,SAAAhsD,GAAAjlB,KAAA,SAAAu0E,GAEA,GAAAxtD,EAAA+tD,UAEA,KADAmD,KACA,GAAA90E,OAAA,YAGA40E,GAAAxD,UAIA,QAAAsE,KACA,MAAAnE,IAAAhsD,EAAArM,EAAA07D,EAAAxD,MAAAxtD,GAAA/mB,KAAA,SAAA84E,GACAf,EAAA/0E,OAAA81E,EAAAt2E,GACAs2E,EAAAjpD,KAAArhB,QAAA,SAAApG,SACA2vE,GAAAxD,MAAAnsE,EAAA2Z,KACAhb,EAAAgyE,YACAhB,EAAAloD,KAAA7qB,KAAAoD,OAKA,QAAA4wE,KACA,IAAAjyD,EAAA+tD,YAAAiD,EAAA,CAGA,OAAAkB,EAAAp5E,OAEA,WADAq5E,IAAA,EAGAnB,GAAAkB,EAAAxuB,QACAmuB,IACA54E,KAAA64E,GACA74E,KAAA63E,GACA73E,KAAAs4E,GACAt4E,KAAAg5E,GACAvtE,MAAA,SAAA1I,GACAo2E,EAAA,yCAAAp2E,MAKA,QAAAm2E,GAAA76D,GACA,WAAA+6D,EAAApoD,QAAAnxB,YACA,IAAAo5E,EAAAp5E,QAAAk4E,KACApb,GAAA0c,EAAA1zC,MAAA2zC,KACAvyD,EAAA3N,MAAA,UACA2N,EAAA7T,KAAA,WAEAomE,GACArB,YAMA55D,GACAi7D,GACAF,EAAApoD,QAAAnxB,QAAAywE,KAEA2I,EAAAj0E,KAAAo0E,GACAA,GACA7pC,IAAA,EACAve,WACAnB,SAEA,YAAA9I,EAAA3N,OAAA,YAAA2N,EAAA3N,QACA2N,EAAA3N,MAAA,SACA2N,EAAA7T,KAAA,WAEA8lE,MAKA,QAAAG,GAAA9zE,EAAAtC,GACAw2E,IAGAx2E,EAAA2C,UACA3C,EAAA2C,QAAAL,GAEA0B,EAAAvE,IAAA,EACAuE,EAAA3F,OAAA,WACA63E,KACAG,GACA7pC,IAAA,EACAve,WACAnB,SAEAooD,EAAAl1E,IAIA,QAAAk1E,GAAAuB,GACAD,GAIAxyD,EAAA+tD,YACA/tE,EAAA3F,OAAA,YACAo3E,KAIAzxE,EAAA3F,OAAA2F,EAAA3F,QAAA,WACA2F,EAAA0yE,SAAA,GAAApiE,MACAtQ,EAAAwjD,WACAgvB,GAAA,EAEAC,GACAA,EAAAzyE,SAEA,iBAAAyyE,EAAA/zE,MAAA,cAAA+zE,EAAA/zE,MACAshB,EAAA7T,KAAA,QAAAsmE,GACAzyD,EAAA9T,sBAEA4jE,GAAAhnE,EAAAkX,EAAAyyD,EAAA,WACA3zC,GAAAnd,EAAArM,EAAAxM,EAAAkX,OAIAA,EAAA7T,KAAA,WAAAnM,GACAggB,EAAA9T,uBAKA,QAAA41C,GAAA/V,GAEA,GAAA/rB,EAAA+tD,UACA,MAAAmD,IAEA,IAAA5nE,GAAAiyC,EAAAzyC,GAAAijC,EACAziC,KAGA+oE,EAAA7pC,IAAAuD,EAAAvD,IACA6pC,EAAApoD,QAAAhsB,KAAA8tC,GACAomC,EAAA,IAAAD,EAAAp5E,QAAAw5E,EAAA1zC,OAIA,QAAA+zC,GAAA1oD,GAGA,GAFA2oD,GAAA,EAEA5yD,EAAA+tD,UACA,MAAAmD,IAKA,IAAAjnD,EAAA+e,QAAAlwC,OAAA,EACAw5E,EAAAz2C,MAAA5R,EAAAu5B,SACAmuB,IACAQ,GAAA,OACK,CAEL,GAAAzmC,GAAA,WACAkqB,GACA0c,EAAA1zC,MAAA,EACA+yC,KAEAY,GAAA,EAEAJ,GAAA,GAIAnB,IAAA,IAAA/mD,EAAA+e,QAAAlwC,OAUA4yC,KATA+lC,GAAA,EACAb,EAAAc,gBAAAznD,EAAAu5B,SACAirB,GAAAx1E,KAAA,WACAw4E,GAAA,EACAzxE,EAAAwjD,WAAAv5B,EAAAu5B,SACA9X,MAEAhnC,MAAAktE,KAQA,QAAAiB,GAAA72E,GAGA,MAFA42E,IAAA,EAEA5yD,EAAA+tD,UACAmD,QAEAkB,GAAA,mBAAAp2E,GAIA,QAAA21E,KASA,QAAAmB,KACA7oD,EAAAhqB,SAEA,QAAAgM,KACA+T,EAAA/T,eAAA,SAAA6mE,GAZA,IACAF,IACAL,GACAL,EAAAp5E,OAAAi6E,EAHA,CAOAH,GAAA,EAQA5yD,EAAAk4C,WACAl4C,EAAA/T,eAAA,SAAA+T,EAAAgzD,eACAhzD,EAAAk4C,SAAAj4D,UAEA+f,EAAAjhB,KAAA,SAAA+zE,EAEA,IAAA7oD,GAAAtI,EAAAsI,QAAAqoD,GACAxmE,GAAA,SAAAg2C,EACA73B,GAAAhxB,KAAAgT,KACAge,EAAAhxB,KAAA05E,GACAjuE,MAAAmuE,GAEA/pE,EAAArO,QAEAulB,EAAAk4C,SAAAjuC,EACAjK,EAAAgzD,cAAAF,IAKA,QAAAG,KACAtC,IAAA13E,KAAA,WAEA,MAAA+mB,GAAA+tD,cACAmD,KAGAN,EAAAsC,gBAAAj6E,KAAA,SAAAu1E,GACAhrB,EAAAgrB,EACA8D,GACAz2C,MAAA2nB,EACA7nB,MAAA4tC,EACAA,aACAjsD,MAAA,WACAu4C,UACAE,aAAA,GAEAjtD,EAAAQ,SACA,gBAAAR,GAAAQ,OAEAgpE,EAAA7vD,cAAA,EAEA6vD,EAAAhpE,OAAAR,EAAAQ,QAGA,aAAAR,KACAwpE,EAAA5I,UAAA5gE,EAAA4gE,WAEA,WAAA5gE,KACAwpE,EAAAlnE,QAAAtC,EAAAsC,SAEAtC,EAAA2yC,eACA62B,EAAA72B,aAAA3yC,EAAA2yC,cAEA3yC,EAAAgS,OACAw3D,EAAAx3D,KAAAhS,EAAAgS,MAEA62D,QAEKjtE,MAAA,SAAA1I,GACLo2E,EAAA,+BAAAp2E,KAKA,QAAA41E,GAAA51E,GACAy1E,GAAA,EACAW,EAAA,uCAAAp2E,GAzZA,GACAg1E,GAeAH,EACAD,EAjBAsB,KAEAG,GACA7pC,IAAA,EACAve,WACAnB,SAEA2oD,GAAA,EACAc,GAAA,EACAC,GAAA,EACAhvB,EAAA,EACAoS,EAAA9sD,EAAA8sD,YAAA9sD,EAAA81B,OAAA,EACA2qC,EAAAzgE,EAAAygE,YAAA,IACAwJ,EAAAjqE,EAAAiqE,eAAA,GACAH,GAAA,EACA/c,EAAA/sD,EAAA+sD,QAGAkb,KAEAtC,EAAA1xB,GAEA/8C,OACAvE,IAAA,EACA03E,WAAA,GAAA7iE,MACA0hE,UAAA,EACAV,aAAA,EACAD,mBAAA,EACAplD,UAGA,IAAAqmD,KA8XA,OA7XAtyD,GAAAglC,MAAArjC,EAAArM,GA6XA0K,EAAA+tD,cACAmD,MAIAlxD,EAAAozD,kBACApzD,EAAAjhB,KAAA,SAAAmyE,GAEA,kBAAApoE,GAAA4iC,WACA1rB,EAAAjhB,KAAA,QAAA+J,EAAA4iC,UACA1rB,EAAAjhB,KAAA,oBAAAiB,GACA8I,EAAA4iC,SAAA,KAAA1rC,MAGAggB,EAAAozD,iBAAA,QAGA,mBAAAtqE,GAAA+yB,MACAo3C,IAEAtC,IAAA13E,KAAA,WAEA,MADAw4E,IAAA,EACAb,EAAAc,gBAAA5oE,EAAA+yB,MAAA4yC,KACKx1E,KAAA,WAGL,MAFAw4E,IAAA,EAEAzxD,EAAA+tD,cACAmD,MAGA1tB,EAAA16C,EAAA+yB,UACAo3C,QACKvuE,MAAAktE,KAOL,QAAAyB,MACAh5B,GAAA/U,aAAAnvC,KAAAP,MACAA,KAAAm4E,WAAA,EACAn4E,KAAAyc,MAAA,SACA,IAAAza,GAAAhC,KACA+J,EAAA,GAAAk3C,IAAA,SAAAj3C,EAAAC,GACAjI,EAAAmH,KAAA,WAAAa,GACAhI,EAAAmH,KAAA,QAAAc,IAEAjI,GAAAqB,KAAA,SAAAkL,EAAAtE,GACA,MAAAF,GAAA1G,KAAAkL,EAAAtE,IAEAjI,EAAA8M,MAAA,SAAA7E,GACA,MAAAF,GAAA+E,MAAA7E,IAIAjI,EAAA8M,MAAA,cA4BA,QAAA4uE,IAAAjxD,EAAAvZ,GACA,GAAAyqE,GAAAzqE,EAAAyqE,gBACA,uBAAAlxD,GACA,GAAAkxD,GAAAlxD,EAAAvZ,GAEAuZ,EAIA,QAAAmxD,IAAA7xD,EAAArM,EAAAxM,EAAAhJ,GAUA,GARA,kBAAAgJ,KACAhJ,EAAAgJ,EACAA,MAEA,mBAAAA,KACAA,MAGAA,EAAA+sD,UAAA33D,MAAAC,QAAA2K,EAAA+sD,SACA,KAAA9a,GAAAO,GACA,4CAGAxyC,GAAA4iC,SAAA5rC,EACAgJ,EAAA3I,EAAA2I,GACAA,EAAA8sD,WAAA9sD,EAAA8sD,YAAA9sD,EAAA81B,KACA91B,EAAArO,MAAA,SAAAqO,MAAArO,MAEAqO,EAAAyqE,iBAAAzqE,EAAAyqE,kBAAA39E,IACA,IAAA69E,GAAA,GAAAJ,IAAAvqE,GACA4qE,EAAAJ,GAAA3xD,EAAA7Y,GACA6qE,EAAAL,GAAAh+D,EAAAxM,EAEA,OADAg2B,IAAA40C,EAAAC,EAAA7qE,EAAA2qE,GACAA,EAIA,QAAAG,IAAAjyD,EAAArM,EAAAxM,EAAAhJ,GAaA,MAZA,kBAAAgJ,KACAhJ,EAAAgJ,EACAA,MAEA,mBAAAA,KACAA,MAEAA,EAAA3I,EAAA2I,GAEAA,EAAAyqE,iBAAAzqE,EAAAyqE,kBAAA39E,KACA+rB,EAAA2xD,GAAA3xD,EAAA7Y,GACAwM,EAAAg+D,GAAAh+D,EAAAxM,GACA,GAAA+qE,IAAAlyD,EAAArM,EAAAxM,EAAAhJ,GAGA,QAAA+zE,IAAAlyD,EAAArM,EAAAxM,EAAAhJ,GAaA,QAAAg0E,GAAA/nC,GACAn0C,EAAAuU,KAAA,UACA4nE,UAAA,OACAhoC,WAGA,QAAAioC,GAAAjoC,GACAn0C,EAAAuU,KAAA,UACA4nE,UAAA,OACAhoC,WAGA,QAAAkoC,GAAA5yE,GACAzJ,EAAAuU,KAAA,UACA4nE,UAAA,OACA1yE,QAGA,QAAA6yE,GAAA7yE,GACAzJ,EAAAuU,KAAA,UACA4nE,UAAA,OACA1yE,QAGA,QAAA8yE,KACAv8E,EAAAu8E,YAAA,EAEAv8E,EAAAw8E,YACAx8E,EAAAuU,KAAA,UAGA,QAAAioE,KACAx8E,EAAAw8E,YAAA,EAEAx8E,EAAAu8E,YACAv8E,EAAAuU,KAAA,UAGA,QAAAkoE,KACAz8E,EAAAu8E,YAAA,EAEAv8E,EAAAw8E,YACAx8E,EAAAuU,KAAA,UACA4nE,UAAA,SAIA,QAAAO,KACA18E,EAAAw8E,YAAA,EAEAx8E,EAAAu8E,YACAv8E,EAAAuU,KAAA,UACA4nE,UAAA,SAOA,QAAAQ,GAAAj5D,GACA,gBAAApO,EAAA5N,GACA,GAAAk1E,GAAA,WAAAtnE,IACA5N,IAAAw0E,GAAAx0E,IAAA00E,GACAS,EAAA,WAAAvnE,IACA5N,IAAA40E,GAAA50E,IAAA20E,GACAS,EAAA,WAAAxnE,IACA5N,IAAA80E,GAAA90E,IAAA60E,GACAQ,EAAA,WAAAznE,IACA5N,IAAAg1E,GAAAh1E,IAAA+0E,IAEAG,GAAAC,GAAAC,GAAAC,KACAznE,IAAA0nE,KACAA,EAAA1nE,OAEA0nE,EAAA1nE,GAAAoO,IAAA,EACA,IAAA9kB,OAAA6M,KAAAuxE,EAAA1nE,IAAApU,QAEAlB,EAAAsU,mBAAAgB,KAWA,QAAA2nE,GAAA34B,EAAAhvC,EAAA84B,GACAkW,EAAAnW,UAAA74B,GAAArR,QAAAmqC,KAAA,GACAkW,EAAApwC,GAAAoB,EAAA84B,GAtGA,GAAApuC,GAAAhC,IACAA,MAAAk/E,UAAA,CAEA,IAAAC,GAAAjsE,EAAA7K,KAAAmlD,MAAwCt6C,IAAA7K,MAAA6K,EACxCksE,EAAAlsE,EAAAmsE,KAAA7xB,MAAwCt6C,IAAAmsE,MAAAnsE,CAExClT,MAAAqI,KAAAu1E,GAAA7xD,EAAArM,EAAAy/D,GACAn/E,KAAAq/E,KAAAzB,GAAAl+D,EAAAqM,EAAAqzD,GAEAp/E,KAAAu+E,YAAA,EACAv+E,KAAAw+E,YAAA,CA2DA,IAAAQ,KA0BA9rE,GAAA81B,OACAhpC,KAAAqI,KAAA6N,GAAA,WAAAlU,EAAAq9E,KAAAh1E,OAAAklC,KAAAvtC,EAAAq9E,OACAr/E,KAAAq/E,KAAAnpE,GAAA,WAAAlU,EAAAqG,KAAAgC,OAAAklC,KAAAvtC,EAAAqG,QASArI,KAAAkW,GAAA,uBAAAoB,GACA,WAAAA,GACA2nE,EAAAj9E,EAAAq9E,KAAA,SAAAnB,GACAe,EAAAj9E,EAAAqG,KAAA,SAAA+1E,IACK,WAAA9mE,GACL2nE,EAAAj9E,EAAAq9E,KAAA,SAAAf,GACAW,EAAAj9E,EAAAqG,KAAA,SAAAg2E,IACK,WAAA/mE,GACL2nE,EAAAj9E,EAAAq9E,KAAA,SAAAX,GACAO,EAAAj9E,EAAAqG,KAAA,SAAAo2E,IACK,WAAAnnE,IACL2nE,EAAAj9E,EAAAq9E,KAAA,SAAAb,GACAS,EAAAj9E,EAAAqG,KAAA,SAAAk2E,MAIAv+E,KAAAkW,GAAA,0BAAAoB,GACA,WAAAA,GACAtV,EAAAq9E,KAAAhpE,eAAA,SAAA6nE,GACAl8E,EAAAqG,KAAAgO,eAAA,SAAA+nE,IACK,WAAA9mE,GACLtV,EAAAq9E,KAAAhpE,eAAA,SAAAioE,GACAt8E,EAAAqG,KAAAgO,eAAA,SAAAgoE,IACK,WAAA/mE,GACLtV,EAAAq9E,KAAAhpE,eAAA,SAAAqoE,GACA18E,EAAAqG,KAAAgO,eAAA,SAAAooE,IACK,WAAAnnE,IACLtV,EAAAq9E,KAAAhpE,eAAA,SAAAmoE,GACAx8E,EAAAqG,KAAAgO,eAAA,SAAAkoE,MAIAv+E,KAAAq/E,KAAAnpE,GAAA,iBAAAyoE,EAAA,SACA3+E,KAAAqI,KAAA6N,GAAA,iBAAAyoE,EAAA,QAEA,IAAA50E,GAAAk3C,GAAA78C,KACApE,KAAAqI,KACArI,KAAAq/E,OACAh8E,KAAA,SAAAC,GACA,GAAAsnB,IACAviB,KAAA/E,EAAA,GACA+7E,KAAA/7E,EAAA,GAOA,OALAtB,GAAAuU,KAAA,WAAAqU,GACA1gB,GACAA,EAAA,KAAA0gB,GAEA5oB,EAAAsU,qBACAsU,GACG,SAAAxkB,GAaH,GAZApE,EAAAqI,SACAH,EAGAA,EAAA9D,GAKApE,EAAAuU,KAAA,QAAAnQ,GAEApE,EAAAsU,qBACApM,EAEA,KAAA9D,IAIApG,MAAAqD,KAAA,SAAAi8E,EAAAl5E,GACA,MAAA2D,GAAA1G,KAAAi8E,EAAAl5E,IAGApG,KAAA8O,MAAA,SAAA1I,GACA,MAAA2D,GAAA+E,MAAA1I,IAYA,QAAAoiC,IAAAnX,GACAA,EAAA6X,UAAA00C,GACAvsD,EAAAkuD,KAAAvB,GAEAp9E,OAAA4G,eAAA6pB,EAAAxwB,UAAA,aACAmF,IAAA,WACA,GAAAhE,GAAAhC,IACA,QACA2kC,KAAA,SAAA66C,EAAAtsE,EAAAhJ,GACA,MAAAlI,GAAAM,YAAA4mC,UAAAs2C,EAAAx9E,EAAAkR,EAAAhJ,IAEA06B,GAAA,SAAA46C,EAAAtsE,EAAAhJ,GACA,MAAAlI,GAAAM,YAAA4mC,UAAAlnC,EAAAw9E,EAAAtsE,EAAAhJ,QAMAmnB,EAAAxwB,UAAA0+E,KAAA,SAAAl7B,EAAAnxC,EAAAhJ,GACA,MAAAlK,MAAAsC,YAAAi9E,KAAAv/E,KAAAqkD,EAAAnxC,EAAAhJ,IAnjWA,GAAAmjB,IAAAF,EAAAjtB,EAAA,KACAoJ,GAAA6jB,EAAAjtB,EAAA,KACAyoB,GAAAwE,EAAAjtB,EAAA,KACAukD,GAAAvkD,EAAA,IACAoK,GAAA6iB,EAAAjtB,EAAA,KACA4J,GAAAqjB,EAAAjtB,EAAA,KACA2rD,GAAA1+B,EAAAjtB,EAAA,KACA2K,GAAAsiB,EAAAjtB,EAAA,KACAm2D,GAAAlpC,EAAAjtB,EAAA,KAGA+gD,GAAA,kBAAA98C,iBAAAkpB,GAqCAwzB,GAAAlpC,SAAA9W,UAAAkZ,SACA+mC,GAAAD,GAAAtgD,KAAAK,QA8GA+M,GAAAgb,GAAA,cAsEAo5B,GAAAlhD,UAAAmF,IAAA,SAAA2F,GACA,GAAA8zE,GAAA59B,EAAAl2C,EACA,OAAA3L,MAAAgiD,OAAAy9B,IAEA19B,EAAAlhD,UAAA8vB,IAAA,SAAAhlB,EAAApJ,GACA,GAAAk9E,GAAA59B,EAAAl2C,EAEA,OADA3L,MAAAgiD,OAAAy9B,GAAAl9E,GACA,GAEAw/C,EAAAlhD,UAAA+9B,IAAA,SAAAjzB,GACA,GAAA8zE,GAAA59B,EAAAl2C,EACA,OAAA8zE,KAAAz/E,MAAAgiD,QAEAD,EAAAlhD,UAAA4d,OAAA,SAAA9S,GACA,GAAA8zE,GAAA59B,EAAAl2C,GACA9H,EAAA47E,IAAAz/E,MAAAgiD,MAEA,cADAhiD,MAAAgiD,OAAAy9B,GACA57E,GAEAk+C,EAAAlhD,UAAAgR,QAAA,SAAAnH,GAEA,OADA+C,GAAA7M,OAAA6M,KAAAzN,KAAAgiD,QACArhD,EAAA,EAAA6I,EAAAiE,EAAAvK,OAAoCvC,EAAA6I,EAAS7I,IAAA,CAC7C,GAAAgL,GAAA8B,EAAA9M,GACA4B,EAAAvC,KAAAgiD,OAAAr2C,EACAA,GAAAm2C,EAAAn2C,GACAjB,EAAAnI,EAAAoJ,KAGA/K,OAAA4G,eAAAu6C,EAAAlhD,UAAA,QACAmF,IAAA,WACA,MAAApF,QAAA6M,KAAAzN,KAAAgiD,QAAA9+C,UAcA++C,EAAAphD,UAAAgjB,IAAA,SAAAlY,GACA,MAAA3L,MAAAgiD,OAAArxB,IAAAhlB,GAAA,IAEAs2C,EAAAphD,UAAA+9B,IAAA,SAAAjzB,GACA,MAAA3L,MAAAgiD,OAAApjB,IAAAjzB,IAEAs2C,EAAAphD,UAAAgR,QAAA,SAAAnH,GACA1K,KAAAgiD,OAAAnwC,QAAA,SAAAtP,EAAAoJ,GACAjB,EAAAiB,MAGA/K,OAAA4G,eAAAy6C,EAAAphD,UAAA,QACAmF,IAAA,WACA,MAAAhG,MAAAgiD,OAAAtB,OAmBA,IAAAwf,IACAnc,EAGA7B,MACAge,GAAA9d,IACA2B,GAAA5B,MAEA+d,GAAAje,EACA8B,GAAAhC,EAOA,IAsIAmC,IAtIAd,GAAA,CAwIA,IAAAY,IACAE,IAAA,MAEA,KACAp7B,aAAA2I,QAAA,+BACAyyB,KAAAp7B,aAAA8I,QAAA,6BACG,MAAAvqB,GACH68C,IAAA,EAQA55C,GAAAk6C,EAAAC,GAAA/U,cA+BA8U,EAAA3jD,UAAAsV,YAAA,SAAAkuC,EAAAhkD,EAAAosB,EAAAvZ,GAOA,QAAAwsE,KAgBA,QAAAl1D,KACAm1D,GAAA,EAfA,GAAA39E,EAAA0iD,WAAArkD,GAAA,CAGA,GAAAs/E,EAEA,YADAA,EAAA,UAGAA,IAAA,CACA,IAAAjD,GAAAtwE,EAAA8G,GACA,0DACA,kDAQAuZ,GAAA4H,QAAAqoD,GAAAxmE,GAAA,kBAAAzV,GACAA,EAAAmyC,IAAA1/B,EAAA+yB,QAAA/yB,EAAAilE,YACAjlE,EAAA+yB,MAAAxlC,EAAAmyC,IACA1/B,EAAAg5C,SAAAzrD,MAEKyV,GAAA,sBACL,YAAAypE,GACA71E,GAAA41E,GAEAC,GAAA,IACKzpE,GAAA,QAAAsU,IAnCL,IAAAxqB,KAAA0kD,WAAArkD,GAAA,CAGA,GAAA2B,GAAAhC,KACA2/E,GAAA,CAiCA3/E,MAAA0kD,WAAArkD,GAAAq/E,EACA1/E,KAAAkW,GAAAmuC,EAAAq7B,KAGAl7B,EAAA3jD,UAAAwV,eAAA,SAAAguC,EAAAhkD,GAEAA,IAAAL,MAAA0kD,aAGAD,GAAA/U,aAAA7uC,UAAAwV,eAAA9V,KAAAP,KAAAqkD,EACArkD,KAAA0kD,WAAArkD,UACAL,MAAA0kD,WAAArkD,KAKAmkD,EAAA3jD,UAAA++E,mBAAA,SAAAv7B,GAGAL,IACAj7B,OAAAtL,QAAAuL,MAAA2H,KAA8B0zB,WAC3BJ,MACHn7B,aAAAu7B,GAAA,MAAAv7B,aAAAu7B,GAAA,UAIAG,EAAA3jD,UAAAi6D,OAAA,SAAAzW,GACArkD,KAAAuW,KAAA8tC,GACArkD,KAAA4/E,mBAAAv7B,GA6CA,IAAA1lC,GAGAA,IADA,kBAAA/d,QAAA+d,OACA/d,OAAA+d,OAIA,SAAAe,GAGA,OAFAklB,GAAAhkC,OAAA8e,GAEAnN,EAAA,EAAyBA,EAAAtP,UAAAC,OAA0BqP,IAAA,CACnD,GAAAstE,GAAA58E,UAAAsP,EAEA,UAAAstE,EACA,OAAAC,KAAAD,GAEAj/E,OAAAC,UAAAC,eAAAP,KAAAs/E,EAAAC,KACAl7C,EAAAk7C,GAAAD,EAAAC,IAKA,MAAAl7C,GAKA,IAAA4oB,IAAA7uC,EAEArU,IAAA46C,EAAA1+C,OAUA0+C,EAAArkD,UAAAkZ,SAAA,WACA,MAAArU,MAAAC,WACAlB,OAAAzE,KAAAyE,OACAqE,KAAA9I,KAAA8I,KACAC,QAAA/I,KAAA+I,QACAL,OAAA1I,KAAA0I,SAIA,IAoIA7E,IAnIAk8E,IADA,GAAA76B,GAAA,qDACA,GAAAA,GAAA,kDACAyQ,GAAA,GAAAzQ,GAAA,2BACA2P,GAAA,GAAA3P,GAAA,2CACAiB,GAAA,GAAAjB,GAAA,qDACAmB,GAAA,GAAAnB,GAAA,6CACAkB,GAAA,GAAAlB,GAAA,2EAEAI,IADA,GAAAJ,GAAA,+CACA,GAAAA,GAAA,8DACAsO,GAAA,GAAAtO,GAAA,+CAEA86B,IADA,GAAA96B,GAAA,6CACA,GAAAA,GAAA,4DACAoL,GAAA,GAAApL,GAAA,oDACAQ,GAAA,GAAAR,GAAA,sDACA+6B,GAAA,GAAA/6B,GAAA,oDAEAuR,IADA,GAAAvR,GAAA,sCACA,GAAAA,GAAA,sCACAohB,GAAA,GAAAphB,GAAA,kCAGAwK,IAFA,GAAAxK,GAAA,uCACA,GAAAA,GAAA,wEACA,GAAAA,GAAA,yCAEA+V,IADA,GAAA/V,GAAA,iFACA,GAAAA,GAAA,mEA6GAg7B,IA5GA,GAAAh7B,GAAA,6CA4GAh+B,EAAApe,KAMAjF,IADAq8E,GACA,SAAA92E,GACA,MAAAA,GAAAN,MAGA,SAAAM,GACA,MAAAA,GAAA2Q,WAAAiO,MAAA,gCA8DA,IAAAva,KAAA,6DACA,qEACAq5C,GAAA,WACAC,GAAA,4BAIAJ,GAAA,mMA4GAS,GAAA,iEAGAh3C,MAAA,GA0fA9F,IAAA0hD,GAAAvH,GAAA/U,cAiFAsc,GAAAnrD,UAAAwJ,OAAA,WACArK,KAAAmsD,aAAA,EACAnsD,KAAAysB,GAAAg1B,UAAAC,SACA1hD,KAAAuW,KAAA,WA2BAy1C,GAAAnrD,UAAAurD,UAAA,SAAAl5C,GACA,GAAAlR,GAAAhC,KACAkK,EAAAgJ,EAAA4iC,QAcA,IAZA5iC,EAAA3I,EAAA2I,GACA,QAAAA,MAAA,cAAAA,MACAA,EAAA8sD,WAAA9sD,EAAA81B,MAEA91B,EAAA0iC,iBAEA,WAAA1iC,EAAA+yB,QACA/yB,EAAA+yB,MAAA,OAEA/yB,EAAA+yB,QACA/yB,EAAA+yB,MAAA,GAEA,QAAA/yB,EAAA+yB,MAUA,WATAjmC,MAAAysB,GAAAwT,OAAA58B,KAAA,SAAA48B,GAEA,MAAAj+B,GAAAmqD,gBACAjiD,GAAA,MAAwBzF,OAAA,eAGxByO,EAAA+yB,MAAAhG,EAAAmiC,eACApgE,GAAAoqD,UAAAl5C,KACKhJ,EASL,IAJAgJ,EAAAgS,OAAAhS,EAAAQ,SACAR,EAAAQ,OAAA,SAGAR,EAAAQ,QAAA,gBAAAR,GAAAQ,SACA,UAAAR,EAAAQ,OACAR,EAAAgS,KAAAshC,EAAAtzC,EAAAgS,MAEAhS,EAAAQ,OAAA8yC,EAAAtzC,EAAAQ,QAGA,SAAA1T,KAAAysB,GAAA/G,SAAAxS,EAAA+sD,SACA,MAAAjgE,MAAAmgF,cAAAjtE,EAIA,eAAAA,KACAA,EAAAgzB,YAAA,GAIAhzB,EAAA6yB,MAAA,IAAA7yB,EAAA6yB,MAAA,EAAA7yB,EAAA6yB,MACA7yB,EAAA4iC,SAAA5rC,CACA,IAAAk2E,GAAApgF,KAAAysB,GAAA61C,SAAApvD,EAEA,IAAAktE,GAAA,kBAAAA,GAAA/1E,OAAA,CACA,GAAAA,GAAArI,EAAAqI,MACArI,GAAAqI,OAAAf,GAAA,SAAAtI,GACAo/E,EAAA/1E,SACAA,EAAAhJ,MAAArB,KAAAgB,OAKAgrD,GAAAnrD,UAAAs/E,cAAA,SAAAjtE,GACA,GAAAlR,GAAAhC,KACAkK,EAAAgJ,EAAA4iC,QACA,cAAA5iC,EAAAQ,OAAA,CACA,IAAAR,EAAAgS,MAAA,gBAAAhS,GAAAgS,KAAA,CACA,GAAA9e,GAAA++C,EAAAO,GACA,gDACA,OAAAx7C,GAAA9D,GAGA,GAAA6e,GAAAshC,EAAArzC,EAAAgS,KACAllB,MAAAysB,GAAAzmB,IAAA,WAAAif,EAAA,YAAA7e,EAAA4e,GAEA,GAAAhjB,EAAAmqD,YACA,MAAAjiD,GAAA,MAA+BzF,OAAA,aAG/B,IAAA2B,EACA,MAAA8D,GAAAm7C,EAAAj/C,GAEA,IAAAwrC,GAAA5sB,KAAAG,OAAAH,EAAAG,MAAAF,EAAA,KACAD,EAAAG,MAAAF,EAAA,IAAAvX,GACA,OAAAkkC,IAKA1+B,EAAAQ,OAAAo4C,GAAAla,OACA5vC,GAAAoqD,UAAAl5C,IALAhJ,EAAAi7C,EAAAwQ,GACA3wC,EAAAG,MAAA,qBAAAF,EAAA,GACA,kCAKG,CAEH,GAAAo7D,GAAA95B,EAAArzC,EAAAQ,OACA,KAAA2sE,EACA,MAAAr+E,GAAAoqD,UAAAl5C,EAEAlT,MAAAysB,GAAAzmB,IAAA,WAAAq6E,EAAA,YAAAj6E,EAAA4e,GAEA,GAAAhjB,EAAAmqD,YACA,MAAAjiD,GAAA,MAA+BzF,OAAA,aAG/B,IAAA2B,EACA,MAAA8D,GAAAm7C,EAAAj/C,GAEA,IAAAu0E,GAAA31D,KAAA2hB,SAAA3hB,EAAA2hB,QAAA05C,EAAA,GACA,OAAA1F,IAKAznE,EAAAQ,OAAAk4C,GAAA+uB,OACA34E,GAAAoqD,UAAAl5C,IALAhJ,EAAAi7C,EAAAwQ,GACA3wC,KAAA2hB,QAAA,qBAAA05C,EAAA,GACA,kCA2JA/1E,GAAA0jD,GAAAvJ,GAAA/U,cAMAse,GAAAntD,UAAAy/E,KACAp/B,EAAA,gBAAAz1C,EAAAyH,EAAAhJ,GAKA,MAJA,kBAAAgJ,KACAhJ,EAAAgJ,EACAA,MAEA,gBAAAzH,IAAAnD,MAAAC,QAAAkD,GACAvB,EAAAi7C,EAAA86B,SAEAjgF,MAAAq1C,UAAiBniB,MAAAznB,IAAYyH,EAAAq5C,GAAAriD,MAG7B8jD,GAAAntD,UAAAqwB,IAAAgwB,EAAA,eAAAz1C,EAAAyH,EAAAxI,GAKA,MAJA,kBAAAwI,KACAxI,EAAAwI,EACAA,MAEA,gBAAAzH,IAAAnD,MAAAC,QAAAkD,GACAf,EAAAy6C,EAAA86B,MAEA/5B,EAAAz6C,EAAA2Z,KACAomC,GAAA//C,EAAA2Z,MAAA,kBAAAplB,MAAA6iE,UACAp3D,EAAAipC,SACA10C,KAAAijE,aAAAx3D,EAAAf,GAEA1K,KAAA6iE,UAAAp3D,EAAAf,QAGA,kBAAA1K,MAAAuzE,MAAArgE,EAAA6iD,aAAA,EACA/1D,KAAAuzE,KAAA9nE,EAAAyH,EAAAxI,GAEA1K,KAAAq1C,UAAmBniB,MAAAznB,IAAYyH,EAAAq5C,GAAA7hD,QAI/BsjD,GAAAntD,UAAAyyE,cACApyB,EAAA,yBAAArwB,EAAAghD,EAAAxrD,EACAurC,EAAAlsC,GAkBA,QAAA66D,GAAA90E,GACA,GAAA+0E,GAAA,QAAA/0E,GAAAkN,SAAAlN,EAAA0a,KAAA,KAOA,OANA1a,GAAAu6C,aAAAv6C,EAAAu6C,iBACAv6C,EAAAu6C,aAAA6rB,IACAje,aAAAluC,EACA5f,KAAA8rD,EACA2K,SAAAikB,GAEAnzB,EAAAn8B,IAAAzlB,GAzBA,GAAA4hD,GAAArtD,IA4BA,OA3BA,kBAAA0lB,KACAA,EAAAksC,EACAA,EAAAvrC,EACAA,EAAA,MAIA,mBAAAX,KACAA,EAAAksC,EACAA,EAAAvrC,EACAA,EAAA,MAEAX,GACAi/B,EAAA,oBAAAktB,EAAA,cAAAhhD,EAAA,2BAcAw8B,EAAArnD,IAAA6qB,GAAAxtB,KAAA,SAAAoI,GACA,GAAAA,EAAA0a,OAAAE,EACA,KAAA8+B,GAAA0P,GAGA,OAAA0rB,GAAA90E,IACG,SAAArF,GAGH,GAAAA,EAAAsC,SAAAitD,GAAA5sD,QACA,MAAAw3E,IAA+Bn7D,IAAAyL,GAE/B,MAAAzqB,OAKA4nD,GAAAntD,UAAAwyE,iBACAnyB,EAAA,4BAAArwB,EAAAghD,EAAAxrD,EACAnc,GACA,GAAAlI,GAAAhC,IACAgC,GAAAgE,IAAA6qB,EAAA,SAAAzqB,EAAA5E,GAEA,MAAA4E,OACA8D,GAAA9D,GAGA5E,EAAA2kB,OAAAE,MACAnc,GAAAi7C,EAAA0P,KAIArzD,EAAAwkD,oBAGAxkD,GAAAwkD,aAAA6rB,GACA,IAAAjxE,OAAA6M,KAAAjM,EAAAwkD,cAAA9iD,cACA1B,GAAAwkD,iBAEAhkD,GAAAkvB,IAAA1vB,EAAA0I,IANAA,QAUA8jD,GAAAntD,UAAAoyE,OACA/xB,EAAA,kBAAAgyB,EAAAC,EAAAjgE,EAAAhJ,GACA,GAAAuB,EACA,iBAAA0nE,IAEA1nE,GACA2Z,IAAA8tD,EACA/sD,KAAAgtD,GAEA,kBAAAjgE,KACAhJ,EAAAgJ,EACAA,QAIAzH,EAAAynE,EACA,kBAAAC,IACAjpE,EAAAipE,EACAjgE,OAEAhJ,EAAAgJ,EACAA,EAAAigE,IAGAjgE,QACAA,EAAAutE,YAAA,CACA,IAAA1vD,IAAgB3L,IAAA3Z,EAAA2Z,IAAAe,KAAA1a,EAAA0a,MAAAjT,EAAAmT,IAEhB,OADA0K,GAAA2jB,UAAA,EACA8W,GAAAz6B,EAAA3L,MAAA,kBAAAplB,MAAAijE,aACAjjE,KAAAijE,aAAAx3D,EAAAvB,OAEAlK,MAAAq1C,UAAiBniB,MAAAnC,IAAe7d,EAAAq5C,GAAAriD,MAGhC8jD,GAAAntD,UAAAyzE,SACApzB,EAAA,oBAAAsE,EAAAtyC,EAAAhJ,GAcA,QAAAw2E,GAAArgF,EAAAsgF,GACA9R,EAAAjwC,IAAAv+B,IACAwuE,EAAAl+C,IAAAtwB,GAAuBwuE,aAEvBA,EAAA7oE,IAAA3F,GAAAwuE,QAAAxmE,KAAAs4E,GAGA,QAAAC,GAAAvgF,EAAAunD,GAEA,GAAAi5B,GAAAr7B,EAAAnlD,GAAAY,MAAA,EACA+mD,GAAAJ,EAAA,SAAAU,EAAAP,EAAAY,EAAApuB,EACArnB,GACA,GAAAmT,GAAA0hC,EAAA,IAAAY,EACAlvC,EAAAonE,EAAA56E,QAAAogB,EACA5M,MAAA,IAIAonE,EAAA/zE,OAAA2M,EAAA,GAEA,cAAAvG,EAAAzO,QACAi8E,EAAArgF,EAAAgmB,MAMAw6D,EAAAhvE,QAAA,SAAAwU,GACAq6D,EAAArgF,EAAAgmB,KAzCA,kBAAAnT,KACAhJ,EAAAgJ,EACAA,KAEA,IAAA+f,GAAAryB,OAAA6M,KAAA+3C,EAEA,KAAAvyB,EAAA/vB,OACA,MAAAgH,GAAA,QAGA,IAAAuE,GAAA,EACAogE,EAAA,GAAA9qB,GAkCA9wB,GAAAvlB,IAAA,SAAArN,GACAL,KAAA0iE,iBAAAriE,EAAA,SAAA+F,EAAAwhD,GACA,GAAAxhD,GAAA,MAAAA,EAAA3B,QAAA,YAAA2B,EAAA2C,QACA8lE,EAAAl+C,IAAAtwB,GAAyBwuE,QAAArpB,EAAAnlD,SAClB,IAAA+F,EAEP,MAAA8D,GAAA9D,EAEAw6E,GAAAvgF,EAAAunD,GAGA,KAAAn5C,IAAAwkB,EAAA/vB,OAAA,CAEA,GAAA49E,KAIA,OAHAjS,GAAAh9D,QAAA,SAAAtP,EAAAoJ,GACAm1E,EAAAn1E,GAAApJ,IAEA2H,EAAA,KAAA42E,OAGG9gF,QAUHguD,GAAAntD,UAAA4hD,QACAvB,EAAA,mBAAAhuC,EAAAhJ,GACAu4C,EAAAziD,KAAAkT,EAAAhJ,KAMA8jD,GAAAntD,UAAAkgF,gBACA7/B,EAAA,2BAAArwB,EAAA0R,EAAAr4B,GACA,GAAAlI,GAAAhC,IACAA,MAAA0iE,iBAAA7xC,EAAA,SAAAzqB,EAAA46E,GAEA,GAAA56E,EACA,MAAA8D,GAAA9D,EAEA,IAAA4mD,GAAAD,GAAAi0B,GACAC,KACAh5B,IACArnD,QAAA6M,KAAAu/C,GAAAn7C,QAAA,SAAAwU,GACA2mC,EAAA3mC,GAAAkc,GACA0+C,EAAA54E,KAAAge,KAIA2hC,EAAAg5B,EAAA,SAAA14B,EAAAP,EAAAY,EAAApuB,EAAArnB,GACA,GAAAmT,GAAA0hC,EAAA,IAAAY,CACA,eAAAz1C,EAAAzO,QAAAw8E,EAAAh7E,QAAAogB,MAAA,GACA4hC,EAAA5/C,KAAAge,KAGArkB,EAAA2gE,cAAA9xC,EAAAo3B,EAAA/9C,OAMA8jD,GAAAntD,UAAAoxE,QACA/wB,EAAA,mBAAAhuC,EAAAhJ,GACA,kBAAAgJ,KACAhJ,EAAAgJ,EACAA,KAGA,IAAAlR,GAAAhC,IACAkT,SAEAlR,EAAA2rD,iBAAA3rD,EAAA2rD,qBACA3rD,EAAA2rD,iBAAAtlD,MAA8B6K,OAAAhJ,aAC9B,IAAAlI,EAAA2rD,iBAAAzqD,QACAwqD,GAAA1rD,KAGAgsD,GAAAntD,UAAAgtD,SAAA,SAAA36C,EAAAhJ,GAQA,QAAAgiD,GAAAr5C,GACAquE,EAAA74E,KAAArG,EAAA++E,gBAAAluE,EAAAxS,GAAA,IAEA,QAAA8oC,GAAA7lC,GACA,GAAA+7D,GAAA/7D,EAAAsqD,QACA3M,IAAA78C,IAAA88E,GAAA79E,KAAA,WACA,MAAAmpB,GAAAxqB,EAAA,6BAAAyJ,GACA,QAAAA,EAAAmiD,UAAAniD,EAAAmiD,SAAAyR,KACA5zD,EAAAmiD,SAAAyR,EACA5zD,OAIKpI,KAAA,WACL6G,EAAA,MAAsBrE,IAAA,MACjBiJ,MAAA5E,GAtBL,GAAAlI,GAAAhC,KACA08E,GACAvc,aAAA,EACAvS,SAAA16C,EAAA06C,UAAA,GAEAszB,IAmBAl/E,GAAAqyB,QAAAqoD,GACAxmE,GAAA,SAAAg2C,GACAh2C,GAAA,WAAAizB,GACAjzB,GAAA,QAAAhM,IAKA8jD,GAAAntD,UAAAmF,IAAAk7C,EAAA,eAAA7gD,EAAA6S,EAAAxI,GAaA,QAAAy2E,KACA,GAAA/2E,MACAqE,EAAA45C,EAAAnlD,MAEA,OAAAuL,OAKA45C,GAAAx2C,QAAA,SAAA42C,GACAzmD,EAAAgE,IAAA3F,GACAgmB,IAAAoiC,EACAR,KAAA/0C,EAAA+0C,KACAwD,OAAAv4C,EAAAu4C,OACA/T,YAAAxkC,EAAAwkC,aACO,SAAAtxC,EAAAqF,GACP,GAAArF,EAaAgE,EAAA/B,MAAuBwmE,QAAApmB,QAbvB,CAGA,OADA24B,GACAzgF,EAAA,EAAAqN,EAAA5D,EAAAlH,OAA4CvC,EAAAqN,EAAOrN,IACnD,GAAAyJ,EAAAzJ,GAAAkF,IAAAuE,EAAAzJ,GAAAkF,GAAAsgB,OAAA1a,EAAA0a,KAAA,CACAi7D,GAAA,CACA,OAGAA,GACAh3E,EAAA/B,MAAyBxC,GAAA4F,IAKzBgD,IACAA,GACA/D,EAAA,KAAAN,OA5BAM,EAAA,KAAAN,GAbA,GAJA,kBAAA8I,KACAxI,EAAAwI,EACAA,MAEA,gBAAA7S,GACA,MAAAqK,GAAAy6C,EAAAgB,IAEA,IAAAqF,GAAAnrD,IAAA,kBAAAL,MAAA4iE,UACA,MAAA5iE,MAAA4iE,UAAAviE,EAAAqK,EAEA,IAAA29C,MAAArmD,EAAAhC,IAyCA,KAAAkT,EAAAywC,UA6BA,MAAA3jD,MAAA4hE,KAAAvhE,EAAA6S,EAAA,SAAA9M,EAAAgE,GACA,GAAAhE,EACA,MAAAsE,GAAAtE,EAGA,IAAAqF,GAAArB,EAAAqB,IACA67C,EAAAl9C,EAAAk9C,SACA/sB,EAAAnwB,EAAAmwB,GAEA,IAAArnB,EAAA+iC,UAAA,CACA,GAAAA,GAAAsS,EAAAjB,EACArR,GAAA/yC,SACAuI,EAAA6gD,WAAArW,GAQA,GAJAsV,GAAAjE,EAAA77C,EAAA0a,QACA1a,EAAAipC,UAAA,GAGAxhC,EAAA+0C,MAAA/0C,EAAA8/D,UAAA,CAQA,OAPAqO,GAAA51E,EAAA0a,KAAA/V,MAAA,KACAkxE,EAAA3oE,SAAA0oE,EAAA,OACA14B,EAAA04B,EAAA,GAEAhoD,EAAAuvB,EAAAtB,EAAAM,UACA7kD,EAAA,KAEApC,EAAA,EAAqBA,EAAA04B,EAAAn2B,OAAkBvC,IAAA,CACvC,GAAA4gF,GAAAloD,EAAA14B,GACA6gF,EAAAD,EAAAtuD,IAAAvlB,IAAA,SAAA8L,GAA0D,MAAAA,GAAAnZ,KAC1D4F,QAAA0iD,GACA84B,EAAAD,IAAAF,EAAA,GAEAG,IAAA1+E,GAAAy+E,KAAA,KACAz+E,EAAAw+E,GAIA,GAAAG,GAAA3+E,EAAAkwB,IAAAvlB,IAAA,SAAA8L,GAAkD,MAAAA,GAAAnZ,KAClD4F,QAAAwF,EAAA0a,KAAA/V,MAAA,WACAuxE,EAAA5+E,EAAAkwB,IAAA/vB,OAAAw+E,CAYA,IAXA3+E,EAAAkwB,IAAAnmB,OAAA40E,EAAAC,GACA5+E,EAAAkwB,IAAAynB,UAEAxnC,EAAA+0C,OACAx8C,EAAAohD,YACAjrB,MAAA7+B,EAAAglD,IAAAhlD,EAAAkwB,IAAA/vB,OAAA,EACA+vB,IAAAlwB,EAAAkwB,IAAAvlB,IAAA,SAAA2Y,GACA,MAAAA,GAAAhmB,OAIA6S,EAAA8/D,UAAA,CACA,GAAAjrB,GAAAhlD,EAAAglD,IAAAhlD,EAAAkwB,IAAA/vB,MACAuI,GAAAm2E,WAAA7+E,EAAAkwB,IAAAvlB,IAAA,SAAA2Y,GAEA,MADA0hC,MAEA1hC,IAAA0hC,EAAA,IAAA1hC,EAAAhmB,GACAoE,OAAA4hB,EAAAnT,KAAAzO,WAMA,GAAAyO,EAAAwkC,aAAAjsC,EAAAu6C,aAAA;AACA,GAAAtO,GAAAjsC,EAAAu6C,aACAv3C,EAAA7N,OAAA6M,KAAAiqC,GAAAx0C,MACA,QAAAuL,EACA,MAAA/D,GAAA,KAAAe,EAEA7K,QAAA6M,KAAAiqC,GAAA7lC,QAAA,SAAAlG,GACA3L,KAAA6hE,eAAAp2D,EAAA2Z,IAAAzZ,EAAA+rC,EAAA/rC,IAIA0a,IAAA5a,EAAA0a,KACAwxB,OAAAzkC,EAAAykC,OACApd,OACS,SAAAn0B,EAAAN,GACT,GAAAigD,GAAAt6C,EAAAu6C,aAAAr6C,EACAo6C,GAAAjgD,aACAigD,GAAAE,WACAF,GAAA7iD,SACAuL,GACA/D,EAAA,KAAAe,MAGOzJ,OACF,CACL,GAAAyJ,EAAAu6C,aACA,OAAAr6C,KAAAF,GAAAu6C,aAEAv6C,EAAAu6C,aAAAllD,eAAA6K,KACAF,EAAAu6C,aAAAr6C,GAAAs6C,MAAA,EAIAv7C,GAAA,KAAAe,KA9HA,YAAAyH,EAAAywC,UACA3jD,KAAA0iE,iBAAAriE,EAAA,SAAA+F,EAAAwhD,GACA,MAAAxhD,GACAsE,EAAAtE,IAEAiiD,EAAAD,EAAAR,GAAAl6C,IAAA,SAAA+6C,GACA,MAAAA,GAAApiC,UAEA86D,YAEK,CACL,IAAA74E,MAAAC,QAAA2K,EAAAywC,WAWA,MAAAj5C,GAAAy6C,EAAAG,GAAA,mBAVA+C,GAAAn1C,EAAAywC,SACA,QAAAhjD,GAAA,EAAuBA,EAAA0nD,EAAAnlD,OAAmBvC,IAAA,CAC1C,GAAAqN,GAAAq6C,EAAA1nD,EAEA,iCAAA0rB,KAAAre,GACA,MAAAtD,GAAAy6C,EAAAuK,KAGAyxB,OAkHAnzB,GAAAntD,UAAAuyE,cACAlyB,EAAA,yBAAArwB,EAAAghD,EAAA3+D,EAAAhJ,GACA,GAAAlI,GAAAhC,IACAkT,aAAAyE,YACAzN,EAAAgJ,EACAA,MAEAlT,KAAA4hE,KAAA/wC,EAAA3d,EAAA,SAAA9M,EAAAvC,GACA,MAAAuC,GACA8D,EAAA9D,GAEAvC,EAAA4H,IAAAu6C,cAAAniD,EAAA4H,IAAAu6C,aAAA6rB,IACA3+D,EAAAqnB,IAAA12B,EAAA02B,IACArnB,EAAAykC,QAAA,EACA31C,EAAA6/D,eAAAhxC,EAAAghD,EACAhuE,EAAA4H,IAAAu6C,aAAA6rB,GAAA3+D,EAAAhJ,GAHAgJ,QAKAhJ,EAAAi7C,EAAAwQ,SAKA3H,GAAAntD,UAAA+rB,QACAs0B,EAAA,mBAAAhuC,EAAAhJ,GAYA,GAXA,kBAAAgJ,KACAhJ,EAAAgJ,EACAA,MAEAA,EAAA8yB,KAAA,mBAAA9yB,GAAA8yB,KAAA9yB,EAAA8yB,KAAA,EACA9yB,EAAAsgE,YACAtgE,EAAAE,SAAAF,EAAAsgE,WAEAtgE,EAAAugE,UACAvgE,EAAAG,OAAAH,EAAAugE,SAEA,QAAAvgE,GAAA,CACA,IAAA5K,MAAAC,QAAA2K,EAAAzF,MACA,MAAAvD,GAAA,GAAApI,WAAA,iCAEA,IAAA+/E,IACA,2BAAAnuE,OAAA,SAAAmuE,GACA,MAAAA,KAAA3uE,KACK,EACL,IAAA2uE,EAKA,WAJA33E,GAAAi7C,EAAA66B,GACA,oBAAA6B,EACA,sCAIA,aAAA7hF,KAAA0lB,OACA,MAAA0nC,IAAAptD,KAAAkT,EAAAhJ,GAIA,MAAAlK,MAAAstD,SAAAp6C,EAAAhJ,KAGA8jD,GAAAntD,UAAAwzB,QAAA,SAAAnhB,EAAAhJ,GAKA,MAJA,kBAAAgJ,KACAhJ,EAAAgJ,EACAA,MAEA,GAAA84C,IAAAhsD,KAAAkT,EAAAhJ,IAGA8jD,GAAAntD,UAAA2hE,MAAAthB,EAAA,iBAAAh3C,GAGA,MAFAlK,MAAAuhD,SAAA,EACAvhD,KAAAuW,KAAA,UACAvW,KAAAuiE,OAAAr4D,KAGA8jD,GAAAntD,UAAAo/B,KAAAihB,EAAA,gBAAAh3C,GACA,GAAAlI,GAAAhC,IACAA,MAAAiiE,MAAA,SAAA77D,EAAA65B,GACA,MAAA75B,GACA8D,EAAA9D,IAGA65B,EAAAsS,QAAAtS,EAAAsS,SAAAvwC,EAAA8G,KACAm3B,EAAAwS,mBAAAzwC,EAAAywC,iBAAA,SAAAzwC,EAAA0jB,QACAua,EAAAyS,QAAA1wC,EAAA0jB,WACAxb,GAAA,KAAA+1B,QAIA+tB,GAAAntD,UAAAR,GAAA6gD,EAAA,cAAAh3C,GACA,MAAAlK,MAAAolB,IAAAlb,KAIA8jD,GAAAntD,UAAA6kB,KAAA,WACA,wBAAA1lB,MAAAkmB,MAAAlmB,KAAAkmB,QAAAlmB,KAAA0yC,SAGAsb,GAAAntD,UAAAw0C,SACA6L,EAAA,oBAAAsE,EAAAtyC,EAAAhJ,GAcA,GAbA,kBAAAgJ,KACAhJ,EAAAgJ,EACAA,MAGAA,QAEA5K,MAAAC,QAAAi9C,KACAA,GACAtyB,KAAAsyB,KAIAA,MAAAtyB,OAAA5qB,MAAAC,QAAAi9C,EAAAtyB,MACA,MAAAhpB,GAAAi7C,EAAA46B,IAGA,QAAAp/E,GAAA,EAAiBA,EAAA6kD,EAAAtyB,KAAAhwB,SAAqBvC,EACtC,mBAAA6kD,GAAAtyB,KAAAvyB,IAAA2H,MAAAC,QAAAi9C,EAAAtyB,KAAAvyB,IACA,MAAAuJ,GAAAi7C,EAAA86B,IAIA,IAAA6B,EAYA,IAXAt8B,EAAAtyB,KAAArhB,QAAA,SAAApG,GACAA,EAAAu6C,cACAplD,OAAA6M,KAAAhC,EAAAu6C,cAAAn0C,QAAA,SAAA/I,GACAg5E,KAAA/zB,GAAAjlD,GACA2C,EAAAu6C,aAAAl9C,GAAA8qD,cACAjP,EAAA,oBAAA77C,EAAA,cAAA2C,EAAA2Z,IAAA,+BAMA08D,EACA,MAAA53E,GAAAi7C,EAAAO,GAAAo8B,GAGA,cAAA5uE,KACA,aAAAsyC,GACAtyC,EAAA6iD,UAAAvQ,EAAAuQ,UAEA7iD,EAAA6iD,WAAA,EAIA,IAAArjB,GAAA1yC,IACAkT,GAAA6iD,WAAA,SAAArjB,EAAAhtB,QAGA8/B,EAAAtyB,KAAAviB,KAAA+7C,IAGAF,GAAAhH,EAAAtyB,KAKA,IAAAD,GAAAuyB,EAAAtyB,KAAAxlB,IAAA,SAAAjC,GACA,MAAAA,GAAA2Z,KAGA,OAAAplB,MAAA0hE,UAAAlc,EAAAtyC,EAAA,SAAA9M,EAAAvC,GACA,GAAAuC,EACA,MAAA8D,GAAA9D,EASA,IAPA8M,EAAA6iD,YAEAlyD,IAAA6P,OAAA,SAAA8F,GACA,MAAAA,GAAAnT,SAIA,SAAAqsC,EAAAhtB,OACA,OAAA/kB,GAAA,EAAAqN,EAAAnK,EAAAX,OAAqCvC,EAAAqN,EAAOrN,IAC5CkD,EAAAlD,GAAAN,GAAAwD,EAAAlD,GAAAN,IAAA4yB,EAAAtyB,EAIAuJ,GAAA,KAAArG,OAIAmqD,GAAAntD,UAAA2xC,0BACA0O,EAAA,qCAAA6gC,EACA73E,GAGA,QAAAwiB,GAAAjhB,GAEA,MADAA,GAAAu2E,aAAAv2E,EAAAu2E,kBACAv2E,EAAAu2E,aAAAD,KAGAt2E,EAAAu2E,aAAAD,IAAA,EACAt2E,GARA,GAAAw2E,GAAA,GAAAjiF,MAAAsC,YAAAy/E,EAAA/hF,KAAA24C,OAUAnsB,GAAAxsB,KAAA,6BAAA0sB,GACArpB,KAAA,WACA6G,EAAA,MAAsBuiB,GAAAw1D,MACjBnzE,MAAA5E,KAGL8jD,GAAAntD,UAAAqvB,QACAgxB,EAAA,mBAAAhuC,EAAAhJ,GAUA,QAAAg4E,KAEAlgF,EAAAkhE,SAAAhwD,EAAA,SAAA9M,EAAA9C,GACA,MAAA8C,GACA8D,EAAA9D,IAEApE,EAAAw/C,YAAA,EACAx/C,EAAAuU,KAAA,iBACArM,GAAA,KAAA5G,IAA8BuC,IAAA,OAhB9B,kBAAAqN,KACAhJ,EAAAgJ,EACAA,KAGA,IAAAlR,GAAAhC,KACAuuD,IAAA,cAAAvsD,OAAAwsD,UAcA,gBAAAxsD,EAAA0jB,OAEAw8D,QAGAlgF,GAAAgE,IAAA,sCAAAI,EAAAkxE,GACA,GAAAlxE,EAEA,aAAAA,EAAA3B,OACAyF,EAAA9D,GAEA87E,GAGA,IAAAF,GAAA1K,EAAA0K,aACA3wD,EAAArvB,EAAAM,YACA6/E,EAAAvhF,OAAA6M,KAAAu0E,GAAAt0E,IAAA,SAAA5E,GAGA,GAAAs5E,GAAA7zB,EACAzlD,EAAA7B,QAAA,GAAAghB,QAAA,IAAAoJ,EAAAG,QAAA,IAAA1oB,CACA,WAAAuoB,GAAA+wD,EAAApgF,EAAA22C,QAAAzoB,WAEA+wB,IAAA78C,IAAA+9E,GAAA9+E,KAAA6+E,EAAAh4E,OAUA+jD,GAAAptD,UAAAwhF,QAAA,WACA,GAAAj5E,EACA,IAAApJ,KAAA4hD,OACA,KAAAx4C,EAAApJ,KAAAqV,MAAAy4C,SACA1kD,EAAApJ,KAAA4hD,YAGA,MAAAx4C,EAAApJ,KAAAqV,MAAAy4C,SACA1kD,KAKA6kD,GAAAptD,UAAAsuD,KAAA,SAAA/oD,GACApG,KAAA4hD,OAAAx7C,EACApG,KAAAqiF,WAGAp0B,GAAAptD,UAAAuuD,MAAA,SAAA3iC,GACAzsB,KAAA0hD,SAAA,EACA1hD,KAAAysB,KACAzsB,KAAAqiF,WAGAp0B,GAAAptD,UAAA8gD,QAAA,SAAAv4C,GACApJ,KAAAqV,MAAAhN,KAAAe,GACApJ,KAAA4hD,QACA5hD,KAAAqiF,WAuFA/3E,GAAA8jD,GAAAJ,IA2DAI,GAAAzlC,SAEAylC,GAAAD,YACAC,GAAAC,qBAEAD,GAAA58B,OAAA,SAEA,IAAA+9B,IAAA,GAAA9K,IAAA/U,YAoBA2f,IAAAjB,IAEAA,GAAA1b,QAAA,SAAAryC,EAAAmB,EAAA8gF,GAEA9gF,EAAA0tD,UACAd,GAAAD,SAAA9tD,GAAAmB,EACA8gF,GACAl0B,GAAAC,kBAAAhmD,KAAAhI,KAKA+tD,GAAA98B,OAAA,SAAA9vB,GACA,qBAAAA,GACAA,EAAA4sD,QACG,oBAAA5sD,IAAA,IAAAZ,OAAA6M,KAAAjM,GAAA0B,OACH,SAAAsD,OAAA,wBAAAhF,EAAA,sCAEAZ,QAAA6M,KAAAjM,GAAAqQ,QAAA,SAAAxR,GACA+tD,GAAAvtD,UAAAR,GAAAmB,EAAAnB,KAGA,MAAA+tD,KAGAA,GAAAm0B,SAAA,SAAAC,GACA,QAAAC,GAAA35E,EAAAoK,GACA,MAAAlT,gBAAAyiF,IAIAvvE,QAEApK,GAAA,gBAAAA,KACAoK,EAAApK,EACAA,EAAAoK,EAAApK,WACAoK,GAAApK,MAGAoK,EAAAs6C,MAAsBi1B,EAAAC,WAAAxvE,OACtBk7C,IAAA7tD,KAAAP,KAAA8I,EAAAoK,IAZA,GAAAuvE,GAAA35E,EAAAoK,GA4BA,MAbA5I,IAAAm4E,EAAAr0B,IAEAq0B,EAAAp0B,kBAAAD,GAAAC,kBAAAptD,QACAL,OAAA6M,KAAA2gD,IAAAv8C,QAAA,SAAAlG,GACAA,IAAA82E,KACAA,EAAA92E,GAAAyiD,GAAAziD,MAMA82E,EAAAC,WAAAl1B,MAAmCxtD,KAAA0iF,WAAAF,GAEnCC,EAIA,IAAAzsE,IAAA,OAEAo4C,IAAAp4C,UASA,IAuvDAquD,IAvvDAhU,GAAA9jB,IACA,MACA,OACA,eACA,WACA,aACA,aACA,aACA,qBACA,aACA,YAEA,kBACA,qBACA,0BACA,4BACA,qBAEA,aAIAgkB,GAAAhkB,IACA,eAEA,kBACA,qBACA,0BACA,4BACA,uBA6GAilB,GAAA,SAAAt5C,GACA,MAAAyqE,MAAAzqE,IAGAq6C,GAAA,SAAAr6C,GACA,MAAAkH,MAAAlH,IAoHA66C,GAAAr7C,EAAA2K,cAAA3K,EAAAlJ,WACA6kD,GAAA,MAwVAqQ,GAAA,EAKArK,GAAA,iBAGAhB,GAAA,cAEAb,GAAA,eAGAc,GAAA,mBAIAiB,GAAA,aAEAD,GAAA,cAEAsF,GAAA,sBA0OA/D,GAAA,GAAArW,GA2rBAya,IAAA,EACA5pD,MA+NAotD,GAAA,GAAA1e,IAEAqf,GAAA,GAAArf,GAyuBAsc,IAAAnR,MAAA,WAIA,GAAAigB,GAAA,mBAAA7C,eACA,4BAAAjgD,KAAAne,UAAA4Z,aACA,SAAAuE,KAAAne,UAAA4Z,aACA,aAAAuE,KAAAne,UAAA00E,SAIA,QAAAzT,GAAA,mBAAA9L,YACA,mBAAApL,aAcA,IAAA4qB,IAAA,SAAAxxD,GACAA,EAAAqhB,QAAA,MAAA2tB,IAAA,IAuEAkK,GAAA,EAIAnD,GAAAtC,GAAA,kBAGAmB,GAAAnB,GAAA,eAEAkB,GAAAlB,GAAA,gBACA2D,GAAA3D,GAAA,eACAqF,GAAArF,GAAA,kBAGAc,GAAAd,GAAA,oBAydAiD,GAAA,GAAAhkB,IA4BA2iB,GAAA,GAAAliB,GAqCA2mB,GAAA,EAGA5C,GACA,sDACAtC,GAAA,kBACA8C,GACA,4DACA9C,GAAA,iBACAqC,GACA,sDACAlB,GAAA,gBACAsC,GACA,sDACA9D,GAAA,SACA6D,GACA,gEACA7D,GAAA,iBAEAuD,GAAAlD,GACA,UAAAmB,GAAA,cAEA8B,GAAAjD,GAAA,gBACAA,GAAA,wBACAA,GAAA,kBACAA,GAAA,gBACAmB,GAAA,mBAggCAwF,IAAA1d,SAEA0d,GAAApe,YAAA,CAEA,IAAAs0B,IAAA,SAAAzxD,GACAA,EAAAqhB,QAAA,SAAAk6B,IAAA,IAuPA8B,GAAAF,KAWAM,GAAA,aA8KA54B,GAAA,GACAu8B,GAAA,GAEAE,MAEAxB,GAAAxoD,GAAA,eA87BAmoD,IAAA5hB,MAAA,WACA,SAGA,IAAA6zB,IAAA,SAAA1xD,GACAA,EAAAqhB,QAAA,OAAAo+B,IAAA,GACAz/C,EAAAqhB,QAAA,QAAAo+B,IAAA,IAkBAl4D,IAAA,IACAH,GAAA,EACAuB,GAAA,EA4WAu6D,IAAA1zE,UAAAgjB,IAAA,SAAAF,GAMA,MALA3jB,MAAA+J,QAAA/J,KAAA+J,QAAA+E,MAAA,cAEGzL,KAAA,WACH,MAAAsgB,OAEA3jB,KAAA+J,SAEAwqE,GAAA1zE,UAAAk1C,OAAA,WACA,MAAA/1C,MAAA+J,SA0FAO,GAAAuoC,GAAArsC,OAYA8D,GAAAwoC,GAAAtsC,OAYA8D,GAAAoqE,GAAAluE,MAuCA,IAAAuuE,IAAApwB,EAAApV,KAAA,YACAhnC,GAAAD,MAAAC,QACAoS,GAAAjV,KAAAmsB,MAqFA0jB,MACAuD,GAAA,GAAAy7B,IACAoC,GAAA,GA8FAK,IACAgM,KAAA,SAAAv1E,EAAAwd,GACA,MAAA2pD,IAAA3pD,IAGAg4D,OAAA,SAAAx1E,EAAAwd,GACA,MAAAA,GAAA/nB,QAGAggF,OAAA,SAAAz1E,EAAAwd,GAGA,QAAAk4D,GAAAl4D,GAEA,OADAm4D,GAAA,EACAziF,EAAA,EAAA6I,EAAAyhB,EAAA/nB,OAA0CvC,EAAA6I,EAAS7I,IAAA,CACnD,GAAAwX,GAAA8S,EAAAtqB,EACAyiF,IAAAjrE,IAEA,MAAAirE,GAEA,OACAxO,OAAA3pD,GACAxe,IAAAD,KAAAC,IAAApL,MAAA,KAAA4pB,GACAhe,IAAAT,KAAAS,IAAA5L,MAAA,KAAA4pB,GACAxc,MAAAwc,EAAA/nB,OACAigF,SAAAl4D,MA2pBAiuB,GAAAzuC,GAAA,WACA,GAAAgiB,GAAAzsB,IACA,gBAAAysB,EAAA/G,OACAyxD,GAAA1qD,GAGA,kBAAAA,GAAA+pD,aACAD,GAAA9pD,GAEAwrB,GAAAxrB,KA0EAhd,GAAA,SAAArG,EAAA8J,EAAAhJ,GACA,kBAAAgJ,KACAhJ,EAAAgJ,EACAA,MAEAA,IAAA4iE,GAAA5iE,MAEA,kBAAA9J,KACAA,GAAWsE,IAAAtE,GAGX,IAAAqjB,GAAAzsB,KACA+J,EAAAk3C,GAAA1yC,UAAAlL,KAAA,WACA,MAAAu1C,IAAAnsB,EAAArjB,EAAA8J,IAGA,OADAvI,IAAAZ,EAAAG,GACAH,GAIAs5E,IACA5zE,SACAypC,gBAyLA+/B,GAAA,EACAD,GAAA,UAQAE,GAAA,EACAU,GAAA,CAoEAT,IAAAt4E,UAAAi7E,gBAAA,SAAAlD,EAAAC,GACA,GAAA72E,GAAAhC,IACA,OAAAA,MAAAsjF,aAAA1K,EAAAC,GAAAx1E,KAAA,WACA,MAAArB,GAAAuhF,aAAA3K,EAAAC,MAIAM,GAAAt4E,UAAAyiF,aAAA,SAAA1K,EAAAC,GACA,MAAAF,IAAA34E,KAAA0f,OAAA1f,KAAAK,GAAAu4E,EACAC,EAAA74E,KAAAoqB,cAGA+uD,GAAAt4E,UAAA0iF,aAAA,SAAA3K,EAAAC,GACA,GAAA72E,GAAAhC,IACA,OAAAA,MAAAwjF,eACAviC,GAAA1yC,SAAA,GAEAoqE,GAAA34E,KAAA+rB,IAAA/rB,KAAAK,GAAAu4E,EACAC,EAAA74E,KAAAoqB,aACAtb,MAAA,SAAA1I,GACA,GAAA6zE,GAAA7zE,GAEA,MADApE,GAAAwhF,gBAAA,GACA,CAEA,MAAAp9E,KAIA,IAAAq9E,KACAtgF,UAAA,SAAAugF,EAAAC,GAEA,WAAA3wE,GAAA0wE,EAAA91B,SAAA+1B,EAAA/1B,UACA+1B,EAAA/1B,SAGA,GAEAg2B,EAAA,SAAAF,EAAAC,GAEA,MAAAvK,IAAAuK,EAAAD,GAAA91B,UAIAurB,IAAAt4E,UAAAy8E,cAAA,WACA,GAAAt7E,GAAAhC,IACA,OAAAgC,GAAA0d,OAAA1Z,IAAAhE,EAAA3B,IAAAgD,KAAA,SAAAqgF,GACA,MAAA1hF,GAAAwhF,eACAviC,GAAA1yC,QAAAm1E,EAAA91B,UAGA5rD,EAAA+pB,IAAA/lB,IAAAhE,EAAA3B,IAAAgD,KAAA,SAAAsgF,GAIA,GAAAD,EAAA1tE,UAAA2tE,EAAA3tE,QACA,MAAA4jE,GAGA,IAAA5jE,EAOA,OALAA,GADA0tE,EAAA1tE,QACA0tE,EAAA1tE,QAAA+D,WAEA,YAGA/D,IAAAytE,IACAA,GAAAztE,GAAA0tE,EAAAC,GAGA/J,IACK,SAAAxzE,GACL,SAAAA,EAAA3B,QAAAi/E,EAAA91B,SACA,MAAA5rD,GAAA+pB,IAAAmF,KACA9L,IAAApjB,EAAA3B,GACAutD,SAAAgsB,KACSv2E,KAAA,WACT,MAAAu2E,KACS,SAAAxzE,GACT,MAAA6zE,IAAA7zE,IACApE,EAAAwhF,gBAAA,EACAE,EAAA91B,UAGAgsB,IAGA,MAAAxzE,OAEG0I,MAAA,SAAA1I,GACH,SAAAA,EAAA3B,OACA,KAAA2B,EAEA,OAAAwzE,MAwEA,IAAAU,IAAA,CAwgBAhwE,IAAAmzE,GAAAh5B,GAAA/U,cAqBA+tC,GAAA58E,UAAAwJ,OAAA,WACArK,KAAAm4E,WAAA,EACAn4E,KAAAyc,MAAA,YACAzc,KAAAuW,KAAA,WAGAknE,GAAA58E,UAAAuuD,MAAA,SAAArjC,EAAArM,GAOA,QAAAusC,KACAjqD,EAAAqI,SAIA,QAAA2uC,KACAjtB,EAAA1V,eAAA,YAAA41C,GACAvsC,EAAArJ,eAAA,YAAA41C,GAbA,GAAAjqD,GAAAhC,IACAgC,GAAA6hF,eAGA7hF,EAAA6hF,cAAA,EAKA93D,EAAA5iB,KAAA,YAAA8iD,GACAvsC,EAAAvW,KAAA,YAAA8iD,GAKAjqD,EAAAmH,KAAA,WAAA6vC,KAwCA1uC,GAAA2zE,GAAAx5B,GAAA/U,cAyMAuuC,GAAAp9E,UAAAwJ,OAAA,WACArK,KAAAk/E,WACAl/E,KAAAk/E,UAAA,EACAl/E,KAAAqI,KAAAgC,SACArK,KAAAq/E,KAAAh1E,WA2BA+jD,GAAA98B,OAAAuxD,IACAvxD,OAAAwxD,IACAxxD,OAAAyxD,IACAzxD,OAAA+xD,IACA/xD,OAAAkX,IAMA3oC,EAAAD,QAAAwuD,K1FmyT8B7tD,KAAKX,EAAU,WAAa,MAAOI,WAI3D,SAASH,EAAQD,EAASM,G2F52pBhC,YAIA,SAAAmpB,MAUA,QAAAllB,GAAAmlB,GACA,qBAAAA,GACA,SAAAxnB,WAAA,8BAEA9B,MAAAyc,MAAA8M,EACAvpB,KAAAqV,SACArV,KAAAwpB,QAAA,OACAF,IAAAD,GACAM,EAAA3pB,KAAAspB,GAsBA,QAAAM,GAAA7f,EAAA8f,EAAAC,GACA9pB,KAAA+J,UACA,kBAAA8f,KACA7pB,KAAA6pB,cACA7pB,KAAA+pB,cAAA/pB,KAAAgqB,oBAEA,kBAAAF,KACA9pB,KAAA8pB,aACA9pB,KAAAiqB,aAAAjqB,KAAAkqB,mBAgBA,QAAAC,GAAApgB,EAAAL,EAAAnH,GACAmf,EAAA,WACA,GAAA0I,EACA,KACAA,EAAA1gB,EAAAnH,GACK,MAAA8E,GACL,MAAAgjB,GAAApgB,OAAAF,EAAA1C,GAEA+iB,IAAArgB,EACAsgB,EAAApgB,OAAAF,EAAA,GAAAjI,WAAA,uCAEAuoB,EAAA9b,QAAAxE,EAAAqgB,KAoCA,QAAAE,GAAA9oB,GAEA,GAAA6B,GAAA7B,KAAA6B,IACA,IAAA7B,GAAA,gBAAAA,IAAA,kBAAA6B,GACA,kBACAA,EAAAhC,MAAAG,EAAAyB,YAKA,QAAA0mB,GAAA3nB,EAAAuoB,GAGA,QAAAC,GAAAjoB,GACA8G,IAGAA,GAAA,EACAghB,EAAApgB,OAAAjI,EAAAO,IAGA,QAAAkoB,GAAAloB,GACA8G,IAGAA,GAAA,EACAghB,EAAA9b,QAAAvM,EAAAO,IAGA,QAAAmoB,KACAH,EAAAE,EAAAD,GAlBA,GAAAnhB,IAAA,EAqBAe,EAAAugB,EAAAD,EACA,WAAAtgB,EAAA3F,QACA+lB,EAAApgB,EAAA7H,OAIA,QAAAooB,GAAAjhB,EAAAnH,GACA,GAAAqoB,KACA,KACAA,EAAAroB,MAAAmH,EAAAnH,GACAqoB,EAAAnmB,OAAA,UACG,MAAA4C,GACHujB,EAAAnmB,OAAA,QACAmmB,EAAAroB,MAAA8E,EAEA,MAAAujB,GAIA,QAAArc,GAAAhM,GACA,MAAAA,aAAAvC,MACAuC,EAEA8nB,EAAA9b,QAAA,GAAAvO,MAAAqpB,GAAA9mB,GAIA,QAAA0H,GAAAvB,GACA,GAAAqB,GAAA,GAAA/J,MAAAqpB,EACA,OAAAgB,GAAApgB,OAAAF,EAAArB,GAIA,QAAAtE,GAAAymB,GAqBA,QAAAC,GAAAvoB,EAAA5B,GAOA,QAAAoqB,GAAAC,GACAC,EAAAtqB,GAAAqqB,IACAE,IAAA1hB,GAAAH,IACAA,GAAA,EACAghB,EAAA9b,QAAAxE,EAAAkhB,IAVAjpB,EAAAuM,QAAAhM,GAAAc,KAAA0nB,EAAA,SAAA1kB,GACAgD,IACAA,GAAA,EACAghB,EAAApgB,OAAAF,EAAA1D,MAxBA,GAAArE,GAAAhC,IACA,uBAAAY,OAAAC,UAAAkZ,SAAAxZ,KAAAsqB,GACA,MAAA7qB,MAAAiK,OAAA,GAAAnI,WAAA,oBAGA,IAAA0H,GAAAqhB,EAAA3nB,OACAmG,GAAA,CACA,KAAAG,EACA,MAAAxJ,MAAAuO,WAQA,KALA,GAAA0c,GAAA,GAAA3iB,OAAAkB,GACA0hB,EAAA,EACAvqB,GAAA,EACAoJ,EAAA,GAAA/J,MAAAqpB,KAEA1oB,EAAA6I,GACAshB,EAAAD,EAAAlqB,KAEA,OAAAoJ,GAmBA,QAAAohB,GAAAN,GAmBA,QAAAvB,GAAA/mB,GACAP,EAAAuM,QAAAhM,GAAAc,KAAA,SAAAkC,GACA8D,IACAA,GAAA,EACAghB,EAAA9b,QAAAxE,EAAAxE,KAEK,SAAAc,GACLgD,IACAA,GAAA,EACAghB,EAAApgB,OAAAF,EAAA1D,MA3BA,GAAArE,GAAAhC,IACA,uBAAAY,OAAAC,UAAAkZ,SAAAxZ,KAAAsqB,GACA,MAAA7qB,MAAAiK,OAAA,GAAAnI,WAAA,oBAGA,IAAA0H,GAAAqhB,EAAA3nB,OACAmG,GAAA,CACA,KAAAG,EACA,MAAAxJ,MAAAuO,WAMA,KAHA,GAAA5N,IAAA,EACAoJ,EAAA,GAAA/J,MAAAqpB,KAEA1oB,EAAA6I,GACA8f,EAAAuB,EAAAlqB,GAEA,OAAAoJ,GA7OA,GAAA2X,GAAAxhB,EAAA,IAKAmqB,KAEAe,GAAA,YACAC,GAAA,aACA9B,GAAA,UAEA1pB,GAAAD,QAAAuE,EAcAA,EAAAtD,UAAA,eAAAipB,GACA,MAAA9pB,MAAAqD,KAAA,KAAAymB,IAEA3lB,EAAAtD,UAAAwC,KAAA,SAAAwmB,EAAAC,GACA,qBAAAD,IAAA7pB,KAAAyc,QAAA4O,GACA,kBAAAvB,IAAA9pB,KAAAyc,QAAA2O,EACA,MAAAprB,KAEA,IAAA+J,GAAA,GAAA/J,MAAAsC,YAAA+mB,EACA,IAAArpB,KAAAyc,QAAA8M,EAAA,CACA,GAAAD,GAAAtpB,KAAAyc,QAAA4O,EAAAxB,EAAAC,CACAK,GAAApgB,EAAAuf,EAAAtpB,KAAAwpB,aAEAxpB,MAAAqV,MAAAhN,KAAA,GAAAuhB,GAAA7f,EAAA8f,EAAAC,GAGA,OAAA/f,IAaA6f,EAAA/oB,UAAAkpB,cAAA,SAAAxnB,GACA8nB,EAAA9b,QAAAvO,KAAA+J,QAAAxH,IAEAqnB,EAAA/oB,UAAAmpB,mBAAA,SAAAznB,GACA4nB,EAAAnqB,KAAA+J,QAAA/J,KAAA6pB,YAAAtnB,IAEAqnB,EAAA/oB,UAAAopB,aAAA,SAAA1nB,GACA8nB,EAAApgB,OAAAjK,KAAA+J,QAAAxH,IAEAqnB,EAAA/oB,UAAAqpB,kBAAA,SAAA3nB,GACA4nB,EAAAnqB,KAAA+J,QAAA/J,KAAA8pB,WAAAvnB,IAmBA8nB,EAAA9b,QAAA,SAAAvM,EAAAO,GACA,GAAA6H,GAAAugB,EAAAL,EAAA/nB,EACA,cAAA6H,EAAA3F,OACA,MAAA4lB,GAAApgB,OAAAjI,EAAAoI,EAAA7H,MAEA,IAAAgoB,GAAAngB,EAAA7H,KAEA,IAAAgoB,EACAZ,EAAA3nB,EAAAuoB,OACG,CACHvoB,EAAAya,MAAA4O,EACArpB,EAAAwnB,QAAAjnB,CAGA,KAFA,GAAA5B,IAAA,EACA6I,EAAAxH,EAAAqT,MAAAnS,SACAvC,EAAA6I,GACAxH,EAAAqT,MAAA1U,GAAAopB,cAAAxnB,GAGA,MAAAP,IAEAqoB,EAAApgB,OAAA,SAAAjI,EAAAqE,GACArE,EAAAya,MAAA2O,EACAppB,EAAAwnB,QAAAnjB,CAGA,KAFA,GAAA1F,IAAA,EACA6I,EAAAxH,EAAAqT,MAAAnS,SACAvC,EAAA6I,GACAxH,EAAAqT,MAAA1U,GAAAspB,aAAA5jB,EAEA,OAAArE,IAsDAmC,EAAAoK,UAQApK,EAAA8F,SAMA9F,EAAAC,MAuCAD,EAAAgnB,Q3Fo5pBM,SAAStrB,EAAQD,EAASM,I4F/mqBhC,SAAAwX,GAEA,GAAA44B,GACA,gBAAA54B,KACA,gBAAA9Q,eACA,gBAAA5E,WAAAhC,KAIA8jF,EAAAxzC,EAAAyzC,oBACAnjF,OAAAojF,oBAAA1zC,GAAArqC,QAAA,yBAGAg+E,EAAAH,GAAAxzC,EAAAyzC,kBAOA,IAJAzzC,EAAAyzC,mBAAA5gF,OAEAtD,EAAAD,QAAAM,EAAA,IAEA4jF,EAEAxzC,EAAAyzC,mBAAAE,MAGA,WACA3zC,GAAAyzC,mBACG,MAAA18E,GACHipC,EAAAyzC,mBAAA5gF,U5FqnqB8B5C,KAAKX,EAAU,WAAa,MAAOI,WAI3D,SAASH,EAAQD,EAASM,I6FrpqBhC,SAAAwX,EAAAxO,IAUA,SAAAwO,GACA,YA0BA,SAAAisB,GAAAugD,EAAAC,EAAAniF,EAAAoiF,GAEA,GAAAC,GAAAF,KAAAtjF,oBAAAyjF,GAAAH,EAAAG,EACAC,EAAA3jF,OAAAyB,OAAAgiF,EAAAxjF,WACAw5B,EAAA,GAAAmqD,GAAAJ,MAMA,OAFAG,GAAAE,QAAAC,EAAAR,EAAAliF,EAAAq4B,GAEAkqD,EAcA,QAAA55D,GAAAzpB,EAAAM,EAAAw+B,GACA,IACA,OAActa,KAAA,SAAAsa,IAAA9+B,EAAAX,KAAAiB,EAAAw+B,IACT,MAAA55B,GACL,OAAcsf,KAAA,QAAAsa,IAAA55B,IAiBd,QAAAk+E,MACA,QAAAK,MACA,QAAAC,MA4BA,QAAAC,GAAAhkF,IACA,yBAAAgR,QAAA,SAAA1M,GACAtE,EAAAsE,GAAA,SAAA66B,GACA,MAAAhgC,MAAAykF,QAAAt/E,EAAA66B,MAoCA,QAAA8kD,GAAAP,GACA,QAAAQ,GAAA5/E,EAAA66B,EAAAzxB,EAAAtE,GACA,GAAA+6E,GAAAr6D,EAAA45D,EAAAp/E,GAAAo/E,EAAAvkD,EACA,cAAAglD,EAAAt/D,KAEO,CACP,GAAAtb,GAAA46E,EAAAhlD,IACAz9B,EAAA6H,EAAA7H,KACA,OAAAA,IACA,gBAAAA,IACA0iF,EAAA1kF,KAAAgC,EAAA,WACA4B,QAAAoK,QAAAhM,EAAA2iF,SAAA7hF,KAAA,SAAAd,GACAwiF,EAAA,OAAAxiF,EAAAgM,EAAAtE,IACW,SAAA7D,GACX2+E,EAAA,QAAA3+E,EAAAmI,EAAAtE,KAIA9F,QAAAoK,QAAAhM,GAAAc,KAAA,SAAA8hF,GAgBA/6E,EAAA7H,MAAA4iF,EACA52E,EAAAnE,IACSH,GAhCTA,EAAA+6E,EAAAhlD,KA0CA,QAAAolD,GAAAjgF,EAAA66B,GACA,QAAAqlD,KACA,UAAAlhF,SAAA,SAAAoK,EAAAtE,GACA86E,EAAA5/E,EAAA66B,EAAAzxB,EAAAtE,KAIA,MAAAq7E,GAaAA,IAAAjiF,KACAgiF,EAGAA,GACAA,IA/BA,gBAAAn8E,MAAAq8E,SACAR,EAAA77E,EAAAq8E,OAAAh2C,KAAAw1C,GAGA,IAAAO,EAgCAtlF,MAAAykF,QAAAW,EAqBA,QAAAV,GAAAR,EAAAliF,EAAAq4B,GACA,GAAA5d,GAAA+oE,CAEA,iBAAArgF,EAAA66B,GACA,GAAAvjB,IAAAgpE,EACA,SAAAj/E,OAAA,+BAGA,IAAAiW,IAAAipE,EAAA,CACA,aAAAvgF,EACA,KAAA66B,EAKA,OAAA2lD,KAMA,IAHAtrD,EAAAl1B,SACAk1B,EAAA2F,QAEA,CACA,GAAA4lD,GAAAvrD,EAAAurD,QACA,IAAAA,EAAA,CACA,GAAAC,GAAAC,EAAAF,EAAAvrD,EACA,IAAAwrD,EAAA,CACA,GAAAA,IAAAE,EAAA,QACA,OAAAF,IAIA,YAAAxrD,EAAAl1B,OAGAk1B,EAAAyJ,KAAAzJ,EAAA2rD,MAAA3rD,EAAA2F,QAES,cAAA3F,EAAAl1B,OAAA,CACT,GAAAsX,IAAA+oE,EAEA,KADA/oE,GAAAipE,EACArrD,EAAA2F,GAGA3F,GAAA4rD,kBAAA5rD,EAAA2F,SAES,WAAA3F,EAAAl1B,QACTk1B,EAAA0J,OAAA,SAAA1J,EAAA2F,IAGAvjB,GAAAgpE,CAEA,IAAAT,GAAAr6D,EAAAu5D,EAAAliF,EAAAq4B,EACA,eAAA2qD,EAAAt/D,KAAA,CAOA,GAJAjJ,EAAA4d,EAAAjyB,KACAs9E,EACAQ,EAEAlB,EAAAhlD,MAAA+lD,EACA,QAGA,QACAxjF,MAAAyiF,EAAAhlD,IACA53B,KAAAiyB,EAAAjyB,MAGS,UAAA48E,EAAAt/D,OACTjJ,EAAAipE,EAGArrD,EAAAl1B,OAAA,QACAk1B,EAAA2F,IAAAglD,EAAAhlD,OAUA,QAAA8lD,GAAAF,EAAAvrD,GACA,GAAAl1B,GAAAygF,EAAA19E,SAAAmyB,EAAAl1B,OACA,IAAAA,IAAAhC,EAAA,CAKA,GAFAk3B,EAAAurD,SAAA,KAEA,UAAAvrD,EAAAl1B,OAAA,CACA,GAAAygF,EAAA19E,SAAAsrB,SAGA6G,EAAAl1B,OAAA,SACAk1B,EAAA2F,IAAA78B,EACA2iF,EAAAF,EAAAvrD,GAEA,UAAAA,EAAAl1B,QAGA,MAAA4gF,EAIA1rD,GAAAl1B,OAAA,QACAk1B,EAAA2F,IAAA,GAAAl+B,WACA,kDAGA,MAAAikF,GAGA,GAAAf,GAAAr6D,EAAAxlB,EAAAygF,EAAA19E,SAAAmyB,EAAA2F,IAEA,cAAAglD,EAAAt/D,KAIA,MAHA2U,GAAAl1B,OAAA,QACAk1B,EAAA2F,IAAAglD,EAAAhlD,IACA3F,EAAAurD,SAAA,KACAG,CAGA,IAAA9lD,GAAA+kD,EAAAhlD,GAEA,OAAAC,GAOAA,EAAA73B,MAGAiyB,EAAAurD,EAAAO,YAAAlmD,EAAA19B,MAGA83B,EAAAlyB,KAAAy9E,EAAAQ,QAQA,WAAA/rD,EAAAl1B,SACAk1B,EAAAl1B,OAAA,OACAk1B,EAAA2F,IAAA78B,GAUAk3B,EAAAurD,SAAA,KACAG,GANA9lD,GA3BA5F,EAAAl1B,OAAA,QACAk1B,EAAA2F,IAAA,GAAAl+B,WAAA,oCACAu4B,EAAAurD,SAAA,KACAG,GA2CA,QAAAM,GAAAC,GACA,GAAAC,IAAiBC,OAAAF,EAAA,GAEjB,KAAAA,KACAC,EAAAE,SAAAH,EAAA,IAGA,IAAAA,KACAC,EAAAG,WAAAJ,EAAA,GACAC,EAAAI,SAAAL,EAAA,IAGAtmF,KAAA4mF,WAAAv+E,KAAAk+E,GAGA,QAAAM,GAAAN,GACA,GAAAvB,GAAAuB,EAAAO,cACA9B,GAAAt/D,KAAA,eACAs/D,GAAAhlD,IACAumD,EAAAO,WAAA9B,EAGA,QAAAR,GAAAJ,GAIApkF,KAAA4mF,aAAwBJ,OAAA,SACxBpC,EAAAvyE,QAAAw0E,EAAArmF,MACAA,KAAAivB,OAAA,GA8BA,QAAAhE,GAAAJ,GACA,GAAAA,EAAA,CACA,GAAAk8D,GAAAl8D,EAAAm8D,EACA,IAAAD,EACA,MAAAA,GAAAxmF,KAAAsqB,EAGA,sBAAAA,GAAA1iB,KACA,MAAA0iB,EAGA,KAAArQ,MAAAqQ,EAAA3nB,QAAA,CACA,GAAAvC,IAAA,EAAAwH,EAAA,QAAAA,KACA,OAAAxH,EAAAkqB,EAAA3nB,QACA,GAAA+hF,EAAA1kF,KAAAsqB,EAAAlqB,GAGA,MAFAwH,GAAA5F,MAAAsoB,EAAAlqB,GACAwH,EAAAC,MAAA,EACAD,CAOA,OAHAA,GAAA5F,MAAAY,EACAgF,EAAAC,MAAA,EAEAD,EAGA,OAAAA,WAKA,OAAYA,KAAAw9E,GAIZ,QAAAA,KACA,OAAYpjF,MAAAY,EAAAiF,MAAA,GApfZ,GAEAjF,GAFA8jF,EAAArmF,OAAAC,UACAokF,EAAAgC,EAAAnmF,eAEAomF,EAAA,kBAAAj/E,kBACA++E,EAAAE,EAAAh/E,UAAA,aACAi/E,EAAAD,EAAAE,aAAA,gBAEAC,EAAA,gBAAAxnF,GACAynF,EAAA5vE,EAAAqsE,kBACA,IAAAuD,EAQA,YAPAD,IAGAxnF,EAAAD,QAAA0nF,GASAA,GAAA5vE,EAAAqsE,mBAAAsD,EAAAxnF,EAAAD,WAcA0nF,EAAA3jD,MAoBA,IAAA6hD,GAAA,iBACAU,EAAA,iBACAT,EAAA,YACAC,EAAA,YAIAK,KAYAwB,IACAA,GAAAP,GAAA,WACA,MAAAhnF,MAGA,IAAAwnF,GAAA5mF,OAAAgI,eACA6+E,EAAAD,OAAAv8D,OACAw8D,IACAA,IAAAR,GACAhC,EAAA1kF,KAAAknF,EAAAT,KAGAO,EAAAE,EAGA,IAAAC,GAAA9C,EAAA/jF,UACAyjF,EAAAzjF,UAAAD,OAAAyB,OAAAklF,EACA5C,GAAA9jF,UAAA6mF,EAAAplF,YAAAsiF,EACAA,EAAAtiF,YAAAqiF,EACAC,EAAAuC,GACAxC,EAAAgD,YAAA,oBAYAL,EAAAM,oBAAA,SAAAC,GACA,GAAA1kE,GAAA,kBAAA0kE,MAAAvlF,WACA,SAAA6gB,IACAA,IAAAwhE,GAGA,uBAAAxhE,EAAAwkE,aAAAxkE,EAAAra,QAIAw+E,EAAA/jD,KAAA,SAAAskD,GAUA,MATAjnF,QAAA+B,eACA/B,OAAA+B,eAAAklF,EAAAjD,IAEAiD,EAAAjlF,UAAAgiF,EACAuC,IAAAU,KACAA,EAAAV,GAAA,sBAGAU,EAAAhnF,UAAAD,OAAAyB,OAAAqlF,GACAG,GAOAP,EAAAQ,MAAA,SAAA9nD,GACA,OAAYklD,QAAAllD,IAkFZ6kD,EAAAC,EAAAjkF,WACAymF,EAAAxC,gBAKAwC,EAAAS,MAAA,SAAA7D,EAAAC,EAAAniF,EAAAoiF,GACA,GAAA4D,GAAA,GAAAlD,GACAnhD,EAAAugD,EAAAC,EAAAniF,EAAAoiF,GAGA,OAAAkD,GAAAM,oBAAAzD,GACA6D,EACAA,EAAA7/E,OAAA9E,KAAA,SAAA+G,GACA,MAAAA,GAAAhC,KAAAgC,EAAA7H,MAAAylF,EAAA7/E,UAsKA08E,EAAA6C,GAEAA,EAAAP,GAAA,YAEAO,EAAA3tE,SAAA,WACA,4BAkCAutE,EAAA75E,KAAA,SAAAwZ,GACA,GAAAxZ,KACA,QAAA9B,KAAAsb,GACAxZ,EAAApF,KAAAsD,EAMA,OAJA8B,GAAAitC,UAIA,QAAAvyC,KACA,KAAAsF,EAAAvK,QAAA,CACA,GAAAyI,GAAA8B,EAAA5D,KACA,IAAA8B,IAAAsb,GAGA,MAFA9e,GAAA5F,MAAAoJ,EACAxD,EAAAC,MAAA,EACAD,EAQA,MADAA,GAAAC,MAAA,EACAD,IAsCAm/E,EAAAr8D,SAMAu5D,EAAA3jF,WACAyB,YAAAkiF,EAEAv1D,MAAA,SAAAg5D,GAcA,GAbAjoF,KAAA6jC,KAAA,EACA7jC,KAAAmI,KAAA,EAGAnI,KAAA8jC,KAAA9jC,KAAAgmF,MAAA7iF,EACAnD,KAAAoI,MAAA,EACApI,KAAA4lF,SAAA,KAEA5lF,KAAAmF,OAAA,OACAnF,KAAAggC,IAAA78B,EAEAnD,KAAA4mF,WAAA/0E,QAAAg1E,IAEAoB,EACA,OAAAn/E,KAAA9I,MAEA,MAAA8I,EAAAq9B,OAAA,IACA8+C,EAAA1kF,KAAAP,KAAA8I,KACA0R,OAAA1R,EAAA7H,MAAA,MACAjB,KAAA8I,GAAA3F,IAMA6gC,KAAA,WACAhkC,KAAAoI,MAAA,CAEA,IAAA8/E,GAAAloF,KAAA4mF,WAAA,GACAuB,EAAAD,EAAApB,UACA,cAAAqB,EAAAziE,KACA,KAAAyiE,GAAAnoD,GAGA,OAAAhgC,MAAAooF,MAGAnC,kBAAA,SAAAr+D,GAMA,QAAAygE,GAAAC,EAAAC,GAYA,MAXAvD,GAAAt/D,KAAA,QACAs/D,EAAAhlD,IAAApY,EACAyS,EAAAlyB,KAAAmgF,EAEAC,IAGAluD,EAAAl1B,OAAA,OACAk1B,EAAA2F,IAAA78B,KAGAolF,EAjBA,GAAAvoF,KAAAoI,KACA,KAAAwf,EAmBA,QAhBAyS,GAAAr6B,KAgBAW,EAAAX,KAAA4mF,WAAA1jF,OAAA,EAA8CvC,GAAA,IAAQA,EAAA,CACtD,GAAA4lF,GAAAvmF,KAAA4mF,WAAAjmF,GACAqkF,EAAAuB,EAAAO,UAEA,aAAAP,EAAAC,OAIA,MAAA6B,GAAA,MAGA,IAAA9B,EAAAC,QAAAxmF,KAAA6jC,KAAA,CACA,GAAA2kD,GAAAvD,EAAA1kF,KAAAgmF,EAAA,YACAkC,EAAAxD,EAAA1kF,KAAAgmF,EAAA,aAEA,IAAAiC,GAAAC,EAAA,CACA,GAAAzoF,KAAA6jC,KAAA0iD,EAAAE,SACA,MAAA4B,GAAA9B,EAAAE,UAAA,EACa,IAAAzmF,KAAA6jC,KAAA0iD,EAAAG,WACb,MAAA2B,GAAA9B,EAAAG,gBAGW,IAAA8B,GACX,GAAAxoF,KAAA6jC,KAAA0iD,EAAAE,SACA,MAAA4B,GAAA9B,EAAAE,UAAA,OAGW,KAAAgC,EAMX,SAAAjiF,OAAA,yCALA,IAAAxG,KAAA6jC,KAAA0iD,EAAAG,WACA,MAAA2B,GAAA9B,EAAAG,gBAUA3iD,OAAA,SAAAre,EAAAsa,GACA,OAAAr/B,GAAAX,KAAA4mF,WAAA1jF,OAAA,EAA8CvC,GAAA,IAAQA,EAAA,CACtD,GAAA4lF,GAAAvmF,KAAA4mF,WAAAjmF,EACA,IAAA4lF,EAAAC,QAAAxmF,KAAA6jC,MACAohD,EAAA1kF,KAAAgmF,EAAA,eACAvmF,KAAA6jC,KAAA0iD,EAAAG,WAAA,CACA,GAAAgC,GAAAnC,CACA,QAIAmC,IACA,UAAAhjE,GACA,aAAAA,IACAgjE,EAAAlC,QAAAxmD,GACAA,GAAA0oD,EAAAhC,aAGAgC,EAAA,KAGA,IAAA1D,GAAA0D,IAAA5B,aAIA,OAHA9B,GAAAt/D,OACAs/D,EAAAhlD,MAEA0oD,GACA1oF,KAAAmF,OAAA,OACAnF,KAAAmI,KAAAugF,EAAAhC,WACAX,GAGA/lF,KAAA81C,SAAAkvC,IAGAlvC,SAAA,SAAAkvC,EAAA2B,GACA,aAAA3B,EAAAt/D,KACA,KAAAs/D,GAAAhlD,GAcA,OAXA,UAAAglD,EAAAt/D,MACA,aAAAs/D,EAAAt/D,KACA1lB,KAAAmI,KAAA68E,EAAAhlD,IACO,WAAAglD,EAAAt/D,MACP1lB,KAAAooF,KAAApoF,KAAAggC,IAAAglD,EAAAhlD,IACAhgC,KAAAmF,OAAA,SACAnF,KAAAmI,KAAA,OACO,WAAA68E,EAAAt/D,MAAAihE,IACP3mF,KAAAmI,KAAAw+E,GAGAZ,GAGAhwC,OAAA,SAAA2wC,GACA,OAAA/lF,GAAAX,KAAA4mF,WAAA1jF,OAAA,EAA8CvC,GAAA,IAAQA,EAAA,CACtD,GAAA4lF,GAAAvmF,KAAA4mF,WAAAjmF,EACA,IAAA4lF,EAAAG,eAGA,MAFA1mF,MAAA81C,SAAAywC,EAAAO,WAAAP,EAAAI,UACAE,EAAAN,GACAR,IAKAj3E,MAAA,SAAA03E,GACA,OAAA7lF,GAAAX,KAAA4mF,WAAA1jF,OAAA,EAA8CvC,GAAA,IAAQA,EAAA,CACtD,GAAA4lF,GAAAvmF,KAAA4mF,WAAAjmF,EACA,IAAA4lF,EAAAC,WAAA,CACA,GAAAxB,GAAAuB,EAAAO,UACA,cAAA9B,EAAAt/D,KAAA,CACA,GAAAijE,GAAA3D,EAAAhlD,GACA6mD,GAAAN,GAEA,MAAAoC,IAMA,SAAAniF,OAAA,0BAGAoiF,cAAA,SAAA/9D,EAAAs7D,EAAAC,GAaA,MAZApmF,MAAA4lF,UACA19E,SAAA+iB,EAAAJ,GACAs7D,aACAC,WAGA,SAAApmF,KAAAmF,SAGAnF,KAAAggC,IAAA78B,GAGA4iF,KAOA,gBAAAruE,KACA,gBAAA9Q,eACA,gBAAA5E,WAAAhC,Q7F0pqB8BO,KAAKX,EAAU,WAAa,MAAOI,SAAYE,EAAoB,KAI3F,SAASL,EAAQD,I8F92rBvB,WACA,GAAAipF,MAAkB/nF,eAClBG,UAEApB,GAAAD,QAAA,SAAAohC,EAAAlkB,GACA,GAAAnR,GAAA8B,EAAAlL,EAAA0oB,CACAxd,MACAwd,IACA,KAAAtf,IAAAmR,GACA+rE,EAAAtoF,KAAAuc,EAAAnR,KACApJ,EAAAua,EAAAnR,GACA,SAAAA,IAGA8B,EAAApF,KAAAsD,GACAsf,EAAA5iB,KAAA9F,IAEA,OAAAoV,UAAAtW,MAAA,KAAAJ,EAAAV,KAAAkN,GAAAnM,QAAA0/B,KAAA3/B,MAAAyb,EAAA,KAAAmO,MAGC1qB,KAAAP,O9Fs3rBK,SAASH,EAAQD,EAASM,I+F34rBhC,SAAAP,GAGAE,EAAAD,QAAAD,KAgBC,SAAAwD,GAED,YA0BA,SAAA4qB,GAAAvU,EAAA/B,GACA,GAAAtW,GAAAqY,EAAA,GACApY,EAAAoY,EAAA,GACA/Y,EAAA+Y,EAAA,GACAmU,EAAAnU,EAAA,EAEArY,KAAAC,EAAAX,GAAAW,EAAAusB,GAAAlW,EAAA,eACAtW,MAAA,EAAAA,IAAA,IAAAC,EAAA,EACAusB,IAAAxsB,EAAAC,GAAAD,EAAAV,GAAAgX,EAAA,eACAkW,MAAA,GAAAA,IAAA,IAAAxsB,EAAA,EACAV,IAAAktB,EAAAxsB,GAAAwsB,EAAAvsB,GAAAqW,EAAA,eACAhX,MAAA,GAAAA,IAAA,IAAAktB,EAAA,EACAvsB,IAAAX,EAAAktB,GAAAltB,EAAAU,GAAAsW,EAAA,gBACArW,MAAA,GAAAA,IAAA,IAAAX,EAAA,EACAU,IAAAC,EAAAX,GAAAW,EAAAusB,GAAAlW,EAAA,eACAtW,MAAA,EAAAA,IAAA,IAAAC,EAAA,EACAusB,IAAAxsB,EAAAC,GAAAD,EAAAV,GAAAgX,EAAA,gBACAkW,MAAA,GAAAA,IAAA,IAAAxsB,EAAA,EACAV,IAAAktB,EAAAxsB,GAAAwsB,EAAAvsB,GAAAqW,EAAA,gBACAhX,MAAA,GAAAA,IAAA,IAAAktB,EAAA,EACAvsB,IAAAX,EAAAktB,GAAAltB,EAAAU,GAAAsW,EAAA,cACArW,MAAA,GAAAA,IAAA,IAAAX,EAAA,EACAU,IAAAC,EAAAX,GAAAW,EAAAusB,GAAAlW,EAAA,gBACAtW,MAAA,EAAAA,IAAA,IAAAC,EAAA,EACAusB,IAAAxsB,EAAAC,GAAAD,EAAAV,GAAAgX,EAAA,gBACAkW,MAAA,GAAAA,IAAA,IAAAxsB,EAAA,EACAV,IAAAktB,EAAAxsB,GAAAwsB,EAAAvsB,GAAAqW,EAAA,YACAhX,MAAA,GAAAA,IAAA,IAAAktB,EAAA,EACAvsB,IAAAX,EAAAktB,GAAAltB,EAAAU,GAAAsW,EAAA,iBACArW,MAAA,GAAAA,IAAA,IAAAX,EAAA,EACAU,IAAAC,EAAAX,GAAAW,EAAAusB,GAAAlW,EAAA,iBACAtW,MAAA,EAAAA,IAAA,IAAAC,EAAA,EACAusB,IAAAxsB,EAAAC,GAAAD,EAAAV,GAAAgX,EAAA,eACAkW,MAAA,GAAAA,IAAA,IAAAxsB,EAAA,EACAV,IAAAktB,EAAAxsB,GAAAwsB,EAAAvsB,GAAAqW,EAAA,iBACAhX,MAAA,GAAAA,IAAA,IAAAktB,EAAA,EACAvsB,IAAAX,EAAAktB,GAAAltB,EAAAU,GAAAsW,EAAA,iBACArW,MAAA,GAAAA,IAAA,IAAAX,EAAA,EAEAU,IAAAC,EAAAusB,EAAAltB,GAAAktB,GAAAlW,EAAA,eACAtW,MAAA,EAAAA,IAAA,IAAAC,EAAA,EACAusB,IAAAxsB,EAAAV,EAAAW,GAAAX,GAAAgX,EAAA,gBACAkW,MAAA,EAAAA,IAAA,IAAAxsB,EAAA,EACAV,IAAAktB,EAAAvsB,EAAAD,GAAAC,GAAAqW,EAAA,gBACAhX,MAAA,GAAAA,IAAA,IAAAktB,EAAA,EACAvsB,IAAAX,EAAAU,EAAAwsB,GAAAxsB,GAAAsW,EAAA,eACArW,MAAA,GAAAA,IAAA,IAAAX,EAAA,EACAU,IAAAC,EAAAusB,EAAAltB,GAAAktB,GAAAlW,EAAA,eACAtW,MAAA,EAAAA,IAAA,IAAAC,EAAA,EACAusB,IAAAxsB,EAAAV,EAAAW,GAAAX,GAAAgX,EAAA,eACAkW,MAAA,EAAAA,IAAA,IAAAxsB,EAAA,EACAV,IAAAktB,EAAAvsB,EAAAD,GAAAC,GAAAqW,EAAA,gBACAhX,MAAA,GAAAA,IAAA,IAAAktB,EAAA,EACAvsB,IAAAX,EAAAU,EAAAwsB,GAAAxsB,GAAAsW,EAAA,eACArW,MAAA,GAAAA,IAAA,IAAAX,EAAA,EACAU,IAAAC,EAAAusB,EAAAltB,GAAAktB,GAAAlW,EAAA,eACAtW,MAAA,EAAAA,IAAA,IAAAC,EAAA,EACAusB,IAAAxsB,EAAAV,EAAAW,GAAAX,GAAAgX,EAAA,iBACAkW,MAAA,EAAAA,IAAA,IAAAxsB,EAAA,EACAV,IAAAktB,EAAAvsB,EAAAD,GAAAC,GAAAqW,EAAA,eACAhX,MAAA,GAAAA,IAAA,IAAAktB,EAAA,EACAvsB,IAAAX,EAAAU,EAAAwsB,GAAAxsB,GAAAsW,EAAA,gBACArW,MAAA,GAAAA,IAAA,IAAAX,EAAA,EACAU,IAAAC,EAAAusB,EAAAltB,GAAAktB,GAAAlW,EAAA,iBACAtW,MAAA,EAAAA,IAAA,IAAAC,EAAA,EACAusB,IAAAxsB,EAAAV,EAAAW,GAAAX,GAAAgX,EAAA,cACAkW,MAAA,EAAAA,IAAA,IAAAxsB,EAAA,EACAV,IAAAktB,EAAAvsB,EAAAD,GAAAC,GAAAqW,EAAA,gBACAhX,MAAA,GAAAA,IAAA,IAAAktB,EAAA,EACAvsB,IAAAX,EAAAU,EAAAwsB,GAAAxsB,GAAAsW,EAAA,iBACArW,MAAA,GAAAA,IAAA,IAAAX,EAAA,EAEAU,IAAAC,EAAAX,EAAAktB,GAAAlW,EAAA,YACAtW,MAAA,EAAAA,IAAA,IAAAC,EAAA,EACAusB,IAAAxsB,EAAAC,EAAAX,GAAAgX,EAAA,gBACAkW,MAAA,GAAAA,IAAA,IAAAxsB,EAAA,EACAV,IAAAktB,EAAAxsB,EAAAC,GAAAqW,EAAA,iBACAhX,MAAA,GAAAA,IAAA,IAAAktB,EAAA,EACAvsB,IAAAX,EAAAktB,EAAAxsB,GAAAsW,EAAA,eACArW,MAAA,GAAAA,IAAA,GAAAX,EAAA,EACAU,IAAAC,EAAAX,EAAAktB,GAAAlW,EAAA,gBACAtW,MAAA,EAAAA,IAAA,IAAAC,EAAA,EACAusB,IAAAxsB,EAAAC,EAAAX,GAAAgX,EAAA,gBACAkW,MAAA,GAAAA,IAAA,IAAAxsB,EAAA,EACAV,IAAAktB,EAAAxsB,EAAAC,GAAAqW,EAAA,eACAhX,MAAA,GAAAA,IAAA,IAAAktB,EAAA,EACAvsB,IAAAX,EAAAktB,EAAAxsB,GAAAsW,EAAA,iBACArW,MAAA,GAAAA,IAAA,GAAAX,EAAA,EACAU,IAAAC,EAAAX,EAAAktB,GAAAlW,EAAA,gBACAtW,MAAA,EAAAA,IAAA,IAAAC,EAAA,EACAusB,IAAAxsB,EAAAC,EAAAX,GAAAgX,EAAA,eACAkW,MAAA,GAAAA,IAAA,IAAAxsB,EAAA,EACAV,IAAAktB,EAAAxsB,EAAAC,GAAAqW,EAAA,eACAhX,MAAA,GAAAA,IAAA,IAAAktB,EAAA,EACAvsB,IAAAX,EAAAktB,EAAAxsB,GAAAsW,EAAA,cACArW,MAAA,GAAAA,IAAA,GAAAX,EAAA,EACAU,IAAAC,EAAAX,EAAAktB,GAAAlW,EAAA,eACAtW,MAAA,EAAAA,IAAA,IAAAC,EAAA,EACAusB,IAAAxsB,EAAAC,EAAAX,GAAAgX,EAAA,gBACAkW,MAAA,GAAAA,IAAA,IAAAxsB,EAAA,EACAV,IAAAktB,EAAAxsB,EAAAC,GAAAqW,EAAA,gBACAhX,MAAA,GAAAA,IAAA,IAAAktB,EAAA,EACAvsB,IAAAX,EAAAktB,EAAAxsB,GAAAsW,EAAA,eACArW,MAAA,GAAAA,IAAA,GAAAX,EAAA,EAEAU,IAAAV,GAAAW,GAAAusB,IAAAlW,EAAA,eACAtW,MAAA,EAAAA,IAAA,IAAAC,EAAA,EACAusB,IAAAvsB,GAAAD,GAAAV,IAAAgX,EAAA,gBACAkW,MAAA,GAAAA,IAAA,IAAAxsB,EAAA,EACAV,IAAAU,GAAAwsB,GAAAvsB,IAAAqW,EAAA,iBACAhX,MAAA,GAAAA,IAAA,IAAAktB,EAAA,EACAvsB,IAAAusB,GAAAltB,GAAAU,IAAAsW,EAAA,cACArW,MAAA,GAAAA,IAAA,IAAAX,EAAA,EACAU,IAAAV,GAAAW,GAAAusB,IAAAlW,EAAA,iBACAtW,MAAA,EAAAA,IAAA,IAAAC,EAAA,EACAusB,IAAAvsB,GAAAD,GAAAV,IAAAgX,EAAA,gBACAkW,MAAA,GAAAA,IAAA,IAAAxsB,EAAA,EACAV,IAAAU,GAAAwsB,GAAAvsB,IAAAqW,EAAA,cACAhX,MAAA,GAAAA,IAAA,IAAAktB,EAAA,EACAvsB,IAAAusB,GAAAltB,GAAAU,IAAAsW,EAAA,gBACArW,MAAA,GAAAA,IAAA,IAAAX,EAAA,EACAU,IAAAV,GAAAW,GAAAusB,IAAAlW,EAAA,gBACAtW,MAAA,EAAAA,IAAA,IAAAC,EAAA,EACAusB,IAAAvsB,GAAAD,GAAAV,IAAAgX,EAAA,eACAkW,MAAA,GAAAA,IAAA,IAAAxsB,EAAA,EACAV,IAAAU,GAAAwsB,GAAAvsB,IAAAqW,EAAA,gBACAhX,MAAA,GAAAA,IAAA,IAAAktB,EAAA,EACAvsB,IAAAusB,GAAAltB,GAAAU,IAAAsW,EAAA,iBACArW,MAAA,GAAAA,IAAA,IAAAX,EAAA,EACAU,IAAAV,GAAAW,GAAAusB,IAAAlW,EAAA,eACAtW,MAAA,EAAAA,IAAA,IAAAC,EAAA,EACAusB,IAAAvsB,GAAAD,GAAAV,IAAAgX,EAAA,iBACAkW,MAAA,GAAAA,IAAA,IAAAxsB,EAAA,EACAV,IAAAU,GAAAwsB,GAAAvsB,IAAAqW,EAAA,eACAhX,MAAA,GAAAA,IAAA,IAAAktB,EAAA,EACAvsB,IAAAusB,GAAAltB,GAAAU,IAAAsW,EAAA,eACArW,MAAA,GAAAA,IAAA,IAAAX,EAAA,EAEA+Y,EAAA,GAAArY,EAAAqY,EAAA,KACAA,EAAA,GAAApY,EAAAoY,EAAA,KACAA,EAAA,GAAA/Y,EAAA+Y,EAAA,KACAA,EAAA,GAAAmU,EAAAnU,EAAA,KAGA,QAAAwU,GAAAP,GACA,GACA9sB,GADAstB,IAGA,KAAAttB,EAAA,EAAmBA,EAAA,GAAQA,GAAA,EAC3BstB,EAAAttB,GAAA,GAAA8sB,EAAAS,WAAAvtB,IAAA8sB,EAAAS,WAAAvtB,EAAA,QAAA8sB,EAAAS,WAAAvtB,EAAA,SAAA8sB,EAAAS,WAAAvtB,EAAA,OAEA,OAAAstB,GAGA,QAAAE,GAAAhtB,GACA,GACAR,GADAstB,IAGA,KAAAttB,EAAA,EAAmBA,EAAA,GAAQA,GAAA,EAC3BstB,EAAAttB,GAAA,GAAAQ,EAAAR,IAAAQ,EAAAR,EAAA,QAAAQ,EAAAR,EAAA,SAAAQ,EAAAR,EAAA,OAEA,OAAAstB,GAGA,QAAAG,GAAAX,GACA,GAEA9sB,GACAuC,EACAmrB,EACAC,EACAC,EACAC,EAPAC,EAAAhB,EAAAvqB,OACAuZ,GAAA,4CAQA,KAAA9b,EAAA,GAAoBA,GAAA8tB,EAAQ9tB,GAAA,GAC5BotB,EAAAtR,EAAAuR,EAAAP,EAAAthB,UAAAxL,EAAA,GAAAA,IAKA,KAHA8sB,IAAAthB,UAAAxL,EAAA,IACAuC,EAAAuqB,EAAAvqB,OACAmrB,GAAA,iCACA1tB,EAAA,EAAmBA,EAAAuC,EAAYvC,GAAA,EAC/B0tB,EAAA1tB,GAAA,IAAA8sB,EAAAS,WAAAvtB,OAAA,KAGA,IADA0tB,EAAA1tB,GAAA,UAAAA,EAAA,MACAA,EAAA,GAEA,IADAotB,EAAAtR,EAAA4R,GACA1tB,EAAA,EAAuBA,EAAA,GAAQA,GAAA,EAC/B0tB,EAAA1tB,GAAA,CAcA,OATA2tB,GAAA,EAAAG,EACAH,IAAAvU,SAAA,IAAAiO,MAAA,kBACAuG,EAAA5V,SAAA2V,EAAA,OACAE,EAAA7V,SAAA2V,EAAA,UAEAD,EAAA,IAAAE,EACAF,EAAA,IAAAG,EAEAT,EAAAtR,EAAA4R,GACA5R,EAGA,QAAAiS,GAAAvtB,GACA,GAEAR,GACAuC,EACAmrB,EACAC,EACAC,EACAC,EAPAC,EAAAttB,EAAA+B,OACAuZ,GAAA,4CAQA,KAAA9b,EAAA,GAAoBA,GAAA8tB,EAAQ9tB,GAAA,GAC5BotB,EAAAtR,EAAA0R,EAAAhtB,EAAAwtB,SAAAhuB,EAAA,GAAAA,IAWA,KAJAQ,EAAAR,EAAA,GAAA8tB,EAAAttB,EAAAwtB,SAAAhuB,EAAA,OAAAqe,YAAA,GAEA9b,EAAA/B,EAAA+B,OACAmrB,GAAA,iCACA1tB,EAAA,EAAmBA,EAAAuC,EAAYvC,GAAA,EAC/B0tB,EAAA1tB,GAAA,IAAAQ,EAAAR,OAAA,KAIA,IADA0tB,EAAA1tB,GAAA,UAAAA,EAAA,MACAA,EAAA,GAEA,IADAotB,EAAAtR,EAAA4R,GACA1tB,EAAA,EAAuBA,EAAA,GAAQA,GAAA,EAC/B0tB,EAAA1tB,GAAA,CAeA,OAVA2tB,GAAA,EAAAG,EACAH,IAAAvU,SAAA,IAAAiO,MAAA,kBACAuG,EAAA5V,SAAA2V,EAAA,OACAE,EAAA7V,SAAA2V,EAAA,UAEAD,EAAA,IAAAE,EACAF,EAAA,IAAAG,EAEAT,EAAAtR,EAAA4R,GAEA5R,EAGA,QAAAoS,GAAAJ,GACA,GACAtK,GADAsJ,EAAA,EAEA,KAAAtJ,EAAA,EAAmBA,EAAA,EAAOA,GAAA,EAC1BsJ,GAAAmB,EAAAH,GAAA,EAAAtK,EAAA,MAAAyK,EAAAH,GAAA,EAAAtK,EAAA,GAEA,OAAAsJ,GAGA,QAAAqB,GAAAtV,GACA,GAAA7Y,EACA,KAAAA,EAAA,EAAmBA,EAAA6Y,EAAAtW,OAAcvC,GAAA,EACjC6Y,EAAA7Y,GAAAkuB,EAAArV,EAAA7Y,GAEA,OAAA6Y,GAAAxF,KAAA,IAmEA,QAAA80E,GAAA5wE,GAKA,MAJA,kBAAAmU,KAAAnU,KACAA,EAAAoX,SAAA3f,mBAAAuI,KAGAA,EAGA,QAAA6wE,GAAA7wE,EAAA8wE,GACA,GAGAroF,GAHAuC,EAAAgV,EAAAhV,OACA8sB,EAAA,GAAAK,aAAAntB,GACAwE,EAAA,GAAAsX,YAAAgR,EAGA,KAAArvB,EAAA,EAAmBA,EAAAuC,EAAYvC,GAAA,EAC/B+G,EAAA/G,GAAAuX,EAAAgW,WAAAvtB,EAGA,OAAAqoF,GAAAthF,EAAAsoB,EAGA,QAAAi5D,GAAAj5D,GACA,MAAA3Q,QAAAC,aAAAje,MAAA,QAAA2d,YAAAgR,IAGA,QAAAk5D,GAAA14D,EAAAC,EAAAu4D,GACA,GAAA5+E,GAAA,GAAA4U,YAAAwR,EAAAD,WAAAE,EAAAF,WAKA,OAHAnmB,GAAAumB,IAAA,GAAA3R,YAAAwR,IACApmB,EAAAumB,IAAA,GAAA3R,YAAAyR,GAAAD,EAAAD,YAEAy4D,EAAA5+E,IAAA0U,OAGA,QAAAqqE,GAAAr6D,GACA,GAEAtV,GAFAk4C,KACAxuD,EAAA4rB,EAAA5rB,MAGA,KAAAsW,EAAA,EAAmBA,EAAAtW,EAAA,EAAgBsW,GAAA,EACnCk4C,EAAArpD,KAAAsQ,SAAAmW,EAAAc,OAAApW,EAAA,OAGA,OAAA6F,QAAAC,aAAAje,MAAAge,OAAAqyC,GAYA,QAAA1iC,KAEAhvB,KAAAivB,QAjZA,GAAA1B,GAAA,SAAApsB,EAAAC,GACA,MAAAD,GAAAC,EAAA,YAEAwtB,GAAA,gEAssBA,OAhbA,qCAAAE,EAAAV,EAAA,YACAb,EAAA,SAAA/T,EAAA0V,GACA,GAAAC,IAAA,MAAA3V,IAAA,MAAA0V,GACAE,GAAA5V,GAAA,KAAA0V,GAAA,KAAAC,GAAA,GACA,OAAAC,IAAA,SAAAD,IAYA,mBAAAkB,0BAAAxvB,UAAAI,QACA,WACA,QAAAmoF,GAAAxuE,EAAA1X,GAGA,MAFA0X,GAAA,EAAAA,GAAA,EAEAA,EAAA,EACApO,KAAAS,IAAA2N,EAAA1X,EAAA,GAGAsJ,KAAAC,IAAAmO,EAAA1X,GAGAmtB,YAAAxvB,UAAAI,MAAA,SAAA0jC,EAAAC,GACA,GAGAzsB,GACAuH,EACA6gC,EACAC,EANAt9C,EAAAlD,KAAAuwB,WACA84D,EAAAD,EAAAzkD,EAAAzhC,GACA2sB,EAAA3sB,CAUA,OAJA0hC,KAAAzhC,IACA0sB,EAAAu5D,EAAAxkD,EAAA1hC,IAGAmmF,EAAAx5D,EACA,GAAAQ,aAAA,IAGAlY,EAAA0X,EAAAw5D,EACA3pE,EAAA,GAAA2Q,aAAAlY,GACAooC,EAAA,GAAAvhC,YAAAU,GAEA8gC,EAAA,GAAAxhC,YAAAhf,KAAAqpF,EAAAlxE,GACAooC,EAAA5vB,IAAA6vB,GAEA9gC,OA+EAsP,EAAAnuB,UAAAwuB,OAAA,SAAAnX,GAKA,MAFAlY,MAAAuvB,aAAAu5D,EAAA5wE,IAEAlY,MAUAgvB,EAAAnuB,UAAA0uB,aAAA,SAAAC,GACAxvB,KAAAyvB,OAAAD,EACAxvB,KAAA0vB,SAAAF,EAAAtsB,MAEA,IACAvC,GADAuC,EAAAlD,KAAAyvB,MAAAvsB,MAGA,KAAAvC,EAAA,GAAoBA,GAAAuC,EAAavC,GAAA,GACjCotB,EAAA/tB,KAAAspF,MAAAt7D,EAAAhuB,KAAAyvB,MAAAtjB,UAAAxL,EAAA,GAAAA,IAKA,OAFAX,MAAAyvB,MAAAzvB,KAAAyvB,MAAAtjB,UAAAxL,EAAA,IAEAX,MAWAgvB,EAAAnuB,UAAAgvB,IAAA,SAAAC,GACA,GAEAnvB,GAEAovB,EAJAC,EAAAhwB,KAAAyvB,MACAvsB,EAAA8sB,EAAA9sB,OAEAmrB,GAAA,gCAGA,KAAA1tB,EAAA,EAAmBA,EAAAuC,EAAYvC,GAAA,EAC/B0tB,EAAA1tB,GAAA,IAAAqvB,EAAA9B,WAAAvtB,OAAA,KAYA,OATAX,MAAAiwB,QAAA5B,EAAAnrB,GACA6sB,EAAAjB,EAAA9uB,KAAAspF,OAEAx5D,IACAC,EAAAo5D,EAAAp5D,IAGA/vB,KAAAivB,QAEAc,GAQAf,EAAAnuB,UAAAouB,MAAA,WAKA,MAJAjvB,MAAAyvB,MAAA,GACAzvB,KAAA0vB,QAAA,EACA1vB,KAAAspF,OAAA,6CAEAtpF,MAQAgvB,EAAAnuB,UAAA0oF,SAAA,WACA,OACAv5D,KAAAhwB,KAAAyvB,MACAvsB,OAAAlD,KAAA0vB,QACAzkB,KAAAjL,KAAAspF,QAWAt6D,EAAAnuB,UAAA2oF,SAAA,SAAA/sE,GAKA,MAJAzc,MAAAyvB,MAAAhT,EAAAuT,KACAhwB,KAAA0vB,QAAAjT,EAAAvZ,OACAlD,KAAAspF,MAAA7sE,EAAAxR,KAEAjL,MAOAgvB,EAAAnuB,UAAAqvB,QAAA,iBACAlwB,MAAAspF,YACAtpF,MAAAyvB,YACAzvB,MAAA0vB,SASAV,EAAAnuB,UAAAovB,QAAA,SAAA5B,EAAAnrB,GACA,GACAorB,GACAC,EACAC,EAHA7tB,EAAAuC,CAMA,IADAmrB,EAAA1tB,GAAA,UAAAA,EAAA,MACAA,EAAA,GAEA,IADAotB,EAAA/tB,KAAAspF,MAAAj7D,GACA1tB,EAAA,EAAuBA,EAAA,GAAQA,GAAA,EAC/B0tB,EAAA1tB,GAAA,CAMA2tB,GAAA,EAAAtuB,KAAA0vB,QACApB,IAAAvU,SAAA,IAAAiO,MAAA,kBACAuG,EAAA5V,SAAA2V,EAAA,OACAE,EAAA7V,SAAA2V,EAAA,UAEAD,EAAA,IAAAE,EACAF,EAAA,IAAAG,EACAT,EAAA/tB,KAAAspF,MAAAj7D,IAYAW,EAAA/jB,KAAA,SAAAiN,EAAA4X,GAGA,MAAAd,GAAAmB,WAAA24D,EAAA5wE,GAAA4X,IAWAd,EAAAmB,WAAA,SAAAC,EAAAN,GACA,GAAA7kB,GAAAmjB,EAAAgC,GACAL,EAAAjB,EAAA7jB,EAEA,OAAA6kB,GAAAq5D,EAAAp5D,MAUAf,EAAAqB,YAAA,WAEArwB,KAAAivB,SAUAD,EAAAqB,YAAAxvB,UAAAwuB,OAAA,SAAA3nB,GACA,GAEA/G,GAFAqvB,EAAAk5D,EAAAlpF,KAAAyvB,MAAA3Q,OAAApX,GAAA,GACAxE,EAAA8sB,EAAA9sB,MAKA,KAFAlD,KAAA0vB,SAAAhoB,EAAA6oB,WAEA5vB,EAAA,GAAoBA,GAAAuC,EAAavC,GAAA,GACjCotB,EAAA/tB,KAAAspF,MAAAn7D,EAAA6B,EAAArB,SAAAhuB,EAAA,GAAAA,IAKA,OAFAX,MAAAyvB,MAAA9uB,EAAA,GAAAuC,EAAA,GAAA8b,YAAAgR,EAAAlR,OAAA7d,MAAAN,EAAA,QAAAqe,YAAA,GAEAhf,MAWAgvB,EAAAqB,YAAAxvB,UAAAgvB,IAAA,SAAAC,GACA,GAGAnvB,GACAovB,EAJAC,EAAAhwB,KAAAyvB,MACAvsB,EAAA8sB,EAAA9sB,OACAmrB,GAAA,gCAIA,KAAA1tB,EAAA,EAAmBA,EAAAuC,EAAYvC,GAAA,EAC/B0tB,EAAA1tB,GAAA,IAAAqvB,EAAArvB,OAAA,KAYA,OATAX,MAAAiwB,QAAA5B,EAAAnrB,GACA6sB,EAAAjB,EAAA9uB,KAAAspF,OAEAx5D,IACAC,EAAAo5D,EAAAp5D,IAGA/vB,KAAAivB,QAEAc,GAQAf,EAAAqB,YAAAxvB,UAAAouB,MAAA,WAKA,MAJAjvB,MAAAyvB,MAAA,GAAAzQ,YAAA,GACAhf,KAAA0vB,QAAA,EACA1vB,KAAAspF,OAAA,6CAEAtpF,MAQAgvB,EAAAqB,YAAAxvB,UAAA0oF,SAAA,WACA,GAAA9sE,GAAAuS,EAAAnuB,UAAA0oF,SAAAhpF,KAAAP,KAKA,OAFAyc,GAAAuT,KAAAi5D,EAAAxsE,EAAAuT,MAEAvT,GAUAuS,EAAAqB,YAAAxvB,UAAA2oF,SAAA,SAAA/sE,GAIA,MAFAA,GAAAuT,KAAA+4D,EAAAtsE,EAAAuT,MAAA,GAEAhB,EAAAnuB,UAAA2oF,SAAAjpF,KAAAP,KAAAyc,IAGAuS,EAAAqB,YAAAxvB,UAAAqvB,QAAAlB,EAAAnuB,UAAAqvB,QAEAlB,EAAAqB,YAAAxvB,UAAAovB,QAAAjB,EAAAnuB,UAAAovB,QAUAjB,EAAAqB,YAAAplB,KAAA,SAAAvD,EAAAooB,GACA,GAAA7kB,GAAAyjB,EAAA,GAAA1P,YAAAtX,IACAqoB,EAAAjB,EAAA7jB,EAEA,OAAA6kB,GAAAq5D,EAAAp5D,MAGAf,K/Fm5rBM,SAASnvB,EAAQD,GgGhotBvB,YAuDA,SAAAiK,GAAArI,EAAAsX,EAAAC,GACA,GAAAC,GAAAD,IAAA7V,OAAA,EACA1B,KAAAwX,EAAA7L,UAEA4L,EAAAlP,MACAmP,EAAAD,IAAA7V,OAAA,GAEA,IAAAiK,GAAA6L,EAAA7L,QACA8L,EAAAD,EAAAzG,KACA,IAAAjK,MAAAC,QAAA4E,GACAA,EAAA9E,KAAA7G,OACG,IAAAyX,IAAAH,EAAA5V,OAAA,GACH,GAAAyI,GAAAmN,EAAAjP,KACAsD,GAAAxB,GAAAnK,MAEAsX,GAAAzQ,KAAA7G,GA/DA5B,EAAA+F,UAAA,SAAAsM,GACA,GAAAoD,KACAA,GAAAhN,MAAc7G,IAAAyQ,GAId,KAFA,GACA9J,GAAA3G,EAAAgwB,EAAA5W,EAAAja,EAAA8oF,EAAAh8E,EAAAgK,EAAA9L,EAAApJ,EAAAmnF,EADA7lF,EAAA,GAEAsE,EAAAkN,EAAAxL,OAKA,GAJArI,EAAA2G,EAAA3G,IACAgwB,EAAArpB,EAAAqpB,QAAA,GACA5W,EAAAzS,EAAAyS,KAAA,GACA/W,GAAA2tB,EACA5W,EACA/W,GAAA+W,MACK,oBAAApZ,GACLqC,GAAA,mBAAArC,GAAA,KAAAkE,KAAAC,UAAAnE,OACK,WAAAA,EACLqC,GAAA,WACK,IAAAyE,MAAAC,QAAA/G,GAAA,CAEL,IADA6T,EAAAhN,MAAkBuS,IAAA,MAClBja,EAAAa,EAAA0B,OAAA,EAA8BvC,GAAA,EAAQA,IACtC8oF,EAAA,IAAA9oF,EAAA,OACA0U,EAAAhN,MAAoB7G,MAAAb,GAAA6wB,OAAAi4D,GAEpBp0E,GAAAhN,MAAkBuS,IAAA,UACb,CACLnN,IACA,KAAAgK,IAAAjW,GACAA,EAAAV,eAAA2W,IACAhK,EAAApF,KAAAoP,EAIA,KADApC,EAAAhN,MAAkBuS,IAAA,MAClBja,EAAA8M,EAAAvK,OAAA,EAA+BvC,GAAA,EAAQA,IACvCgL,EAAA8B,EAAA9M,GACA4B,EAAAf,EAAAmK,GACA+9E,EAAA/oF,EAAA,SACA+oF,GAAAhkF,KAAAC,UAAAgG,GAAA,IACA0J,EAAAhN,MAAoB7G,IAAAe,EAAAivB,OAAAk4D,GAEpBr0E,GAAAhN,MAAkBuS,IAAA,MAGlB,MAAA/W,IAyBAjE,EAAAiyB,MAAA,SAAA3Z,GAOA,IANA,GAGAqB,GAAAuB,EAAA6uE,EACAC,EAAAC,EAAAC,EAAA59E,EACA8O,EAAAC,EALAnC,KACAC,KACApY,EAAA,IAMA,GADA4Y,EAAArB,EAAAvX,KACA,MAAA4Y,GACA,MAAAA,GACA,mBAAAA,GAQA,OAAAA,GACA,QACA,SACA,SACA,QACA,QACA,KACA,SACA5Y,GAAA,EACAkJ,EAAA,KAAAiP,EAAAC,EACA,MACA,SACApY,GAAA,EACAkJ,GAAA,EAAAiP,EAAAC,EACA,MACA,SACApY,GAAA,EACAkJ,GAAA,EAAAiP,EAAAC,EACA,MACA,SACA,QACA,QACA,QACA,QACA,QACA,QACA,QACA,QACA,QACA,QAGA,IAFA+B,EAAA,GACAna,MACA,CAEA,GADAgpF,EAAAzxE,EAAAvX,MACA,cAAA0rB,KAAAs9D,GAEW,CACXhpF,GACA,OAHAma,GAAA6uE,EAMA9/E,EAAAgP,WAAAiC,GAAAhC,EAAAC,EACA,MACA,SAIA,IAHA6wE,EAAA,GACAC,EAAA,OACAC,EAAA,IACA,CAEA,GADA59E,EAAAgM,EAAAvX,KACA,MAAAuL,IAAA,OAAA29E,GACAC,EAAA,OASA,KARAF,IAAA19E,EACA29E,EAAA39E,EACA,OAAA29E,EACAC,IAEAA,EAAA,EAMAjgF,EAAAnE,KAAAmsB,MAAA,IAAA+3D,EAAA,KAAA9wE,EAAAC,EACA,MACA,SACAiC,GAAwB7N,WAAAoF,MAAAuG,EAAA5V,QACxB4V,EAAAzQ,KAAA2S,EAAA7N,SACA4L,EAAA1Q,KAAA2S,EACA,MACA,SACAC,GAAsB9N,WAAYoF,MAAAuG,EAAA5V,QAClC4V,EAAAzQ,KAAA4S,EAAA9N,SACA4L,EAAA1Q,KAAA4S,EACA,MACA,SACA,SAAAzU,OACA,sCAAA+S,OAtFA,CAGA,OAAAT,EAAA5V,OACA,MAAA4V,GAAAjP,KAEAA,GAAAiP,EAAAjP,MAAAiP,EAAAC,MhG0ttBM,SAASlZ,EAAQD,IiGnztBvB,SAAAoC,GACA,YA2CA,SAAA+nF,GAAAjhF,GAIA,GAHA,gBAAAA,KACAA,EAAAuW,OAAAvW,IAEA,6BAAAujB,KAAAvjB,GACA,SAAAhH,WAAA,yCAEA,OAAAgH,GAAAif,cAGA,QAAAiiE,GAAAznF,GAIA,MAHA,gBAAAA,KACAA,EAAA8c,OAAA9c,IAEAA,EAIA,QAAA0nF,GAAAC,GACA,GAAAhiF,IACAC,KAAA,WACA,GAAA5F,GAAA2nF,EAAAp8B,OACA,QAAgB1lD,KAAAjF,SAAAZ,YAUhB,OANA4nF,GAAAt/D,WACA3iB,EAAAD,OAAAC,UAAA,WACA,MAAAA,KAIAA,EAGA,QAAA+kE,GAAAjpE,GACAhE,KAAA0N,OAEA1J,YAAAipE,GACAjpE,EAAA6N,QAAA,SAAAtP,EAAAuG,GACA9I,KAAAqvB,OAAAvmB,EAAAvG,IACOvC,MACFsI,MAAAC,QAAAvE,GACLA,EAAA6N,QAAA,SAAAu4E,GACApqF,KAAAqvB,OAAA+6D,EAAA,GAAAA,EAAA,KACOpqF,MACFgE,GACLpD,OAAAojF,oBAAAhgF,GAAA6N,QAAA,SAAA/I,GACA9I,KAAAqvB,OAAAvmB,EAAA9E,EAAA8E,KACO9I,MA0DP,QAAAqqF,GAAAjlF,GACA,MAAAA,GAAAklF,SACAnmF,QAAA8F,OAAA,GAAAnI,WAAA,sBAEAsD,EAAAklF,UAAA,GAGA,QAAAC,GAAAv4B,GACA,UAAA7tD,SAAA,SAAAoK,EAAAtE,GACA+nD,EAAAzxB,OAAA,WACAhyB,EAAAyjD,EAAA5nD,SAEA4nD,EAAAoK,QAAA,WACAnyD,EAAA+nD,EAAA3rD,UAKA,QAAAmkF,GAAA54B,GACA,GAAAI,GAAA,GAAAH,YACA9nD,EAAAwgF,EAAAv4B,EAEA,OADAA,GAAAD,kBAAAH,GACA7nD,EAGA,QAAA0gF,GAAA74B,GACA,GAAAI,GAAA,GAAAH,YACA9nD,EAAAwgF,EAAAv4B,EAEA,OADAA,GAAA04B,WAAA94B,GACA7nD,EAGA,QAAA4gF,GAAAx5B,GAIA,OAHAjsC,GAAA,GAAAlG,YAAAmyC,GACA/J,EAAA,GAAA9+C,OAAA4c,EAAAhiB,QAEAvC,EAAA,EAAmBA,EAAAukB,EAAAhiB,OAAiBvC,IACpCymD,EAAAzmD,GAAA0e,OAAAC,aAAA4F,EAAAvkB,GAEA,OAAAymD,GAAApzC,KAAA,IAGA,QAAA42E,GAAAz5B,GACA,GAAAA,EAAAlwD,MACA,MAAAkwD,GAAAlwD,MAAA,EAEA,IAAAikB,GAAA,GAAAlG,YAAAmyC,EAAA5gC,WAEA,OADArL,GAAAyL,IAAA,GAAA3R,YAAAmyC,IACAjsC,EAAApG,OAIA,QAAA+rE,KA0FA,MAzFA7qF,MAAAsqF,UAAA,EAEAtqF,KAAA8qF,UAAA,SAAA1lF,GAEA,GADApF,KAAA+qF,UAAA3lF,EACAA,EAEO,mBAAAA,GACPpF,KAAAgrF,UAAA5lF,MACO,IAAA+kF,EAAAv4B,MAAA38B,KAAAp0B,UAAAoqF,cAAA7lF,GACPpF,KAAAkrF,UAAA9lF,MACO,IAAA+kF,EAAAgB,UAAAC,SAAAvqF,UAAAoqF,cAAA7lF,GACPpF,KAAAqrF,cAAAjmF,MACO,IAAA+kF,EAAAxrD,cAAA2sD,gBAAAzqF,UAAAoqF,cAAA7lF,GACPpF,KAAAgrF,UAAA5lF,EAAA2U,eACO,IAAAowE,EAAAv3B,aAAAu3B,EAAAv4B,MAAA25B,EAAAnmF,GACPpF,KAAAwrF,iBAAAZ,EAAAxlF,EAAA0Z,QAEA9e,KAAA+qF,UAAA,GAAA91D,OAAAj1B,KAAAwrF,uBACO,KAAArB,EAAAv3B,cAAAviC,YAAAxvB,UAAAoqF,cAAA7lF,KAAAqmF,EAAArmF,GAGP,SAAAoB,OAAA,4BAFAxG,MAAAwrF,iBAAAZ,EAAAxlF,OAdApF,MAAAgrF,UAAA,EAmBAhrF,MAAAgE,QAAAgC,IAAA,kBACA,gBAAAZ,GACApF,KAAAgE,QAAA2sB,IAAA,2CACS3wB,KAAAkrF,WAAAlrF,KAAAkrF,UAAAxlE,KACT1lB,KAAAgE,QAAA2sB,IAAA,eAAA3wB,KAAAkrF,UAAAxlE,MACSykE,EAAAxrD,cAAA2sD,gBAAAzqF,UAAAoqF,cAAA7lF,IACTpF,KAAAgE,QAAA2sB,IAAA,oEAKAw5D,EAAAv4B,OACA5xD,KAAA4xD,KAAA,WACA,GAAA85B,GAAArB,EAAArqF,KACA,IAAA0rF,EACA,MAAAA,EAGA,IAAA1rF,KAAAkrF,UACA,MAAA/mF,SAAAoK,QAAAvO,KAAAkrF,UACS,IAAAlrF,KAAAwrF,iBACT,MAAArnF,SAAAoK,QAAA,GAAA0mB,OAAAj1B,KAAAwrF,mBACS,IAAAxrF,KAAAqrF,cACT,SAAA7kF,OAAA,uCAEA,OAAArC,SAAAoK,QAAA,GAAA0mB,OAAAj1B,KAAAgrF,cAIAhrF,KAAA4yD,YAAA,WACA,MAAA5yD,MAAAwrF,iBACAnB,EAAArqF,OAAAmE,QAAAoK,QAAAvO,KAAAwrF,kBAEAxrF,KAAA4xD,OAAAvuD,KAAAmnF;GAKAxqF,KAAAmG,KAAA,WACA,GAAAulF,GAAArB,EAAArqF,KACA,IAAA0rF,EACA,MAAAA,EAGA,IAAA1rF,KAAAkrF,UACA,MAAAT,GAAAzqF,KAAAkrF,UACO,IAAAlrF,KAAAwrF,iBACP,MAAArnF,SAAAoK,QAAAo8E,EAAA3qF,KAAAwrF,kBACO,IAAAxrF,KAAAqrF,cACP,SAAA7kF,OAAA,uCAEA,OAAArC,SAAAoK,QAAAvO,KAAAgrF,YAIAb,EAAAgB,WACAnrF,KAAAmrF,SAAA,WACA,MAAAnrF,MAAAmG,OAAA9C,KAAAsoF,KAIA3rF,KAAAkG,KAAA,WACA,MAAAlG,MAAAmG,OAAA9C,KAAAqC,KAAAmsB,QAGA7xB,KAMA,QAAA4rF,GAAAzmF,GACA,GAAA0mF,GAAA1mF,EAAAihC,aACA,OAAA0lD,GAAA7lF,QAAA4lF,IAAA,EAAAA,EAAA1mF,EAGA,QAAA4mF,GAAA95E,EAAAjP,GACAA,OACA,IAAAoC,GAAApC,EAAAoC,IAEA,IAAA6M,YAAA85E,GAAA,CACA,GAAA95E,EAAAq4E,SACA,SAAAxoF,WAAA,eAEA9B,MAAAgH,IAAAiL,EAAAjL,IACAhH,KAAA4D,YAAAqO,EAAArO,YACAZ,EAAAgB,UACAhE,KAAAgE,QAAA,GAAAipE,GAAAh7D,EAAAjO,UAEAhE,KAAAmF,OAAA8M,EAAA9M,OACAnF,KAAAg5D,KAAA/mD,EAAA+mD,KACA5zD,GAAA,MAAA6M,EAAA84E,YACA3lF,EAAA6M,EAAA84E,UACA94E,EAAAq4E,UAAA,OAGAtqF,MAAAgH,IAAAqY,OAAApN,EAWA,IARAjS,KAAA4D,YAAAZ,EAAAY,aAAA5D,KAAA4D,aAAA,QACAZ,EAAAgB,SAAAhE,KAAAgE,UACAhE,KAAAgE,QAAA,GAAAipE,GAAAjqE,EAAAgB,UAEAhE,KAAAmF,OAAAymF,EAAA5oF,EAAAmC,QAAAnF,KAAAmF,QAAA,OACAnF,KAAAg5D,KAAAh2D,EAAAg2D,MAAAh5D,KAAAg5D,MAAA,KACAh5D,KAAAgsF,SAAA,MAEA,QAAAhsF,KAAAmF,QAAA,SAAAnF,KAAAmF,SAAAC,EACA,SAAAtD,WAAA,4CAEA9B,MAAA8qF,UAAA1lF,GAOA,QAAAumF,GAAAvmF,GACA,GAAA6mF,GAAA,GAAAb,SASA,OARAhmF,GAAAsvB,OAAAtkB,MAAA,KAAAyB,QAAA,SAAA6/C,GACA,GAAAA,EAAA,CACA,GAAAthD,GAAAshD,EAAAthD,MAAA,KACAtH,EAAAsH,EAAA09C,QAAA7mD,QAAA,WACA1E,EAAA6N,EAAA4D,KAAA,KAAA/M,QAAA,UACAglF,GAAA58D,OAAA/e,mBAAAxH,GAAAwH,mBAAA/N,OAGA0pF,EAGA,QAAAC,GAAAC,GACA,GAAAnoF,GAAA,GAAAipE,EASA,OARAkf,GAAA/7E,MAAA,SAAAyB,QAAA,SAAAu6E,GACA,GAAAj8E,GAAAi8E,EAAAh8E,MAAA,KACAzE,EAAAwE,EAAA29C,QAAAp5B,MACA,IAAA/oB,EAAA,CACA,GAAApJ,GAAA4N,EAAA6D,KAAA,KAAA0gB,MACA1wB,GAAAqrB,OAAA1jB,EAAApJ,MAGAyB,EAKA,QAAAqoF,GAAAC,EAAAtpF,GACAA,IACAA,MAGAhD,KAAA0lB,KAAA,UACA1lB,KAAAyE,OAAA,UAAAzB,KAAAyB,OAAA,IACAzE,KAAA6F,GAAA7F,KAAAyE,QAAA,KAAAzE,KAAAyE,OAAA,IACAzE,KAAAusF,WAAA,cAAAvpF,KAAAupF,WAAA,KACAvsF,KAAAgE,QAAA,GAAAipE,GAAAjqE,EAAAgB,SACAhE,KAAAgH,IAAAhE,EAAAgE,KAAA,GACAhH,KAAA8qF,UAAAwB,GA7XA,IAAAtqF,EAAAwB,MAAA,CAIA,GAAA2mF,IACAxrD,aAAA,mBAAA38B,GACA6oB,SAAA,UAAA7oB,IAAA,YAAAiG,QACA2pD,KAAA,cAAA5vD,IAAA,QAAAA,IAAA,WACA,IAEA,MADA,IAAAizB,OACA,EACO,MAAA5tB,GACP,aAGA8jF,SAAA,YAAAnpF,GACA4wD,YAAA,eAAA5wD,GAGA,IAAAmoF,EAAAv3B,YACA,GAAA45B,IACA,qBACA,sBACA,6BACA,sBACA,uBACA,sBACA,uBACA,wBACA,yBAGAjB,EAAA,SAAA/pF,GACA,MAAAA,IAAAirF,SAAA5rF,UAAAoqF,cAAAzpF,IAGAiqF,EAAAp7D,YAAAq8D,QAAA,SAAAlrF,GACA,MAAAA,IAAAgrF,EAAAvmF,QAAArF,OAAAC,UAAAkZ,SAAAxZ,KAAAiB,KAAA,EAyDAyrE,GAAApsE,UAAAwuB,OAAA,SAAAvmB,EAAAvG,GACAuG,EAAAihF,EAAAjhF,GACAvG,EAAAynF,EAAAznF,EACA,IAAAoqF,GAAA3sF,KAAA0N,IAAA5E,EACA9I,MAAA0N,IAAA5E,GAAA6jF,IAAA,IAAApqF,KAGA0qE,EAAApsE,UAAA,gBAAAiI,SACA9I,MAAA0N,IAAAq8E,EAAAjhF,KAGAmkE,EAAApsE,UAAAmF,IAAA,SAAA8C,GAEA,MADAA,GAAAihF,EAAAjhF,GACA9I,KAAA4+B,IAAA91B,GAAA9I,KAAA0N,IAAA5E,GAAA,MAGAmkE,EAAApsE,UAAA+9B,IAAA,SAAA91B,GACA,MAAA9I,MAAA0N,IAAA5M,eAAAipF,EAAAjhF,KAGAmkE,EAAApsE,UAAA8vB,IAAA,SAAA7nB,EAAAvG,GACAvC,KAAA0N,IAAAq8E,EAAAjhF,IAAAkhF,EAAAznF,IAGA0qE,EAAApsE,UAAAgR,QAAA,SAAA3H,EAAA0iF,GACA,OAAA9jF,KAAA9I,MAAA0N,IACA1N,KAAA0N,IAAA5M,eAAAgI,IACAoB,EAAA3J,KAAAqsF,EAAA5sF,KAAA0N,IAAA5E,KAAA9I,OAKAitE,EAAApsE,UAAA4M,KAAA,WACA,GAAAy8E,KAEA,OADAlqF,MAAA6R,QAAA,SAAAtP,EAAAuG,GAAwCohF,EAAA7hF,KAAAS,KACxCmhF,EAAAC,IAGAjd,EAAApsE,UAAAoqB,OAAA,WACA,GAAAi/D,KAEA,OADAlqF,MAAA6R,QAAA,SAAAtP,GAAkC2nF,EAAA7hF,KAAA9F,KAClC0nF,EAAAC,IAGAjd,EAAApsE,UAAAgsF,QAAA,WACA,GAAA3C,KAEA,OADAlqF,MAAA6R,QAAA,SAAAtP,EAAAuG,GAAwCohF,EAAA7hF,MAAAS,EAAAvG,MACxC0nF,EAAAC,IAGAC,EAAAt/D,WACAoiD,EAAApsE,UAAAoH,OAAAC,UAAA+kE,EAAApsE,UAAAgsF,QAqJA,IAAAf,IAAA,6CA4CAC,GAAAlrF,UAAA0J,MAAA,WACA,UAAAwhF,GAAA/rF,MAA8BoF,KAAApF,KAAA+qF,aA6B9BF,EAAAtqF,KAAAwrF,EAAAlrF,WAgBAgqF,EAAAtqF,KAAA8rF,EAAAxrF,WAEAwrF,EAAAxrF,UAAA0J,MAAA,WACA,UAAA8hF,GAAArsF,KAAA+qF,WACAtmF,OAAAzE,KAAAyE,OACA8nF,WAAAvsF,KAAAusF,WACAvoF,QAAA,GAAAipE,GAAAjtE,KAAAgE,SACAgD,IAAAhH,KAAAgH,OAIAqlF,EAAAhmF,MAAA,WACA,GAAAd,GAAA,GAAA8mF,GAAA,MAAuC5nF,OAAA,EAAA8nF,WAAA,IAEvC,OADAhnF,GAAAmgB,KAAA,QACAngB,EAGA,IAAAunF,IAAA,oBAEAT,GAAArvD,SAAA,SAAAh2B,EAAAvC,GACA,GAAAqoF,EAAA7mF,QAAAxB,MAAA,EACA,SAAAsoF,YAAA,sBAGA,WAAAV,GAAA,MAA+B5nF,SAAAT,SAA0B6C,SAAAG,MAGzDhF,EAAAirE,UACAjrE,EAAA+pF,UACA/pF,EAAAqqF,WAEArqF,EAAAwB,MAAA,SAAAyO,EAAAmrB,GACA,UAAAj5B,SAAA,SAAAoK,EAAAtE,GACA,GAAAmvC,GAAA,GAAA2yC,GAAA95E,EAAAmrB,GACAowC,EAAA,GAAAO,eAEAP,GAAAjtC,OAAA,WACA,GAAAv9B,IACAyB,OAAA+oE,EAAA/oE,OACA8nF,WAAA/e,EAAA+e,WACAvoF,QAAAkoF,EAAA1e,EAAAwf,yBAAA,IAEAhqF,GAAAgE,IAAA,eAAAwmE,KAAAyf,YAAAjqF,EAAAgB,QAAAgC,IAAA,gBACA,IAAAZ,GAAA,YAAAooE,KAAAjoE,SAAAioE,EAAAc,YACA//D,GAAA,GAAA89E,GAAAjnF,EAAApC,KAGAwqE,EAAApR,QAAA,WACAnyD,EAAA,GAAAnI,WAAA,4BAGA0rE,EAAA9T,UAAA,WACAzvD,EAAA,GAAAnI,WAAA,4BAGA0rE,EAAA/J,KAAArqB,EAAAj0C,OAAAi0C,EAAApyC,KAAA,GAEA,YAAAoyC,EAAAx1C,cACA4pE,EAAAQ,iBAAA,GAGA,gBAAAR,IAAA2c,EAAAv4B,OACA4b,EAAAU,aAAA,QAGA90B,EAAAp1C,QAAA6N,QAAA,SAAAtP,EAAAuG,GACA0kE,EAAAW,iBAAArlE,EAAAvG,KAGAirE,EAAAe,KAAA,mBAAAn1B,GAAA2xC,UAAA,KAAA3xC,EAAA2xC,cAGA/oF,EAAAwB,MAAA0pF,UAAA,IACC,mBAAAlrF,WAAAhC,OjG0ztBK,SAASH,EAAQD,KAMvB","file":"cozy-client.min.js","sourcesContent":["(function webpackUniversalModuleDefinition(root, factory) {\n\tif(typeof exports === 'object' && typeof module === 'object')\n\t\tmodule.exports = factory();\n\telse if(typeof define === 'function' && define.amd)\n\t\tdefine(\"client\", [], factory);\n\telse if(typeof exports === 'object')\n\t\texports[\"client\"] = factory();\n\telse\n\t\troot[\"cozy\"] = root[\"cozy\"] || {}, root[\"cozy\"][\"client\"] = factory();\n})(this, function() {\nreturn \n\n\n// WEBPACK FOOTER //\n// webpack/universalModuleDefinition","(function webpackUniversalModuleDefinition(root, factory) {\n\tif(typeof exports === 'object' && typeof module === 'object')\n\t\tmodule.exports = factory();\n\telse if(typeof define === 'function' && define.amd)\n\t\tdefine(\"client\", [], factory);\n\telse if(typeof exports === 'object')\n\t\texports[\"client\"] = factory();\n\telse\n\t\troot[\"cozy\"] = root[\"cozy\"] || {}, root[\"cozy\"][\"client\"] = factory();\n})(this, function() {\nreturn /******/ (function(modules) { // webpackBootstrap\n/******/ \t// The module cache\n/******/ \tvar installedModules = {};\n/******/\n/******/ \t// The require function\n/******/ \tfunction __webpack_require__(moduleId) {\n/******/\n/******/ \t\t// Check if module is in cache\n/******/ \t\tif(installedModules[moduleId])\n/******/ \t\t\treturn installedModules[moduleId].exports;\n/******/\n/******/ \t\t// Create a new module (and put it into the cache)\n/******/ \t\tvar module = installedModules[moduleId] = {\n/******/ \t\t\texports: {},\n/******/ \t\t\tid: moduleId,\n/******/ \t\t\tloaded: false\n/******/ \t\t};\n/******/\n/******/ \t\t// Execute the module function\n/******/ \t\tmodules[moduleId].call(module.exports, module, module.exports, __webpack_require__);\n/******/\n/******/ \t\t// Flag the module as loaded\n/******/ \t\tmodule.loaded = true;\n/******/\n/******/ \t\t// Return the exports of the module\n/******/ \t\treturn module.exports;\n/******/ \t}\n/******/\n/******/\n/******/ \t// expose the modules object (__webpack_modules__)\n/******/ \t__webpack_require__.m = modules;\n/******/\n/******/ \t// expose the module cache\n/******/ \t__webpack_require__.c = installedModules;\n/******/\n/******/ \t// __webpack_public_path__\n/******/ \t__webpack_require__.p = \"\";\n/******/\n/******/ \t// Load entry module and return exports\n/******/ \treturn __webpack_require__(0);\n/******/ })\n/************************************************************************/\n/******/ ((function(modules) {\n\t// Check all modules for deduplicated modules\n\tfor(var i in modules) {\n\t\tif(Object.prototype.hasOwnProperty.call(modules, i)) {\n\t\t\tswitch(typeof modules[i]) {\n\t\t\tcase \"function\": break;\n\t\t\tcase \"object\":\n\t\t\t\t// Module can be created from a template\n\t\t\t\tmodules[i] = (function(_m) {\n\t\t\t\t\tvar args = _m.slice(1), fn = modules[_m[0]];\n\t\t\t\t\treturn function (a,b,c) {\n\t\t\t\t\t\tfn.apply(this, [a,b,c].concat(args));\n\t\t\t\t\t};\n\t\t\t\t}(modules[i]));\n\t\t\t\tbreak;\n\t\t\tdefault:\n\t\t\t\t// Module is a copy of another module\n\t\t\t\tmodules[i] = modules[modules[i]];\n\t\t\t\tbreak;\n\t\t\t}\n\t\t}\n\t}\n\treturn modules;\n}([\n/* 0 */\n/***/ function(module, exports, __webpack_require__) {\n\n\t__webpack_require__(76);\n\tmodule.exports = __webpack_require__(40);\n\n\n/***/ },\n/* 1 */\n/***/ function(module, exports, __webpack_require__) {\n\n\t'use strict';\n\t\n\tObject.defineProperty(exports, \"__esModule\", {\n\t  value: true\n\t});\n\texports.FetchError = undefined;\n\t\n\tvar _slicedToArray = function () { function sliceIterator(arr, i) { var _arr = []; var _n = true; var _d = false; var _e = undefined; try { for (var _i = arr[Symbol.iterator](), _s; !(_n = (_s = _i.next()).done); _n = true) { _arr.push(_s.value); if (i && _arr.length === i) break; } } catch (err) { _d = true; _e = err; } finally { try { if (!_n && _i[\"return\"]) _i[\"return\"](); } finally { if (_d) throw _e; } } return _arr; } return function (arr, i) { if (Array.isArray(arr)) { return arr; } else if (Symbol.iterator in Object(arr)) { return sliceIterator(arr, i); } else { throw new TypeError(\"Invalid attempt to destructure non-iterable instance\"); } }; }(); /* global fetch */\n\t\n\t\n\texports.cozyFetch = cozyFetch;\n\texports.cozyFetchJSON = cozyFetchJSON;\n\texports.cozyFetchRawJSON = cozyFetchRawJSON;\n\texports.handleInvalidTokenError = handleInvalidTokenError;\n\t\n\tvar _auth_v = __webpack_require__(9);\n\t\n\tvar _utils = __webpack_require__(3);\n\t\n\tvar _jsonapi = __webpack_require__(18);\n\t\n\tvar _jsonapi2 = _interopRequireDefault(_jsonapi);\n\t\n\tfunction _interopRequireDefault(obj) { return obj && obj.__esModule ? obj : { default: obj }; }\n\t\n\tfunction _classCallCheck(instance, Constructor) { if (!(instance instanceof Constructor)) { throw new TypeError(\"Cannot call a class as a function\"); } }\n\t\n\tfunction _possibleConstructorReturn(self, call) { if (!self) { throw new ReferenceError(\"this hasn't been initialised - super() hasn't been called\"); } return call && (typeof call === \"object\" || typeof call === \"function\") ? call : self; }\n\t\n\tfunction _inherits(subClass, superClass) { if (typeof superClass !== \"function\" && superClass !== null) { throw new TypeError(\"Super expression must either be null or a function, not \" + typeof superClass); } subClass.prototype = Object.create(superClass && superClass.prototype, { constructor: { value: subClass, enumerable: false, writable: true, configurable: true } }); if (superClass) Object.setPrototypeOf ? Object.setPrototypeOf(subClass, superClass) : subClass.__proto__ = superClass; }\n\t\n\tfunction cozyFetch(cozy, path) {\n\t  var options = arguments.length > 2 && arguments[2] !== undefined ? arguments[2] : {};\n\t\n\t  return cozy.fullpath(path).then(function (fullpath) {\n\t    var resp = void 0;\n\t    if (options.disableAuth) {\n\t      resp = fetch(fullpath, options);\n\t    } else if (options.manualAuthCredentials) {\n\t      resp = cozyFetchWithAuth(cozy, fullpath, options, options.manualAuthCredentials);\n\t    } else {\n\t      resp = cozy.authorize().then(function (credentials) {\n\t        return cozyFetchWithAuth(cozy, fullpath, options, credentials);\n\t      });\n\t    }\n\t    return resp.then(function (res) {\n\t      return handleResponse(res, cozy._invalidTokenErrorHandler);\n\t    });\n\t  });\n\t}\n\t\n\tfunction cozyFetchWithAuth(cozy, fullpath, options, credentials) {\n\t  if (credentials) {\n\t    options.headers = options.headers || {};\n\t    options.headers['Authorization'] = credentials.token.toAuthHeader();\n\t  }\n\t\n\t  // the option credentials:include tells fetch to include the cookies in the\n\t  // request even for cross-origin requests\n\t  options.credentials = 'include';\n\t\n\t  return Promise.all([cozy.isV2(), fetch(fullpath, options)]).then(function (_ref) {\n\t    var _ref2 = _slicedToArray(_ref, 2),\n\t        isV2 = _ref2[0],\n\t        res = _ref2[1];\n\t\n\t    if (res.status !== 400 && res.status !== 401 || isV2 || !credentials || options.dontRetry) {\n\t      return res;\n\t    }\n\t    // we try to refresh the token only for OAuth, ie, the client defined\n\t    // and the token is an instance of AccessToken.\n\t    var client = credentials.client,\n\t        token = credentials.token;\n\t\n\t    if (!client || !(token instanceof _auth_v.AccessToken)) {\n\t      return res;\n\t    }\n\t    options.dontRetry = true;\n\t    return (0, _utils.retry)(function () {\n\t      return (0, _auth_v.refreshToken)(cozy, client, token);\n\t    }, 3)().then(function (newToken) {\n\t      return cozy.saveCredentials(client, newToken);\n\t    }).then(function (credentials) {\n\t      return cozyFetchWithAuth(cozy, fullpath, options, credentials);\n\t    });\n\t  });\n\t}\n\t\n\tfunction cozyFetchJSON(cozy, method, path, body) {\n\t  var options = arguments.length > 4 && arguments[4] !== undefined ? arguments[4] : {};\n\t\n\t  var processJSONAPI = typeof options.processJSONAPI === 'undefined' || options.processJSONAPI;\n\t  return fetchJSON(cozy, method, path, body, options).then(function (response) {\n\t    return handleJSONResponse(response, processJSONAPI);\n\t  });\n\t}\n\t\n\tfunction cozyFetchRawJSON(cozy, method, path, body) {\n\t  var options = arguments.length > 4 && arguments[4] !== undefined ? arguments[4] : {};\n\t\n\t  return fetchJSON(cozy, method, path, body, options).then(function (response) {\n\t    return handleJSONResponse(response, false);\n\t  });\n\t}\n\t\n\tfunction fetchJSON(cozy, method, path, body) {\n\t  var options = arguments.length > 4 && arguments[4] !== undefined ? arguments[4] : {};\n\t\n\t  options.method = method;\n\t\n\t  var headers = options.headers = options.headers || {};\n\t\n\t  headers['Accept'] = 'application/json';\n\t\n\t  if (method !== 'GET' && method !== 'HEAD' && body !== undefined) {\n\t    if (headers['Content-Type']) {\n\t      options.body = body;\n\t    } else {\n\t      headers['Content-Type'] = 'application/json';\n\t      options.body = JSON.stringify(body);\n\t    }\n\t  }\n\t\n\t  return cozyFetch(cozy, path, options);\n\t}\n\t\n\tfunction handleResponse(res, invalidTokenErrorHandler) {\n\t  if (res.ok) {\n\t    return res;\n\t  }\n\t  var data = void 0;\n\t  var contentType = res.headers.get('content-type');\n\t  if (contentType && contentType.indexOf('json') >= 0) {\n\t    data = res.json();\n\t  } else {\n\t    data = res.text();\n\t  }\n\t  return data.then(function (err) {\n\t    var error = new FetchError(res, err);\n\t    if (FetchError.isInvalidToken(error) && invalidTokenErrorHandler) {\n\t      invalidTokenErrorHandler(error);\n\t    }\n\t    throw error;\n\t  });\n\t}\n\t\n\tfunction handleJSONResponse(res) {\n\t  var processJSONAPI = arguments.length > 1 && arguments[1] !== undefined ? arguments[1] : true;\n\t\n\t  var contentType = res.headers.get('content-type');\n\t  if (!contentType || contentType.indexOf('json') < 0) {\n\t    return res.text(function (data) {\n\t      throw new FetchError(res, new Error('Response is not JSON: ' + data));\n\t    });\n\t  }\n\t\n\t  var json = res.json();\n\t  if (contentType.indexOf('application/vnd.api+json') === 0 && processJSONAPI) {\n\t    return json.then(_jsonapi2.default);\n\t  } else {\n\t    return json;\n\t  }\n\t}\n\t\n\tfunction handleInvalidTokenError(error) {\n\t  try {\n\t    var currentOrigin = window.location.origin;\n\t    var requestUrl = error.url;\n\t\n\t    if (requestUrl.indexOf(currentOrigin.replace(/^(https?:\\/\\/\\w+)-\\w+\\./, '$1.')) === 0) {\n\t      var redirectURL = currentOrigin + '?' + (0, _utils.encodeQuery)({ 'disconnect': 1 });\n\t      window.location = redirectURL;\n\t    }\n\t  } catch (e) {\n\t    console.warn('Unable to handle invalid token error', e, error);\n\t  }\n\t}\n\t\n\tvar FetchError = exports.FetchError = function (_Error) {\n\t  _inherits(FetchError, _Error);\n\t\n\t  function FetchError(res, reason) {\n\t    _classCallCheck(this, FetchError);\n\t\n\t    var _this = _possibleConstructorReturn(this, (FetchError.__proto__ || Object.getPrototypeOf(FetchError)).call(this));\n\t\n\t    if (Error.captureStackTrace) {\n\t      Error.captureStackTrace(_this, _this.constructor);\n\t    }\n\t    // XXX We have to hardcode this because babel doesn't play nice when extending Error\n\t    _this.name = 'FetchError';\n\t    _this.response = res;\n\t    _this.url = res.url;\n\t    _this.status = res.status;\n\t    _this.reason = reason;\n\t\n\t    Object.defineProperty(_this, 'message', {\n\t      value: reason.message || (typeof reason === 'string' ? reason : JSON.stringify(reason))\n\t    });\n\t    return _this;\n\t  }\n\t\n\t  return FetchError;\n\t}(Error);\n\t\n\tFetchError.isUnauthorized = function (err) {\n\t  // XXX We can't use err instanceof FetchError because of the caveats of babel\n\t  return err.name === 'FetchError' && err.status === 401;\n\t};\n\t\n\tFetchError.isNotFound = function (err) {\n\t  // XXX We can't use err instanceof FetchError because of the caveats of babel\n\t  return err.name === 'FetchError' && err.status === 404;\n\t};\n\t\n\tFetchError.isInvalidToken = function (err) {\n\t  // XXX We can't use err instanceof FetchError because of the caveats of babel\n\t  return err.name === 'FetchError' && err.status === 400 && err.reason && (err.reason.error === 'Invalid JWT token' || err.reason.error === 'Expired token');\n\t};\n\n/***/ },\n/* 2 */\n/***/ function(module, exports, __webpack_require__) {\n\n\t/* WEBPACK VAR INJECTION */(function(process) {'use strict';\n\t\n\tvar Promise = __webpack_require__(33);\n\t\n\t/* istanbul ignore next */\n\texports.once = function (fun) {\n\t  var called = false;\n\t  return exports.getArguments(function (args) {\n\t    if (called) {\n\t      console.trace();\n\t      throw new Error('once called  more than once');\n\t    } else {\n\t      called = true;\n\t      fun.apply(this, args);\n\t    }\n\t  });\n\t};\n\t/* istanbul ignore next */\n\texports.getArguments = function (fun) {\n\t  return function () {\n\t    var len = arguments.length;\n\t    var args = new Array(len);\n\t    var i = -1;\n\t    while (++i < len) {\n\t      args[i] = arguments[i];\n\t    }\n\t    return fun.call(this, args);\n\t  };\n\t};\n\t/* istanbul ignore next */\n\texports.toPromise = function (func) {\n\t  //create the function we will be returning\n\t  return exports.getArguments(function (args) {\n\t    var self = this;\n\t    var tempCB = (typeof args[args.length - 1] === 'function') ? args.pop() : false;\n\t    // if the last argument is a function, assume its a callback\n\t    var usedCB;\n\t    if (tempCB) {\n\t      // if it was a callback, create a new callback which calls it,\n\t      // but do so async so we don't trap any errors\n\t      usedCB = function (err, resp) {\n\t        process.nextTick(function () {\n\t          tempCB(err, resp);\n\t        });\n\t      };\n\t    }\n\t    var promise = new Promise(function (fulfill, reject) {\n\t      try {\n\t        var callback = exports.once(function (err, mesg) {\n\t          if (err) {\n\t            reject(err);\n\t          } else {\n\t            fulfill(mesg);\n\t          }\n\t        });\n\t        // create a callback for this invocation\n\t        // apply the function in the orig context\n\t        args.push(callback);\n\t        func.apply(self, args);\n\t      } catch (e) {\n\t        reject(e);\n\t      }\n\t    });\n\t    // if there is a callback, call it back\n\t    if (usedCB) {\n\t      promise.then(function (result) {\n\t        usedCB(null, result);\n\t      }, usedCB);\n\t    }\n\t    promise.cancel = function () {\n\t      return this;\n\t    };\n\t    return promise;\n\t  });\n\t};\n\t\n\texports.inherits = __webpack_require__(14);\n\texports.Promise = Promise;\n\t\n\texports.clone = function (obj) {\n\t  return exports.extend(true, {}, obj);\n\t};\n\t\n\texports.extend = __webpack_require__(29);\n\t\n\texports.callbackify = function (fun) {\n\t  return exports.getArguments(function (args) {\n\t    var cb = args.pop();\n\t    var promise = fun.apply(this, args);\n\t    exports.promisedCallback(promise, cb);\n\t    return promise;\n\t  });\n\t};\n\t\n\texports.promisedCallback = function (promise, callback) {\n\t  promise.then(function (res) {\n\t    process.nextTick(function () {\n\t      callback(null, res);\n\t    });\n\t  }, function (reason) {\n\t    process.nextTick(function () {\n\t      callback(reason);\n\t    });\n\t  });\n\t  return promise;\n\t};\n\t\n\tvar crypto = __webpack_require__(98);\n\tvar Md5 = __webpack_require__(34);\n\t\n\texports.MD5 = function (string) {\n\t  /* istanbul ignore else */\n\t  if (!process.browser) {\n\t    return crypto.createHash('md5').update(string).digest('hex');\n\t  } else {\n\t    return Md5.hash(string);\n\t  }\n\t};\n\t\n\texports.flatten = exports.getArguments(function (args) {\n\t  var res = [];\n\t  for (var i = 0, len = args.length; i < len; i++) {\n\t    var subArr = args[i];\n\t    if (Array.isArray(subArr)) {\n\t      res = res.concat(exports.flatten.apply(null, subArr));\n\t    } else {\n\t      res.push(subArr);\n\t    }\n\t  }\n\t  return res;\n\t});\n\t\n\texports.mergeObjects = function (arr) {\n\t  var res = {};\n\t  for (var i = 0, len = arr.length; i < len; i++) {\n\t    res = exports.extend(true, res, arr[i]);\n\t  }\n\t  return res;\n\t};\n\t\n\t// this would just be \"return doc[field]\", but fields\n\t// can be \"deep\" due to dot notation\n\texports.getFieldFromDoc = function (doc, parsedField) {\n\t  var value = doc;\n\t  for (var i = 0, len = parsedField.length; i < len; i++) {\n\t    var key = parsedField[i];\n\t    value = value[key];\n\t    if (!value) {\n\t      break;\n\t    }\n\t  }\n\t  return value;\n\t};\n\t\n\texports.setFieldInDoc = function (doc, parsedField, value) {\n\t  for (var i = 0, len = parsedField.length; i < len-1; i++) {\n\t    var elem = parsedField[i];\n\t    doc = doc[elem] = {};\n\t  }\n\t  doc[parsedField[len-1]] = value;\n\t};\n\t\n\t// Converts a string in dot notation to an array of its components, with backslash escaping\n\texports.parseField = function (fieldName) {\n\t  // fields may be deep (e.g. \"foo.bar.baz\"), so parse\n\t  var fields = [];\n\t  var current = '';\n\t  for (var i = 0, len = fieldName.length; i < len; i++) {\n\t    var ch = fieldName[i];\n\t    if (ch === '.') {\n\t      if (i > 0 && fieldName[i - 1] === '\\\\') { // escaped delimiter\n\t        current = current.substring(0, current.length - 1) + '.';\n\t      } else { // not escaped, so delimiter\n\t        fields.push(current);\n\t        current = '';\n\t      }\n\t    } else { // normal character\n\t      current += ch;\n\t    }\n\t  }\n\t  fields.push(current);\n\t  return fields;\n\t};\n\t\n\t// Selects a list of fields defined in dot notation from one doc\n\t// and copies them to a new doc. Like underscore _.pick but supports nesting.\n\texports.pick = function (obj, arr) {\n\t  var res = {};\n\t  for (var i = 0, len = arr.length; i < len; i++) {\n\t    var parsedField = exports.parseField(arr[i]);\n\t    var value = exports.getFieldFromDoc(obj, parsedField);\n\t    if(typeof value !== 'undefined') {\n\t      exports.setFieldInDoc(res, parsedField, value);\n\t    }\n\t  }\n\t  return res;\n\t};\n\t\n\t// e.g. ['a'], ['a', 'b'] is true, but ['b'], ['a', 'b'] is false\n\texports.oneArrayIsSubArrayOfOther = function (left, right) {\n\t\n\t  for (var i = 0, len = Math.min(left.length, right.length); i < len; i++) {\n\t    if (left[i] !== right[i]) {\n\t      return false;\n\t    }\n\t  }\n\t  return true;\n\t};\n\t\n\t// e.g.['a', 'b', 'c'], ['a', 'b'] is false\n\texports.oneArrayIsStrictSubArrayOfOther = function (left, right) {\n\t\n\t  if (left.length > right.length) {\n\t    return false;\n\t  }\n\t\n\t  return exports.oneArrayIsSubArrayOfOther(left, right);\n\t};\n\t\n\t// same as above, but treat the left array as an unordered set\n\t// e.g. ['b', 'a'], ['a', 'b', 'c'] is true, but ['c'], ['a', 'b', 'c'] is false\n\texports.oneSetIsSubArrayOfOther = function (left, right) {\n\t  left = left.slice();\n\t  for (var i = 0, len = right.length; i < len; i++) {\n\t    var field = right[i];\n\t    if (!left.length) {\n\t      break;\n\t    }\n\t    var leftIdx = left.indexOf(field);\n\t    if (leftIdx === -1) {\n\t      return false;\n\t    } else {\n\t      left.splice(leftIdx, 1);\n\t    }\n\t  }\n\t  return true;\n\t};\n\t\n\texports.compare = function (left, right) {\n\t  return left < right ? -1 : left > right ? 1 : 0;\n\t};\n\t\n\texports.arrayToObject = function (arr) {\n\t  var res = {};\n\t  for (var i = 0, len = arr.length; i < len; i++) {\n\t    res[arr[i]] = true;\n\t  }\n\t  return res;\n\t};\n\t\n\texports.max = function (arr, fun) {\n\t  var max = null;\n\t  var maxScore = -1;\n\t  for (var i = 0, len = arr.length; i < len; i++) {\n\t    var element = arr[i];\n\t    var score = fun(element);\n\t    if (score > maxScore) {\n\t      maxScore = score;\n\t      max = element;\n\t    }\n\t  }\n\t  return max;\n\t};\n\t\n\texports.arrayEquals = function (arr1, arr2) {\n\t  if (arr1.length !== arr2.length) {\n\t    return false;\n\t  }\n\t  for (var i = 0, len = arr1.length; i < len; i++) {\n\t    if (arr1[i] !== arr2[i]) {\n\t      return false;\n\t    }\n\t  }\n\t  return true;\n\t};\n\t\n\texports.uniq = function(arr) {\n\t  var obj = {};\n\t  for (var i = 0; i < arr.length; i++) {\n\t    obj['$' + arr[i]] = true;\n\t  }\n\t  return Object.keys(obj).map(function (key) {\n\t    return key.substring(1);\n\t  });\n\t};\n\t\n\texports.log = __webpack_require__(27)('pouchdb:find');\n\t\n\t/* WEBPACK VAR INJECTION */}.call(exports, __webpack_require__(5)))\n\n/***/ },\n/* 3 */\n/***/ function(module, exports) {\n\n\t'use strict';\n\t\n\tObject.defineProperty(exports, \"__esModule\", {\n\t  value: true\n\t});\n\texports.unpromiser = unpromiser;\n\texports.isPromise = isPromise;\n\texports.isOnline = isOnline;\n\texports.isOffline = isOffline;\n\texports.sleep = sleep;\n\texports.retry = retry;\n\texports.getFuzzedDelay = getFuzzedDelay;\n\texports.getBackedoffDelay = getBackedoffDelay;\n\texports.createPath = createPath;\n\texports.encodeQuery = encodeQuery;\n\texports.decodeQuery = decodeQuery;\n\texports.warn = warn;\n\t/* global navigator */\n\tvar FuzzFactor = 0.3;\n\t\n\tfunction unpromiser(fn) {\n\t  return function () {\n\t    for (var _len = arguments.length, args = Array(_len), _key = 0; _key < _len; _key++) {\n\t      args[_key] = arguments[_key];\n\t    }\n\t\n\t    var value = fn.apply(this, args);\n\t    if (!isPromise(value)) {\n\t      return value;\n\t    }\n\t    var l = args.length;\n\t    if (l === 0 || typeof args[l - 1] !== 'function') {\n\t      return;\n\t    }\n\t    var cb = args[l - 1];\n\t    value.then(function (res) {\n\t      return cb(null, res);\n\t    }, function (err) {\n\t      return cb(err, null);\n\t    });\n\t  };\n\t}\n\t\n\tfunction isPromise(value) {\n\t  return !!value && typeof value.then === 'function';\n\t}\n\t\n\tfunction isOnline() {\n\t  return typeof navigator !== 'undefined' ? navigator.onLine : true;\n\t}\n\t\n\tfunction isOffline() {\n\t  return !isOnline();\n\t}\n\t\n\tfunction sleep(time, args) {\n\t  return new Promise(function (resolve) {\n\t    setTimeout(resolve, time, args);\n\t  });\n\t}\n\t\n\tfunction retry(fn, count) {\n\t  var delay = arguments.length > 2 && arguments[2] !== undefined ? arguments[2] : 300;\n\t\n\t  return function doTry() {\n\t    for (var _len2 = arguments.length, args = Array(_len2), _key2 = 0; _key2 < _len2; _key2++) {\n\t      args[_key2] = arguments[_key2];\n\t    }\n\t\n\t    return fn.apply(undefined, args).catch(function (err) {\n\t      if (--count < 0) {\n\t        throw err;\n\t      }\n\t      return sleep(getBackedoffDelay(delay, count)).then(function () {\n\t        return doTry.apply(undefined, args);\n\t      });\n\t    });\n\t  };\n\t}\n\t\n\tfunction getFuzzedDelay(retryDelay) {\n\t  var fuzzingFactor = (Math.random() * 2 - 1) * FuzzFactor;\n\t  return retryDelay * (1.0 + fuzzingFactor);\n\t}\n\t\n\tfunction getBackedoffDelay(retryDelay) {\n\t  var retryCount = arguments.length > 1 && arguments[1] !== undefined ? arguments[1] : 1;\n\t\n\t  return getFuzzedDelay(retryDelay * Math.pow(2, retryCount - 1));\n\t}\n\t\n\tfunction createPath(cozy, isV2, doctype) {\n\t  var id = arguments.length > 3 && arguments[3] !== undefined ? arguments[3] : '';\n\t  var query = arguments.length > 4 && arguments[4] !== undefined ? arguments[4] : null;\n\t\n\t  var route = '/data/';\n\t  if (!isV2) {\n\t    route += encodeURIComponent(doctype) + '/';\n\t  }\n\t  if (id !== '') {\n\t    route += encodeURIComponent(id);\n\t  }\n\t  var q = encodeQuery(query);\n\t  if (q !== '') {\n\t    route += '?' + q;\n\t  }\n\t  return route;\n\t}\n\t\n\tfunction encodeQuery(query) {\n\t  if (!query) {\n\t    return '';\n\t  }\n\t  var q = '';\n\t  for (var qname in query) {\n\t    if (q !== '') {\n\t      q += '&';\n\t    }\n\t    q += encodeURIComponent(qname) + '=' + encodeURIComponent(query[qname]);\n\t  }\n\t  return q;\n\t}\n\t\n\tfunction decodeQuery(url) {\n\t  var queryIndex = url.indexOf('?');\n\t  if (queryIndex < 0) {\n\t    queryIndex = url.length;\n\t  }\n\t  var queries = {};\n\t  var fragIndex = url.indexOf('#');\n\t  if (fragIndex < 0) {\n\t    fragIndex = url.length;\n\t  }\n\t  if (fragIndex < queryIndex) {\n\t    return queries;\n\t  }\n\t  var queryStr = url.slice(queryIndex + 1, fragIndex);\n\t  if (queryStr === '') {\n\t    return queries;\n\t  }\n\t  var parts = queryStr.split('&');\n\t  for (var i = 0; i < parts.length; i++) {\n\t    var pair = parts[i].split('=');\n\t    if (pair.length === 0 || pair[0] === '') {\n\t      continue;\n\t    }\n\t    var qname = decodeURIComponent(pair[0]);\n\t    if (queries.hasOwnProperty(qname)) {\n\t      continue;\n\t    }\n\t    if (pair.length === 1) {\n\t      queries[qname] = true;\n\t    } else if (pair.length === 2) {\n\t      queries[qname] = decodeURIComponent(pair[1]);\n\t    } else {\n\t      throw new Error('Malformed URL');\n\t    }\n\t  }\n\t  return queries;\n\t}\n\t\n\tvar warned = [];\n\tfunction warn(text) {\n\t  if (warned.indexOf(text) === -1) {\n\t    warned.push(text);\n\t    console.warn('cozy-client-js', text);\n\t  }\n\t}\n\n/***/ },\n/* 4 */\n/***/ function(module, exports, __webpack_require__) {\n\n\t'use strict';\n\t\n\tvar utils = __webpack_require__(2);\n\tvar collate = __webpack_require__(8);\n\t\n\tfunction getKey(obj) {\n\t  return Object.keys(obj)[0];\n\t}\n\t\n\tfunction getValue(obj) {\n\t  return obj[getKey(obj)];\n\t}\n\t\n\t// normalize the \"sort\" value\n\tfunction massageSort(sort) {\n\t  if (!Array.isArray(sort)) {\n\t    throw new Error('invalid sort json - should be an array');\n\t  }\n\t  return sort.map(function (sorting) {\n\t    if (typeof sorting === 'string') {\n\t      var obj = {};\n\t      obj[sorting] = 'asc';\n\t      return obj;\n\t    } else {\n\t      return sorting;\n\t    }\n\t  });\n\t}\n\t\n\tvar combinationFields = ['$or', '$nor', '$not'];\n\tfunction isCombinationalField (field) {\n\t  return combinationFields.indexOf(field) > -1;\n\t}\n\t\n\t// collapse logically equivalent gt/gte values\n\tfunction mergeGtGte(operator, value, fieldMatchers) {\n\t  if (typeof fieldMatchers.$eq !== 'undefined') {\n\t    return; // do nothing\n\t  }\n\t  if (typeof fieldMatchers.$gte !== 'undefined') {\n\t    if (operator === '$gte') {\n\t      if (value > fieldMatchers.$gte) { // more specificity\n\t        fieldMatchers.$gte = value;\n\t      }\n\t    } else { // operator === '$gt'\n\t      if (value >= fieldMatchers.$gte) { // more specificity\n\t        delete fieldMatchers.$gte;\n\t        fieldMatchers.$gt = value;\n\t      }\n\t    }\n\t  } else if (typeof fieldMatchers.$gt !== 'undefined') {\n\t    if (operator === '$gte') {\n\t      if (value > fieldMatchers.$gt) { // more specificity\n\t        delete fieldMatchers.$gt;\n\t        fieldMatchers.$gte = value;\n\t      }\n\t    } else { // operator === '$gt'\n\t      if (value > fieldMatchers.$gt) { // more specificity\n\t        fieldMatchers.$gt = value;\n\t      }\n\t    }\n\t  } else {\n\t    fieldMatchers[operator] = value;\n\t  }\n\t}\n\t\n\t// collapse logically equivalent lt/lte values\n\tfunction mergeLtLte(operator, value, fieldMatchers) {\n\t  if (typeof fieldMatchers.$eq !== 'undefined') {\n\t    return; // do nothing\n\t  }\n\t  if (typeof fieldMatchers.$lte !== 'undefined') {\n\t    if (operator === '$lte') {\n\t      if (value < fieldMatchers.$lte) { // more specificity\n\t        fieldMatchers.$lte = value;\n\t      }\n\t    } else { // operator === '$gt'\n\t      if (value <= fieldMatchers.$lte) { // more specificity\n\t        delete fieldMatchers.$lte;\n\t        fieldMatchers.$lt = value;\n\t      }\n\t    }\n\t  } else if (typeof fieldMatchers.$lt !== 'undefined') {\n\t    if (operator === '$lte') {\n\t      if (value < fieldMatchers.$lt) { // more specificity\n\t        delete fieldMatchers.$lt;\n\t        fieldMatchers.$lte = value;\n\t      }\n\t    } else { // operator === '$gt'\n\t      if (value < fieldMatchers.$lt) { // more specificity\n\t        fieldMatchers.$lt = value;\n\t      }\n\t    }\n\t  } else {\n\t    fieldMatchers[operator] = value;\n\t  }\n\t}\n\t\n\t// combine $ne values into one array\n\tfunction mergeNe(value, fieldMatchers) {\n\t  if ('$ne' in fieldMatchers) {\n\t    // there are many things this could \"not\" be\n\t    fieldMatchers.$ne.push(value);\n\t  } else { // doesn't exist yet\n\t    fieldMatchers.$ne = [value];\n\t  }\n\t}\n\t\n\t// add $eq into the mix\n\tfunction mergeEq(value, fieldMatchers) {\n\t  // these all have less specificity than the $eq\n\t  // TODO: check for user errors here\n\t  delete fieldMatchers.$gt;\n\t  delete fieldMatchers.$gte;\n\t  delete fieldMatchers.$lt;\n\t  delete fieldMatchers.$lte;\n\t  delete fieldMatchers.$ne;\n\t  fieldMatchers.$eq = value;\n\t}\n\t\n\t// flatten an array of selectors joined by an $and operator\n\tfunction mergeAndedSelectors(selectors) {\n\t\n\t  // sort to ensure that e.g. if the user specified\n\t  // $and: [{$gt: 'a'}, {$gt: 'b'}], then it's collapsed into\n\t  // just {$gt: 'b'}\n\t  var res = {};\n\t\n\t  selectors.forEach(function (selector) {\n\t    Object.keys(selector).forEach(function (field) {\n\t      var matcher = selector[field];\n\t      if (typeof matcher !== 'object') {\n\t        matcher = {$eq: matcher};\n\t      }\n\t\n\t      if (isCombinationalField(field)) {\n\t        if (matcher instanceof Array) {\n\t          res[field] = matcher.map(function (m) {\n\t            return mergeAndedSelectors([m]);\n\t          });\n\t        } else {\n\t          res[field] = mergeAndedSelectors([matcher]);\n\t        }\n\t      } else {\n\t        var fieldMatchers = res[field] = res[field] || {};\n\t        Object.keys(matcher).forEach(function (operator) {\n\t          var value = matcher[operator];\n\t\n\t          if (operator === '$gt' || operator === '$gte') {\n\t            return mergeGtGte(operator, value, fieldMatchers);\n\t          } else if (operator === '$lt' || operator === '$lte') {\n\t            return mergeLtLte(operator, value, fieldMatchers);\n\t          } else if (operator === '$ne') {\n\t            return mergeNe(value, fieldMatchers);\n\t          } else if (operator === '$eq') {\n\t            return mergeEq(value, fieldMatchers);\n\t          }\n\t          fieldMatchers[operator] = value;\n\t        });\n\t      }\n\t    });\n\t  });\n\t\n\t  return res;\n\t}\n\t\n\t//\n\t// normalize the selector\n\t//\n\tfunction massageSelector(input) {\n\t  var result = utils.clone(input);\n\t  var wasAnded = false;\n\t  if ('$and' in result) {\n\t    result = mergeAndedSelectors(result['$and']);\n\t    wasAnded = true;\n\t  }\n\t\n\t  if ('$not' in result) {\n\t    //This feels a little like forcing, but it will work for now,\n\t    //I would like to come back to this and make the merging of selectors a little more generic\n\t    result['$not'] = mergeAndedSelectors([result['$not']]);\n\t  }\n\t\n\t  var fields = Object.keys(result);\n\t\n\t  for (var i = 0; i < fields.length; i++) {\n\t    var field = fields[i];\n\t    var matcher = result[field];\n\t\n\t    if (typeof matcher !== 'object' || matcher === null) {\n\t      matcher = {$eq: matcher};\n\t    } else if ('$ne' in matcher && !wasAnded) {\n\t      // I put these in an array, since there may be more than one\n\t      // but in the \"mergeAnded\" operation, I already take care of that\n\t      matcher.$ne = [matcher.$ne];\n\t    }\n\t    result[field] = matcher;\n\t  }\n\t\n\t  return result;\n\t}\n\t\n\t\n\tfunction massageIndexDef(indexDef) {\n\t  indexDef.fields = indexDef.fields.map(function (field) {\n\t    if (typeof field === 'string') {\n\t      var obj = {};\n\t      obj[field] = 'asc';\n\t      return obj;\n\t    }\n\t    return field;\n\t  });\n\t  return indexDef;\n\t}\n\t\n\tfunction getKeyFromDoc(doc, index) {\n\t  var res = [];\n\t  for (var i = 0; i < index.def.fields.length; i++) {\n\t    var field = getKey(index.def.fields[i]);\n\t    res.push(doc[field]);\n\t  }\n\t  return res;\n\t}\n\t\n\t// have to do this manually because REASONS. I don't know why\n\t// CouchDB didn't implement inclusive_start\n\tfunction filterInclusiveStart(rows, targetValue, index) {\n\t  var indexFields = index.def.fields;\n\t  for (var i = 0, len = rows.length; i < len; i++) {\n\t    var row = rows[i];\n\t\n\t    // shave off any docs at the beginning that are <= the\n\t    // target value\n\t\n\t    var docKey = getKeyFromDoc(row.doc, index);\n\t    if (indexFields.length === 1) {\n\t      docKey = docKey[0]; // only one field, not multi-field\n\t    } else { // more than one field in index\n\t      // in the case where e.g. the user is searching {$gt: {a: 1}}\n\t      // but the index is [a, b], then we need to shorten the doc key\n\t      while (docKey.length > targetValue.length) {\n\t        docKey.pop();\n\t      }\n\t    }\n\t    //ABS as we just looking for values that don't match\n\t    if (Math.abs(collate.collate(docKey, targetValue)) > 0) {\n\t      // no need to filter any further; we're past the key\n\t      break;\n\t    }\n\t  }\n\t  return i > 0 ? rows.slice(i) : rows;\n\t}\n\t\n\tfunction reverseOptions(opts) {\n\t  var newOpts = utils.clone(opts);\n\t  delete newOpts.startkey;\n\t  delete newOpts.endkey;\n\t  delete newOpts.inclusive_start;\n\t  delete newOpts.inclusive_end;\n\t\n\t  if ('endkey' in opts) {\n\t    newOpts.startkey = opts.endkey;\n\t  }\n\t  if ('startkey' in opts) {\n\t    newOpts.endkey = opts.startkey;\n\t  }\n\t  if ('inclusive_start' in opts) {\n\t    newOpts.inclusive_end = opts.inclusive_start;\n\t  }\n\t  if ('inclusive_end' in opts) {\n\t    newOpts.inclusive_start = opts.inclusive_end;\n\t  }\n\t  return newOpts;\n\t}\n\t\n\tfunction validateIndex(index) {\n\t  var ascFields = index.fields.filter(function (field) {\n\t    return getValue(field) === 'asc';\n\t  });\n\t  if (ascFields.length !== 0 && ascFields.length !== index.fields.length) {\n\t    throw new Error('unsupported mixed sorting');\n\t  }\n\t}\n\t\n\tfunction validateSort (requestDef, index) {\n\t  if (index.defaultUsed && requestDef.sort) {\n\t    var noneIdSorts = requestDef.sort.filter(function (sortItem) {\n\t      return Object.keys(sortItem)[0] !== '_id';\n\t    }).map(function (sortItem) {\n\t      return Object.keys(sortItem)[0];\n\t    });\n\t\n\t    if (noneIdSorts.length > 0) {\n\t      throw new Error('Cannot sort on field(s) \"' + noneIdSorts.join(',') +\n\t      '\" when using the default index');\n\t    }\n\t  }\n\t\n\t  if (index.defaultUsed) {\n\t    return;\n\t  }\n\t}\n\t\n\tfunction validateFindRequest(requestDef) {\n\t  if (typeof requestDef.selector !== 'object') {\n\t    throw new Error('you must provide a selector when you find()');\n\t  }\n\t\n\t  /*var selectors = requestDef.selector['$and'] || [requestDef.selector];\n\t  for (var i = 0; i < selectors.length; i++) {\n\t    var selector = selectors[i];\n\t    var keys = Object.keys(selector);\n\t    if (keys.length === 0) {\n\t      throw new Error('invalid empty selector');\n\t    }\n\t    //var selection = selector[keys[0]];\n\t    /*if (Object.keys(selection).length !== 1) {\n\t      throw new Error('invalid selector: ' + JSON.stringify(selection) +\n\t        ' - it must have exactly one key/value');\n\t    }\n\t  }*/\n\t}\n\t\n\t// determine the maximum number of fields\n\t// we're going to need to query, e.g. if the user\n\t// has selection ['a'] and sorting ['a', 'b'], then we\n\t// need to use the longer of the two: ['a', 'b']\n\tfunction getUserFields(selector, sort) {\n\t  var selectorFields = Object.keys(selector);\n\t  var sortFields = sort? sort.map(getKey) : [];\n\t  var userFields;\n\t  if (selectorFields.length >= sortFields.length) {\n\t    userFields = selectorFields;\n\t  } else {\n\t    userFields = sortFields;\n\t  }\n\t\n\t  if (sortFields.length === 0) {\n\t    return {\n\t      fields: userFields\n\t    };\n\t  }\n\t\n\t  // sort according to the user's preferred sorting\n\t  userFields = userFields.sort(function (left, right) {\n\t    var leftIdx = sortFields.indexOf(left);\n\t    if (leftIdx === -1) {\n\t      leftIdx = Number.MAX_VALUE;\n\t    }\n\t    var rightIdx = sortFields.indexOf(right);\n\t    if (rightIdx === -1) {\n\t      rightIdx = Number.MAX_VALUE;\n\t    }\n\t    return leftIdx < rightIdx ? -1 : leftIdx > rightIdx ? 1 : 0;\n\t  });\n\t\n\t  return {\n\t    fields: userFields,\n\t    sortOrder: sort.map(getKey)\n\t  };\n\t}\n\t\n\tmodule.exports = {\n\t  getKey: getKey,\n\t  getValue: getValue,\n\t  massageSort: massageSort,\n\t  massageSelector: massageSelector,\n\t  validateIndex: validateIndex,\n\t  validateFindRequest: validateFindRequest,\n\t  validateSort: validateSort,\n\t  reverseOptions: reverseOptions,\n\t  filterInclusiveStart: filterInclusiveStart,\n\t  massageIndexDef: massageIndexDef,\n\t  parseField: utils.parseField,\n\t  getUserFields: getUserFields,\n\t  isCombinationalField: isCombinationalField\n\t};\n\n\n/***/ },\n/* 5 */\n/***/ function(module, exports) {\n\n\t// shim for using process in browser\n\tvar process = module.exports = {};\n\t\n\t// cached from whatever global is present so that test runners that stub it\n\t// don't break things.  But we need to wrap it in a try catch in case it is\n\t// wrapped in strict mode code which doesn't define any globals.  It's inside a\n\t// function because try/catches deoptimize in certain engines.\n\t\n\tvar cachedSetTimeout;\n\tvar cachedClearTimeout;\n\t\n\tfunction defaultSetTimout() {\n\t    throw new Error('setTimeout has not been defined');\n\t}\n\tfunction defaultClearTimeout () {\n\t    throw new Error('clearTimeout has not been defined');\n\t}\n\t(function () {\n\t    try {\n\t        if (typeof setTimeout === 'function') {\n\t            cachedSetTimeout = setTimeout;\n\t        } else {\n\t            cachedSetTimeout = defaultSetTimout;\n\t        }\n\t    } catch (e) {\n\t        cachedSetTimeout = defaultSetTimout;\n\t    }\n\t    try {\n\t        if (typeof clearTimeout === 'function') {\n\t            cachedClearTimeout = clearTimeout;\n\t        } else {\n\t            cachedClearTimeout = defaultClearTimeout;\n\t        }\n\t    } catch (e) {\n\t        cachedClearTimeout = defaultClearTimeout;\n\t    }\n\t} ())\n\tfunction runTimeout(fun) {\n\t    if (cachedSetTimeout === setTimeout) {\n\t        //normal enviroments in sane situations\n\t        return setTimeout(fun, 0);\n\t    }\n\t    // if setTimeout wasn't available but was latter defined\n\t    if ((cachedSetTimeout === defaultSetTimout || !cachedSetTimeout) && setTimeout) {\n\t        cachedSetTimeout = setTimeout;\n\t        return setTimeout(fun, 0);\n\t    }\n\t    try {\n\t        // when when somebody has screwed with setTimeout but no I.E. maddness\n\t        return cachedSetTimeout(fun, 0);\n\t    } catch(e){\n\t        try {\n\t            // When we are in I.E. but the script has been evaled so I.E. doesn't trust the global object when called normally\n\t            return cachedSetTimeout.call(null, fun, 0);\n\t        } catch(e){\n\t            // same as above but when it's a version of I.E. that must have the global object for 'this', hopfully our context correct otherwise it will throw a global error\n\t            return cachedSetTimeout.call(this, fun, 0);\n\t        }\n\t    }\n\t\n\t\n\t}\n\tfunction runClearTimeout(marker) {\n\t    if (cachedClearTimeout === clearTimeout) {\n\t        //normal enviroments in sane situations\n\t        return clearTimeout(marker);\n\t    }\n\t    // if clearTimeout wasn't available but was latter defined\n\t    if ((cachedClearTimeout === defaultClearTimeout || !cachedClearTimeout) && clearTimeout) {\n\t        cachedClearTimeout = clearTimeout;\n\t        return clearTimeout(marker);\n\t    }\n\t    try {\n\t        // when when somebody has screwed with setTimeout but no I.E. maddness\n\t        return cachedClearTimeout(marker);\n\t    } catch (e){\n\t        try {\n\t            // When we are in I.E. but the script has been evaled so I.E. doesn't  trust the global object when called normally\n\t            return cachedClearTimeout.call(null, marker);\n\t        } catch (e){\n\t            // same as above but when it's a version of I.E. that must have the global object for 'this', hopfully our context correct otherwise it will throw a global error.\n\t            // Some versions of I.E. have different rules for clearTimeout vs setTimeout\n\t            return cachedClearTimeout.call(this, marker);\n\t        }\n\t    }\n\t\n\t\n\t\n\t}\n\tvar queue = [];\n\tvar draining = false;\n\tvar currentQueue;\n\tvar queueIndex = -1;\n\t\n\tfunction cleanUpNextTick() {\n\t    if (!draining || !currentQueue) {\n\t        return;\n\t    }\n\t    draining = false;\n\t    if (currentQueue.length) {\n\t        queue = currentQueue.concat(queue);\n\t    } else {\n\t        queueIndex = -1;\n\t    }\n\t    if (queue.length) {\n\t        drainQueue();\n\t    }\n\t}\n\t\n\tfunction drainQueue() {\n\t    if (draining) {\n\t        return;\n\t    }\n\t    var timeout = runTimeout(cleanUpNextTick);\n\t    draining = true;\n\t\n\t    var len = queue.length;\n\t    while(len) {\n\t        currentQueue = queue;\n\t        queue = [];\n\t        while (++queueIndex < len) {\n\t            if (currentQueue) {\n\t                currentQueue[queueIndex].run();\n\t            }\n\t        }\n\t        queueIndex = -1;\n\t        len = queue.length;\n\t    }\n\t    currentQueue = null;\n\t    draining = false;\n\t    runClearTimeout(timeout);\n\t}\n\t\n\tprocess.nextTick = function (fun) {\n\t    var args = new Array(arguments.length - 1);\n\t    if (arguments.length > 1) {\n\t        for (var i = 1; i < arguments.length; i++) {\n\t            args[i - 1] = arguments[i];\n\t        }\n\t    }\n\t    queue.push(new Item(fun, args));\n\t    if (queue.length === 1 && !draining) {\n\t        runTimeout(drainQueue);\n\t    }\n\t};\n\t\n\t// v8 likes predictible objects\n\tfunction Item(fun, array) {\n\t    this.fun = fun;\n\t    this.array = array;\n\t}\n\tItem.prototype.run = function () {\n\t    this.fun.apply(null, this.array);\n\t};\n\tprocess.title = 'browser';\n\tprocess.browser = true;\n\tprocess.env = {};\n\tprocess.argv = [];\n\tprocess.version = ''; // empty string to avoid regexp issues\n\tprocess.versions = {};\n\t\n\tfunction noop() {}\n\t\n\tprocess.on = noop;\n\tprocess.addListener = noop;\n\tprocess.once = noop;\n\tprocess.off = noop;\n\tprocess.removeListener = noop;\n\tprocess.removeAllListeners = noop;\n\tprocess.emit = noop;\n\t\n\tprocess.binding = function (name) {\n\t    throw new Error('process.binding is not supported');\n\t};\n\t\n\tprocess.cwd = function () { return '/' };\n\tprocess.chdir = function (dir) {\n\t    throw new Error('process.chdir is not supported');\n\t};\n\tprocess.umask = function() { return 0; };\n\n\n/***/ },\n/* 6 */\n/***/ function(module, exports, __webpack_require__) {\n\n\t'use strict';\n\t\n\tObject.defineProperty(exports, \"__esModule\", {\n\t  value: true\n\t});\n\texports.DOCTYPE_FILES = undefined;\n\texports.normalizeDoctype = normalizeDoctype;\n\t\n\tvar _utils = __webpack_require__(3);\n\t\n\tvar DOCTYPE_FILES = exports.DOCTYPE_FILES = 'io.cozy.files';\n\t\n\tvar KNOWN_DOCTYPES = {\n\t  'files': DOCTYPE_FILES,\n\t  'folder': DOCTYPE_FILES,\n\t  'contact': 'io.cozy.contacts',\n\t  'event': 'io.cozy.events',\n\t  'track': 'io.cozy.labs.music.track',\n\t  'playlist': 'io.cozy.labs.music.playlist'\n\t};\n\t\n\tvar REVERSE_KNOWN = {};\n\tObject.keys(KNOWN_DOCTYPES).forEach(function (k) {\n\t  REVERSE_KNOWN[KNOWN_DOCTYPES[k]] = k;\n\t});\n\t\n\tfunction normalizeDoctype(cozy, isV2, doctype) {\n\t  var isQualified = doctype.indexOf('.') !== -1;\n\t  if (isV2 && isQualified) {\n\t    var known = REVERSE_KNOWN[doctype];\n\t    if (known) return known;\n\t    return doctype.replace(/\\./g, '-');\n\t  }\n\t  if (!isV2 && !isQualified) {\n\t    var _known = KNOWN_DOCTYPES[doctype];\n\t    if (_known) {\n\t      (0, _utils.warn)('you are using a non-qualified doctype ' + doctype + ' assumed to be ' + _known);\n\t      return _known;\n\t    }\n\t    throw new Error('Doctype ' + doctype + ' should be qualified.');\n\t  }\n\t  return doctype;\n\t}\n\n/***/ },\n/* 7 */\n/***/ function(module, exports) {\n\n\t// https://github.com/zloirock/core-js/issues/86#issuecomment-115759028\n\tvar global = module.exports = typeof window != 'undefined' && window.Math == Math\n\t  ? window : typeof self != 'undefined' && self.Math == Math ? self\n\t  // eslint-disable-next-line no-new-func\n\t  : Function('return this')();\n\tif (typeof __g == 'number') __g = global; // eslint-disable-line no-undef\n\n\n/***/ },\n/* 8 */\n/***/ function(module, exports, __webpack_require__) {\n\n\t'use strict';\n\t\n\tvar MIN_MAGNITUDE = -324; // verified by -Number.MIN_VALUE\n\tvar MAGNITUDE_DIGITS = 3; // ditto\n\tvar SEP = ''; // set to '_' for easier debugging \n\t\n\tvar utils = __webpack_require__(77);\n\t\n\texports.collate = function (a, b) {\n\t\n\t  if (a === b) {\n\t    return 0;\n\t  }\n\t\n\t  a = exports.normalizeKey(a);\n\t  b = exports.normalizeKey(b);\n\t\n\t  var ai = collationIndex(a);\n\t  var bi = collationIndex(b);\n\t  if ((ai - bi) !== 0) {\n\t    return ai - bi;\n\t  }\n\t  if (a === null) {\n\t    return 0;\n\t  }\n\t  switch (typeof a) {\n\t    case 'number':\n\t      return a - b;\n\t    case 'boolean':\n\t      return a === b ? 0 : (a < b ? -1 : 1);\n\t    case 'string':\n\t      return stringCollate(a, b);\n\t  }\n\t  return Array.isArray(a) ? arrayCollate(a, b) : objectCollate(a, b);\n\t};\n\t\n\t// couch considers null/NaN/Infinity/-Infinity === undefined,\n\t// for the purposes of mapreduce indexes. also, dates get stringified.\n\texports.normalizeKey = function (key) {\n\t  switch (typeof key) {\n\t    case 'undefined':\n\t      return null;\n\t    case 'number':\n\t      if (key === Infinity || key === -Infinity || isNaN(key)) {\n\t        return null;\n\t      }\n\t      return key;\n\t    case 'object':\n\t      var origKey = key;\n\t      if (Array.isArray(key)) {\n\t        var len = key.length;\n\t        key = new Array(len);\n\t        for (var i = 0; i < len; i++) {\n\t          key[i] = exports.normalizeKey(origKey[i]);\n\t        }\n\t      } else if (key instanceof Date) {\n\t        return key.toJSON();\n\t      } else if (key !== null) { // generic object\n\t        key = {};\n\t        for (var k in origKey) {\n\t          if (origKey.hasOwnProperty(k)) {\n\t            var val = origKey[k];\n\t            if (typeof val !== 'undefined') {\n\t              key[k] = exports.normalizeKey(val);\n\t            }\n\t          }\n\t        }\n\t      }\n\t  }\n\t  return key;\n\t};\n\t\n\tfunction indexify(key) {\n\t  if (key !== null) {\n\t    switch (typeof key) {\n\t      case 'boolean':\n\t        return key ? 1 : 0;\n\t      case 'number':\n\t        return numToIndexableString(key);\n\t      case 'string':\n\t        // We've to be sure that key does not contain \\u0000\n\t        // Do order-preserving replacements:\n\t        // 0 -> 1, 1\n\t        // 1 -> 1, 2\n\t        // 2 -> 2, 2\n\t        return key\n\t          .replace(/\\u0002/g, '\\u0002\\u0002')\n\t          .replace(/\\u0001/g, '\\u0001\\u0002')\n\t          .replace(/\\u0000/g, '\\u0001\\u0001');\n\t      case 'object':\n\t        var isArray = Array.isArray(key);\n\t        var arr = isArray ? key : Object.keys(key);\n\t        var i = -1;\n\t        var len = arr.length;\n\t        var result = '';\n\t        if (isArray) {\n\t          while (++i < len) {\n\t            result += exports.toIndexableString(arr[i]);\n\t          }\n\t        } else {\n\t          while (++i < len) {\n\t            var objKey = arr[i];\n\t            result += exports.toIndexableString(objKey) +\n\t                exports.toIndexableString(key[objKey]);\n\t          }\n\t        }\n\t        return result;\n\t    }\n\t  }\n\t  return '';\n\t}\n\t\n\t// convert the given key to a string that would be appropriate\n\t// for lexical sorting, e.g. within a database, where the\n\t// sorting is the same given by the collate() function.\n\texports.toIndexableString = function (key) {\n\t  var zero = '\\u0000';\n\t  key = exports.normalizeKey(key);\n\t  return collationIndex(key) + SEP + indexify(key) + zero;\n\t};\n\t\n\tfunction parseNumber(str, i) {\n\t  var originalIdx = i;\n\t  var num;\n\t  var zero = str[i] === '1';\n\t  if (zero) {\n\t    num = 0;\n\t    i++;\n\t  } else {\n\t    var neg = str[i] === '0';\n\t    i++;\n\t    var numAsString = '';\n\t    var magAsString = str.substring(i, i + MAGNITUDE_DIGITS);\n\t    var magnitude = parseInt(magAsString, 10) + MIN_MAGNITUDE;\n\t    if (neg) {\n\t      magnitude = -magnitude;\n\t    }\n\t    i += MAGNITUDE_DIGITS;\n\t    while (true) {\n\t      var ch = str[i];\n\t      if (ch === '\\u0000') {\n\t        break;\n\t      } else {\n\t        numAsString += ch;\n\t      }\n\t      i++;\n\t    }\n\t    numAsString = numAsString.split('.');\n\t    if (numAsString.length === 1) {\n\t      num = parseInt(numAsString, 10);\n\t    } else {\n\t      num = parseFloat(numAsString[0] + '.' + numAsString[1]);\n\t    }\n\t    if (neg) {\n\t      num = num - 10;\n\t    }\n\t    if (magnitude !== 0) {\n\t      // parseFloat is more reliable than pow due to rounding errors\n\t      // e.g. Number.MAX_VALUE would return Infinity if we did\n\t      // num * Math.pow(10, magnitude);\n\t      num = parseFloat(num + 'e' + magnitude);\n\t    }\n\t  }\n\t  return {num: num, length : i - originalIdx};\n\t}\n\t\n\t// move up the stack while parsing\n\t// this function moved outside of parseIndexableString for performance\n\tfunction pop(stack, metaStack) {\n\t  var obj = stack.pop();\n\t\n\t  if (metaStack.length) {\n\t    var lastMetaElement = metaStack[metaStack.length - 1];\n\t    if (obj === lastMetaElement.element) {\n\t      // popping a meta-element, e.g. an object whose value is another object\n\t      metaStack.pop();\n\t      lastMetaElement = metaStack[metaStack.length - 1];\n\t    }\n\t    var element = lastMetaElement.element;\n\t    var lastElementIndex = lastMetaElement.index;\n\t    if (Array.isArray(element)) {\n\t      element.push(obj);\n\t    } else if (lastElementIndex === stack.length - 2) { // obj with key+value\n\t      var key = stack.pop();\n\t      element[key] = obj;\n\t    } else {\n\t      stack.push(obj); // obj with key only\n\t    }\n\t  }\n\t}\n\t\n\texports.parseIndexableString = function (str) {\n\t  var stack = [];\n\t  var metaStack = []; // stack for arrays and objects\n\t  var i = 0;\n\t\n\t  while (true) {\n\t    var collationIndex = str[i++];\n\t    if (collationIndex === '\\u0000') {\n\t      if (stack.length === 1) {\n\t        return stack.pop();\n\t      } else {\n\t        pop(stack, metaStack);\n\t        continue;\n\t      }\n\t    }\n\t    switch (collationIndex) {\n\t      case '1':\n\t        stack.push(null);\n\t        break;\n\t      case '2':\n\t        stack.push(str[i] === '1');\n\t        i++;\n\t        break;\n\t      case '3':\n\t        var parsedNum = parseNumber(str, i);\n\t        stack.push(parsedNum.num);\n\t        i += parsedNum.length;\n\t        break;\n\t      case '4':\n\t        var parsedStr = '';\n\t        while (true) {\n\t          var ch = str[i];\n\t          if (ch === '\\u0000') {\n\t            break;\n\t          }\n\t          parsedStr += ch;\n\t          i++;\n\t        }\n\t        // perform the reverse of the order-preserving replacement\n\t        // algorithm (see above)\n\t        parsedStr = parsedStr.replace(/\\u0001\\u0001/g, '\\u0000')\n\t          .replace(/\\u0001\\u0002/g, '\\u0001')\n\t          .replace(/\\u0002\\u0002/g, '\\u0002');\n\t        stack.push(parsedStr);\n\t        break;\n\t      case '5':\n\t        var arrayElement = { element: [], index: stack.length };\n\t        stack.push(arrayElement.element);\n\t        metaStack.push(arrayElement);\n\t        break;\n\t      case '6':\n\t        var objElement = { element: {}, index: stack.length };\n\t        stack.push(objElement.element);\n\t        metaStack.push(objElement);\n\t        break;\n\t      default:\n\t        throw new Error(\n\t          'bad collationIndex or unexpectedly reached end of input: ' + collationIndex);\n\t    }\n\t  }\n\t};\n\t\n\tfunction arrayCollate(a, b) {\n\t  var len = Math.min(a.length, b.length);\n\t  for (var i = 0; i < len; i++) {\n\t    var sort = exports.collate(a[i], b[i]);\n\t    if (sort !== 0) {\n\t      return sort;\n\t    }\n\t  }\n\t  return (a.length === b.length) ? 0 :\n\t    (a.length > b.length) ? 1 : -1;\n\t}\n\tfunction stringCollate(a, b) {\n\t  // See: https://github.com/daleharvey/pouchdb/issues/40\n\t  // This is incompatible with the CouchDB implementation, but its the\n\t  // best we can do for now\n\t  return (a === b) ? 0 : ((a > b) ? 1 : -1);\n\t}\n\tfunction objectCollate(a, b) {\n\t  var ak = Object.keys(a), bk = Object.keys(b);\n\t  var len = Math.min(ak.length, bk.length);\n\t  for (var i = 0; i < len; i++) {\n\t    // First sort the keys\n\t    var sort = exports.collate(ak[i], bk[i]);\n\t    if (sort !== 0) {\n\t      return sort;\n\t    }\n\t    // if the keys are equal sort the values\n\t    sort = exports.collate(a[ak[i]], b[bk[i]]);\n\t    if (sort !== 0) {\n\t      return sort;\n\t    }\n\t\n\t  }\n\t  return (ak.length === bk.length) ? 0 :\n\t    (ak.length > bk.length) ? 1 : -1;\n\t}\n\t// The collation is defined by erlangs ordered terms\n\t// the atoms null, true, false come first, then numbers, strings,\n\t// arrays, then objects\n\t// null/undefined/NaN/Infinity/-Infinity are all considered null\n\tfunction collationIndex(x) {\n\t  var id = ['boolean', 'number', 'string', 'object'];\n\t  var idx = id.indexOf(typeof x);\n\t  //false if -1 otherwise true, but fast!!!!1\n\t  if (~idx) {\n\t    if (x === null) {\n\t      return 1;\n\t    }\n\t    if (Array.isArray(x)) {\n\t      return 5;\n\t    }\n\t    return idx < 3 ? (idx + 2) : (idx + 3);\n\t  }\n\t  if (Array.isArray(x)) {\n\t    return 5;\n\t  }\n\t}\n\t\n\t// conversion:\n\t// x yyy zz...zz\n\t// x = 0 for negative, 1 for 0, 2 for positive\n\t// y = exponent (for negative numbers negated) moved so that it's >= 0\n\t// z = mantisse\n\tfunction numToIndexableString(num) {\n\t\n\t  if (num === 0) {\n\t    return '1';\n\t  }\n\t\n\t  // convert number to exponential format for easier and\n\t  // more succinct string sorting\n\t  var expFormat = num.toExponential().split(/e\\+?/);\n\t  var magnitude = parseInt(expFormat[1], 10);\n\t\n\t  var neg = num < 0;\n\t\n\t  var result = neg ? '0' : '2';\n\t\n\t  // first sort by magnitude\n\t  // it's easier if all magnitudes are positive\n\t  var magForComparison = ((neg ? -magnitude : magnitude) - MIN_MAGNITUDE);\n\t  var magString = utils.padLeft((magForComparison).toString(), '0', MAGNITUDE_DIGITS);\n\t\n\t  result += SEP + magString;\n\t\n\t  // then sort by the factor\n\t  var factor = Math.abs(parseFloat(expFormat[0])); // [1..10)\n\t  if (neg) { // for negative reverse ordering\n\t    factor = 10 - factor;\n\t  }\n\t\n\t  var factorStr = factor.toFixed(20);\n\t\n\t  // strip zeros from the end\n\t  factorStr = factorStr.replace(/\\.?0+$/, '');\n\t\n\t  result += SEP + factorStr;\n\t\n\t  return result;\n\t}\n\n\n/***/ },\n/* 9 */\n/***/ function(module, exports, __webpack_require__) {\n\n\t'use strict';\n\t\n\tObject.defineProperty(exports, \"__esModule\", {\n\t  value: true\n\t});\n\texports.AppToken = exports.AccessToken = exports.Client = exports.StateKey = exports.CredsKey = undefined;\n\t\n\tvar _slicedToArray = function () { function sliceIterator(arr, i) { var _arr = []; var _n = true; var _d = false; var _e = undefined; try { for (var _i = arr[Symbol.iterator](), _s; !(_n = (_s = _i.next()).done); _n = true) { _arr.push(_s.value); if (i && _arr.length === i) break; } } catch (err) { _d = true; _e = err; } finally { try { if (!_n && _i[\"return\"]) _i[\"return\"](); } finally { if (_d) throw _e; } } return _arr; } return function (arr, i) { if (Array.isArray(arr)) { return arr; } else if (Symbol.iterator in Object(arr)) { return sliceIterator(arr, i); } else { throw new TypeError(\"Invalid attempt to destructure non-iterable instance\"); } }; }();\n\t\n\tvar _createClass = function () { function defineProperties(target, props) { for (var i = 0; i < props.length; i++) { var descriptor = props[i]; descriptor.enumerable = descriptor.enumerable || false; descriptor.configurable = true; if (\"value\" in descriptor) descriptor.writable = true; Object.defineProperty(target, descriptor.key, descriptor); } } return function (Constructor, protoProps, staticProps) { if (protoProps) defineProperties(Constructor.prototype, protoProps); if (staticProps) defineProperties(Constructor, staticProps); return Constructor; }; }(); /* global btoa */\n\t\n\t\n\texports.client = client;\n\texports.registerClient = registerClient;\n\texports.updateClient = updateClient;\n\texports.unregisterClient = unregisterClient;\n\texports.getClient = getClient;\n\texports.getAuthCodeURL = getAuthCodeURL;\n\texports.getAccessToken = getAccessToken;\n\texports.refreshToken = refreshToken;\n\texports.oauthFlow = oauthFlow;\n\t\n\tvar _utils = __webpack_require__(3);\n\t\n\tvar _fetch = __webpack_require__(1);\n\t\n\tfunction _classCallCheck(instance, Constructor) { if (!(instance instanceof Constructor)) { throw new TypeError(\"Cannot call a class as a function\"); } }\n\t\n\tvar StateSize = 16;\n\t\n\tvar CredsKey = exports.CredsKey = 'creds';\n\tvar StateKey = exports.StateKey = 'state';\n\t\n\tvar Client = exports.Client = function () {\n\t  function Client(opts) {\n\t    _classCallCheck(this, Client);\n\t\n\t    this.clientID = opts.clientID || opts.client_id || '';\n\t    this.clientSecret = opts.clientSecret || opts.client_secret || '';\n\t    this.registrationAccessToken = opts.registrationAccessToken || opts.registration_access_token || '';\n\t\n\t    if (opts.redirect_uris) {\n\t      this.redirectURI = opts.redirect_uris[0] || '';\n\t    } else {\n\t      this.redirectURI = opts.redirectURI || '';\n\t    }\n\t\n\t    this.softwareID = opts.softwareID || opts.software_id || '';\n\t    this.softwareVersion = opts.softwareVersion || opts.software_version || '';\n\t    this.clientName = opts.clientName || opts.client_name || '';\n\t    this.clientKind = opts.clientKind || opts.client_kind || '';\n\t    this.clientURI = opts.clientURI || opts.client_uri || '';\n\t\n\t    this.logoURI = opts.logoURI || opts.logo_uri || '';\n\t    this.policyURI = opts.policyURI || opts.policy_uri || '';\n\t\n\t    this.notificationPlatform = opts.notificationPlatform || opts.notification_platform || '';\n\t    this.notificationDeviceToken = opts.notificationDeviceToken || opts.notification_device_token || '';\n\t\n\t    if (!this.registrationAccessToken) {\n\t      if (this.redirectURI === '') {\n\t        throw new Error('Missing redirectURI field');\n\t      }\n\t      if (this.softwareID === '') {\n\t        throw new Error('Missing softwareID field');\n\t      }\n\t      if (this.clientName === '') {\n\t        throw new Error('Missing clientName field');\n\t      }\n\t    }\n\t  }\n\t\n\t  _createClass(Client, [{\n\t    key: 'isRegistered',\n\t    value: function isRegistered() {\n\t      return this.clientID !== '';\n\t    }\n\t  }, {\n\t    key: 'toRegisterJSON',\n\t    value: function toRegisterJSON() {\n\t      return {\n\t        redirect_uris: [this.redirectURI],\n\t        software_id: this.softwareID,\n\t        software_version: this.softwareVersion,\n\t        client_name: this.clientName,\n\t        client_kind: this.clientKind,\n\t        client_uri: this.clientURI,\n\t        logo_uri: this.logoURI,\n\t        policy_uri: this.policyURI,\n\t        notification_platform: this.notificationPlatform,\n\t        notification_device_token: this.notificationDeviceToken\n\t      };\n\t    }\n\t  }, {\n\t    key: 'toAuthHeader',\n\t    value: function toAuthHeader() {\n\t      return 'Bearer ' + this.registrationAccessToken;\n\t    }\n\t  }]);\n\t\n\t  return Client;\n\t}();\n\t\n\tvar AccessToken = exports.AccessToken = function () {\n\t  function AccessToken(opts) {\n\t    _classCallCheck(this, AccessToken);\n\t\n\t    this.tokenType = opts.tokenType || opts.token_type;\n\t    this.accessToken = opts.accessToken || opts.access_token;\n\t    this.refreshToken = opts.refreshToken || opts.refresh_token;\n\t    this.scope = opts.scope;\n\t  }\n\t\n\t  _createClass(AccessToken, [{\n\t    key: 'toAuthHeader',\n\t    value: function toAuthHeader() {\n\t      return 'Bearer ' + this.accessToken;\n\t    }\n\t  }, {\n\t    key: 'toBasicAuth',\n\t    value: function toBasicAuth() {\n\t      return 'user:' + this.accessToken + '@';\n\t    }\n\t  }]);\n\t\n\t  return AccessToken;\n\t}();\n\t\n\tvar AppToken = exports.AppToken = function () {\n\t  function AppToken(opts) {\n\t    _classCallCheck(this, AppToken);\n\t\n\t    this.token = opts.token || '';\n\t  }\n\t\n\t  _createClass(AppToken, [{\n\t    key: 'toAuthHeader',\n\t    value: function toAuthHeader() {\n\t      return 'Bearer ' + this.token;\n\t    }\n\t  }, {\n\t    key: 'toBasicAuth',\n\t    value: function toBasicAuth() {\n\t      return 'user:' + this.token + '@';\n\t    }\n\t  }]);\n\t\n\t  return AppToken;\n\t}();\n\t\n\tfunction client(cozy, clientParams) {\n\t  if (!clientParams) {\n\t    clientParams = cozy._clientParams;\n\t  }\n\t  if (clientParams instanceof Client) {\n\t    return clientParams;\n\t  }\n\t  return new Client(clientParams);\n\t}\n\t\n\tfunction registerClient(cozy, clientParams) {\n\t  var cli = client(cozy, clientParams);\n\t  if (cli.isRegistered()) {\n\t    return Promise.reject(new Error('Client already registered'));\n\t  }\n\t  return (0, _fetch.cozyFetchJSON)(cozy, 'POST', '/auth/register', cli.toRegisterJSON(), {\n\t    disableAuth: true\n\t  }).then(function (data) {\n\t    return new Client(data);\n\t  });\n\t}\n\t\n\tfunction updateClient(cozy, clientParams) {\n\t  var resetSecret = arguments.length > 2 && arguments[2] !== undefined ? arguments[2] : false;\n\t\n\t  var cli = client(cozy, clientParams);\n\t  if (!cli.isRegistered()) {\n\t    return Promise.reject(new Error('Client not registered'));\n\t  }\n\t  var data = cli.toRegisterJSON();\n\t  data.client_id = cli.clientID;\n\t  if (resetSecret) data.client_secret = cli.clientSecret;\n\t\n\t  return (0, _fetch.cozyFetchJSON)(cozy, 'PUT', '/auth/register/' + cli.clientID, data, {\n\t    manualAuthCredentials: {\n\t      token: cli\n\t    }\n\t  }).then(function (data) {\n\t    return createClient(data, cli);\n\t  });\n\t}\n\t\n\tfunction unregisterClient(cozy, clientParams) {\n\t  var cli = client(cozy, clientParams);\n\t  if (!cli.isRegistered()) {\n\t    return Promise.reject(new Error('Client not registered'));\n\t  }\n\t  return (0, _fetch.cozyFetchJSON)(cozy, 'DELETE', '/auth/register/' + cli.clientID, null, {\n\t    manualAuthCredentials: {\n\t      token: cli\n\t    }\n\t  });\n\t}\n\t\n\t// getClient will retrive the registered client informations from the server.\n\tfunction getClient(cozy, clientParams) {\n\t  var cli = client(cozy, clientParams);\n\t  if (!cli.isRegistered()) {\n\t    return Promise.reject(new Error('Client not registered'));\n\t  }\n\t  if ((0, _utils.isOffline)()) {\n\t    return Promise.resolve(cli);\n\t  }\n\t  return (0, _fetch.cozyFetchJSON)(cozy, 'GET', '/auth/register/' + cli.clientID, null, {\n\t    manualAuthCredentials: {\n\t      token: cli\n\t    }\n\t  }).then(function (data) {\n\t    return createClient(data, cli);\n\t  }).catch(function (err) {\n\t    // If we fall into an error while fetching the client (because of a\n\t    // bad connectivity for instance), we do not bail the whole process\n\t    // since the client should be able to continue with the persisted\n\t    // client and token.\n\t    //\n\t    // If it is an explicit Unauthorized error though, we bail, clear th\n\t    // cache and retry.\n\t    if (_fetch.FetchError.isUnauthorized(err) || _fetch.FetchError.isNotFound(err)) {\n\t      throw new Error('Client has been revoked');\n\t    }\n\t    throw err;\n\t  });\n\t}\n\t\n\t// createClient returns a new Client instance given on object containing the\n\t// data of the client, from the API, and an old instance of the client.\n\tfunction createClient(data, oldClient) {\n\t  var newClient = new Client(data);\n\t  // we need to keep track of the registrationAccessToken since it is send\n\t  // only on registration. The GET /auth/register/:client-id endpoint does\n\t  // not return this token.\n\t  var shouldPassRegistration = !!oldClient && oldClient.registrationAccessToken !== '' && newClient.registrationAccessToken === '';\n\t  if (shouldPassRegistration) {\n\t    newClient.registrationAccessToken = oldClient.registrationAccessToken;\n\t  }\n\t  return newClient;\n\t}\n\t\n\t// getAuthCodeURL returns a pair {authURL,state} given a registered client. The\n\t// state should be stored in order to be checked against on the user validation\n\t// phase.\n\tfunction getAuthCodeURL(cozy, client) {\n\t  var scopes = arguments.length > 2 && arguments[2] !== undefined ? arguments[2] : [];\n\t\n\t  if (!(client instanceof Client)) {\n\t    client = new Client(client);\n\t  }\n\t  if (!client.isRegistered()) {\n\t    throw new Error('Client not registered');\n\t  }\n\t  var state = generateRandomState();\n\t  var query = {\n\t    'client_id': client.clientID,\n\t    'redirect_uri': client.redirectURI,\n\t    'state': state,\n\t    'response_type': 'code',\n\t    'scope': scopes.join(' ')\n\t  };\n\t  return {\n\t    url: cozy._url + ('/auth/authorize?' + (0, _utils.encodeQuery)(query)),\n\t    state: state\n\t  };\n\t}\n\t\n\t// getAccessToken perform a request on the access_token entrypoint with the\n\t// authorization_code grant type in order to generate a new access token for a\n\t// newly registered client.\n\t//\n\t// This method extracts the access code and state from the given URL. By\n\t// default it uses window.location.href. Also, it checks the given state with\n\t// the one specified in the URL query parameter to prevent CSRF attacks.\n\tfunction getAccessToken(cozy, client, state) {\n\t  var pageURL = arguments.length > 3 && arguments[3] !== undefined ? arguments[3] : '';\n\t\n\t  if (!state) {\n\t    return Promise.reject(new Error('Missing state value'));\n\t  }\n\t  var grantQueries = getGrantCodeFromPageURL(pageURL);\n\t  if (grantQueries === null) {\n\t    return Promise.reject(new Error('Missing states from current URL'));\n\t  }\n\t  if (state !== grantQueries.state) {\n\t    return Promise.reject(new Error('Given state does not match url query state'));\n\t  }\n\t  return retrieveToken(cozy, client, null, {\n\t    'grant_type': 'authorization_code',\n\t    'code': grantQueries.code\n\t  });\n\t}\n\t\n\t// refreshToken perform a request on the access_token entrypoint with the\n\t// refresh_token grant type in order to refresh the given token.\n\tfunction refreshToken(cozy, client, token) {\n\t  return retrieveToken(cozy, client, token, {\n\t    'grant_type': 'refresh_token',\n\t    'refresh_token': token.refreshToken\n\t  });\n\t}\n\t\n\t// oauthFlow performs the stateful registration and access granting of an OAuth\n\t// client.\n\tfunction oauthFlow(cozy, storage, clientParams, onRegistered) {\n\t  var ignoreCachedCredentials = arguments.length > 4 && arguments[4] !== undefined ? arguments[4] : false;\n\t\n\t  if (ignoreCachedCredentials) {\n\t    return storage.clear().then(function () {\n\t      return oauthFlow(cozy, storage, clientParams, onRegistered, false);\n\t    });\n\t  }\n\t\n\t  var tryCount = 0;\n\t\n\t  function clearAndRetry(err) {\n\t    if (tryCount++ > 0) {\n\t      throw err;\n\t    }\n\t    return storage.clear().then(function () {\n\t      return oauthFlow(cozy, storage, clientParams, onRegistered);\n\t    });\n\t  }\n\t\n\t  function registerNewClient() {\n\t    return storage.clear().then(function () {\n\t      return registerClient(cozy, clientParams);\n\t    }).then(function (client) {\n\t      var _getAuthCodeURL = getAuthCodeURL(cozy, client, clientParams.scopes),\n\t          url = _getAuthCodeURL.url,\n\t          state = _getAuthCodeURL.state;\n\t\n\t      return storage.save(StateKey, { client: client, url: url, state: state });\n\t    });\n\t  }\n\t\n\t  return Promise.all([storage.load(CredsKey), storage.load(StateKey)]).then(function (_ref) {\n\t    var _ref2 = _slicedToArray(_ref, 2),\n\t        credentials = _ref2[0],\n\t        storedState = _ref2[1];\n\t\n\t    // If credentials are cached we re-fetch the registered client with the\n\t    // said token. Fetching the client, if the token is outdated we should try\n\t    // the token is refreshed.\n\t    if (credentials) {\n\t      var oldClient = void 0,\n\t          _token = void 0;\n\t      try {\n\t        oldClient = new Client(credentials.client);\n\t        _token = new AccessToken(credentials.token);\n\t      } catch (err) {\n\t        // bad cache, we should clear and retry the process\n\t        return clearAndRetry(err);\n\t      }\n\t      return getClient(cozy, oldClient).then(function (client) {\n\t        return { client: client, token: _token };\n\t      }).catch(function (err) {\n\t        // If we fall into an error while fetching the client (because of a\n\t        // bad connectivity for instance), we do not bail the whole process\n\t        // since the client should be able to continue with the persisted\n\t        // client and token.\n\t        //\n\t        // If it is an explicit Unauthorized error though, we bail, clear th\n\t        // cache and retry.\n\t        if (_fetch.FetchError.isUnauthorized(err) || _fetch.FetchError.isNotFound(err)) {\n\t          throw new Error('Client has been revoked');\n\t        }\n\t        return { client: oldClient, token: _token };\n\t      });\n\t    }\n\t\n\t    // Otherwise register a new client if necessary (ie. no client is stored)\n\t    // and call the onRegistered callback to wait for the user to grant the\n\t    // access. Finally fetches to access token on success.\n\t    var statePromise = void 0;\n\t    if (!storedState) {\n\t      statePromise = registerNewClient();\n\t    } else {\n\t      statePromise = Promise.resolve(storedState);\n\t    }\n\t\n\t    var client = void 0,\n\t        state = void 0,\n\t        token = void 0;\n\t    return statePromise.then(function (data) {\n\t      client = data.client;\n\t      state = data.state;\n\t      return Promise.resolve(onRegistered(client, data.url));\n\t    }).then(function (pageURL) {\n\t      return getAccessToken(cozy, client, state, pageURL);\n\t    }).then(function (t) {\n\t      token = t;\n\t    }).then(function () {\n\t      return storage.delete(StateKey);\n\t    }).then(function () {\n\t      return { client: client, token: token };\n\t    });\n\t  }).then(function (creds) {\n\t    return storage.save(CredsKey, creds);\n\t  }, function (err) {\n\t    if (_fetch.FetchError.isUnauthorized(err)) {\n\t      return clearAndRetry(err);\n\t    } else {\n\t      throw err;\n\t    }\n\t  });\n\t}\n\t\n\t// retrieveToken perform a request on the access_token entrypoint in order to\n\t// fetch a token.\n\tfunction retrieveToken(cozy, client, token, query) {\n\t  if (!(client instanceof Client)) {\n\t    client = new Client(client);\n\t  }\n\t  if (!client.isRegistered()) {\n\t    return Promise.reject(new Error('Client not registered'));\n\t  }\n\t  var body = (0, _utils.encodeQuery)(Object.assign({}, query, {\n\t    'client_id': client.clientID,\n\t    'client_secret': client.clientSecret\n\t  }));\n\t  return (0, _fetch.cozyFetchJSON)(cozy, 'POST', '/auth/access_token', body, {\n\t    disableAuth: token === null,\n\t    dontRetry: true,\n\t    manualAuthCredentials: { client: client, token: token },\n\t    headers: { 'Content-Type': 'application/x-www-form-urlencoded' }\n\t  }).then(function (data) {\n\t    data.refreshToken = data.refreshToken || query.refresh_token;\n\t    return new AccessToken(data);\n\t  });\n\t}\n\t\n\t// getGrantCodeFromPageURL extract the state and access_code query parameters\n\t// from the given url\n\tfunction getGrantCodeFromPageURL() {\n\t  var pageURL = arguments.length > 0 && arguments[0] !== undefined ? arguments[0] : '';\n\t\n\t  if (pageURL === '' && typeof window !== 'undefined') {\n\t    pageURL = window.location.href;\n\t  }\n\t  var queries = (0, _utils.decodeQuery)(pageURL);\n\t  if (!queries.hasOwnProperty('state')) {\n\t    return null;\n\t  }\n\t  return {\n\t    state: queries['state'],\n\t    code: queries['access_code']\n\t  };\n\t}\n\t\n\t// generateRandomState will try to generate a 128bits random value from a secure\n\t// pseudo random generator. It will fallback on Math.random if it cannot find\n\t// such generator.\n\tfunction generateRandomState() {\n\t  var buffer = void 0;\n\t  if (typeof window !== 'undefined' && typeof window.crypto !== 'undefined' && typeof window.crypto.getRandomValues === 'function') {\n\t    buffer = new Uint8Array(StateSize);\n\t    window.crypto.getRandomValues(buffer);\n\t  } else {\n\t    try {\n\t      buffer = __webpack_require__(!(function webpackMissingModule() { var e = new Error(\"Cannot find module \\\"crypto\\\"\"); e.code = 'MODULE_NOT_FOUND'; throw e; }())).randomBytes(StateSize);\n\t    } catch (e) {}\n\t  }\n\t  if (!buffer) {\n\t    buffer = new Array(StateSize);\n\t    for (var i = 0; i < buffer.length; i++) {\n\t      buffer[i] = Math.floor(Math.random() * 255);\n\t    }\n\t  }\n\t  return btoa(String.fromCharCode.apply(null, buffer)).replace(/=+$/, '').replace(/\\//g, '_').replace(/\\+/g, '-');\n\t}\n\n/***/ },\n/* 10 */\n/***/ function(module, exports, __webpack_require__) {\n\n\t// Thank's IE8 for his funny defineProperty\n\tmodule.exports = !__webpack_require__(11)(function () {\n\t  return Object.defineProperty({}, 'a', { get: function () { return 7; } }).a != 7;\n\t});\n\n\n/***/ },\n/* 11 */\n/***/ function(module, exports) {\n\n\tmodule.exports = function (exec) {\n\t  try {\n\t    return !!exec();\n\t  } catch (e) {\n\t    return true;\n\t  }\n\t};\n\n\n/***/ },\n/* 12 */\n/***/ function(module, exports) {\n\n\tmodule.exports = function (it) {\n\t  return typeof it === 'object' ? it !== null : typeof it === 'function';\n\t};\n\n\n/***/ },\n/* 13 */\n/***/ function(module, exports) {\n\n\t/* WEBPACK VAR INJECTION */(function(global) {'use strict';\n\tvar Mutation = global.MutationObserver || global.WebKitMutationObserver;\n\t\n\tvar scheduleDrain;\n\t\n\t{\n\t  if (Mutation) {\n\t    var called = 0;\n\t    var observer = new Mutation(nextTick);\n\t    var element = global.document.createTextNode('');\n\t    observer.observe(element, {\n\t      characterData: true\n\t    });\n\t    scheduleDrain = function () {\n\t      element.data = (called = ++called % 2);\n\t    };\n\t  } else if (!global.setImmediate && typeof global.MessageChannel !== 'undefined') {\n\t    var channel = new global.MessageChannel();\n\t    channel.port1.onmessage = nextTick;\n\t    scheduleDrain = function () {\n\t      channel.port2.postMessage(0);\n\t    };\n\t  } else if ('document' in global && 'onreadystatechange' in global.document.createElement('script')) {\n\t    scheduleDrain = function () {\n\t\n\t      // Create a <script> element; its readystatechange event will be fired asynchronously once it is inserted\n\t      // into the document. Do so, thus queuing up the task. Remember to clean up once it's been called.\n\t      var scriptEl = global.document.createElement('script');\n\t      scriptEl.onreadystatechange = function () {\n\t        nextTick();\n\t\n\t        scriptEl.onreadystatechange = null;\n\t        scriptEl.parentNode.removeChild(scriptEl);\n\t        scriptEl = null;\n\t      };\n\t      global.document.documentElement.appendChild(scriptEl);\n\t    };\n\t  } else {\n\t    scheduleDrain = function () {\n\t      setTimeout(nextTick, 0);\n\t    };\n\t  }\n\t}\n\t\n\tvar draining;\n\tvar queue = [];\n\t//named nextTick for less confusing stack traces\n\tfunction nextTick() {\n\t  draining = true;\n\t  var i, oldQueue;\n\t  var len = queue.length;\n\t  while (len) {\n\t    oldQueue = queue;\n\t    queue = [];\n\t    i = -1;\n\t    while (++i < len) {\n\t      oldQueue[i]();\n\t    }\n\t    len = queue.length;\n\t  }\n\t  draining = false;\n\t}\n\t\n\tmodule.exports = immediate;\n\tfunction immediate(task) {\n\t  if (queue.push(task) === 1 && !draining) {\n\t    scheduleDrain();\n\t  }\n\t}\n\t\n\t/* WEBPACK VAR INJECTION */}.call(exports, (function() { return this; }())))\n\n/***/ },\n/* 14 */\n/***/ function(module, exports) {\n\n\tif (typeof Object.create === 'function') {\n\t  // implementation from standard node.js 'util' module\n\t  module.exports = function inherits(ctor, superCtor) {\n\t    ctor.super_ = superCtor\n\t    ctor.prototype = Object.create(superCtor.prototype, {\n\t      constructor: {\n\t        value: ctor,\n\t        enumerable: false,\n\t        writable: true,\n\t        configurable: true\n\t      }\n\t    });\n\t  };\n\t} else {\n\t  // old school shim for old browsers\n\t  module.exports = function inherits(ctor, superCtor) {\n\t    ctor.super_ = superCtor\n\t    var TempCtor = function () {}\n\t    TempCtor.prototype = superCtor.prototype\n\t    ctor.prototype = new TempCtor()\n\t    ctor.prototype.constructor = ctor\n\t  }\n\t}\n\n\n/***/ },\n/* 15 */\n/***/ function(module, exports, __webpack_require__) {\n\n\t/* WEBPACK VAR INJECTION */(function(process) {'use strict';\n\t/* istanbul ignore if */\n\texports.Promise = __webpack_require__(33);\n\t\n\texports.inherits = __webpack_require__(14);\n\texports.extend = __webpack_require__(29);\n\tvar argsarray = __webpack_require__(17);\n\t\n\t/* istanbul ignore next */\n\texports.promisedCallback = function (promise, callback) {\n\t  if (callback) {\n\t    promise.then(function (res) {\n\t      process.nextTick(function () {\n\t        callback(null, res);\n\t      });\n\t    }, function (reason) {\n\t      process.nextTick(function () {\n\t        callback(reason);\n\t      });\n\t    });\n\t  }\n\t  return promise;\n\t};\n\t\n\t/* istanbul ignore next */\n\texports.callbackify = function (fun) {\n\t  return argsarray(function (args) {\n\t    var cb = args.pop();\n\t    var promise = fun.apply(this, args);\n\t    if (typeof cb === 'function') {\n\t      exports.promisedCallback(promise, cb);\n\t    }\n\t    return promise;\n\t  });\n\t};\n\t\n\t// Promise finally util similar to Q.finally\n\t/* istanbul ignore next */\n\texports.fin = function (promise, cb) {\n\t  return promise.then(function (res) {\n\t    var promise2 = cb();\n\t    if (typeof promise2.then === 'function') {\n\t      return promise2.then(function () {\n\t        return res;\n\t      });\n\t    }\n\t    return res;\n\t  }, function (reason) {\n\t    var promise2 = cb();\n\t    if (typeof promise2.then === 'function') {\n\t      return promise2.then(function () {\n\t        throw reason;\n\t      });\n\t    }\n\t    throw reason;\n\t  });\n\t};\n\t\n\texports.sequentialize = function (queue, promiseFactory) {\n\t  return function () {\n\t    var args = arguments;\n\t    var that = this;\n\t    return queue.add(function () {\n\t      return promiseFactory.apply(that, args);\n\t    });\n\t  };\n\t};\n\t\n\texports.flatten = function (arrs) {\n\t  var res = [];\n\t  for (var i = 0, len = arrs.length; i < len; i++) {\n\t    res = res.concat(arrs[i]);\n\t  }\n\t  return res;\n\t};\n\t\n\t// uniq an array of strings, order not guaranteed\n\t// similar to underscore/lodash _.uniq\n\texports.uniq = function (arr) {\n\t  var map = {};\n\t\n\t  for (var i = 0, len = arr.length; i < len; i++) {\n\t    map['$' + arr[i]] = true;\n\t  }\n\t\n\t  var keys = Object.keys(map);\n\t  var output = new Array(keys.length);\n\t\n\t  for (i = 0, len = keys.length; i < len; i++) {\n\t    output[i] = keys[i].substring(1);\n\t  }\n\t  return output;\n\t};\n\t\n\tvar crypto = __webpack_require__(99);\n\tvar Md5 = __webpack_require__(34);\n\t\n\texports.MD5 = function (string) {\n\t  /* istanbul ignore else */\n\t  if (!process.browser) {\n\t    return crypto.createHash('md5').update(string).digest('hex');\n\t  } else {\n\t    return Md5.hash(string);\n\t  }\n\t};\n\t/* WEBPACK VAR INJECTION */}.call(exports, __webpack_require__(5)))\n\n/***/ },\n/* 16 */\n/***/ function(module, exports, __webpack_require__) {\n\n\t'use strict';\n\t\n\tvar localUtils = __webpack_require__(4);\n\tvar abstractMapReduce = __webpack_require__(79);\n\tvar parseField = localUtils.parseField;\n\t\n\t//\n\t// One thing about these mappers:\n\t//\n\t// Per the advice of John-David Dalton (http://youtu.be/NthmeLEhDDM),\n\t// what you want to do in this case is optimize for the smallest possible\n\t// function, since that's the thing that gets run over and over again.\n\t//\n\t// This code would be a lot simpler if all the if/elses were inside\n\t// the function, but it would also be a lot less performant.\n\t//\n\t\n\t\n\tfunction createDeepMultiMapper(fields, emit) {\n\t  return function (doc) {\n\t    var toEmit = [];\n\t    for (var i = 0, iLen = fields.length; i < iLen; i++) {\n\t      var parsedField = parseField(fields[i]);\n\t      var value = doc;\n\t      for (var j = 0, jLen = parsedField.length; j < jLen; j++) {\n\t        var key = parsedField[j];\n\t        value = value[key];\n\t        if (!value) {\n\t          break;\n\t        }\n\t      }\n\t      toEmit.push(value);\n\t    }\n\t    emit(toEmit);\n\t  };\n\t}\n\t\n\tfunction createDeepSingleMapper(field, emit) {\n\t  var parsedField = parseField(field);\n\t  return function (doc) {\n\t    var value = doc;\n\t    for (var i = 0, len = parsedField.length; i < len; i++) {\n\t      var key = parsedField[i];\n\t      value = value[key];\n\t      if (!value) {\n\t        return; // do nothing\n\t      }\n\t    }\n\t    emit(value);\n\t  };\n\t}\n\t\n\tfunction createShallowSingleMapper(field, emit) {\n\t  return function (doc) {\n\t    emit(doc[field]);\n\t  };\n\t}\n\t\n\tfunction createShallowMultiMapper(fields, emit) {\n\t  return function (doc) {\n\t    var toEmit = [];\n\t    for (var i = 0, len = fields.length; i < len; i++) {\n\t      toEmit.push(doc[fields[i]]);\n\t    }\n\t    emit(toEmit);\n\t  };\n\t}\n\t\n\tfunction checkShallow(fields) {\n\t  for (var i = 0, len = fields.length; i < len; i++) {\n\t    var field = fields[i];\n\t    if (field.indexOf('.') !== -1) {\n\t      return false;\n\t    }\n\t  }\n\t  return true;\n\t}\n\t\n\tfunction createMapper(fields, emit) {\n\t  var isShallow = checkShallow(fields);\n\t  var isSingle = fields.length === 1;\n\t\n\t  // notice we try to optimize for the most common case,\n\t  // i.e. single shallow indexes\n\t  if (isShallow) {\n\t    if (isSingle) {\n\t      return createShallowSingleMapper(fields[0], emit);\n\t    } else { // multi\n\t      return createShallowMultiMapper(fields, emit);\n\t    }\n\t  } else { // deep\n\t    if (isSingle) {\n\t      return createDeepSingleMapper(fields[0], emit);\n\t    } else { // multi\n\t      return createDeepMultiMapper(fields, emit);\n\t    }\n\t  }\n\t}\n\t\n\tfunction mapper(mapFunDef, emit) {\n\t  // mapFunDef is a list of fields\n\t\n\t  var fields = Object.keys(mapFunDef.fields);\n\t\n\t  return createMapper(fields, emit);\n\t}\n\t\n\t/* istanbul ignore next */\n\tfunction reducer(/*reduceFunDef*/) {\n\t  throw new Error('reduce not supported');\n\t}\n\t\n\tfunction ddocValidator(ddoc, viewName) {\n\t  var view = ddoc.views[viewName];\n\t  // This doesn't actually need to be here apparently, but\n\t  // I feel safer keeping it.\n\t  /* istanbul ignore if */\n\t  if (!view.map || !view.map.fields) {\n\t    throw new Error('ddoc ' + ddoc._id +' with view ' + viewName +\n\t      ' doesn\\'t have map.fields defined. ' +\n\t      'maybe it wasn\\'t created by this plugin?');\n\t  }\n\t}\n\t\n\tvar abstractMapper = abstractMapReduce({\n\t  name: 'indexes',\n\t  mapper: mapper,\n\t  reducer: reducer,\n\t  ddocValidator: ddocValidator\n\t});\n\t\n\tmodule.exports = abstractMapper;\n\n/***/ },\n/* 17 */\n/***/ function(module, exports) {\n\n\t'use strict';\n\t\n\tmodule.exports = argsArray;\n\t\n\tfunction argsArray(fun) {\n\t  return function () {\n\t    var len = arguments.length;\n\t    if (len) {\n\t      var args = [];\n\t      var i = -1;\n\t      while (++i < len) {\n\t        args[i] = arguments[i];\n\t      }\n\t      return fun.call(this, args);\n\t    } else {\n\t      return fun.call(this, []);\n\t    }\n\t  };\n\t}\n\n/***/ },\n/* 18 */\n/***/ function(module, exports) {\n\n\t'use strict';\n\t\n\tObject.defineProperty(exports, \"__esModule\", {\n\t  value: true\n\t});\n\tfunction indexKey(doc) {\n\t  return doc.type + '/' + doc.id;\n\t}\n\t\n\tfunction findByRef(resources, ref) {\n\t  return resources[indexKey(ref)];\n\t}\n\t\n\tfunction handleResource(rawResource, resources, links) {\n\t  var resource = {\n\t    _id: rawResource.id,\n\t    _type: rawResource.type,\n\t    _rev: rawResource.meta && rawResource.meta.rev,\n\t    links: Object.assign({}, rawResource.links, links),\n\t    attributes: rawResource.attributes,\n\t    relations: function relations(name) {\n\t      var rels = rawResource.relationships[name];\n\t      if (rels === undefined || rels.data === undefined) return undefined;\n\t      if (rels.data === null) return null;\n\t      if (!Array.isArray(rels.data)) return findByRef(resources, rels.data);\n\t      return rels.data.map(function (ref) {\n\t        return findByRef(resources, ref);\n\t      });\n\t    }\n\t  };\n\t  if (rawResource.relationships) {\n\t    resource.relationships = rawResource.relationships;\n\t  }\n\t\n\t  resources[indexKey(rawResource)] = resource;\n\t\n\t  return resource;\n\t}\n\t\n\tfunction handleTopLevel(doc) {\n\t  var resources = arguments.length > 1 && arguments[1] !== undefined ? arguments[1] : {};\n\t\n\t  // build an index of included resource by Type & ID\n\t  var included = doc.included;\n\t\n\t  if (Array.isArray(included)) {\n\t    included.forEach(function (r) {\n\t      return handleResource(r, resources, doc.links);\n\t    });\n\t  }\n\t\n\t  if (Array.isArray(doc.data)) {\n\t    return doc.data.map(function (r) {\n\t      return handleResource(r, resources, doc.links);\n\t    });\n\t  } else {\n\t    return handleResource(doc.data, resources, doc.links);\n\t  }\n\t}\n\t\n\texports.default = handleTopLevel;\n\n/***/ },\n/* 19 */\n/***/ function(module, exports) {\n\n\tvar core = module.exports = { version: '2.5.3' };\n\tif (typeof __e == 'number') __e = core; // eslint-disable-line no-undef\n\n\n/***/ },\n/* 20 */\n/***/ function(module, exports) {\n\n\t// 7.2.1 RequireObjectCoercible(argument)\n\tmodule.exports = function (it) {\n\t  if (it == undefined) throw TypeError(\"Can't call method on  \" + it);\n\t  return it;\n\t};\n\n\n/***/ },\n/* 21 */\n/***/ function(module, exports) {\n\n\tvar hasOwnProperty = {}.hasOwnProperty;\n\tmodule.exports = function (it, key) {\n\t  return hasOwnProperty.call(it, key);\n\t};\n\n\n/***/ },\n/* 22 */\n/***/ function(module, exports, __webpack_require__) {\n\n\tvar dP = __webpack_require__(58);\n\tvar createDesc = __webpack_require__(63);\n\tmodule.exports = __webpack_require__(10) ? function (object, key, value) {\n\t  return dP.f(object, key, createDesc(1, value));\n\t} : function (object, key, value) {\n\t  object[key] = value;\n\t  return object;\n\t};\n\n\n/***/ },\n/* 23 */\n/***/ function(module, exports, __webpack_require__) {\n\n\t// fallback for non-array-like ES3 and non-enumerable old V8 strings\n\tvar cof = __webpack_require__(51);\n\t// eslint-disable-next-line no-prototype-builtins\n\tmodule.exports = Object('z').propertyIsEnumerable(0) ? Object : function (it) {\n\t  return cof(it) == 'String' ? it.split('') : Object(it);\n\t};\n\n\n/***/ },\n/* 24 */\n/***/ function(module, exports) {\n\n\t// 7.1.4 ToInteger\n\tvar ceil = Math.ceil;\n\tvar floor = Math.floor;\n\tmodule.exports = function (it) {\n\t  return isNaN(it = +it) ? 0 : (it > 0 ? floor : ceil)(it);\n\t};\n\n\n/***/ },\n/* 25 */\n/***/ function(module, exports, __webpack_require__) {\n\n\t// to indexed object, toObject with fallback for non-array-like ES3 strings\n\tvar IObject = __webpack_require__(23);\n\tvar defined = __webpack_require__(20);\n\tmodule.exports = function (it) {\n\t  return IObject(defined(it));\n\t};\n\n\n/***/ },\n/* 26 */\n/***/ function(module, exports) {\n\n\tvar id = 0;\n\tvar px = Math.random();\n\tmodule.exports = function (key) {\n\t  return 'Symbol('.concat(key === undefined ? '' : key, ')_', (++id + px).toString(36));\n\t};\n\n\n/***/ },\n/* 27 */\n/***/ function(module, exports, __webpack_require__) {\n\n\t/* WEBPACK VAR INJECTION */(function(process) {/**\n\t * This is the web browser implementation of `debug()`.\n\t *\n\t * Expose `debug()` as the module.\n\t */\n\t\n\texports = module.exports = __webpack_require__(73);\n\texports.log = log;\n\texports.formatArgs = formatArgs;\n\texports.save = save;\n\texports.load = load;\n\texports.useColors = useColors;\n\texports.storage = 'undefined' != typeof chrome\n\t               && 'undefined' != typeof chrome.storage\n\t                  ? chrome.storage.local\n\t                  : localstorage();\n\t\n\t/**\n\t * Colors.\n\t */\n\t\n\texports.colors = [\n\t  'lightseagreen',\n\t  'forestgreen',\n\t  'goldenrod',\n\t  'dodgerblue',\n\t  'darkorchid',\n\t  'crimson'\n\t];\n\t\n\t/**\n\t * Currently only WebKit-based Web Inspectors, Firefox >= v31,\n\t * and the Firebug extension (any Firefox version) are known\n\t * to support \"%c\" CSS customizations.\n\t *\n\t * TODO: add a `localStorage` variable to explicitly enable/disable colors\n\t */\n\t\n\tfunction useColors() {\n\t  // NB: In an Electron preload script, document will be defined but not fully\n\t  // initialized. Since we know we're in Chrome, we'll just detect this case\n\t  // explicitly\n\t  if (typeof window !== 'undefined' && window && typeof window.process !== 'undefined' && window.process.type === 'renderer') {\n\t    return true;\n\t  }\n\t\n\t  // is webkit? http://stackoverflow.com/a/16459606/376773\n\t  // document is undefined in react-native: https://github.com/facebook/react-native/pull/1632\n\t  return (typeof document !== 'undefined' && document && 'WebkitAppearance' in document.documentElement.style) ||\n\t    // is firebug? http://stackoverflow.com/a/398120/376773\n\t    (typeof window !== 'undefined' && window && window.console && (console.firebug || (console.exception && console.table))) ||\n\t    // is firefox >= v31?\n\t    // https://developer.mozilla.org/en-US/docs/Tools/Web_Console#Styling_messages\n\t    (typeof navigator !== 'undefined' && navigator && navigator.userAgent && navigator.userAgent.toLowerCase().match(/firefox\\/(\\d+)/) && parseInt(RegExp.$1, 10) >= 31) ||\n\t    // double check webkit in userAgent just in case we are in a worker\n\t    (typeof navigator !== 'undefined' && navigator && navigator.userAgent && navigator.userAgent.toLowerCase().match(/applewebkit\\/(\\d+)/));\n\t}\n\t\n\t/**\n\t * Map %j to `JSON.stringify()`, since no Web Inspectors do that by default.\n\t */\n\t\n\texports.formatters.j = function(v) {\n\t  try {\n\t    return JSON.stringify(v);\n\t  } catch (err) {\n\t    return '[UnexpectedJSONParseError]: ' + err.message;\n\t  }\n\t};\n\t\n\t\n\t/**\n\t * Colorize log arguments if enabled.\n\t *\n\t * @api public\n\t */\n\t\n\tfunction formatArgs(args) {\n\t  var useColors = this.useColors;\n\t\n\t  args[0] = (useColors ? '%c' : '')\n\t    + this.namespace\n\t    + (useColors ? ' %c' : ' ')\n\t    + args[0]\n\t    + (useColors ? '%c ' : ' ')\n\t    + '+' + exports.humanize(this.diff);\n\t\n\t  if (!useColors) return;\n\t\n\t  var c = 'color: ' + this.color;\n\t  args.splice(1, 0, c, 'color: inherit')\n\t\n\t  // the final \"%c\" is somewhat tricky, because there could be other\n\t  // arguments passed either before or after the %c, so we need to\n\t  // figure out the correct index to insert the CSS into\n\t  var index = 0;\n\t  var lastC = 0;\n\t  args[0].replace(/%[a-zA-Z%]/g, function(match) {\n\t    if ('%%' === match) return;\n\t    index++;\n\t    if ('%c' === match) {\n\t      // we only are interested in the *last* %c\n\t      // (the user may have provided their own)\n\t      lastC = index;\n\t    }\n\t  });\n\t\n\t  args.splice(lastC, 0, c);\n\t}\n\t\n\t/**\n\t * Invokes `console.log()` when available.\n\t * No-op when `console.log` is not a \"function\".\n\t *\n\t * @api public\n\t */\n\t\n\tfunction log() {\n\t  // this hackery is required for IE8/9, where\n\t  // the `console.log` function doesn't have 'apply'\n\t  return 'object' === typeof console\n\t    && console.log\n\t    && Function.prototype.apply.call(console.log, console, arguments);\n\t}\n\t\n\t/**\n\t * Save `namespaces`.\n\t *\n\t * @param {String} namespaces\n\t * @api private\n\t */\n\t\n\tfunction save(namespaces) {\n\t  try {\n\t    if (null == namespaces) {\n\t      exports.storage.removeItem('debug');\n\t    } else {\n\t      exports.storage.debug = namespaces;\n\t    }\n\t  } catch(e) {}\n\t}\n\t\n\t/**\n\t * Load `namespaces`.\n\t *\n\t * @return {String} returns the previously persisted debug modes\n\t * @api private\n\t */\n\t\n\tfunction load() {\n\t  try {\n\t    return exports.storage.debug;\n\t  } catch(e) {}\n\t\n\t  // If debug isn't set in LS, and we're in Electron, try to load $DEBUG\n\t  if (typeof process !== 'undefined' && 'env' in process) {\n\t    return process.env.DEBUG;\n\t  }\n\t}\n\t\n\t/**\n\t * Enable namespaces listed in `localStorage.debug` initially.\n\t */\n\t\n\texports.enable(load());\n\t\n\t/**\n\t * Localstorage attempts to return the localstorage.\n\t *\n\t * This is necessary because safari throws\n\t * when a user disables cookies/localstorage\n\t * and you attempt to access it.\n\t *\n\t * @return {LocalStorage}\n\t * @api private\n\t */\n\t\n\tfunction localstorage() {\n\t  try {\n\t    return window.localStorage;\n\t  } catch (e) {}\n\t}\n\t\n\t/* WEBPACK VAR INJECTION */}.call(exports, __webpack_require__(5)))\n\n/***/ },\n/* 28 */\n/***/ function(module, exports, __webpack_require__) {\n\n\t/* WEBPACK VAR INJECTION */(function(process) {'use strict';\n\tvar immediate = __webpack_require__(13);\n\t\n\t/* istanbul ignore next */\n\tfunction INTERNAL() {}\n\t\n\tvar handlers = {};\n\t\n\tvar REJECTED = ['REJECTED'];\n\tvar FULFILLED = ['FULFILLED'];\n\tvar PENDING = ['PENDING'];\n\t/* istanbul ignore else */\n\tif (!process.browser) {\n\t  // in which we actually take advantage of JS scoping\n\t  var UNHANDLED = ['UNHANDLED'];\n\t}\n\t\n\tmodule.exports = Promise;\n\t\n\tfunction Promise(resolver) {\n\t  if (typeof resolver !== 'function') {\n\t    throw new TypeError('resolver must be a function');\n\t  }\n\t  this.state = PENDING;\n\t  this.queue = [];\n\t  this.outcome = void 0;\n\t  /* istanbul ignore else */\n\t  if (!process.browser) {\n\t    this.handled = UNHANDLED;\n\t  }\n\t  if (resolver !== INTERNAL) {\n\t    safelyResolveThenable(this, resolver);\n\t  }\n\t}\n\t\n\tPromise.prototype.catch = function (onRejected) {\n\t  return this.then(null, onRejected);\n\t};\n\tPromise.prototype.then = function (onFulfilled, onRejected) {\n\t  if (typeof onFulfilled !== 'function' && this.state === FULFILLED ||\n\t    typeof onRejected !== 'function' && this.state === REJECTED) {\n\t    return this;\n\t  }\n\t  var promise = new this.constructor(INTERNAL);\n\t  /* istanbul ignore else */\n\t  if (!process.browser) {\n\t    if (this.handled === UNHANDLED) {\n\t      this.handled = null;\n\t    }\n\t  }\n\t  if (this.state !== PENDING) {\n\t    var resolver = this.state === FULFILLED ? onFulfilled : onRejected;\n\t    unwrap(promise, resolver, this.outcome);\n\t  } else {\n\t    this.queue.push(new QueueItem(promise, onFulfilled, onRejected));\n\t  }\n\t\n\t  return promise;\n\t};\n\tfunction QueueItem(promise, onFulfilled, onRejected) {\n\t  this.promise = promise;\n\t  if (typeof onFulfilled === 'function') {\n\t    this.onFulfilled = onFulfilled;\n\t    this.callFulfilled = this.otherCallFulfilled;\n\t  }\n\t  if (typeof onRejected === 'function') {\n\t    this.onRejected = onRejected;\n\t    this.callRejected = this.otherCallRejected;\n\t  }\n\t}\n\tQueueItem.prototype.callFulfilled = function (value) {\n\t  handlers.resolve(this.promise, value);\n\t};\n\tQueueItem.prototype.otherCallFulfilled = function (value) {\n\t  unwrap(this.promise, this.onFulfilled, value);\n\t};\n\tQueueItem.prototype.callRejected = function (value) {\n\t  handlers.reject(this.promise, value);\n\t};\n\tQueueItem.prototype.otherCallRejected = function (value) {\n\t  unwrap(this.promise, this.onRejected, value);\n\t};\n\t\n\tfunction unwrap(promise, func, value) {\n\t  immediate(function () {\n\t    var returnValue;\n\t    try {\n\t      returnValue = func(value);\n\t    } catch (e) {\n\t      return handlers.reject(promise, e);\n\t    }\n\t    if (returnValue === promise) {\n\t      handlers.reject(promise, new TypeError('Cannot resolve promise with itself'));\n\t    } else {\n\t      handlers.resolve(promise, returnValue);\n\t    }\n\t  });\n\t}\n\t\n\thandlers.resolve = function (self, value) {\n\t  var result = tryCatch(getThen, value);\n\t  if (result.status === 'error') {\n\t    return handlers.reject(self, result.value);\n\t  }\n\t  var thenable = result.value;\n\t\n\t  if (thenable) {\n\t    safelyResolveThenable(self, thenable);\n\t  } else {\n\t    self.state = FULFILLED;\n\t    self.outcome = value;\n\t    var i = -1;\n\t    var len = self.queue.length;\n\t    while (++i < len) {\n\t      self.queue[i].callFulfilled(value);\n\t    }\n\t  }\n\t  return self;\n\t};\n\thandlers.reject = function (self, error) {\n\t  self.state = REJECTED;\n\t  self.outcome = error;\n\t  /* istanbul ignore else */\n\t  if (!process.browser) {\n\t    if (self.handled === UNHANDLED) {\n\t      immediate(function () {\n\t        if (self.handled === UNHANDLED) {\n\t          process.emit('unhandledRejection', error, self);\n\t        }\n\t      });\n\t    }\n\t  }\n\t  var i = -1;\n\t  var len = self.queue.length;\n\t  while (++i < len) {\n\t    self.queue[i].callRejected(error);\n\t  }\n\t  return self;\n\t};\n\t\n\tfunction getThen(obj) {\n\t  // Make sure we only access the accessor once as required by the spec\n\t  var then = obj && obj.then;\n\t  if (obj && typeof obj === 'object' && typeof then === 'function') {\n\t    return function appyThen() {\n\t      then.apply(obj, arguments);\n\t    };\n\t  }\n\t}\n\t\n\tfunction safelyResolveThenable(self, thenable) {\n\t  // Either fulfill, reject or reject with error\n\t  var called = false;\n\t  function onError(value) {\n\t    if (called) {\n\t      return;\n\t    }\n\t    called = true;\n\t    handlers.reject(self, value);\n\t  }\n\t\n\t  function onSuccess(value) {\n\t    if (called) {\n\t      return;\n\t    }\n\t    called = true;\n\t    handlers.resolve(self, value);\n\t  }\n\t\n\t  function tryToUnwrap() {\n\t    thenable(onSuccess, onError);\n\t  }\n\t\n\t  var result = tryCatch(tryToUnwrap);\n\t  if (result.status === 'error') {\n\t    onError(result.value);\n\t  }\n\t}\n\t\n\tfunction tryCatch(func, value) {\n\t  var out = {};\n\t  try {\n\t    out.value = func(value);\n\t    out.status = 'success';\n\t  } catch (e) {\n\t    out.status = 'error';\n\t    out.value = e;\n\t  }\n\t  return out;\n\t}\n\t\n\tPromise.resolve = resolve;\n\tfunction resolve(value) {\n\t  if (value instanceof this) {\n\t    return value;\n\t  }\n\t  return handlers.resolve(new this(INTERNAL), value);\n\t}\n\t\n\tPromise.reject = reject;\n\tfunction reject(reason) {\n\t  var promise = new this(INTERNAL);\n\t  return handlers.reject(promise, reason);\n\t}\n\t\n\tPromise.all = all;\n\tfunction all(iterable) {\n\t  var self = this;\n\t  if (Object.prototype.toString.call(iterable) !== '[object Array]') {\n\t    return this.reject(new TypeError('must be an array'));\n\t  }\n\t\n\t  var len = iterable.length;\n\t  var called = false;\n\t  if (!len) {\n\t    return this.resolve([]);\n\t  }\n\t\n\t  var values = new Array(len);\n\t  var resolved = 0;\n\t  var i = -1;\n\t  var promise = new this(INTERNAL);\n\t\n\t  while (++i < len) {\n\t    allResolver(iterable[i], i);\n\t  }\n\t  return promise;\n\t  function allResolver(value, i) {\n\t    self.resolve(value).then(resolveFromAll, function (error) {\n\t      if (!called) {\n\t        called = true;\n\t        handlers.reject(promise, error);\n\t      }\n\t    });\n\t    function resolveFromAll(outValue) {\n\t      values[i] = outValue;\n\t      if (++resolved === len && !called) {\n\t        called = true;\n\t        handlers.resolve(promise, values);\n\t      }\n\t    }\n\t  }\n\t}\n\t\n\tPromise.race = race;\n\tfunction race(iterable) {\n\t  var self = this;\n\t  if (Object.prototype.toString.call(iterable) !== '[object Array]') {\n\t    return this.reject(new TypeError('must be an array'));\n\t  }\n\t\n\t  var len = iterable.length;\n\t  var called = false;\n\t  if (!len) {\n\t    return this.resolve([]);\n\t  }\n\t\n\t  var i = -1;\n\t  var promise = new this(INTERNAL);\n\t\n\t  while (++i < len) {\n\t    resolver(iterable[i]);\n\t  }\n\t  return promise;\n\t  function resolver(value) {\n\t    self.resolve(value).then(function (response) {\n\t      if (!called) {\n\t        called = true;\n\t        handlers.resolve(promise, response);\n\t      }\n\t    }, function (error) {\n\t      if (!called) {\n\t        called = true;\n\t        handlers.reject(promise, error);\n\t      }\n\t    });\n\t  }\n\t}\n\t\n\t/* WEBPACK VAR INJECTION */}.call(exports, __webpack_require__(5)))\n\n/***/ },\n/* 29 */\n/***/ function(module, exports) {\n\n\t\"use strict\";\n\t\n\t// Extends method\n\t// (taken from http://code.jquery.com/jquery-1.9.0.js)\n\t// Populate the class2type map\n\tvar class2type = {};\n\t\n\tvar types = [\n\t  \"Boolean\", \"Number\", \"String\", \"Function\", \"Array\",\n\t  \"Date\", \"RegExp\", \"Object\", \"Error\"\n\t];\n\tfor (var i = 0; i < types.length; i++) {\n\t  var typename = types[i];\n\t  class2type[\"[object \" + typename + \"]\"] = typename.toLowerCase();\n\t}\n\t\n\tvar core_toString = class2type.toString;\n\tvar core_hasOwn = class2type.hasOwnProperty;\n\t\n\tfunction type(obj) {\n\t  if (obj === null) {\n\t    return String(obj);\n\t  }\n\t  return typeof obj === \"object\" || typeof obj === \"function\" ?\n\t    class2type[core_toString.call(obj)] || \"object\" :\n\t    typeof obj;\n\t}\n\t\n\tfunction isWindow(obj) {\n\t  return obj !== null && obj === obj.window;\n\t}\n\t\n\tfunction isPlainObject(obj) {\n\t  // Must be an Object.\n\t  // Because of IE, we also have to check the presence of\n\t  // the constructor property.\n\t  // Make sure that DOM nodes and window objects don't pass through, as well\n\t  if (!obj || type(obj) !== \"object\" || obj.nodeType || isWindow(obj)) {\n\t    return false;\n\t  }\n\t\n\t  try {\n\t    // Not own constructor property must be Object\n\t    if (obj.constructor &&\n\t      !core_hasOwn.call(obj, \"constructor\") &&\n\t      !core_hasOwn.call(obj.constructor.prototype, \"isPrototypeOf\")) {\n\t      return false;\n\t    }\n\t  } catch ( e ) {\n\t    // IE8,9 Will throw exceptions on certain host objects #9897\n\t    return false;\n\t  }\n\t\n\t  // Own properties are enumerated firstly, so to speed up,\n\t  // if last one is own, then all properties are own.\n\t  var key;\n\t  for (key in obj) {}\n\t\n\t  return key === undefined || core_hasOwn.call(obj, key);\n\t}\n\t\n\t\n\tfunction isFunction(obj) {\n\t  return type(obj) === \"function\";\n\t}\n\t\n\tvar isArray = Array.isArray || function (obj) {\n\t  return type(obj) === \"array\";\n\t};\n\t\n\tfunction extend() {\n\t  // originally extend() was recursive, but this ended up giving us\n\t  // \"call stack exceeded\", so it's been unrolled to use a literal stack\n\t  // (see https://github.com/pouchdb/pouchdb/issues/2543)\n\t  var stack = [];\n\t  var i = -1;\n\t  var len = arguments.length;\n\t  var args = new Array(len);\n\t  while (++i < len) {\n\t    args[i] = arguments[i];\n\t  }\n\t  var container = {};\n\t  stack.push({args: args, result: {container: container, key: 'key'}});\n\t  var next;\n\t  while ((next = stack.pop())) {\n\t    extendInner(stack, next.args, next.result);\n\t  }\n\t  return container.key;\n\t}\n\t\n\tfunction extendInner(stack, args, result) {\n\t  var options, name, src, copy, copyIsArray, clone,\n\t    target = args[0] || {},\n\t    i = 1,\n\t    length = args.length,\n\t    deep = false,\n\t    numericStringRegex = /\\d+/,\n\t    optionsIsArray;\n\t\n\t  // Handle a deep copy situation\n\t  if (typeof target === \"boolean\") {\n\t    deep = target;\n\t    target = args[1] || {};\n\t    // skip the boolean and the target\n\t    i = 2;\n\t  }\n\t\n\t  // Handle case when target is a string or something (possible in deep copy)\n\t  if (typeof target !== \"object\" && !isFunction(target)) {\n\t    target = {};\n\t  }\n\t\n\t  // extend jQuery itself if only one argument is passed\n\t  if (length === i) {\n\t    /* jshint validthis: true */\n\t    target = this;\n\t    --i;\n\t  }\n\t\n\t  for (; i < length; i++) {\n\t    // Only deal with non-null/undefined values\n\t    if ((options = args[i]) != null) {\n\t      optionsIsArray = isArray(options);\n\t      // Extend the base object\n\t      for (name in options) {\n\t        //if (options.hasOwnProperty(name)) {\n\t        if (!(name in Object.prototype)) {\n\t          if (optionsIsArray && !numericStringRegex.test(name)) {\n\t            continue;\n\t          }\n\t\n\t          src = target[name];\n\t          copy = options[name];\n\t\n\t          // Prevent never-ending loop\n\t          if (target === copy) {\n\t            continue;\n\t          }\n\t\n\t          // Recurse if we're merging plain objects or arrays\n\t          if (deep && copy && (isPlainObject(copy) ||\n\t              (copyIsArray = isArray(copy)))) {\n\t            if (copyIsArray) {\n\t              copyIsArray = false;\n\t              clone = src && isArray(src) ? src : [];\n\t\n\t            } else {\n\t              clone = src && isPlainObject(src) ? src : {};\n\t            }\n\t\n\t            // Never move original objects, clone them\n\t            stack.push({\n\t              args: [deep, clone, copy],\n\t              result: {\n\t                container: target,\n\t                key: name\n\t              }\n\t            });\n\t\n\t          // Don't bring in undefined values\n\t          } else if (copy !== undefined) {\n\t            if (!(isArray(options) && isFunction(copy))) {\n\t              target[name] = copy;\n\t            }\n\t          }\n\t        }\n\t      }\n\t    }\n\t  }\n\t\n\t  // \"Return\" the modified object by setting the key\n\t  // on the given container\n\t  result.container[result.key] = target;\n\t}\n\t\n\t\n\tmodule.exports = extend;\n\t\n\t\n\n\n/***/ },\n/* 30 */\n/***/ function(module, exports, __webpack_require__) {\n\n\t'use strict';\n\t\n\tvar upsert = __webpack_require__(35).upsert;\n\t\n\tmodule.exports = function (db, doc, diffFun) {\n\t  return upsert.apply(db, [doc, diffFun]);\n\t};\n\n/***/ },\n/* 31 */\n/***/ function(module, exports, __webpack_require__) {\n\n\t'use strict';\n\t\n\tvar utils = __webpack_require__(2);\n\t\n\tvar localUtils = __webpack_require__(4);\n\tvar massageIndexDef = localUtils.massageIndexDef;\n\t\n\tfunction getIndexes(db) {\n\t  // just search through all the design docs and filter in-memory.\n\t  // hopefully there aren't that many ddocs.\n\t  return db.allDocs({\n\t    startkey: '_design/',\n\t    endkey: '_design/\\uffff',\n\t    include_docs: true\n\t  }).then(function (allDocsRes) {\n\t    var res = {\n\t      indexes: [{\n\t        ddoc: null,\n\t        name: '_all_docs',\n\t        type: 'special',\n\t        def: {\n\t          fields: [{_id: 'asc'}]\n\t        }\n\t      }]\n\t    };\n\t\n\t    res.indexes = utils.flatten(res.indexes, allDocsRes.rows.filter(function (row) {\n\t      return row.doc.language === 'query';\n\t    }).map(function (row) {\n\t      var viewNames = row.doc.views !== undefined ? Object.keys(row.doc.views) : [];\n\t\n\t      return viewNames.map(function (viewName) {\n\t        var view = row.doc.views[viewName];\n\t        return {\n\t          ddoc: row.id,\n\t          name: viewName,\n\t          type: 'json',\n\t          def: massageIndexDef(view.options.def)\n\t        };\n\t      });\n\t    }));\n\t\n\t    // these are sorted by view name for some reason\n\t    res.indexes.sort(function (left, right) {\n\t      return utils.compare(left.name, right.name);\n\t    });\n\t    res.total_rows = res.indexes.length;\n\t    return res;\n\t  });\n\t}\n\t\n\tmodule.exports = getIndexes;\n\n\n/***/ },\n/* 32 */\n/***/ function(module, exports, __webpack_require__) {\n\n\t'use strict';\n\t\n\tvar utils = __webpack_require__(2);\n\tvar clone = utils.clone;\n\t\n\t// we restucture the supplied JSON considerably, because the official\n\t// Mango API is very particular about a lot of this stuff, but we like\n\t// to be liberal with what we accept in order to prevent mental\n\t// breakdowns in our users\n\tmodule.exports = function (requestDef) {\n\t  requestDef = clone(requestDef);\n\t\n\t  if (!requestDef.index) {\n\t    requestDef.index = {};\n\t  }\n\t\n\t  ['type', 'name', 'ddoc'].forEach(function (key) {\n\t    if (requestDef.index[key]) {\n\t      requestDef[key] = requestDef.index[key];\n\t      delete requestDef.index[key];\n\t    }\n\t  });\n\t\n\t  if (requestDef.fields) {\n\t    requestDef.index.fields = requestDef.fields;\n\t    delete requestDef.fields;\n\t  }\n\t\n\t  if (!requestDef.type) {\n\t    requestDef.type = 'json';\n\t  }\n\t  return requestDef;\n\t};\n\n/***/ },\n/* 33 */\n/***/ function(module, exports, __webpack_require__) {\n\n\t'use strict';\n\t\n\tfunction _interopDefault (ex) { return (ex && (typeof ex === 'object') && 'default' in ex) ? ex['default'] : ex; }\n\t\n\tvar lie = _interopDefault(__webpack_require__(28));\n\t\n\t/* istanbul ignore next */\n\tvar PouchPromise = typeof Promise === 'function' ? Promise : lie;\n\t\n\tmodule.exports = PouchPromise;\n\n/***/ },\n/* 34 */\n/***/ function(module, exports, __webpack_require__) {\n\n\t/*jshint bitwise:false*/\n\t/*global unescape*/\n\t\n\t(function (factory) {\n\t    if (true) {\n\t        // Node/CommonJS\n\t        module.exports = factory();\n\t    } else if (typeof define === 'function' && define.amd) {\n\t        // AMD\n\t        define(factory);\n\t    } else {\n\t        // Browser globals (with support for web workers)\n\t        var glob;\n\t        try {\n\t            glob = window;\n\t        } catch (e) {\n\t            glob = self;\n\t        }\n\t\n\t        glob.SparkMD5 = factory();\n\t    }\n\t}(function (undefined) {\n\t\n\t    'use strict';\n\t\n\t    ////////////////////////////////////////////////////////////////////////////\n\t\n\t    /*\n\t     * Fastest md5 implementation around (JKM md5)\n\t     * Credits: Joseph Myers\n\t     *\n\t     * @see http://www.myersdaily.org/joseph/javascript/md5-text.html\n\t     * @see http://jsperf.com/md5-shootout/7\n\t     */\n\t\n\t    /* this function is much faster,\n\t      so if possible we use it. Some IEs\n\t      are the only ones I know of that\n\t      need the idiotic second function,\n\t      generated by an if clause.  */\n\t    var add32 = function (a, b) {\n\t        return (a + b) & 0xFFFFFFFF;\n\t    },\n\t\n\t    cmn = function (q, a, b, x, s, t) {\n\t        a = add32(add32(a, q), add32(x, t));\n\t        return add32((a << s) | (a >>> (32 - s)), b);\n\t    },\n\t\n\t    ff = function (a, b, c, d, x, s, t) {\n\t        return cmn((b & c) | ((~b) & d), a, b, x, s, t);\n\t    },\n\t\n\t    gg = function (a, b, c, d, x, s, t) {\n\t        return cmn((b & d) | (c & (~d)), a, b, x, s, t);\n\t    },\n\t\n\t    hh = function (a, b, c, d, x, s, t) {\n\t        return cmn(b ^ c ^ d, a, b, x, s, t);\n\t    },\n\t\n\t    ii = function (a, b, c, d, x, s, t) {\n\t        return cmn(c ^ (b | (~d)), a, b, x, s, t);\n\t    },\n\t\n\t    md5cycle = function (x, k) {\n\t        var a = x[0],\n\t            b = x[1],\n\t            c = x[2],\n\t            d = x[3];\n\t\n\t        a = ff(a, b, c, d, k[0], 7, -680876936);\n\t        d = ff(d, a, b, c, k[1], 12, -389564586);\n\t        c = ff(c, d, a, b, k[2], 17, 606105819);\n\t        b = ff(b, c, d, a, k[3], 22, -1044525330);\n\t        a = ff(a, b, c, d, k[4], 7, -176418897);\n\t        d = ff(d, a, b, c, k[5], 12, 1200080426);\n\t        c = ff(c, d, a, b, k[6], 17, -1473231341);\n\t        b = ff(b, c, d, a, k[7], 22, -45705983);\n\t        a = ff(a, b, c, d, k[8], 7, 1770035416);\n\t        d = ff(d, a, b, c, k[9], 12, -1958414417);\n\t        c = ff(c, d, a, b, k[10], 17, -42063);\n\t        b = ff(b, c, d, a, k[11], 22, -1990404162);\n\t        a = ff(a, b, c, d, k[12], 7, 1804603682);\n\t        d = ff(d, a, b, c, k[13], 12, -40341101);\n\t        c = ff(c, d, a, b, k[14], 17, -1502002290);\n\t        b = ff(b, c, d, a, k[15], 22, 1236535329);\n\t\n\t        a = gg(a, b, c, d, k[1], 5, -165796510);\n\t        d = gg(d, a, b, c, k[6], 9, -1069501632);\n\t        c = gg(c, d, a, b, k[11], 14, 643717713);\n\t        b = gg(b, c, d, a, k[0], 20, -373897302);\n\t        a = gg(a, b, c, d, k[5], 5, -701558691);\n\t        d = gg(d, a, b, c, k[10], 9, 38016083);\n\t        c = gg(c, d, a, b, k[15], 14, -660478335);\n\t        b = gg(b, c, d, a, k[4], 20, -405537848);\n\t        a = gg(a, b, c, d, k[9], 5, 568446438);\n\t        d = gg(d, a, b, c, k[14], 9, -1019803690);\n\t        c = gg(c, d, a, b, k[3], 14, -187363961);\n\t        b = gg(b, c, d, a, k[8], 20, 1163531501);\n\t        a = gg(a, b, c, d, k[13], 5, -1444681467);\n\t        d = gg(d, a, b, c, k[2], 9, -51403784);\n\t        c = gg(c, d, a, b, k[7], 14, 1735328473);\n\t        b = gg(b, c, d, a, k[12], 20, -1926607734);\n\t\n\t        a = hh(a, b, c, d, k[5], 4, -378558);\n\t        d = hh(d, a, b, c, k[8], 11, -2022574463);\n\t        c = hh(c, d, a, b, k[11], 16, 1839030562);\n\t        b = hh(b, c, d, a, k[14], 23, -35309556);\n\t        a = hh(a, b, c, d, k[1], 4, -1530992060);\n\t        d = hh(d, a, b, c, k[4], 11, 1272893353);\n\t        c = hh(c, d, a, b, k[7], 16, -155497632);\n\t        b = hh(b, c, d, a, k[10], 23, -1094730640);\n\t        a = hh(a, b, c, d, k[13], 4, 681279174);\n\t        d = hh(d, a, b, c, k[0], 11, -358537222);\n\t        c = hh(c, d, a, b, k[3], 16, -722521979);\n\t        b = hh(b, c, d, a, k[6], 23, 76029189);\n\t        a = hh(a, b, c, d, k[9], 4, -640364487);\n\t        d = hh(d, a, b, c, k[12], 11, -421815835);\n\t        c = hh(c, d, a, b, k[15], 16, 530742520);\n\t        b = hh(b, c, d, a, k[2], 23, -995338651);\n\t\n\t        a = ii(a, b, c, d, k[0], 6, -198630844);\n\t        d = ii(d, a, b, c, k[7], 10, 1126891415);\n\t        c = ii(c, d, a, b, k[14], 15, -1416354905);\n\t        b = ii(b, c, d, a, k[5], 21, -57434055);\n\t        a = ii(a, b, c, d, k[12], 6, 1700485571);\n\t        d = ii(d, a, b, c, k[3], 10, -1894986606);\n\t        c = ii(c, d, a, b, k[10], 15, -1051523);\n\t        b = ii(b, c, d, a, k[1], 21, -2054922799);\n\t        a = ii(a, b, c, d, k[8], 6, 1873313359);\n\t        d = ii(d, a, b, c, k[15], 10, -30611744);\n\t        c = ii(c, d, a, b, k[6], 15, -1560198380);\n\t        b = ii(b, c, d, a, k[13], 21, 1309151649);\n\t        a = ii(a, b, c, d, k[4], 6, -145523070);\n\t        d = ii(d, a, b, c, k[11], 10, -1120210379);\n\t        c = ii(c, d, a, b, k[2], 15, 718787259);\n\t        b = ii(b, c, d, a, k[9], 21, -343485551);\n\t\n\t        x[0] = add32(a, x[0]);\n\t        x[1] = add32(b, x[1]);\n\t        x[2] = add32(c, x[2]);\n\t        x[3] = add32(d, x[3]);\n\t    },\n\t\n\t    /* there needs to be support for Unicode here,\n\t       * unless we pretend that we can redefine the MD-5\n\t       * algorithm for multi-byte characters (perhaps\n\t       * by adding every four 16-bit characters and\n\t       * shortening the sum to 32 bits). Otherwise\n\t       * I suggest performing MD-5 as if every character\n\t       * was two bytes--e.g., 0040 0025 = @%--but then\n\t       * how will an ordinary MD-5 sum be matched?\n\t       * There is no way to standardize text to something\n\t       * like UTF-8 before transformation; speed cost is\n\t       * utterly prohibitive. The JavaScript standard\n\t       * itself needs to look at this: it should start\n\t       * providing access to strings as preformed UTF-8\n\t       * 8-bit unsigned value arrays.\n\t       */\n\t    md5blk = function (s) {\n\t        var md5blks = [],\n\t            i; /* Andy King said do it this way. */\n\t\n\t        for (i = 0; i < 64; i += 4) {\n\t            md5blks[i >> 2] = s.charCodeAt(i) + (s.charCodeAt(i + 1) << 8) + (s.charCodeAt(i + 2) << 16) + (s.charCodeAt(i + 3) << 24);\n\t        }\n\t        return md5blks;\n\t    },\n\t\n\t    md5blk_array = function (a) {\n\t        var md5blks = [],\n\t            i; /* Andy King said do it this way. */\n\t\n\t        for (i = 0; i < 64; i += 4) {\n\t            md5blks[i >> 2] = a[i] + (a[i + 1] << 8) + (a[i + 2] << 16) + (a[i + 3] << 24);\n\t        }\n\t        return md5blks;\n\t    },\n\t\n\t    md51 = function (s) {\n\t        var n = s.length,\n\t            state = [1732584193, -271733879, -1732584194, 271733878],\n\t            i,\n\t            length,\n\t            tail,\n\t            tmp,\n\t            lo,\n\t            hi;\n\t\n\t        for (i = 64; i <= n; i += 64) {\n\t            md5cycle(state, md5blk(s.substring(i - 64, i)));\n\t        }\n\t        s = s.substring(i - 64);\n\t        length = s.length;\n\t        tail = [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0];\n\t        for (i = 0; i < length; i += 1) {\n\t            tail[i >> 2] |= s.charCodeAt(i) << ((i % 4) << 3);\n\t        }\n\t        tail[i >> 2] |= 0x80 << ((i % 4) << 3);\n\t        if (i > 55) {\n\t            md5cycle(state, tail);\n\t            for (i = 0; i < 16; i += 1) {\n\t                tail[i] = 0;\n\t            }\n\t        }\n\t\n\t        // Beware that the final length might not fit in 32 bits so we take care of that\n\t        tmp = n * 8;\n\t        tmp = tmp.toString(16).match(/(.*?)(.{0,8})$/);\n\t        lo = parseInt(tmp[2], 16);\n\t        hi = parseInt(tmp[1], 16) || 0;\n\t\n\t        tail[14] = lo;\n\t        tail[15] = hi;\n\t\n\t        md5cycle(state, tail);\n\t        return state;\n\t    },\n\t\n\t    md51_array = function (a) {\n\t        var n = a.length,\n\t            state = [1732584193, -271733879, -1732584194, 271733878],\n\t            i,\n\t            length,\n\t            tail,\n\t            tmp,\n\t            lo,\n\t            hi;\n\t\n\t        for (i = 64; i <= n; i += 64) {\n\t            md5cycle(state, md5blk_array(a.subarray(i - 64, i)));\n\t        }\n\t\n\t        // Not sure if it is a bug, however IE10 will always produce a sub array of length 1\n\t        // containing the last element of the parent array if the sub array specified starts\n\t        // beyond the length of the parent array - weird.\n\t        // https://connect.microsoft.com/IE/feedback/details/771452/typed-array-subarray-issue\n\t        a = (i - 64) < n ? a.subarray(i - 64) : new Uint8Array(0);\n\t\n\t        length = a.length;\n\t        tail = [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0];\n\t        for (i = 0; i < length; i += 1) {\n\t            tail[i >> 2] |= a[i] << ((i % 4) << 3);\n\t        }\n\t\n\t        tail[i >> 2] |= 0x80 << ((i % 4) << 3);\n\t        if (i > 55) {\n\t            md5cycle(state, tail);\n\t            for (i = 0; i < 16; i += 1) {\n\t                tail[i] = 0;\n\t            }\n\t        }\n\t\n\t        // Beware that the final length might not fit in 32 bits so we take care of that\n\t        tmp = n * 8;\n\t        tmp = tmp.toString(16).match(/(.*?)(.{0,8})$/);\n\t        lo = parseInt(tmp[2], 16);\n\t        hi = parseInt(tmp[1], 16) || 0;\n\t\n\t        tail[14] = lo;\n\t        tail[15] = hi;\n\t\n\t        md5cycle(state, tail);\n\t\n\t        return state;\n\t    },\n\t\n\t    hex_chr = ['0', '1', '2', '3', '4', '5', '6', '7', '8', '9', 'a', 'b', 'c', 'd', 'e', 'f'],\n\t\n\t    rhex = function (n) {\n\t        var s = '',\n\t            j;\n\t        for (j = 0; j < 4; j += 1) {\n\t            s += hex_chr[(n >> (j * 8 + 4)) & 0x0F] + hex_chr[(n >> (j * 8)) & 0x0F];\n\t        }\n\t        return s;\n\t    },\n\t\n\t    hex = function (x) {\n\t        var i;\n\t        for (i = 0; i < x.length; i += 1) {\n\t            x[i] = rhex(x[i]);\n\t        }\n\t        return x.join('');\n\t    },\n\t\n\t    md5 = function (s) {\n\t        return hex(md51(s));\n\t    },\n\t\n\t\n\t\n\t    ////////////////////////////////////////////////////////////////////////////\n\t\n\t    /**\n\t     * SparkMD5 OOP implementation.\n\t     *\n\t     * Use this class to perform an incremental md5, otherwise use the\n\t     * static methods instead.\n\t     */\n\t    SparkMD5 = function () {\n\t        // call reset to init the instance\n\t        this.reset();\n\t    };\n\t\n\t\n\t    // In some cases the fast add32 function cannot be used..\n\t    if (md5('hello') !== '5d41402abc4b2a76b9719d911017c592') {\n\t        add32 = function (x, y) {\n\t            var lsw = (x & 0xFFFF) + (y & 0xFFFF),\n\t                msw = (x >> 16) + (y >> 16) + (lsw >> 16);\n\t            return (msw << 16) | (lsw & 0xFFFF);\n\t        };\n\t    }\n\t\n\t\n\t    /**\n\t     * Appends a string.\n\t     * A conversion will be applied if an utf8 string is detected.\n\t     *\n\t     * @param {String} str The string to be appended\n\t     *\n\t     * @return {SparkMD5} The instance itself\n\t     */\n\t    SparkMD5.prototype.append = function (str) {\n\t        // converts the string to utf8 bytes if necessary\n\t        if (/[\\u0080-\\uFFFF]/.test(str)) {\n\t            str = unescape(encodeURIComponent(str));\n\t        }\n\t\n\t        // then append as binary\n\t        this.appendBinary(str);\n\t\n\t        return this;\n\t    };\n\t\n\t    /**\n\t     * Appends a binary string.\n\t     *\n\t     * @param {String} contents The binary string to be appended\n\t     *\n\t     * @return {SparkMD5} The instance itself\n\t     */\n\t    SparkMD5.prototype.appendBinary = function (contents) {\n\t        this._buff += contents;\n\t        this._length += contents.length;\n\t\n\t        var length = this._buff.length,\n\t            i;\n\t\n\t        for (i = 64; i <= length; i += 64) {\n\t            md5cycle(this._state, md5blk(this._buff.substring(i - 64, i)));\n\t        }\n\t\n\t        this._buff = this._buff.substr(i - 64);\n\t\n\t        return this;\n\t    };\n\t\n\t    /**\n\t     * Finishes the incremental computation, reseting the internal state and\n\t     * returning the result.\n\t     * Use the raw parameter to obtain the raw result instead of the hex one.\n\t     *\n\t     * @param {Boolean} raw True to get the raw result, false to get the hex result\n\t     *\n\t     * @return {String|Array} The result\n\t     */\n\t    SparkMD5.prototype.end = function (raw) {\n\t        var buff = this._buff,\n\t            length = buff.length,\n\t            i,\n\t            tail = [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0],\n\t            ret;\n\t\n\t        for (i = 0; i < length; i += 1) {\n\t            tail[i >> 2] |= buff.charCodeAt(i) << ((i % 4) << 3);\n\t        }\n\t\n\t        this._finish(tail, length);\n\t        ret = !!raw ? this._state : hex(this._state);\n\t\n\t        this.reset();\n\t\n\t        return ret;\n\t    };\n\t\n\t    /**\n\t     * Finish the final calculation based on the tail.\n\t     *\n\t     * @param {Array}  tail   The tail (will be modified)\n\t     * @param {Number} length The length of the remaining buffer\n\t     */\n\t    SparkMD5.prototype._finish = function (tail, length) {\n\t        var i = length,\n\t            tmp,\n\t            lo,\n\t            hi;\n\t\n\t        tail[i >> 2] |= 0x80 << ((i % 4) << 3);\n\t        if (i > 55) {\n\t            md5cycle(this._state, tail);\n\t            for (i = 0; i < 16; i += 1) {\n\t                tail[i] = 0;\n\t            }\n\t        }\n\t\n\t        // Do the final computation based on the tail and length\n\t        // Beware that the final length may not fit in 32 bits so we take care of that\n\t        tmp = this._length * 8;\n\t        tmp = tmp.toString(16).match(/(.*?)(.{0,8})$/);\n\t        lo = parseInt(tmp[2], 16);\n\t        hi = parseInt(tmp[1], 16) || 0;\n\t\n\t        tail[14] = lo;\n\t        tail[15] = hi;\n\t        md5cycle(this._state, tail);\n\t    };\n\t\n\t    /**\n\t     * Resets the internal state of the computation.\n\t     *\n\t     * @return {SparkMD5} The instance itself\n\t     */\n\t    SparkMD5.prototype.reset = function () {\n\t        this._buff = \"\";\n\t        this._length = 0;\n\t        this._state = [1732584193, -271733879, -1732584194, 271733878];\n\t\n\t        return this;\n\t    };\n\t\n\t    /**\n\t     * Releases memory used by the incremental buffer and other aditional\n\t     * resources. If you plan to use the instance again, use reset instead.\n\t     */\n\t    SparkMD5.prototype.destroy = function () {\n\t        delete this._state;\n\t        delete this._buff;\n\t        delete this._length;\n\t    };\n\t\n\t\n\t    /**\n\t     * Performs the md5 hash on a string.\n\t     * A conversion will be applied if utf8 string is detected.\n\t     *\n\t     * @param {String}  str The string\n\t     * @param {Boolean} raw True to get the raw result, false to get the hex result\n\t     *\n\t     * @return {String|Array} The result\n\t     */\n\t    SparkMD5.hash = function (str, raw) {\n\t        // converts the string to utf8 bytes if necessary\n\t        if (/[\\u0080-\\uFFFF]/.test(str)) {\n\t            str = unescape(encodeURIComponent(str));\n\t        }\n\t\n\t        var hash = md51(str);\n\t\n\t        return !!raw ? hash : hex(hash);\n\t    };\n\t\n\t    /**\n\t     * Performs the md5 hash on a binary string.\n\t     *\n\t     * @param {String}  content The binary string\n\t     * @param {Boolean} raw     True to get the raw result, false to get the hex result\n\t     *\n\t     * @return {String|Array} The result\n\t     */\n\t    SparkMD5.hashBinary = function (content, raw) {\n\t        var hash = md51(content);\n\t\n\t        return !!raw ? hash : hex(hash);\n\t    };\n\t\n\t    /**\n\t     * SparkMD5 OOP implementation for array buffers.\n\t     *\n\t     * Use this class to perform an incremental md5 ONLY for array buffers.\n\t     */\n\t    SparkMD5.ArrayBuffer = function () {\n\t        // call reset to init the instance\n\t        this.reset();\n\t    };\n\t\n\t    ////////////////////////////////////////////////////////////////////////////\n\t\n\t    /**\n\t     * Appends an array buffer.\n\t     *\n\t     * @param {ArrayBuffer} arr The array to be appended\n\t     *\n\t     * @return {SparkMD5.ArrayBuffer} The instance itself\n\t     */\n\t    SparkMD5.ArrayBuffer.prototype.append = function (arr) {\n\t        // TODO: we could avoid the concatenation here but the algorithm would be more complex\n\t        //       if you find yourself needing extra performance, please make a PR.\n\t        var buff = this._concatArrayBuffer(this._buff, arr),\n\t            length = buff.length,\n\t            i;\n\t\n\t        this._length += arr.byteLength;\n\t\n\t        for (i = 64; i <= length; i += 64) {\n\t            md5cycle(this._state, md5blk_array(buff.subarray(i - 64, i)));\n\t        }\n\t\n\t        // Avoids IE10 weirdness (documented above)\n\t        this._buff = (i - 64) < length ? buff.subarray(i - 64) : new Uint8Array(0);\n\t\n\t        return this;\n\t    };\n\t\n\t    /**\n\t     * Finishes the incremental computation, reseting the internal state and\n\t     * returning the result.\n\t     * Use the raw parameter to obtain the raw result instead of the hex one.\n\t     *\n\t     * @param {Boolean} raw True to get the raw result, false to get the hex result\n\t     *\n\t     * @return {String|Array} The result\n\t     */\n\t    SparkMD5.ArrayBuffer.prototype.end = function (raw) {\n\t        var buff = this._buff,\n\t            length = buff.length,\n\t            tail = [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0],\n\t            i,\n\t            ret;\n\t\n\t        for (i = 0; i < length; i += 1) {\n\t            tail[i >> 2] |= buff[i] << ((i % 4) << 3);\n\t        }\n\t\n\t        this._finish(tail, length);\n\t        ret = !!raw ? this._state : hex(this._state);\n\t\n\t        this.reset();\n\t\n\t        return ret;\n\t    };\n\t\n\t    SparkMD5.ArrayBuffer.prototype._finish = SparkMD5.prototype._finish;\n\t\n\t    /**\n\t     * Resets the internal state of the computation.\n\t     *\n\t     * @return {SparkMD5.ArrayBuffer} The instance itself\n\t     */\n\t    SparkMD5.ArrayBuffer.prototype.reset = function () {\n\t        this._buff = new Uint8Array(0);\n\t        this._length = 0;\n\t        this._state = [1732584193, -271733879, -1732584194, 271733878];\n\t\n\t        return this;\n\t    };\n\t\n\t    /**\n\t     * Releases memory used by the incremental buffer and other aditional\n\t     * resources. If you plan to use the instance again, use reset instead.\n\t     */\n\t    SparkMD5.ArrayBuffer.prototype.destroy = SparkMD5.prototype.destroy;\n\t\n\t    /**\n\t     * Concats two array buffers, returning a new one.\n\t     *\n\t     * @param  {ArrayBuffer} first  The first array buffer\n\t     * @param  {ArrayBuffer} second The second array buffer\n\t     *\n\t     * @return {ArrayBuffer} The new array buffer\n\t     */\n\t    SparkMD5.ArrayBuffer.prototype._concatArrayBuffer = function (first, second) {\n\t        var firstLength = first.length,\n\t            result = new Uint8Array(firstLength + second.byteLength);\n\t\n\t        result.set(first);\n\t        result.set(new Uint8Array(second), firstLength);\n\t\n\t        return result;\n\t    };\n\t\n\t    /**\n\t     * Performs the md5 hash on an array buffer.\n\t     *\n\t     * @param {ArrayBuffer} arr The array buffer\n\t     * @param {Boolean}     raw True to get the raw result, false to get the hex result\n\t     *\n\t     * @return {String|Array} The result\n\t     */\n\t    SparkMD5.ArrayBuffer.hash = function (arr, raw) {\n\t        var hash = md51_array(new Uint8Array(arr));\n\t\n\t        return !!raw ? hash : hex(hash);\n\t    };\n\t\n\t    return SparkMD5;\n\t}));\n\n\n/***/ },\n/* 35 */\n/***/ function(module, exports, __webpack_require__) {\n\n\t'use strict';\n\t\n\tvar PouchPromise = __webpack_require__(89);\n\t\n\t// this is essentially the \"update sugar\" function from daleharvey/pouchdb#1388\n\t// the diffFun tells us what delta to apply to the doc.  it either returns\n\t// the doc, or false if it doesn't need to do an update after all\n\tfunction upsertInner(db, docId, diffFun) {\n\t  if (typeof docId !== 'string') {\n\t    return PouchPromise.reject(new Error('doc id is required'));\n\t  }\n\t\n\t  return db.get(docId).catch(function (err) {\n\t    /* istanbul ignore next */\n\t    if (err.status !== 404) {\n\t      throw err;\n\t    }\n\t    return {};\n\t  }).then(function (doc) {\n\t    // the user might change the _rev, so save it for posterity\n\t    var docRev = doc._rev;\n\t    var newDoc = diffFun(doc);\n\t\n\t    if (!newDoc) {\n\t      // if the diffFun returns falsy, we short-circuit as\n\t      // an optimization\n\t      return { updated: false, rev: docRev };\n\t    }\n\t\n\t    // users aren't allowed to modify these values,\n\t    // so reset them here\n\t    newDoc._id = docId;\n\t    newDoc._rev = docRev;\n\t    return tryAndPut(db, newDoc, diffFun);\n\t  });\n\t}\n\t\n\tfunction tryAndPut(db, doc, diffFun) {\n\t  return db.put(doc).then(function (res) {\n\t    return {\n\t      updated: true,\n\t      rev: res.rev\n\t    };\n\t  }, function (err) {\n\t    /* istanbul ignore next */\n\t    if (err.status !== 409) {\n\t      throw err;\n\t    }\n\t    return upsertInner(db, doc._id, diffFun);\n\t  });\n\t}\n\t\n\texports.upsert = function upsert(docId, diffFun, cb) {\n\t  var db = this;\n\t  var promise = upsertInner(db, docId, diffFun);\n\t  if (typeof cb !== 'function') {\n\t    return promise;\n\t  }\n\t  promise.then(function (resp) {\n\t    cb(null, resp);\n\t  }, cb);\n\t};\n\t\n\texports.putIfNotExists = function putIfNotExists(docId, doc, cb) {\n\t  var db = this;\n\t\n\t  if (typeof docId !== 'string') {\n\t    cb = doc;\n\t    doc = docId;\n\t    docId = doc._id;\n\t  }\n\t\n\t  var diffFun = function (existingDoc) {\n\t    if (existingDoc._rev) {\n\t      return false; // do nothing\n\t    }\n\t    return doc;\n\t  };\n\t\n\t  var promise = upsertInner(db, docId, diffFun);\n\t  if (typeof cb !== 'function') {\n\t    return promise;\n\t  }\n\t  promise.then(function (resp) {\n\t    cb(null, resp);\n\t  }, cb);\n\t};\n\t\n\t\n\t/* istanbul ignore next */\n\tif (typeof window !== 'undefined' && window.PouchDB) {\n\t  window.PouchDB.plugin(exports);\n\t}\n\n\n/***/ },\n/* 36 */\n/***/ function(module, exports) {\n\n\t'use strict';\n\t\n\tObject.defineProperty(exports, \"__esModule\", {\n\t  value: true\n\t});\n\t\n\tvar _createClass = function () { function defineProperties(target, props) { for (var i = 0; i < props.length; i++) { var descriptor = props[i]; descriptor.enumerable = descriptor.enumerable || false; descriptor.configurable = true; if (\"value\" in descriptor) descriptor.writable = true; Object.defineProperty(target, descriptor.key, descriptor); } } return function (Constructor, protoProps, staticProps) { if (protoProps) defineProperties(Constructor.prototype, protoProps); if (staticProps) defineProperties(Constructor, staticProps); return Constructor; }; }();\n\t\n\tfunction _classCallCheck(instance, Constructor) { if (!(instance instanceof Constructor)) { throw new TypeError(\"Cannot call a class as a function\"); } }\n\t\n\tvar LocalStorage = exports.LocalStorage = function () {\n\t  function LocalStorage(storage, prefix) {\n\t    _classCallCheck(this, LocalStorage);\n\t\n\t    if (!storage && typeof window !== 'undefined') {\n\t      storage = window.localStorage;\n\t    }\n\t    this.storage = storage;\n\t    this.prefix = prefix || 'cozy:oauth:';\n\t  }\n\t\n\t  _createClass(LocalStorage, [{\n\t    key: 'save',\n\t    value: function save(key, value) {\n\t      var _this = this;\n\t\n\t      return new Promise(function (resolve) {\n\t        _this.storage.setItem(_this.prefix + key, JSON.stringify(value));\n\t        resolve(value);\n\t      });\n\t    }\n\t  }, {\n\t    key: 'load',\n\t    value: function load(key) {\n\t      var _this2 = this;\n\t\n\t      return new Promise(function (resolve) {\n\t        var item = _this2.storage.getItem(_this2.prefix + key);\n\t        if (!item) {\n\t          resolve();\n\t        } else {\n\t          resolve(JSON.parse(item));\n\t        }\n\t      });\n\t    }\n\t  }, {\n\t    key: 'delete',\n\t    value: function _delete(key) {\n\t      var _this3 = this;\n\t\n\t      return new Promise(function (resolve) {\n\t        return resolve(_this3.storage.removeItem(_this3.prefix + key));\n\t      });\n\t    }\n\t  }, {\n\t    key: 'clear',\n\t    value: function clear() {\n\t      var _this4 = this;\n\t\n\t      return new Promise(function (resolve) {\n\t        var storage = _this4.storage;\n\t        for (var i = 0; i < storage.length; i++) {\n\t          var key = storage.key(i);\n\t          if (key.indexOf(_this4.prefix) === 0) {\n\t            storage.removeItem(key);\n\t          }\n\t        }\n\t        resolve();\n\t      });\n\t    }\n\t  }]);\n\t\n\t  return LocalStorage;\n\t}();\n\t\n\tvar MemoryStorage = exports.MemoryStorage = function () {\n\t  function MemoryStorage() {\n\t    _classCallCheck(this, MemoryStorage);\n\t\n\t    this.hash = Object.create(null);\n\t  }\n\t\n\t  _createClass(MemoryStorage, [{\n\t    key: 'save',\n\t    value: function save(key, value) {\n\t      this.hash[key] = value;\n\t      return Promise.resolve(value);\n\t    }\n\t  }, {\n\t    key: 'load',\n\t    value: function load(key) {\n\t      return Promise.resolve(this.hash[key]);\n\t    }\n\t  }, {\n\t    key: 'delete',\n\t    value: function _delete(key) {\n\t      var deleted = delete this.hash[key];\n\t      return Promise.resolve(deleted);\n\t    }\n\t  }, {\n\t    key: 'clear',\n\t    value: function clear() {\n\t      this.hash = Object.create(null);\n\t      return Promise.resolve();\n\t    }\n\t  }]);\n\n\t  return MemoryStorage;\n\t}();\n\n/***/ },\n/* 37 */\n/***/ function(module, exports) {\n\n\t'use strict';\n\t\n\tObject.defineProperty(exports, \"__esModule\", {\n\t  value: true\n\t});\n\t\n\tvar _createClass = function () { function defineProperties(target, props) { for (var i = 0; i < props.length; i++) { var descriptor = props[i]; descriptor.enumerable = descriptor.enumerable || false; descriptor.configurable = true; if (\"value\" in descriptor) descriptor.writable = true; Object.defineProperty(target, descriptor.key, descriptor); } } return function (Constructor, protoProps, staticProps) { if (protoProps) defineProperties(Constructor.prototype, protoProps); if (staticProps) defineProperties(Constructor, staticProps); return Constructor; }; }();\n\t\n\texports.getAppToken = getAppToken;\n\t\n\tfunction _classCallCheck(instance, Constructor) { if (!(instance instanceof Constructor)) { throw new TypeError(\"Cannot call a class as a function\"); } }\n\t\n\t/* global btoa */\n\tvar V2TOKEN_ABORT_TIMEOUT = 3000;\n\t\n\tfunction getAppToken() {\n\t  return new Promise(function (resolve, reject) {\n\t    if (typeof window === 'undefined') {\n\t      return reject(new Error('getV2Token should be used in browser'));\n\t    } else if (!window.parent) {\n\t      return reject(new Error('getV2Token should be used in iframe'));\n\t    } else if (!window.parent.postMessage) {\n\t      return reject(new Error('getV2Token should be used in modern browser'));\n\t    }\n\t    var origin = window.location.origin;\n\t    var intent = { action: 'getToken' };\n\t    var timeout = null;\n\t    var receiver = function receiver(event) {\n\t      var token = void 0;\n\t      try {\n\t        token = new AppToken({\n\t          appName: event.data.appName,\n\t          token: event.data.token\n\t        });\n\t      } catch (e) {\n\t        reject(e);\n\t        return;\n\t      }\n\t      window.removeEventListener('message', receiver);\n\t      clearTimeout(timeout);\n\t      resolve({ client: null, token: token });\n\t    };\n\t    window.addEventListener('message', receiver, false);\n\t    window.parent.postMessage(intent, origin);\n\t    timeout = setTimeout(function () {\n\t      reject(new Error('No response from parent iframe after 3s'));\n\t    }, V2TOKEN_ABORT_TIMEOUT);\n\t  });\n\t}\n\t\n\tvar AppToken = exports.AppToken = function () {\n\t  function AppToken(opts) {\n\t    _classCallCheck(this, AppToken);\n\t\n\t    this.appName = opts.appName || '';\n\t    this.token = opts.token || '';\n\t  }\n\t\n\t  _createClass(AppToken, [{\n\t    key: 'toAuthHeader',\n\t    value: function toAuthHeader() {\n\t      return 'Basic ' + btoa(this.appName + ':' + this.token);\n\t    }\n\t  }]);\n\n\t  return AppToken;\n\t}();\n\n/***/ },\n/* 38 */\n/***/ function(module, exports, __webpack_require__) {\n\n\t'use strict';\n\t\n\tObject.defineProperty(exports, \"__esModule\", {\n\t  value: true\n\t});\n\texports.create = create;\n\texports.find = find;\n\texports.findMany = findMany;\n\texports.findAll = findAll;\n\texports.changesFeed = changesFeed;\n\texports.update = update;\n\texports.updateAttributes = updateAttributes;\n\texports._delete = _delete;\n\t\n\tvar _utils = __webpack_require__(3);\n\t\n\tvar _doctypes = __webpack_require__(6);\n\t\n\tvar _fetch = __webpack_require__(1);\n\t\n\tvar NOREV = 'stack-v2-no-rev';\n\t\n\tfunction create(cozy, doctype, attributes) {\n\t  return cozy.isV2().then(function (isV2) {\n\t    doctype = (0, _doctypes.normalizeDoctype)(cozy, isV2, doctype);\n\t    if (isV2) {\n\t      attributes.docType = doctype;\n\t    }\n\t    var path = (0, _utils.createPath)(cozy, isV2, doctype, attributes._id);\n\t    var httpVerb = attributes._id ? 'PUT' : 'POST';\n\t    delete attributes._id;\n\t    return (0, _fetch.cozyFetchJSON)(cozy, httpVerb, path, attributes).then(function (resp) {\n\t      if (isV2) {\n\t        return find(cozy, doctype, resp._id);\n\t      } else {\n\t        return resp.data;\n\t      }\n\t    });\n\t  });\n\t}\n\t\n\tfunction find(cozy, doctype, id) {\n\t  return cozy.isV2().then(function (isV2) {\n\t    doctype = (0, _doctypes.normalizeDoctype)(cozy, isV2, doctype);\n\t\n\t    if (!id) {\n\t      return Promise.reject(new Error('Missing id parameter'));\n\t    }\n\t\n\t    var path = (0, _utils.createPath)(cozy, isV2, doctype, id);\n\t    return (0, _fetch.cozyFetchJSON)(cozy, 'GET', path).then(function (resp) {\n\t      if (isV2) {\n\t        return Object.assign(resp, { _rev: NOREV });\n\t      } else {\n\t        return resp;\n\t      }\n\t    });\n\t  });\n\t}\n\t\n\tfunction findMany(cozy, doctype, ids) {\n\t  if (!(ids instanceof Array)) {\n\t    return Promise.reject(new Error('Parameter ids must be a non-empty array'));\n\t  }\n\t  if (ids.length === 0) {\n\t    // So users don't need to be defensive regarding the array content.\n\t    // This should not hide issues in user code since the result will be an\n\t    // empty object anyway.\n\t    return Promise.resolve({});\n\t  }\n\t\n\t  return cozy.isV2().then(function (isV2) {\n\t    if (isV2) {\n\t      return Promise.reject(new Error('findMany is not available on v2'));\n\t    }\n\t\n\t    var path = (0, _utils.createPath)(cozy, isV2, doctype, '_all_docs', { include_docs: true });\n\t\n\t    return (0, _fetch.cozyFetchJSON)(cozy, 'POST', path, { keys: ids }).then(function (resp) {\n\t      var docs = {};\n\t\n\t      var _iteratorNormalCompletion = true;\n\t      var _didIteratorError = false;\n\t      var _iteratorError = undefined;\n\t\n\t      try {\n\t        for (var _iterator = resp.rows[Symbol.iterator](), _step; !(_iteratorNormalCompletion = (_step = _iterator.next()).done); _iteratorNormalCompletion = true) {\n\t          var row = _step.value;\n\t          var key = row.key,\n\t              doc = row.doc,\n\t              error = row.error;\n\t\n\t          docs[key] = error ? { error: error } : { doc: doc };\n\t        }\n\t      } catch (err) {\n\t        _didIteratorError = true;\n\t        _iteratorError = err;\n\t      } finally {\n\t        try {\n\t          if (!_iteratorNormalCompletion && _iterator.return) {\n\t            _iterator.return();\n\t          }\n\t        } finally {\n\t          if (_didIteratorError) {\n\t            throw _iteratorError;\n\t          }\n\t        }\n\t      }\n\t\n\t      return docs;\n\t    }).catch(function (error) {\n\t      if (error.status !== 404) return Promise.reject(error);\n\t\n\t      // When no doc was ever created and the database does not exist yet,\n\t      // the response will be a 404 error.\n\t      var docs = {};\n\t\n\t      var _iteratorNormalCompletion2 = true;\n\t      var _didIteratorError2 = false;\n\t      var _iteratorError2 = undefined;\n\t\n\t      try {\n\t        for (var _iterator2 = ids[Symbol.iterator](), _step2; !(_iteratorNormalCompletion2 = (_step2 = _iterator2.next()).done); _iteratorNormalCompletion2 = true) {\n\t          var id = _step2.value;\n\t\n\t          docs[id] = { error: error };\n\t        }\n\t      } catch (err) {\n\t        _didIteratorError2 = true;\n\t        _iteratorError2 = err;\n\t      } finally {\n\t        try {\n\t          if (!_iteratorNormalCompletion2 && _iterator2.return) {\n\t            _iterator2.return();\n\t          }\n\t        } finally {\n\t          if (_didIteratorError2) {\n\t            throw _iteratorError2;\n\t          }\n\t        }\n\t      }\n\t\n\t      return docs;\n\t    });\n\t  });\n\t}\n\t\n\tfunction findAll(cozy, doctype) {\n\t  return cozy.isV2().then(function (isV2) {\n\t    if (isV2) {\n\t      return Promise.reject(new Error('findAll is not available on v2'));\n\t    }\n\t\n\t    var path = (0, _utils.createPath)(cozy, isV2, doctype, '_all_docs', { include_docs: true });\n\t\n\t    return (0, _fetch.cozyFetchJSON)(cozy, 'POST', path, {}).then(function (resp) {\n\t      var docs = [];\n\t\n\t      var _iteratorNormalCompletion3 = true;\n\t      var _didIteratorError3 = false;\n\t      var _iteratorError3 = undefined;\n\t\n\t      try {\n\t        for (var _iterator3 = resp.rows[Symbol.iterator](), _step3; !(_iteratorNormalCompletion3 = (_step3 = _iterator3.next()).done); _iteratorNormalCompletion3 = true) {\n\t          var row = _step3.value;\n\t          var doc = row.doc;\n\t          // if not couchDB indexes\n\t\n\t          if (!doc._id.match(/_design\\//)) docs.push(doc);\n\t        }\n\t      } catch (err) {\n\t        _didIteratorError3 = true;\n\t        _iteratorError3 = err;\n\t      } finally {\n\t        try {\n\t          if (!_iteratorNormalCompletion3 && _iterator3.return) {\n\t            _iterator3.return();\n\t          }\n\t        } finally {\n\t          if (_didIteratorError3) {\n\t            throw _iteratorError3;\n\t          }\n\t        }\n\t      }\n\t\n\t      return docs;\n\t    }).catch(function (error) {\n\t      // the _all_docs endpoint returns a 404 error if no document with the given\n\t      // doctype exists.\n\t      if (error.status === 404) return [];\n\t      throw error;\n\t    });\n\t  });\n\t}\n\t\n\tfunction changesFeed(cozy, doctype, options) {\n\t  return cozy.isV2().then(function (isV2) {\n\t    doctype = (0, _doctypes.normalizeDoctype)(cozy, isV2, doctype);\n\t    var path = (0, _utils.createPath)(cozy, isV2, doctype, '_changes', options);\n\t    return (0, _fetch.cozyFetchJSON)(cozy, 'GET', path);\n\t  });\n\t}\n\t\n\tfunction update(cozy, doctype, doc, changes) {\n\t  return cozy.isV2().then(function (isV2) {\n\t    doctype = (0, _doctypes.normalizeDoctype)(cozy, isV2, doctype);\n\t    var _id = doc._id,\n\t        _rev = doc._rev;\n\t\n\t\n\t    if (!_id) {\n\t      return Promise.reject(new Error('Missing _id field in passed document'));\n\t    }\n\t\n\t    if (!isV2 && !_rev) {\n\t      return Promise.reject(new Error('Missing _rev field in passed document'));\n\t    }\n\t\n\t    if (isV2) {\n\t      changes = Object.assign({ _id: _id }, changes);\n\t    } else {\n\t      changes = Object.assign({ _id: _id, _rev: _rev }, changes);\n\t    }\n\t\n\t    var path = (0, _utils.createPath)(cozy, isV2, doctype, _id);\n\t    return (0, _fetch.cozyFetchJSON)(cozy, 'PUT', path, changes).then(function (resp) {\n\t      if (isV2) {\n\t        return find(cozy, doctype, _id);\n\t      } else {\n\t        return resp.data;\n\t      }\n\t    });\n\t  });\n\t}\n\t\n\tfunction updateAttributes(cozy, doctype, _id, changes) {\n\t  var tries = arguments.length > 4 && arguments[4] !== undefined ? arguments[4] : 3;\n\t\n\t  return cozy.isV2().then(function (isV2) {\n\t    doctype = (0, _doctypes.normalizeDoctype)(cozy, isV2, doctype);\n\t    return find(cozy, doctype, _id).then(function (doc) {\n\t      return update(cozy, doctype, doc, Object.assign({ _id: _id }, doc, changes));\n\t    }).catch(function (err) {\n\t      if (tries > 0) {\n\t        return updateAttributes(cozy, doctype, _id, changes, tries - 1);\n\t      } else {\n\t        throw err;\n\t      }\n\t    });\n\t  });\n\t}\n\t\n\tfunction _delete(cozy, doctype, doc) {\n\t  return cozy.isV2().then(function (isV2) {\n\t    doctype = (0, _doctypes.normalizeDoctype)(cozy, isV2, doctype);\n\t    var _id = doc._id,\n\t        _rev = doc._rev;\n\t\n\t\n\t    if (!_id) {\n\t      return Promise.reject(new Error('Missing _id field in passed document'));\n\t    }\n\t\n\t    if (!isV2 && !_rev) {\n\t      return Promise.reject(new Error('Missing _rev field in passed document'));\n\t    }\n\t\n\t    var query = isV2 ? null : { rev: _rev };\n\t    var path = (0, _utils.createPath)(cozy, isV2, doctype, _id, query);\n\t    return (0, _fetch.cozyFetchJSON)(cozy, 'DELETE', path).then(function (resp) {\n\t      if (isV2) {\n\t        return { id: _id, rev: NOREV };\n\t      } else {\n\t        return resp;\n\t      }\n\t    });\n\t  });\n\t}\n\n/***/ },\n/* 39 */\n/***/ function(module, exports, __webpack_require__) {\n\n\t'use strict';\n\t\n\tObject.defineProperty(exports, \"__esModule\", {\n\t  value: true\n\t});\n\texports.TRASH_DIR_ID = exports.ROOT_DIR_ID = undefined;\n\t\n\tvar _slicedToArray = function () { function sliceIterator(arr, i) { var _arr = []; var _n = true; var _d = false; var _e = undefined; try { for (var _i = arr[Symbol.iterator](), _s; !(_n = (_s = _i.next()).done); _n = true) { _arr.push(_s.value); if (i && _arr.length === i) break; } } catch (err) { _d = true; _e = err; } finally { try { if (!_n && _i[\"return\"]) _i[\"return\"](); } finally { if (_d) throw _e; } } return _arr; } return function (arr, i) { if (Array.isArray(arr)) { return arr; } else if (Symbol.iterator in Object(arr)) { return sliceIterator(arr, i); } else { throw new TypeError(\"Invalid attempt to destructure non-iterable instance\"); } }; }();\n\t\n\tvar _typeof = typeof Symbol === \"function\" && typeof Symbol.iterator === \"symbol\" ? function (obj) { return typeof obj; } : function (obj) { return obj && typeof Symbol === \"function\" && obj.constructor === Symbol && obj !== Symbol.prototype ? \"symbol\" : typeof obj; }; /* global Blob, File */\n\t\n\t\n\texports.create = create;\n\texports.createDirectory = createDirectory;\n\texports.createDirectoryByPath = createDirectoryByPath;\n\texports.updateById = updateById;\n\texports.updateAttributesById = updateAttributesById;\n\texports.updateAttributesByPath = updateAttributesByPath;\n\texports.trashById = trashById;\n\texports.statById = statById;\n\texports.statByPath = statByPath;\n\texports.downloadById = downloadById;\n\texports.downloadByPath = downloadByPath;\n\texports.getDownloadLinkByPath = getDownloadLinkByPath;\n\texports.getDownloadLinkById = getDownloadLinkById;\n\texports.getFilePath = getFilePath;\n\texports.getCollectionShareLink = getCollectionShareLink;\n\texports.getArchiveLinkByPaths = getArchiveLinkByPaths;\n\texports.getArchiveLinkByIds = getArchiveLinkByIds;\n\texports.listTrash = listTrash;\n\texports.clearTrash = clearTrash;\n\texports.restoreById = restoreById;\n\texports.destroyById = destroyById;\n\t\n\tvar _fetch = __webpack_require__(1);\n\t\n\tvar _jsonapi = __webpack_require__(18);\n\t\n\tvar _jsonapi2 = _interopRequireDefault(_jsonapi);\n\t\n\tvar _doctypes = __webpack_require__(6);\n\t\n\tfunction _interopRequireDefault(obj) { return obj && obj.__esModule ? obj : { default: obj }; }\n\t\n\t// global variables\n\tvar ROOT_DIR_ID = exports.ROOT_DIR_ID = 'io.cozy.files.root-dir';\n\tvar TRASH_DIR_ID = exports.TRASH_DIR_ID = 'io.cozy.files.trash-dir';\n\t\n\tvar contentTypeOctetStream = 'application/octet-stream';\n\t\n\tfunction sanitizeFileName(name) {\n\t  return name && name.trim();\n\t}\n\t\n\tfunction getFileTypeFromName(name) {\n\t  if (/\\.heic$/i.test(name)) return 'image/heic';else if (/\\.heif$/i.test(name)) return 'image/heif';else return null;\n\t}\n\t\n\tfunction doUpload(cozy, data, method, path, options) {\n\t  if (!data) {\n\t    throw new Error('missing data argument');\n\t  }\n\t\n\t  // transform any ArrayBufferView to ArrayBuffer\n\t  if (data.buffer && data.buffer instanceof ArrayBuffer) {\n\t    data = data.buffer;\n\t  }\n\t\n\t  var isBuffer = typeof ArrayBuffer !== 'undefined' && data instanceof ArrayBuffer;\n\t  var isFile = typeof File !== 'undefined' && data instanceof File;\n\t  var isBlob = typeof Blob !== 'undefined' && data instanceof Blob;\n\t  var isStream = data.readable === true && typeof data.pipe === 'function';\n\t  var isString = typeof data === 'string';\n\t\n\t  if (!isBuffer && !isFile && !isBlob && !isStream && !isString) {\n\t    throw new Error('invalid data type');\n\t  }\n\t\n\t  var _ref = options || {},\n\t      contentType = _ref.contentType,\n\t      contentLength = _ref.contentLength,\n\t      checksum = _ref.checksum,\n\t      lastModifiedDate = _ref.lastModifiedDate,\n\t      ifMatch = _ref.ifMatch;\n\t\n\t  if (!contentType) {\n\t    if (isBuffer) {\n\t      contentType = contentTypeOctetStream;\n\t    } else if (isFile) {\n\t      contentType = data.type || getFileTypeFromName(data.name.toLowerCase()) || contentTypeOctetStream;\n\t      if (!lastModifiedDate) {\n\t        lastModifiedDate = data.lastModifiedDate;\n\t      }\n\t    } else if (isBlob) {\n\t      contentType = data.type || contentTypeOctetStream;\n\t    } else if (isStream) {\n\t      contentType = contentTypeOctetStream;\n\t    } else if (typeof data === 'string') {\n\t      contentType = 'text/plain';\n\t    }\n\t  }\n\t\n\t  if (lastModifiedDate && typeof lastModifiedDate === 'string') {\n\t    lastModifiedDate = new Date(lastModifiedDate);\n\t  }\n\t\n\t  var headers = {\n\t    'Content-Type': contentType\n\t  };\n\t  if (contentLength) headers['Content-Length'] = String(contentLength);\n\t  if (checksum) headers['Content-MD5'] = checksum;\n\t  if (lastModifiedDate) headers['Date'] = lastModifiedDate.toGMTString();\n\t  if (ifMatch) headers['If-Match'] = ifMatch;\n\t\n\t  return (0, _fetch.cozyFetch)(cozy, path, {\n\t    method: method,\n\t    headers: headers,\n\t    body: data\n\t  }).then(function (res) {\n\t    var json = res.json();\n\t    if (!res.ok) {\n\t      return json.then(function (err) {\n\t        throw err;\n\t      });\n\t    } else {\n\t      return json.then(_jsonapi2.default);\n\t    }\n\t  });\n\t}\n\t\n\tfunction create(cozy, data, options) {\n\t  var _ref2 = options || {},\n\t      name = _ref2.name,\n\t      dirID = _ref2.dirID,\n\t      executable = _ref2.executable;\n\t\n\t  // handle case where data is a file and contains the name\n\t\n\t\n\t  if (!name && typeof data.name === 'string') {\n\t    name = data.name;\n\t  }\n\t\n\t  name = sanitizeFileName(name);\n\t\n\t  if (typeof name !== 'string' || name === '') {\n\t    throw new Error('missing name argument');\n\t  }\n\t\n\t  if (executable === undefined) {\n\t    executable = false;\n\t  }\n\t\n\t  var path = '/files/' + encodeURIComponent(dirID || '');\n\t  var query = '?Name=' + encodeURIComponent(name) + '&Type=file&Executable=' + executable;\n\t  return doUpload(cozy, data, 'POST', '' + path + query, options);\n\t}\n\t\n\tfunction createDirectory(cozy, options) {\n\t  var _ref3 = options || {},\n\t      name = _ref3.name,\n\t      dirID = _ref3.dirID,\n\t      lastModifiedDate = _ref3.lastModifiedDate;\n\t\n\t  name = sanitizeFileName(name);\n\t\n\t  if (typeof name !== 'string' || name === '') {\n\t    throw new Error('missing name argument');\n\t  }\n\t\n\t  if (lastModifiedDate && typeof lastModifiedDate === 'string') {\n\t    lastModifiedDate = new Date(lastModifiedDate);\n\t  }\n\t\n\t  var path = '/files/' + encodeURIComponent(dirID || '');\n\t  var query = '?Name=' + encodeURIComponent(name) + '&Type=directory';\n\t  return (0, _fetch.cozyFetchJSON)(cozy, 'POST', '' + path + query, undefined, {\n\t    headers: {\n\t      'Date': lastModifiedDate ? lastModifiedDate.toGMTString() : ''\n\t    }\n\t  });\n\t}\n\t\n\tfunction getDirectoryOrCreate(cozy, name, parentDirectory) {\n\t  if (parentDirectory && !parentDirectory.attributes) throw new Error('Malformed parent directory');\n\t\n\t  name = sanitizeFileName(name);\n\t\n\t  var path = (parentDirectory._id === ROOT_DIR_ID ? '' : parentDirectory.attributes.path) + '/' + name;\n\t\n\t  return cozy.files.statByPath(path || '/').catch(function (error) {\n\t    var parsedError = JSON.parse(error.message);\n\t    var errors = parsedError.errors;\n\t    if (errors && errors.length && errors[0].status === '404') {\n\t      return cozy.files.createDirectory({\n\t        name: name,\n\t        dirID: parentDirectory && parentDirectory._id\n\t      });\n\t    }\n\t\n\t    throw errors;\n\t  });\n\t}\n\t\n\tfunction createDirectoryByPath(cozy, path, offline) {\n\t  var parts = path.split('/').filter(function (part) {\n\t    return part !== '';\n\t  });\n\t\n\t  var rootDirectoryPromise = cozy.files.statById(ROOT_DIR_ID, offline);\n\t\n\t  return parts.length ? parts.reduce(function (parentDirectoryPromise, part) {\n\t    return parentDirectoryPromise.then(function (parentDirectory) {\n\t      return getDirectoryOrCreate(cozy, part, parentDirectory);\n\t    });\n\t  }, rootDirectoryPromise) : rootDirectoryPromise;\n\t}\n\t\n\tfunction updateById(cozy, id, data, options) {\n\t  return doUpload(cozy, data, 'PUT', '/files/' + encodeURIComponent(id), options);\n\t}\n\t\n\tfunction doUpdateAttributes(cozy, attrs, path, options) {\n\t  if (!attrs || (typeof attrs === 'undefined' ? 'undefined' : _typeof(attrs)) !== 'object') {\n\t    throw new Error('missing attrs argument');\n\t  }\n\t\n\t  var _ref4 = options || {},\n\t      ifMatch = _ref4.ifMatch;\n\t\n\t  var body = {\n\t    data: {\n\t      attributes: Object.assign({}, attrs, { name: sanitizeFileName(attrs.name) })\n\t    }\n\t  };\n\t  return (0, _fetch.cozyFetchJSON)(cozy, 'PATCH', path, body, {\n\t    headers: {\n\t      'If-Match': ifMatch || ''\n\t    }\n\t  });\n\t}\n\t\n\tfunction updateAttributesById(cozy, id, attrs, options) {\n\t  return doUpdateAttributes(cozy, attrs, '/files/' + encodeURIComponent(id), options);\n\t}\n\t\n\tfunction updateAttributesByPath(cozy, path, attrs, options) {\n\t  return doUpdateAttributes(cozy, attrs, '/files/metadata?Path=' + encodeURIComponent(path), options);\n\t}\n\t\n\tfunction trashById(cozy, id, options) {\n\t  if (typeof id !== 'string' || id === '') {\n\t    throw new Error('missing id argument');\n\t  }\n\t\n\t  var _ref5 = options || {},\n\t      ifMatch = _ref5.ifMatch;\n\t\n\t  return (0, _fetch.cozyFetchJSON)(cozy, 'DELETE', '/files/' + encodeURIComponent(id), undefined, {\n\t    headers: {\n\t      'If-Match': ifMatch || ''\n\t    }\n\t  });\n\t}\n\t\n\tfunction statById(cozy, id) {\n\t  var offline = arguments.length > 2 && arguments[2] !== undefined ? arguments[2] : true;\n\t  var options = arguments.length > 3 && arguments[3] !== undefined ? arguments[3] : {};\n\t\n\t  if (offline && cozy.offline.hasDatabase(_doctypes.DOCTYPE_FILES)) {\n\t    var db = cozy.offline.getDatabase(_doctypes.DOCTYPE_FILES);\n\t    return Promise.all([db.get(id), db.find(Object.assign({ selector: { 'dir_id': id } }, options))]).then(function (_ref6) {\n\t      var _ref7 = _slicedToArray(_ref6, 2),\n\t          doc = _ref7[0],\n\t          children = _ref7[1];\n\t\n\t      if (id === ROOT_DIR_ID) {\n\t        children.docs = children.docs.filter(function (doc) {\n\t          return doc._id !== TRASH_DIR_ID;\n\t        });\n\t      }\n\t      children = sortFiles(children.docs.map(function (doc) {\n\t        return addIsDir(toJsonApi(cozy, doc));\n\t      }));\n\t      return addIsDir(toJsonApi(cozy, doc, children));\n\t    });\n\t  }\n\t  var query = Object.keys(options).length === 0 ? '' : '?' + encodePageOptions(options);\n\t  return (0, _fetch.cozyFetchJSON)(cozy, 'GET', '/files/' + encodeURIComponent(id) + query).then(addIsDir);\n\t}\n\t\n\tfunction statByPath(cozy, path) {\n\t  return (0, _fetch.cozyFetchJSON)(cozy, 'GET', '/files/metadata?Path=' + encodeURIComponent(path)).then(addIsDir);\n\t}\n\t\n\tfunction downloadById(cozy, id) {\n\t  return (0, _fetch.cozyFetch)(cozy, '/files/download/' + encodeURIComponent(id));\n\t}\n\t\n\tfunction downloadByPath(cozy, path) {\n\t  return (0, _fetch.cozyFetch)(cozy, '/files/download?Path=' + encodeURIComponent(path));\n\t}\n\t\n\tfunction extractResponseLinkRelated(res) {\n\t  var href = res.links && res.links.related;\n\t  if (!href) throw new Error('No related link in server response');\n\t  return href;\n\t}\n\t\n\tfunction getDownloadLinkByPath(cozy, path) {\n\t  return (0, _fetch.cozyFetchJSON)(cozy, 'POST', '/files/downloads?Path=' + encodeURIComponent(path)).then(extractResponseLinkRelated);\n\t}\n\t\n\tfunction getDownloadLinkById(cozy, id) {\n\t  return (0, _fetch.cozyFetchJSON)(cozy, 'POST', '/files/downloads?Id=' + encodeURIComponent(id)).then(extractResponseLinkRelated);\n\t}\n\t\n\tfunction getFilePath(cozy) {\n\t  var file = arguments.length > 1 && arguments[1] !== undefined ? arguments[1] : {};\n\t  var folder = arguments[2];\n\t\n\t  if (!folder || !folder.attributes) {\n\t    throw Error('Folder should be valid with an attributes.path property');\n\t  }\n\t\n\t  var folderPath = folder.attributes.path.endsWith('/') ? folder.attributes.path : folder.attributes.path + '/';\n\t\n\t  return '' + folderPath + file.name;\n\t}\n\t\n\tfunction getCollectionShareLink(cozy, id, collectionType) {\n\t  if (!id) {\n\t    return Promise.reject(Error('An id should be provided to create a share link'));\n\t  }\n\t  return (0, _fetch.cozyFetchJSON)(cozy, 'POST', '/permissions?codes=email', {\n\t    data: {\n\t      type: 'io.cozy.permissions',\n\t      attributes: {\n\t        permissions: {\n\t          files: {\n\t            type: 'io.cozy.files',\n\t            verbs: ['GET'],\n\t            values: [id],\n\t            selector: 'referenced_by'\n\t          },\n\t          collection: {\n\t            type: collectionType,\n\t            verbs: ['GET'],\n\t            values: [id]\n\t          }\n\t        }\n\t      }\n\t    }\n\t  }).then(function (data) {\n\t    return { sharecode: 'sharecode=' + data.attributes.codes.email, id: 'id=' + id };\n\t  });\n\t}\n\t\n\tfunction getArchiveLinkByPaths(cozy, paths) {\n\t  var name = arguments.length > 2 && arguments[2] !== undefined ? arguments[2] : 'files';\n\t\n\t  var archive = {\n\t    type: 'io.cozy.archives',\n\t    attributes: {\n\t      name: name,\n\t      files: paths\n\t    }\n\t  };\n\t  return (0, _fetch.cozyFetchJSON)(cozy, 'POST', '/files/archive', { data: archive }).then(extractResponseLinkRelated);\n\t}\n\t\n\tfunction getArchiveLinkByIds(cozy, ids) {\n\t  var name = arguments.length > 2 && arguments[2] !== undefined ? arguments[2] : 'files';\n\t\n\t  var archive = {\n\t    type: 'io.cozy.archives',\n\t    attributes: {\n\t      name: name,\n\t      ids: ids\n\t    }\n\t  };\n\t  return (0, _fetch.cozyFetchJSON)(cozy, 'POST', '/files/archive', { data: archive }).then(extractResponseLinkRelated);\n\t}\n\t\n\tfunction listTrash(cozy) {\n\t  return (0, _fetch.cozyFetchJSON)(cozy, 'GET', '/files/trash');\n\t}\n\t\n\tfunction clearTrash(cozy) {\n\t  return (0, _fetch.cozyFetchJSON)(cozy, 'DELETE', '/files/trash');\n\t}\n\t\n\tfunction restoreById(cozy, id) {\n\t  return (0, _fetch.cozyFetchJSON)(cozy, 'POST', '/files/trash/' + encodeURIComponent(id));\n\t}\n\t\n\tfunction destroyById(cozy, id, options) {\n\t  var _ref8 = options || {},\n\t      ifMatch = _ref8.ifMatch;\n\t\n\t  return (0, _fetch.cozyFetchJSON)(cozy, 'DELETE', '/files/trash/' + encodeURIComponent(id), undefined, {\n\t    headers: {\n\t      'If-Match': ifMatch || ''\n\t    }\n\t  });\n\t}\n\t\n\tfunction addIsDir(obj) {\n\t  obj.isDir = obj.attributes.type === 'directory';\n\t  return obj;\n\t}\n\t\n\tfunction encodePageOptions(options) {\n\t  var opts = [];\n\t  for (var name in options) {\n\t    opts.push('page[' + encodeURIComponent(name) + ']=' + encodeURIComponent(options[name]));\n\t  }\n\t  return opts.join('&');\n\t}\n\t\n\tfunction toJsonApi(cozy, doc) {\n\t  var contents = arguments.length > 2 && arguments[2] !== undefined ? arguments[2] : [];\n\t\n\t  var clone = JSON.parse(JSON.stringify(doc));\n\t  delete clone._id;\n\t  delete clone._rev;\n\t  return {\n\t    _id: doc._id,\n\t    _rev: doc._rev,\n\t    _type: _doctypes.DOCTYPE_FILES,\n\t    attributes: clone,\n\t    relationships: {\n\t      contents: {\n\t        data: contents,\n\t        meta: {\n\t          count: contents.length\n\t        }\n\t      }\n\t    },\n\t    relations: function relations(name) {\n\t      if (name === 'contents') {\n\t        return contents;\n\t      }\n\t    }\n\t  };\n\t}\n\t\n\tfunction sortFiles(allFiles) {\n\t  var folders = allFiles.filter(function (f) {\n\t    return f.attributes.type === 'directory';\n\t  });\n\t  var files = allFiles.filter(function (f) {\n\t    return f.attributes.type !== 'directory';\n\t  });\n\t  var sort = function sort(files) {\n\t    return files.sort(function (a, b) {\n\t      return a.attributes.name.localeCompare(b.attributes.name);\n\t    });\n\t  };\n\t  return sort(folders).concat(sort(files));\n\t}\n\n/***/ },\n/* 40 */\n/***/ function(module, exports, __webpack_require__) {\n\n\t'use strict';\n\t\n\tvar _createClass = function () { function defineProperties(target, props) { for (var i = 0; i < props.length; i++) { var descriptor = props[i]; descriptor.enumerable = descriptor.enumerable || false; descriptor.configurable = true; if (\"value\" in descriptor) descriptor.writable = true; Object.defineProperty(target, descriptor.key, descriptor); } } return function (Constructor, protoProps, staticProps) { if (protoProps) defineProperties(Constructor.prototype, protoProps); if (staticProps) defineProperties(Constructor, staticProps); return Constructor; }; }(); /* global fetch URL */\n\t\n\t\n\t__webpack_require__(71);\n\t\n\tvar _utils = __webpack_require__(3);\n\t\n\tvar _auth_storage = __webpack_require__(36);\n\t\n\tvar _auth_v = __webpack_require__(37);\n\t\n\tvar _auth_v2 = __webpack_require__(9);\n\t\n\tvar auth = _interopRequireWildcard(_auth_v2);\n\t\n\tvar _data = __webpack_require__(38);\n\t\n\tvar data = _interopRequireWildcard(_data);\n\t\n\tvar _fetch = __webpack_require__(1);\n\t\n\tvar cozyFetch = _interopRequireWildcard(_fetch);\n\t\n\tvar _mango = __webpack_require__(43);\n\t\n\tvar mango = _interopRequireWildcard(_mango);\n\t\n\tvar _files = __webpack_require__(39);\n\t\n\tvar files = _interopRequireWildcard(_files);\n\t\n\tvar _intents = __webpack_require__(41);\n\t\n\tvar intents = _interopRequireWildcard(_intents);\n\t\n\tvar _jobs = __webpack_require__(42);\n\t\n\tvar jobs = _interopRequireWildcard(_jobs);\n\t\n\tvar _offline = __webpack_require__(44);\n\t\n\tvar offline = _interopRequireWildcard(_offline);\n\t\n\tvar _settings = __webpack_require__(46);\n\t\n\tvar settings = _interopRequireWildcard(_settings);\n\t\n\tvar _relations = __webpack_require__(45);\n\t\n\tvar relations = _interopRequireWildcard(_relations);\n\t\n\tfunction _interopRequireWildcard(obj) { if (obj && obj.__esModule) { return obj; } else { var newObj = {}; if (obj != null) { for (var key in obj) { if (Object.prototype.hasOwnProperty.call(obj, key)) newObj[key] = obj[key]; } } newObj.default = obj; return newObj; } }\n\t\n\tfunction _classCallCheck(instance, Constructor) { if (!(instance instanceof Constructor)) { throw new TypeError(\"Cannot call a class as a function\"); } }\n\t\n\tvar AppTokenV3 = auth.AppToken,\n\t    AccessTokenV3 = auth.AccessToken,\n\t    ClientV3 = auth.Client;\n\t\n\t\n\tvar AuthNone = 0;\n\tvar AuthRunning = 1;\n\tvar AuthError = 2;\n\tvar AuthOK = 3;\n\t\n\tvar defaultClientParams = {\n\t  softwareID: 'github.com/cozy/cozy-client-js'\n\t};\n\t\n\tvar dataProto = {\n\t  create: data.create,\n\t  find: data.find,\n\t  findMany: data.findMany,\n\t  findAll: data.findAll,\n\t  update: data.update,\n\t  delete: data._delete,\n\t  updateAttributes: data.updateAttributes,\n\t  changesFeed: data.changesFeed,\n\t  defineIndex: mango.defineIndex,\n\t  query: mango.query,\n\t  addReferencedFiles: relations.addReferencedFiles,\n\t  removeReferencedFiles: relations.removeReferencedFiles,\n\t  listReferencedFiles: relations.listReferencedFiles,\n\t  fetchReferencedFiles: relations.fetchReferencedFiles,\n\t  destroy: function destroy() {\n\t    (0, _utils.warn)('destroy is deprecated, use cozy.data.delete instead.');\n\t    return data._delete.apply(data, arguments);\n\t  }\n\t};\n\t\n\tvar authProto = {\n\t  client: auth.client,\n\t  registerClient: auth.registerClient,\n\t  updateClient: auth.updateClient,\n\t  unregisterClient: auth.unregisterClient,\n\t  getClient: auth.getClient,\n\t  getAuthCodeURL: auth.getAuthCodeURL,\n\t  getAccessToken: auth.getAccessToken,\n\t  refreshToken: auth.refreshToken\n\t};\n\t\n\tvar filesProto = {\n\t  create: files.create,\n\t  createDirectory: files.createDirectory,\n\t  createDirectoryByPath: files.createDirectoryByPath,\n\t  updateById: files.updateById,\n\t  updateAttributesById: files.updateAttributesById,\n\t  updateAttributesByPath: files.updateAttributesByPath,\n\t  trashById: files.trashById,\n\t  statById: files.statById,\n\t  statByPath: files.statByPath,\n\t  downloadById: files.downloadById,\n\t  downloadByPath: files.downloadByPath,\n\t  getDownloadLinkById: files.getDownloadLinkById,\n\t  getDownloadLink: files.getDownloadLinkByPath, // DEPRECATED, should be removed very soon\n\t  getDownloadLinkByPath: files.getDownloadLinkByPath,\n\t  getArchiveLink: function getArchiveLink() {\n\t    (0, _utils.warn)('getArchiveLink is deprecated, use cozy.files.getArchiveLinkByPaths instead.');\n\t    return files.getArchiveLinkByPaths.apply(files, arguments);\n\t  },\n\t  getArchiveLinkByPaths: files.getArchiveLinkByPaths,\n\t  getArchiveLinkByIds: files.getArchiveLinkByIds,\n\t  getFilePath: files.getFilePath,\n\t  getCollectionShareLink: files.getCollectionShareLink,\n\t  query: mango.queryFiles,\n\t  listTrash: files.listTrash,\n\t  clearTrash: files.clearTrash,\n\t  restoreById: files.restoreById,\n\t  destroyById: files.destroyById\n\t};\n\t\n\tvar intentsProto = {\n\t  create: intents.create,\n\t  createService: intents.createService,\n\t  getRedirectionURL: intents.getRedirectionURL,\n\t  redirect: intents.redirect\n\t};\n\t\n\tvar jobsProto = {\n\t  create: jobs.create,\n\t  count: jobs.count,\n\t  queued: jobs.queued\n\t};\n\t\n\tvar offlineProto = {\n\t  init: offline.init,\n\t  getDoctypes: offline.getDoctypes,\n\t  // database\n\t  hasDatabase: offline.hasDatabase,\n\t  getDatabase: offline.getDatabase,\n\t  createDatabase: offline.createDatabase,\n\t  destroyDatabase: offline.destroyDatabase,\n\t  destroyAllDatabase: offline.destroyAllDatabase,\n\t  // replication\n\t  hasReplication: offline.hasReplication,\n\t  replicateFromCozy: offline.replicateFromCozy,\n\t  stopReplication: offline.stopReplication,\n\t  stopAllReplication: offline.stopAllReplication,\n\t  // repeated replication\n\t  hasRepeatedReplication: offline.hasRepeatedReplication,\n\t  startRepeatedReplication: offline.startRepeatedReplication,\n\t  stopRepeatedReplication: offline.stopRepeatedReplication,\n\t  stopAllRepeatedReplication: offline.stopAllRepeatedReplication\n\t};\n\t\n\tvar settingsProto = {\n\t  diskUsage: settings.diskUsage,\n\t  changePassphrase: settings.changePassphrase,\n\t  getInstance: settings.getInstance,\n\t  updateInstance: settings.updateInstance,\n\t  getClients: settings.getClients,\n\t  deleteClientById: settings.deleteClientById,\n\t  updateLastSync: settings.updateLastSync\n\t};\n\t\n\tvar ensureHasReconnectParam = function ensureHasReconnectParam(_url) {\n\t  var url = new URL(_url);\n\t  if (url.searchParams && !url.searchParams.has('reconnect')) {\n\t    url.searchParams.append('reconnect', 1);\n\t  } else if (!url.search || url.search.indexOf('reconnect') === -1) {\n\t    // Some old navigators do not have the searchParams API\n\t    // and it is not polyfilled by babel-polyfill\n\t    url.search = url.search + '&reconnect=1';\n\t  }\n\t  return url.toString();\n\t};\n\t\n\tvar Client = function () {\n\t  function Client(options) {\n\t    _classCallCheck(this, Client);\n\t\n\t    this.data = {};\n\t    this.files = {};\n\t    this.intents = {};\n\t    this.jobs = {};\n\t    this.offline = {};\n\t    this.settings = {};\n\t    this.auth = {\n\t      Client: ClientV3,\n\t      AccessToken: AccessTokenV3,\n\t      AppToken: AppTokenV3,\n\t      AppTokenV2: _auth_v.AppToken,\n\t      LocalStorage: _auth_storage.LocalStorage,\n\t      MemoryStorage: _auth_storage.MemoryStorage\n\t    };\n\t    this._inited = false;\n\t    if (options) {\n\t      this.init(options);\n\t    }\n\t  }\n\t\n\t  _createClass(Client, [{\n\t    key: 'init',\n\t    value: function init() {\n\t      var options = arguments.length > 0 && arguments[0] !== undefined ? arguments[0] : {};\n\t\n\t      this._inited = true;\n\t      this._oauth = false; // is oauth activated or not\n\t      this._token = null; // application token\n\t      this._authstate = AuthNone;\n\t      this._authcreds = null;\n\t      this._storage = null;\n\t      this._version = options.version || null;\n\t      this._offline = null;\n\t\n\t      var token = options.token;\n\t      var oauth = options.oauth;\n\t      if (token && oauth) {\n\t        throw new Error('Cannot specify an application token with a oauth activated');\n\t      }\n\t\n\t      if (token) {\n\t        this._token = new AppTokenV3({ token: token });\n\t      } else if (oauth) {\n\t        this._oauth = true;\n\t        this._storage = oauth.storage;\n\t        this._clientParams = Object.assign({}, defaultClientParams, oauth.clientParams);\n\t        this._onRegistered = oauth.onRegistered || nopOnRegistered;\n\t      }\n\t\n\t      var url = options.cozyURL || '';\n\t      while (url[url.length - 1] === '/') {\n\t        url = url.slice(0, -1);\n\t      }\n\t\n\t      this._url = url;\n\t\n\t      this._invalidTokenErrorHandler = options.onInvalidTokenError !== undefined ? options.onInvalidTokenError : cozyFetch.handleInvalidTokenError;\n\t\n\t      var disablePromises = !!options.disablePromises;\n\t      addToProto(this, this.data, dataProto, disablePromises);\n\t      addToProto(this, this.auth, authProto, disablePromises);\n\t      addToProto(this, this.files, filesProto, disablePromises);\n\t      addToProto(this, this.intents, intentsProto, disablePromises);\n\t      addToProto(this, this.jobs, jobsProto, disablePromises);\n\t      addToProto(this, this.offline, offlineProto, disablePromises);\n\t      addToProto(this, this.settings, settingsProto, disablePromises);\n\t\n\t      if (options.offline) {\n\t        this.offline.init(options.offline);\n\t      }\n\t\n\t      // Exposing cozyFetchJSON to make some development easier. Should be temporary.\n\t      this.fetchJSON = function _fetchJSON() {\n\t        var args = [this].concat(Array.prototype.slice.call(arguments));\n\t        return cozyFetch.cozyFetchJSON.apply(this, args);\n\t      };\n\t    }\n\t  }, {\n\t    key: 'authorize',\n\t    value: function authorize() {\n\t      var _this = this;\n\t\n\t      var forceTokenRefresh = arguments.length > 0 && arguments[0] !== undefined ? arguments[0] : false;\n\t\n\t      var state = this._authstate;\n\t      if (state === AuthOK || state === AuthRunning) {\n\t        return this._authcreds;\n\t      }\n\t\n\t      this._authstate = AuthRunning;\n\t      this._authcreds = this.isV2().then(function (isV2) {\n\t        if (isV2 && _this._oauth) {\n\t          throw new Error('OAuth is not supported on the V2 stack');\n\t        }\n\t        if (_this._oauth) {\n\t          if (forceTokenRefresh && _this._clientParams.redirectURI) {\n\t            _this._clientParams.redirectURI = ensureHasReconnectParam(_this._clientParams.redirectURI);\n\t          }\n\t          return auth.oauthFlow(_this, _this._storage, _this._clientParams, _this._onRegistered, forceTokenRefresh);\n\t        }\n\t        // we expect to be on a client side application running in a browser\n\t        // with cookie-based authentication.\n\t        if (isV2) {\n\t          return (0, _auth_v.getAppToken)();\n\t        } else if (_this._token) {\n\t          return Promise.resolve({ client: null, token: _this._token });\n\t        } else {\n\t          throw new Error('Missing application token');\n\t        }\n\t      });\n\t\n\t      this._authcreds.then(function () {\n\t        _this._authstate = AuthOK;\n\t      }, function () {\n\t        _this._authstate = AuthError;\n\t      });\n\t\n\t      return this._authcreds;\n\t    }\n\t  }, {\n\t    key: 'saveCredentials',\n\t    value: function saveCredentials(client, token) {\n\t      var creds = { client: client, token: token };\n\t      if (!this._storage || this._authstate === AuthRunning) {\n\t        return Promise.resolve(creds);\n\t      }\n\t      this._storage.save(auth.CredsKey, creds);\n\t      this._authcreds = Promise.resolve(creds);\n\t      return this._authcreds;\n\t    }\n\t  }, {\n\t    key: 'fullpath',\n\t    value: function fullpath(path) {\n\t      var _this2 = this;\n\t\n\t      return this.isV2().then(function (isV2) {\n\t        var pathprefix = isV2 ? '/ds-api' : '';\n\t        return _this2._url + pathprefix + path;\n\t      });\n\t    }\n\t  }, {\n\t    key: 'isV2',\n\t    value: function isV2() {\n\t      var _this3 = this;\n\t\n\t      if (!this._version) {\n\t        return (0, _utils.retry)(function () {\n\t          return fetch(_this3._url + '/status/');\n\t        }, 3)().then(function (res) {\n\t          if (!res.ok) {\n\t            throw new Error('Could not fetch cozy status');\n\t          } else {\n\t            return res.json();\n\t          }\n\t        }).then(function (status) {\n\t          _this3._version = status.datasystem !== undefined ? 2 : 3;\n\t          return _this3.isV2();\n\t        });\n\t      }\n\t      return Promise.resolve(this._version === 2);\n\t    }\n\t  }]);\n\t\n\t  return Client;\n\t}();\n\t\n\tfunction nopOnRegistered() {\n\t  throw new Error('Missing onRegistered callback');\n\t}\n\t\n\tfunction protoify(context, fn) {\n\t  return function prototyped() {\n\t    for (var _len = arguments.length, args = Array(_len), _key = 0; _key < _len; _key++) {\n\t      args[_key] = arguments[_key];\n\t    }\n\t\n\t    return fn.apply(undefined, [context].concat(args));\n\t  };\n\t}\n\t\n\tfunction addToProto(ctx, obj, proto, disablePromises) {\n\t  for (var attr in proto) {\n\t    var fn = protoify(ctx, proto[attr]);\n\t    if (disablePromises) {\n\t      fn = (0, _utils.unpromiser)(fn);\n\t    }\n\t    obj[attr] = fn;\n\t  }\n\t}\n\t\n\tmodule.exports = new Client();\n\tObject.assign(module.exports, { Client: Client, LocalStorage: _auth_storage.LocalStorage, MemoryStorage: _auth_storage.MemoryStorage });\n\n/***/ },\n/* 41 */\n/***/ function(module, exports, __webpack_require__) {\n\n\t'use strict';\n\t\n\tObject.defineProperty(exports, \"__esModule\", {\n\t  value: true\n\t});\n\texports.redirect = exports.getRedirectionURL = undefined;\n\t\n\tvar _regenerator = __webpack_require__(47);\n\t\n\tvar _regenerator2 = _interopRequireDefault(_regenerator);\n\t\n\tvar _typeof = typeof Symbol === \"function\" && typeof Symbol.iterator === \"symbol\" ? function (obj) { return typeof obj; } : function (obj) { return obj && typeof Symbol === \"function\" && obj.constructor === Symbol && obj !== Symbol.prototype ? \"symbol\" : typeof obj; };\n\t\n\t// Redirect to an app able to handle the doctype\n\t// Redirections are more or less a hack of the intent API to retrieve an URL for\n\t// accessing a given doctype or a given document.\n\t// It needs to use a special action `REDIRECT`\n\tvar getRedirectionURL = exports.getRedirectionURL = function () {\n\t  var _ref = _asyncToGenerator( /*#__PURE__*/_regenerator2.default.mark(function _callee(cozy, type, data) {\n\t    var intent, service, baseURL, sanitizedURL;\n\t    return _regenerator2.default.wrap(function _callee$(_context) {\n\t      while (1) {\n\t        switch (_context.prev = _context.next) {\n\t          case 0:\n\t            if (!(!type && !data)) {\n\t              _context.next = 2;\n\t              break;\n\t            }\n\t\n\t            throw new Error('Cannot retrieve redirection, at least type or doc must be provided');\n\t\n\t          case 2:\n\t            _context.next = 4;\n\t            return create(cozy, 'REDIRECT', type, data);\n\t\n\t          case 4:\n\t            intent = _context.sent;\n\t            service = pickService(intent);\n\t\n\t            if (service) {\n\t              _context.next = 8;\n\t              break;\n\t            }\n\t\n\t            throw new Error('Unable to find a service');\n\t\n\t          case 8:\n\t\n\t            // Intents cannot be deleted now\n\t            // await deleteIntent(cozy, intent)\n\t\n\t            // ignore query string and intent id\n\t            baseURL = service.href.split('?')[0];\n\t            // FIXME: Handle the fact that the stack encode the '#' character in the URL\n\t\n\t            sanitizedURL = baseURL.replace('%23', '#');\n\t            return _context.abrupt('return', data ? buildRedirectionURL(sanitizedURL, data) : sanitizedURL);\n\t\n\t          case 11:\n\t          case 'end':\n\t            return _context.stop();\n\t        }\n\t      }\n\t    }, _callee, this);\n\t  }));\n\t\n\t  return function getRedirectionURL(_x3, _x4, _x5) {\n\t    return _ref.apply(this, arguments);\n\t  };\n\t}();\n\t\n\tvar redirect = exports.redirect = function () {\n\t  var _ref2 = _asyncToGenerator( /*#__PURE__*/_regenerator2.default.mark(function _callee2(cozy, type, doc) {\n\t    var redirectionURL;\n\t    return _regenerator2.default.wrap(function _callee2$(_context2) {\n\t      while (1) {\n\t        switch (_context2.prev = _context2.next) {\n\t          case 0:\n\t            if (window) {\n\t              _context2.next = 2;\n\t              break;\n\t            }\n\t\n\t            throw new Error('redirect() method can only be called in a browser');\n\t\n\t          case 2:\n\t            _context2.next = 4;\n\t            return getRedirectionURL(cozy, type, doc);\n\t\n\t          case 4:\n\t            redirectionURL = _context2.sent;\n\t\n\t            window.location.href = redirectionURL;\n\t\n\t          case 6:\n\t          case 'end':\n\t            return _context2.stop();\n\t        }\n\t      }\n\t    }, _callee2, this);\n\t  }));\n\t\n\t  return function redirect(_x6, _x7, _x8) {\n\t    return _ref2.apply(this, arguments);\n\t  };\n\t}();\n\t\n\texports.create = create;\n\texports.createService = createService;\n\t\n\tvar _fetch = __webpack_require__(1);\n\t\n\tfunction _interopRequireDefault(obj) { return obj && obj.__esModule ? obj : { default: obj }; }\n\t\n\tfunction _asyncToGenerator(fn) { return function () { var gen = fn.apply(this, arguments); return new Promise(function (resolve, reject) { function step(key, arg) { try { var info = gen[key](arg); var value = info.value; } catch (error) { reject(error); return; } if (info.done) { resolve(value); } else { return Promise.resolve(value).then(function (value) { step(\"next\", value); }, function (err) { step(\"throw\", err); }); } } return step(\"next\"); }); }; }\n\t\n\tvar intentClass = 'coz-intent';\n\t\n\t// helper to serialize/deserialize an error for/from postMessage\n\tvar errorSerializer = function () {\n\t  function mapErrorProperties(from, to) {\n\t    var result = Object.assign(to, from);\n\t    var nativeProperties = ['name', 'message'];\n\t    return nativeProperties.reduce(function (result, property) {\n\t      if (from[property]) {\n\t        to[property] = from[property];\n\t      }\n\t      return result;\n\t    }, result);\n\t  }\n\t  return {\n\t    serialize: function serialize(error) {\n\t      return mapErrorProperties(error, {});\n\t    },\n\t    deserialize: function deserialize(data) {\n\t      return mapErrorProperties(data, new Error(data.message));\n\t    }\n\t  };\n\t}();\n\t\n\t// inject iframe for service in given element\n\tfunction injectService(url, element, intent, data, onReadyCallback) {\n\t  var document = element.ownerDocument;\n\t  if (!document) throw new Error('Cannot retrieve document object from given element');\n\t\n\t  var window = document.defaultView;\n\t  if (!window) throw new Error('Cannot retrieve window object from document');\n\t\n\t  var iframe = document.createElement('iframe');\n\t  // if callback provided for when iframe is loaded\n\t  if (typeof onReadyCallback === 'function') iframe.onload = onReadyCallback;\n\t  // TODO: implement 'title' attribute\n\t  iframe.setAttribute('src', url);\n\t  iframe.classList.add(intentClass);\n\t  element.appendChild(iframe);\n\t  iframe.focus();\n\t\n\t  // Keeps only http://domain:port/\n\t  var serviceOrigin = url.split('/', 3).join('/');\n\t\n\t  return new Promise(function (resolve, reject) {\n\t    var handshaken = false;\n\t    var messageHandler = function messageHandler(event) {\n\t      if (event.origin !== serviceOrigin) return;\n\t\n\t      var eventType = event.data.type;\n\t      if (eventType === 'load') {\n\t        // Safari 9.1 (At least) send a MessageEvent when the iframe loads,\n\t        // making the handshake fails.\n\t        console.warn && console.warn('Cozy Client ignored MessageEvent having data.type `load`.');\n\t        return;\n\t      }\n\t\n\t      if (eventType === 'intent-' + intent._id + ':ready') {\n\t        handshaken = true;\n\t        return event.source.postMessage(data, event.origin);\n\t      }\n\t\n\t      if (handshaken && eventType === 'intent-' + intent._id + ':resize') {\n\t        ['width', 'height', 'maxWidth', 'maxHeight'].forEach(function (prop) {\n\t          if (event.data.transition) element.style.transition = event.data.transition;\n\t          if (event.data.dimensions[prop]) element.style[prop] = event.data.dimensions[prop] + 'px';\n\t        });\n\t\n\t        return true;\n\t      }\n\t\n\t      window.removeEventListener('message', messageHandler);\n\t      var removeIntentFrame = function removeIntentFrame() {\n\t        // check if the parent node has not been already removed from the DOM\n\t        iframe.parentNode && iframe.parentNode.removeChild(iframe);\n\t      };\n\t\n\t      if (handshaken && eventType === 'intent-' + intent._id + ':exposeFrameRemoval') {\n\t        return resolve({ removeIntentFrame: removeIntentFrame, doc: event.data.document });\n\t      }\n\t\n\t      removeIntentFrame();\n\t\n\t      if (eventType === 'intent-' + intent._id + ':error') {\n\t        return reject(errorSerializer.deserialize(event.data.error));\n\t      }\n\t\n\t      if (handshaken && eventType === 'intent-' + intent._id + ':cancel') {\n\t        return resolve(null);\n\t      }\n\t\n\t      if (handshaken && eventType === 'intent-' + intent._id + ':done') {\n\t        return resolve(event.data.document);\n\t      }\n\t\n\t      if (!handshaken) {\n\t        return reject(new Error('Unexpected handshake message from intent service'));\n\t      }\n\t\n\t      // We may be in a state where the messageHandler is still attached to then\n\t      // window, but will not be needed anymore. For example, the service failed\n\t      // before adding the `unload` listener, so no `intent:cancel` message has\n\t      // never been sent.\n\t      // So we simply ignore other messages, and this listener will stay here,\n\t      // waiting for a message which will never come, forever (almost).\n\t    };\n\t\n\t    window.addEventListener('message', messageHandler);\n\t  });\n\t}\n\t\n\tvar first = function first(arr) {\n\t  return arr && arr[0];\n\t};\n\t// In a far future, the user will have to pick the desired service from a list.\n\t// For now it's our job, an easy job as we arbitrary pick the first service of\n\t// the list.\n\tfunction pickService(intent, filterServices) {\n\t  var services = intent.attributes.services;\n\t  var filteredServices = filterServices ? (services || []).filter(filterServices) : services;\n\t  return first(filteredServices);\n\t}\n\t\n\tfunction create(cozy, action, type) {\n\t  var data = arguments.length > 3 && arguments[3] !== undefined ? arguments[3] : {};\n\t  var permissions = arguments.length > 4 && arguments[4] !== undefined ? arguments[4] : [];\n\t\n\t  if (!action) throw new Error('Misformed intent, \"action\" property must be provided');\n\t  if (!type) throw new Error('Misformed intent, \"type\" property must be provided');\n\t\n\t  var createPromise = (0, _fetch.cozyFetchJSON)(cozy, 'POST', '/intents', {\n\t    data: {\n\t      type: 'io.cozy.intents',\n\t      attributes: {\n\t        action: action,\n\t        type: type,\n\t        data: data,\n\t        permissions: permissions\n\t      }\n\t    }\n\t  });\n\t\n\t  createPromise.start = function (element, onReadyCallback) {\n\t    return createPromise.then(function (intent) {\n\t      var service = pickService(intent, data.filterServices);\n\t      var restData = Object.assign({}, data);\n\t      delete restData.filterServices;\n\t\n\t      if (!service) {\n\t        return Promise.reject(new Error('Unable to find a service'));\n\t      }\n\t\n\t      return injectService(service.href, element, intent, restData, onReadyCallback);\n\t    });\n\t  };\n\t\n\t  return createPromise;\n\t}\n\t\n\tfunction listenClientData(intent, window) {\n\t  return new Promise(function (resolve, reject) {\n\t    var messageEventListener = function messageEventListener(event) {\n\t      if (event.origin !== intent.attributes.client) return;\n\t\n\t      window.removeEventListener('message', messageEventListener);\n\t      resolve(event.data);\n\t    };\n\t\n\t    window.addEventListener('message', messageEventListener);\n\t    window.parent.postMessage({\n\t      type: 'intent-' + intent._id + ':ready'\n\t    }, intent.attributes.client);\n\t  });\n\t}\n\t\n\t// returns a service to communicate with intent client\n\tfunction createService(cozy, intentId, serviceWindow) {\n\t  serviceWindow = serviceWindow || typeof window !== 'undefined' && window;\n\t  if (!serviceWindow) throw new Error('Intent service should be used in browser');\n\t\n\t  intentId = intentId || serviceWindow.location.search.split('=')[1];\n\t  if (!intentId) throw new Error('Cannot retrieve intent from URL');\n\t\n\t  return (0, _fetch.cozyFetchJSON)(cozy, 'GET', '/intents/' + intentId).then(function (intent) {\n\t    var terminated = false;\n\t\n\t    var _terminate = function _terminate(message) {\n\t      if (terminated) throw new Error('Intent service has already been terminated');\n\t      terminated = true;\n\t      serviceWindow.parent.postMessage(message, intent.attributes.client);\n\t    };\n\t\n\t    var resizeClient = function resizeClient(dimensions, transitionProperty) {\n\t      if (terminated) throw new Error('Intent service has been terminated');\n\t\n\t      var message = {\n\t        type: 'intent-' + intent._id + ':resize',\n\t        // if a dom element is passed, calculate its size\n\t        dimensions: dimensions.element ? Object.assign({}, dimensions, {\n\t          maxHeight: dimensions.element.clientHeight,\n\t          maxWidth: dimensions.element.clientWidth\n\t        }) : dimensions,\n\t        transition: transitionProperty\n\t      };\n\t\n\t      serviceWindow.parent.postMessage(message, intent.attributes.client);\n\t    };\n\t\n\t    var cancel = function cancel() {\n\t      _terminate({ type: 'intent-' + intent._id + ':cancel' });\n\t    };\n\t\n\t    // Prevent unfulfilled client promises when this window unloads for a\n\t    // reason or another.\n\t    serviceWindow.addEventListener('unload', function () {\n\t      if (!terminated) cancel();\n\t    });\n\t\n\t    return listenClientData(intent, serviceWindow).then(function (data) {\n\t      return {\n\t        getData: function getData() {\n\t          return data;\n\t        },\n\t        getIntent: function getIntent() {\n\t          return intent;\n\t        },\n\t        terminate: function terminate(doc) {\n\t          var eventName = data && data.exposeIntentFrameRemoval ? 'exposeFrameRemoval' : 'done';\n\t          return _terminate({\n\t            type: 'intent-' + intent._id + ':' + eventName,\n\t            document: doc\n\t          });\n\t        },\n\t        throw: function _throw(error) {\n\t          return _terminate({\n\t            type: 'intent-' + intent._id + ':error',\n\t            error: errorSerializer.serialize(error)\n\t          });\n\t        },\n\t        resizeClient: resizeClient,\n\t        cancel: cancel\n\t      };\n\t    });\n\t  });\n\t}\n\t\n\tfunction isSerializable(value) {\n\t  return !['object', 'function'].includes(typeof value === 'undefined' ? 'undefined' : _typeof(value));\n\t}\n\t\n\tfunction buildRedirectionURL(url, data) {\n\t  var parameterStrings = Object.keys(data).filter(function (key) {\n\t    return isSerializable(data[key]);\n\t  }).map(function (key) {\n\t    return key + '=' + data[key];\n\t  });\n\t\n\t  return parameterStrings.length ? url + '?' + parameterStrings.join('&') : url;\n\t}\n\n/***/ },\n/* 42 */\n/***/ function(module, exports, __webpack_require__) {\n\n\t'use strict';\n\t\n\tObject.defineProperty(exports, \"__esModule\", {\n\t  value: true\n\t});\n\texports.count = count;\n\texports.queued = queued;\n\texports.create = create;\n\t\n\tvar _fetch = __webpack_require__(1);\n\t\n\tfunction count(cozy, workerType) {\n\t  return (0, _fetch.cozyFetchJSON)(cozy, 'GET', '/jobs/queue/' + workerType).then(function (data) {\n\t    return data.length;\n\t  });\n\t}\n\t\n\tfunction queued(cozy, workerType) {\n\t  return (0, _fetch.cozyFetchJSON)(cozy, 'GET', '/jobs/queue/' + workerType);\n\t}\n\t\n\tfunction create(cozy, workerType, args, options) {\n\t  return (0, _fetch.cozyFetchJSON)(cozy, 'POST', '/jobs/queue/' + workerType, {\n\t    data: {\n\t      type: 'io.cozy.jobs',\n\t      attributes: {\n\t        arguments: args || {},\n\t        options: options || {}\n\t      }\n\t    }\n\t  });\n\t}\n\n/***/ },\n/* 43 */\n/***/ function(module, exports, __webpack_require__) {\n\n\t'use strict';\n\t\n\tObject.defineProperty(exports, \"__esModule\", {\n\t  value: true\n\t});\n\t\n\tvar _slicedToArray = function () { function sliceIterator(arr, i) { var _arr = []; var _n = true; var _d = false; var _e = undefined; try { for (var _i = arr[Symbol.iterator](), _s; !(_n = (_s = _i.next()).done); _n = true) { _arr.push(_s.value); if (i && _arr.length === i) break; } } catch (err) { _d = true; _e = err; } finally { try { if (!_n && _i[\"return\"]) _i[\"return\"](); } finally { if (_d) throw _e; } } return _arr; } return function (arr, i) { if (Array.isArray(arr)) { return arr; } else if (Symbol.iterator in Object(arr)) { return sliceIterator(arr, i); } else { throw new TypeError(\"Invalid attempt to destructure non-iterable instance\"); } }; }();\n\t\n\tvar _typeof = typeof Symbol === \"function\" && typeof Symbol.iterator === \"symbol\" ? function (obj) { return typeof obj; } : function (obj) { return obj && typeof Symbol === \"function\" && obj.constructor === Symbol && obj !== Symbol.prototype ? \"symbol\" : typeof obj; };\n\t\n\texports.defineIndex = defineIndex;\n\texports.query = query;\n\texports.queryFiles = queryFiles;\n\texports.parseSelector = parseSelector;\n\texports.normalizeSelector = normalizeSelector;\n\texports.makeMapReduceQuery = makeMapReduceQuery;\n\t\n\tvar _utils = __webpack_require__(3);\n\t\n\tvar _doctypes = __webpack_require__(6);\n\t\n\tvar _fetch = __webpack_require__(1);\n\t\n\tfunction _defineProperty(obj, key, value) { if (key in obj) { Object.defineProperty(obj, key, { value: value, enumerable: true, configurable: true, writable: true }); } else { obj[key] = value; } return obj; }\n\t\n\tfunction defineIndex(cozy, doctype, fields) {\n\t  return cozy.isV2().then(function (isV2) {\n\t    doctype = (0, _doctypes.normalizeDoctype)(cozy, isV2, doctype);\n\t    if (!Array.isArray(fields) || fields.length === 0) {\n\t      throw new Error('defineIndex fields should be a non-empty array');\n\t    }\n\t    if (isV2) {\n\t      return defineIndexV2(cozy, doctype, fields);\n\t    } else {\n\t      return defineIndexV3(cozy, doctype, fields);\n\t    }\n\t  });\n\t}\n\t\n\tfunction query(cozy, indexRef, options) {\n\t  return cozy.isV2().then(function (isV2) {\n\t    if (!indexRef) {\n\t      throw new Error('query should be passed the indexRef');\n\t    }\n\t    if (isV2) {\n\t      return queryV2(cozy, indexRef, options);\n\t    } else {\n\t      return queryV3(cozy, indexRef, options);\n\t    }\n\t  });\n\t}\n\t\n\tfunction queryFiles(cozy, indexRef, options) {\n\t  var opts = getV3Options(indexRef, options);\n\t  return (0, _fetch.cozyFetchRawJSON)(cozy, 'POST', '/files/_find', opts).then(function (response) {\n\t    return options.wholeResponse ? response : response.docs;\n\t  });\n\t}\n\t\n\t// Internals\n\t\n\tvar VALUEOPERATORS = ['$eq', '$gt', '$gte', '$lt', '$lte'];\n\tvar LOGICOPERATORS = ['$or', '$and', '$not'];\n\t\n\t/* eslint-disable */\n\tvar MAP_TEMPLATE = function (doc) {\n\t  if (doc.docType.toLowerCase() === 'DOCTYPEPLACEHOLDER') {\n\t    emit(FIELDSPLACEHOLDER, doc);\n\t  }\n\t}.toString().replace(/ /g, '').replace(/\\n/g, '');\n\tvar COUCHDB_INFINITY = { '\\uFFFF': '\\uFFFF' };\n\tvar COUCHDB_LOWEST = null;\n\t/* eslint-enable */\n\t\n\t// defineIndexV2 is equivalent to defineIndex but only works for V2.\n\t// It transforms the index fields into a map reduce view.\n\tfunction defineIndexV2(cozy, doctype, fields) {\n\t  var indexName = 'by' + fields.map(capitalize).join('');\n\t  var indexDefinition = { map: makeMapFunction(doctype, fields), reduce: '_count' };\n\t  var path = '/request/' + doctype + '/' + indexName + '/';\n\t  return (0, _fetch.cozyFetchJSON)(cozy, 'PUT', path, indexDefinition).then(function () {\n\t    return { doctype: doctype, type: 'mapreduce', name: indexName, fields: fields };\n\t  });\n\t}\n\t\n\tfunction defineIndexV3(cozy, doctype, fields) {\n\t  var path = (0, _utils.createPath)(cozy, false, doctype, '_index');\n\t  var indexDefinition = { 'index': { fields: fields } };\n\t  return (0, _fetch.cozyFetchJSON)(cozy, 'POST', path, indexDefinition).then(function (response) {\n\t    var indexResult = { doctype: doctype, type: 'mango', name: response.id, fields: fields };\n\t\n\t    if (response.result === 'exists') return indexResult;\n\t\n\t    // indexes might not be usable right after being created; so we delay the resolving until they are\n\t    var selector = {};\n\t    selector[fields[0]] = { '$gt': null };\n\t\n\t    var opts = getV3Options(indexResult, { 'selector': selector });\n\t    var path = (0, _utils.createPath)(cozy, false, indexResult.doctype, '_find');\n\t    return (0, _fetch.cozyFetchJSON)(cozy, 'POST', path, opts).then(function () {\n\t      return indexResult;\n\t    }).catch(function () {\n\t      // one retry\n\t      return (0, _utils.sleep)(1000).then(function () {\n\t        return (0, _fetch.cozyFetchJSON)(cozy, 'POST', path, opts);\n\t      }).then(function () {\n\t        return indexResult;\n\t      }).catch(function () {\n\t        return (0, _utils.sleep)(500).then(function () {\n\t          return indexResult;\n\t        });\n\t      });\n\t    });\n\t  });\n\t}\n\t\n\t// queryV2 is equivalent to query but only works for V2.\n\t// It transforms the query into a _views call using makeMapReduceQuery\n\tfunction queryV2(cozy, indexRef, options) {\n\t  if (indexRef.type !== 'mapreduce') {\n\t    throw new Error('query indexRef should be the return value of defineIndexV2');\n\t  }\n\t  if (options.fields) {\n\t    (0, _utils.warn)('query fields will be ignored on v2');\n\t  }\n\t\n\t  var path = '/request/' + indexRef.doctype + '/' + indexRef.name + '/';\n\t  var opts = makeMapReduceQuery(indexRef, options);\n\t  return (0, _fetch.cozyFetchJSON)(cozy, 'POST', path, opts).then(function (response) {\n\t    return response.map(function (r) {\n\t      return r.value;\n\t    });\n\t  });\n\t}\n\t\n\t// queryV3 is equivalent to query but only works for V3\n\tfunction queryV3(cozy, indexRef, options) {\n\t  var opts = getV3Options(indexRef, options);\n\t\n\t  var path = (0, _utils.createPath)(cozy, false, indexRef.doctype, '_find');\n\t  return (0, _fetch.cozyFetchJSON)(cozy, 'POST', path, opts).then(function (response) {\n\t    return options.wholeResponse ? response : response.docs;\n\t  });\n\t}\n\t\n\tfunction getV3Options(indexRef, options) {\n\t  if (indexRef.type !== 'mango') {\n\t    throw new Error('indexRef should be the return value of defineIndexV3');\n\t  }\n\t\n\t  var opts = {\n\t    use_index: indexRef.name,\n\t    fields: options.fields,\n\t    selector: options.selector,\n\t    limit: options.limit,\n\t    skip: options.skip,\n\t    since: options.since,\n\t    sort: options.sort\n\t  };\n\t\n\t  if (options.descending) {\n\t    opts.sort = indexRef.fields.map(function (f) {\n\t      return _defineProperty({}, f, 'desc');\n\t    });\n\t  }\n\t\n\t  return opts;\n\t}\n\t\n\t// misc\n\tfunction capitalize(name) {\n\t  return name.charAt(0).toUpperCase() + name.slice(1);\n\t}\n\t\n\tfunction makeMapFunction(doctype, fields) {\n\t  fields = '[' + fields.map(function (name) {\n\t    return 'doc.' + name;\n\t  }).join(',') + ']';\n\t\n\t  return MAP_TEMPLATE.replace('DOCTYPEPLACEHOLDER', doctype.toLowerCase()).replace('FIELDSPLACEHOLDER', fields);\n\t}\n\t\n\t// parseSelector takes a mango selector and returns it as an array of filter\n\t// a filter is [path, operator, value] array\n\t// a path is an array of field names\n\t// This function is only exported so it can be unit tested.\n\t// Example :\n\t// parseSelector({\"test\":{\"deep\": {\"$gt\": 3}}})\n\t// [[['test', 'deep'], '$gt', 3 ]]\n\tfunction parseSelector(selector) {\n\t  var path = arguments.length > 1 && arguments[1] !== undefined ? arguments[1] : [];\n\t  var operator = arguments.length > 2 && arguments[2] !== undefined ? arguments[2] : '$eq';\n\t\n\t  if ((typeof selector === 'undefined' ? 'undefined' : _typeof(selector)) !== 'object') {\n\t    return [[path, operator, selector]];\n\t  }\n\t\n\t  var keys = Object.keys(selector);\n\t  if (keys.length === 0) {\n\t    throw new Error('empty selector');\n\t  } else {\n\t    return keys.reduce(function (acc, k) {\n\t      if (LOGICOPERATORS.indexOf(k) !== -1) {\n\t        throw new Error('cozy-client-js does not support mango logic ops');\n\t      } else if (VALUEOPERATORS.indexOf(k) !== -1) {\n\t        return acc.concat(parseSelector(selector[k], path, k));\n\t      } else {\n\t        return acc.concat(parseSelector(selector[k], path.concat(k), '$eq'));\n\t      }\n\t    }, []);\n\t  }\n\t}\n\t\n\t// normalizeSelector takes a mango selector and returns it as an object\n\t// normalized.\n\t// This function is only exported so it can be unit tested.\n\t// Example :\n\t// parseSelector({\"test\":{\"deep\": {\"$gt\": 3}}})\n\t// {\"test.deep\": {\"$gt\": 3}}\n\tfunction normalizeSelector(selector) {\n\t  var filters = parseSelector(selector);\n\t  return filters.reduce(function (acc, filter) {\n\t    var _filter = _slicedToArray(filter, 3),\n\t        path = _filter[0],\n\t        op = _filter[1],\n\t        value = _filter[2];\n\t\n\t    var field = path.join('.');\n\t    acc[field] = acc[field] || {};\n\t    acc[field][op] = value;\n\t    return acc;\n\t  }, {});\n\t}\n\t\n\t// applySelector takes the normalized selector for the current field\n\t// and append the proper values to opts.startkey, opts.endkey\n\tfunction applySelector(selector, opts) {\n\t  var value = selector['$eq'];\n\t  var lower = COUCHDB_LOWEST;\n\t  var upper = COUCHDB_INFINITY;\n\t  var inclusiveEnd = void 0;\n\t\n\t  if (value) {\n\t    opts.startkey.push(value);\n\t    opts.endkey.push(value);\n\t    return false;\n\t  }\n\t\n\t  value = selector['$gt'];\n\t  if (value) {\n\t    throw new Error('operator $gt (strict greater than) not supported');\n\t  }\n\t\n\t  value = selector['$gte'];\n\t  if (value) {\n\t    lower = value;\n\t  }\n\t\n\t  value = selector['$lte'];\n\t  if (value) {\n\t    upper = value;\n\t    inclusiveEnd = true;\n\t  }\n\t\n\t  value = selector['$lt'];\n\t  if (value) {\n\t    upper = value;\n\t    inclusiveEnd = false;\n\t  }\n\t\n\t  opts.startkey.push(lower);\n\t  opts.endkey.push(upper);\n\t  if (inclusiveEnd !== undefined) opts.inclusive_end = inclusiveEnd;\n\t  return true;\n\t}\n\t\n\t// makeMapReduceQuery takes a mango query and generate _views call parameters\n\t// to obtain same results depending on fields in the passed indexRef.\n\tfunction makeMapReduceQuery(indexRef, query) {\n\t  var mrquery = {\n\t    startkey: [],\n\t    endkey: [],\n\t    reduce: false\n\t  };\n\t  var firstFreeValueField = null;\n\t  var normalizedSelector = normalizeSelector(query.selector);\n\t\n\t  indexRef.fields.forEach(function (field) {\n\t    var selector = normalizedSelector[field];\n\t\n\t    if (selector && firstFreeValueField != null) {\n\t      throw new Error('Selector on field ' + field + ', but not on ' + firstFreeValueField + ' which is higher in index fields.');\n\t    } else if (selector) {\n\t      selector.used = true;\n\t      var isFreeValue = applySelector(selector, mrquery);\n\t      if (isFreeValue) firstFreeValueField = field;\n\t    } else if (firstFreeValueField == null) {\n\t      firstFreeValueField = field;\n\t      mrquery.endkey.push(COUCHDB_INFINITY);\n\t    }\n\t  });\n\t\n\t  Object.keys(normalizedSelector).forEach(function (field) {\n\t    if (!normalizedSelector[field].used) {\n\t      throw new Error('Cant apply selector on ' + field + ', it is not in index');\n\t    }\n\t  });\n\t\n\t  if (query.descending) {\n\t    mrquery = {\n\t      descending: true,\n\t      reduce: false,\n\t      startkey: mrquery.endkey,\n\t      endkey: mrquery.startkey,\n\t      inclusive_end: mrquery.inclusive_end\n\t    };\n\t  }\n\t\n\t  return mrquery;\n\t}\n\n/***/ },\n/* 44 */\n/***/ function(module, exports, __webpack_require__) {\n\n\t'use strict';\n\t\n\tObject.defineProperty(exports, \"__esModule\", {\n\t  value: true\n\t});\n\texports.replicationOfflineError = undefined;\n\texports.init = init;\n\texports.getDoctypes = getDoctypes;\n\texports.hasDatabase = hasDatabase;\n\texports.getDatabase = getDatabase;\n\texports.setDatabase = setDatabase;\n\texports.createDatabase = createDatabase;\n\texports.destroyDatabase = destroyDatabase;\n\texports.destroyAllDatabase = destroyAllDatabase;\n\texports.hasReplication = hasReplication;\n\texports.replicateFromCozy = replicateFromCozy;\n\texports.stopReplication = stopReplication;\n\texports.stopAllReplication = stopAllReplication;\n\texports.hasRepeatedReplication = hasRepeatedReplication;\n\texports.startRepeatedReplication = startRepeatedReplication;\n\texports.stopRepeatedReplication = stopRepeatedReplication;\n\texports.stopAllRepeatedReplication = stopAllRepeatedReplication;\n\t\n\tvar _doctypes = __webpack_require__(6);\n\t\n\tvar _auth_v = __webpack_require__(9);\n\t\n\tvar _utils = __webpack_require__(3);\n\t\n\tvar _pouchdb = __webpack_require__(90);\n\t\n\tvar _pouchdb2 = _interopRequireDefault(_pouchdb);\n\t\n\tvar _pouchdbFind = __webpack_require__(88);\n\t\n\tvar _pouchdbFind2 = _interopRequireDefault(_pouchdbFind);\n\t\n\tfunction _interopRequireDefault(obj) { return obj && obj.__esModule ? obj : { default: obj }; }\n\t\n\tvar replicationOfflineError = exports.replicationOfflineError = 'Replication abort, your device is actually offline.'; /* global pouchdbAdapterCordovaSqlite */\n\t\n\t\n\tvar pluginLoaded = false;\n\t\n\t/*\n\t  For each doctype we have some parameters:\n\t  cozy._offline[doctype] = {\n\t    database: pouchdb database\n\t    replication: the pouchdb replication\n\t    replicationPromise: promise of replication\n\t    interval: repeated replication interval\n\t  }\n\t*/\n\t\n\tfunction init(cozy, _ref) {\n\t  var _ref$options = _ref.options,\n\t      options = _ref$options === undefined ? {} : _ref$options,\n\t      _ref$doctypes = _ref.doctypes,\n\t      doctypes = _ref$doctypes === undefined ? [] : _ref$doctypes;\n\t  var _iteratorNormalCompletion = true;\n\t  var _didIteratorError = false;\n\t  var _iteratorError = undefined;\n\t\n\t  try {\n\t    for (var _iterator = doctypes[Symbol.iterator](), _step; !(_iteratorNormalCompletion = (_step = _iterator.next()).done); _iteratorNormalCompletion = true) {\n\t      var doctype = _step.value;\n\t\n\t      createDatabase(cozy, doctype, options);\n\t    }\n\t  } catch (err) {\n\t    _didIteratorError = true;\n\t    _iteratorError = err;\n\t  } finally {\n\t    try {\n\t      if (!_iteratorNormalCompletion && _iterator.return) {\n\t        _iterator.return();\n\t      }\n\t    } finally {\n\t      if (_didIteratorError) {\n\t        throw _iteratorError;\n\t      }\n\t    }\n\t  }\n\t}\n\t\n\t// helper\n\t\n\tfunction getInfo(cozy, doctype) {\n\t  cozy._offline = cozy._offline || [];\n\t  cozy._offline[doctype] = cozy._offline[doctype] || {};\n\t  return cozy._offline[doctype];\n\t}\n\t\n\tfunction getDoctypes(cozy) {\n\t  cozy._offline = cozy._offline || [];\n\t  return Object.keys(cozy._offline);\n\t}\n\t\n\t//\n\t// DATABASE\n\t//\n\t\n\tfunction hasDatabase(cozy, doctype) {\n\t  return getDatabase(cozy, doctype) !== undefined;\n\t}\n\t\n\tfunction getDatabase(cozy, doctype) {\n\t  return getInfo(cozy, doctype).database;\n\t}\n\t\n\tfunction setDatabase(cozy, doctype, database) {\n\t  cozy._offline[doctype].database = database;\n\t  return getDatabase(cozy, doctype);\n\t}\n\t\n\tfunction createDatabase(cozy, doctype) {\n\t  var options = arguments.length > 2 && arguments[2] !== undefined ? arguments[2] : {};\n\t\n\t  if (!pluginLoaded) {\n\t    _pouchdb2.default.plugin(_pouchdbFind2.default);\n\t    if (typeof pouchdbAdapterCordovaSqlite !== 'undefined') _pouchdb2.default.plugin(pouchdbAdapterCordovaSqlite);\n\t    pluginLoaded = true;\n\t  }\n\t\n\t  if (hasDatabase(cozy, doctype)) {\n\t    return Promise.resolve(getDatabase(cozy, doctype));\n\t  }\n\t\n\t  setDatabase(cozy, doctype, new _pouchdb2.default(doctype, options));\n\t  return createIndexes(cozy, doctype).then(function () {\n\t    return getDatabase(cozy, doctype);\n\t  });\n\t}\n\t\n\tfunction destroyDatabase(cozy, doctype) {\n\t  if (!hasDatabase(cozy, doctype)) {\n\t    return Promise.resolve(false);\n\t  }\n\t\n\t  return stopRepeatedReplication(cozy, doctype).then(function () {\n\t    return stopReplication(cozy, doctype);\n\t  }).then(function () {\n\t    return getDatabase(cozy, doctype).destroy();\n\t  }).then(function (response) {\n\t    setDatabase(cozy, doctype, undefined);\n\t    return response;\n\t  });\n\t}\n\t\n\tfunction destroyAllDatabase(cozy) {\n\t  var doctypes = getDoctypes(cozy);\n\t  var destroy = function destroy(doctype) {\n\t    return destroyDatabase(cozy, doctype);\n\t  };\n\t  return Promise.all(doctypes.map(destroy));\n\t}\n\t\n\tfunction createIndexes(cozy, doctype) {\n\t  if (doctype === _doctypes.DOCTYPE_FILES) {\n\t    return getDatabase(cozy, doctype).createIndex({ index: { fields: ['dir_id'] } });\n\t  }\n\t  return Promise.resolve();\n\t}\n\t\n\t//\n\t// REPLICATION\n\t//\n\t\n\tfunction hasReplication(cozy, doctype) {\n\t  return getReplication(cozy, doctype) !== undefined;\n\t}\n\t\n\tfunction getReplication(cozy, doctype) {\n\t  return getInfo(cozy, doctype).replication;\n\t}\n\t\n\tfunction setReplication(cozy, doctype, replication) {\n\t  cozy._offline[doctype].replication = replication;\n\t  return getReplication(cozy, doctype);\n\t}\n\t\n\tfunction getReplicationUrl(cozy, doctype) {\n\t  return cozy.authorize().then(function (credentials) {\n\t    var basic = credentials.token.toBasicAuth();\n\t    return (cozy._url + '/data/' + doctype).replace('//', '//' + basic);\n\t  });\n\t}\n\t\n\tfunction getReplicationPromise(cozy, doctype) {\n\t  return getInfo(cozy, doctype).replicationPromise;\n\t}\n\t\n\tfunction setReplicationPromise(cozy, doctype, promise) {\n\t  cozy._offline[doctype].replicationPromise = promise;\n\t  return getReplicationPromise(cozy, doctype);\n\t}\n\t\n\tfunction replicateFromCozy(cozy, doctype) {\n\t  var options = arguments.length > 2 && arguments[2] !== undefined ? arguments[2] : {};\n\t\n\t  return setReplicationPromise(cozy, doctype, new Promise(function (resolve, reject) {\n\t    if (!hasDatabase(cozy, doctype)) {\n\t      createDatabase(cozy, doctype);\n\t    }\n\t    if (options.live === true) {\n\t      return reject(new Error('You can\\'t use `live` option with Cozy couchdb.'));\n\t    }\n\t\n\t    if ((0, _utils.isOffline)()) {\n\t      reject(replicationOfflineError);\n\t      options.onError && options.onError(replicationOfflineError);\n\t      return;\n\t    }\n\t\n\t    getReplicationUrl(cozy, doctype).then(function (url) {\n\t      return setReplication(cozy, doctype, getDatabase(cozy, doctype).replicate.from(url, options).on('complete', function (info) {\n\t        setReplication(cozy, doctype, undefined);\n\t        resolve(info);\n\t        options.onComplete && options.onComplete(info);\n\t      }).on('error', function (err) {\n\t        if (err.error === 'code=400, message=Expired token') {\n\t          cozy.authorize().then(function (_ref2) {\n\t            var client = _ref2.client,\n\t                token = _ref2.token;\n\t\n\t            (0, _auth_v.refreshToken)(cozy, client, token).then(function (newToken) {\n\t              return cozy.saveCredentials(client, newToken);\n\t            }).then(function (credentials) {\n\t              return replicateFromCozy(cozy, doctype, options);\n\t            });\n\t          });\n\t        } else {\n\t          console.warn('ReplicateFromCozy \\'' + doctype + '\\' Error:');\n\t          console.warn(err);\n\t          setReplication(cozy, doctype, undefined);\n\t          reject(err);\n\t          options.onError && options.onError(err);\n\t        }\n\t      }));\n\t    });\n\t  }));\n\t}\n\t\n\tfunction stopReplication(cozy, doctype) {\n\t  if (!getDatabase(cozy, doctype) || !hasReplication(cozy, doctype)) {\n\t    return Promise.resolve();\n\t  }\n\t\n\t  return new Promise(function (resolve) {\n\t    try {\n\t      getReplicationPromise(cozy, doctype).then(function () {\n\t        resolve();\n\t      });\n\t      getReplication(cozy, doctype).cancel();\n\t      // replication is set to undefined by complete replication\n\t    } catch (e) {\n\t      resolve();\n\t    }\n\t  });\n\t}\n\t\n\tfunction stopAllReplication(cozy) {\n\t  var doctypes = getDoctypes(cozy);\n\t  var stop = function stop(doctype) {\n\t    return stopReplication(cozy, doctype);\n\t  };\n\t  return Promise.all(doctypes.map(stop));\n\t}\n\t\n\t//\n\t// REPEATED REPLICATION\n\t//\n\t\n\tfunction getRepeatedReplication(cozy, doctype) {\n\t  return getInfo(cozy, doctype).interval;\n\t}\n\t\n\tfunction setRepeatedReplication(cozy, doctype, interval) {\n\t  cozy._offline[doctype].interval = interval;\n\t}\n\t\n\tfunction hasRepeatedReplication(cozy, doctype) {\n\t  return getRepeatedReplication(cozy, doctype) !== undefined;\n\t}\n\t\n\tfunction startRepeatedReplication(cozy, doctype, timer) {\n\t  var options = arguments.length > 3 && arguments[3] !== undefined ? arguments[3] : {};\n\t\n\t  // TODO: add timer limitation for not flooding Gozy\n\t  if (hasRepeatedReplication(cozy, doctype)) {\n\t    return getRepeatedReplication(cozy, doctype);\n\t  }\n\t\n\t  return setRepeatedReplication(cozy, doctype, setInterval(function () {\n\t    if ((0, _utils.isOffline)()) {\n\t      // network is offline, replication cannot be launched\n\t      console.info(replicationOfflineError);\n\t      return;\n\t    }\n\t    if (!hasReplication(cozy, doctype)) {\n\t      replicateFromCozy(cozy, doctype, options);\n\t      // TODO: add replicationToCozy\n\t    }\n\t  }, timer * 1000));\n\t}\n\t\n\tfunction stopRepeatedReplication(cozy, doctype) {\n\t  if (hasRepeatedReplication(cozy, doctype)) {\n\t    clearInterval(getRepeatedReplication(cozy, doctype));\n\t    setRepeatedReplication(cozy, doctype, undefined);\n\t  }\n\t  if (hasReplication(cozy, doctype)) {\n\t    return stopReplication(cozy, doctype);\n\t  }\n\t\n\t  return Promise.resolve();\n\t}\n\t\n\tfunction stopAllRepeatedReplication(cozy) {\n\t  var doctypes = getDoctypes(cozy);\n\t  var stop = function stop(doctype) {\n\t    return stopRepeatedReplication(cozy, doctype);\n\t  };\n\t  return Promise.all(doctypes.map(stop));\n\t}\n\n/***/ },\n/* 45 */\n/***/ function(module, exports, __webpack_require__) {\n\n\t'use strict';\n\t\n\tObject.defineProperty(exports, \"__esModule\", {\n\t  value: true\n\t});\n\texports.removeReferencedFiles = exports.addReferencedFiles = undefined;\n\texports.listReferencedFiles = listReferencedFiles;\n\texports.fetchReferencedFiles = fetchReferencedFiles;\n\t\n\tvar _fetch = __webpack_require__(1);\n\t\n\tvar _doctypes = __webpack_require__(6);\n\t\n\tfunction updateRelations(verb) {\n\t  return function (cozy, doc, ids) {\n\t    if (!doc) throw new Error('missing doc argument');\n\t    if (!Array.isArray(ids)) ids = [ids];\n\t\n\t    var refs = ids.map(function (id) {\n\t      return { type: _doctypes.DOCTYPE_FILES, id: id };\n\t    });\n\t\n\t    return (0, _fetch.cozyFetchJSON)(cozy, verb, makeReferencesPath(doc), { data: refs });\n\t  };\n\t}\n\t\n\tvar addReferencedFiles = exports.addReferencedFiles = updateRelations('POST');\n\tvar removeReferencedFiles = exports.removeReferencedFiles = updateRelations('DELETE');\n\t\n\tfunction listReferencedFiles(cozy, doc) {\n\t  if (!doc) throw new Error('missing doc argument');\n\t  return (0, _fetch.cozyFetchJSON)(cozy, 'GET', makeReferencesPath(doc)).then(function (files) {\n\t    return files.map(function (file) {\n\t      return file._id;\n\t    });\n\t  });\n\t}\n\t\n\tfunction fetchReferencedFiles(cozy, doc, options) {\n\t  if (!doc) throw new Error('missing doc argument');\n\t  var params = Object.keys(options).map(function (key) {\n\t    return '&page[' + key + ']=' + options[key];\n\t  }).join('');\n\t  // As datetime is the only sort option available, I see no reason to not have it by default\n\t  return (0, _fetch.cozyFetchRawJSON)(cozy, 'GET', makeReferencesPath(doc) + '?include=files&sort=datetime' + params);\n\t}\n\t\n\tfunction makeReferencesPath(doc) {\n\t  var type = encodeURIComponent(doc._type);\n\t  var id = encodeURIComponent(doc._id);\n\t  return '/data/' + type + '/' + id + '/relationships/references';\n\t}\n\n/***/ },\n/* 46 */\n/***/ function(module, exports, __webpack_require__) {\n\n\t'use strict';\n\t\n\tObject.defineProperty(exports, \"__esModule\", {\n\t  value: true\n\t});\n\texports.diskUsage = diskUsage;\n\texports.changePassphrase = changePassphrase;\n\texports.getInstance = getInstance;\n\texports.updateInstance = updateInstance;\n\texports.getClients = getClients;\n\texports.deleteClientById = deleteClientById;\n\texports.updateLastSync = updateLastSync;\n\t\n\tvar _fetch = __webpack_require__(1);\n\t\n\tfunction diskUsage(cozy) {\n\t  return (0, _fetch.cozyFetchJSON)(cozy, 'GET', '/settings/disk-usage');\n\t}\n\t\n\tfunction changePassphrase(cozy, currentPassPhrase, newPassPhrase) {\n\t  return (0, _fetch.cozyFetchJSON)(cozy, 'PUT', '/settings/passphrase', {\n\t    current_passphrase: currentPassPhrase,\n\t    new_passphrase: newPassPhrase\n\t  });\n\t}\n\t\n\tfunction getInstance(cozy) {\n\t  return (0, _fetch.cozyFetchJSON)(cozy, 'GET', '/settings/instance');\n\t}\n\t\n\tfunction updateInstance(cozy, instance) {\n\t  return (0, _fetch.cozyFetchJSON)(cozy, 'PUT', '/settings/instance', instance);\n\t}\n\t\n\tfunction getClients(cozy) {\n\t  return (0, _fetch.cozyFetchJSON)(cozy, 'GET', '/settings/clients');\n\t}\n\t\n\tfunction deleteClientById(cozy, id) {\n\t  return (0, _fetch.cozyFetchJSON)(cozy, 'DELETE', '/settings/clients/' + id);\n\t}\n\t\n\tfunction updateLastSync(cozy) {\n\t  return (0, _fetch.cozyFetchJSON)(cozy, 'POST', '/settings/synchronized');\n\t}\n\n/***/ },\n/* 47 */\n/***/ function(module, exports, __webpack_require__) {\n\n\tmodule.exports = __webpack_require__(92);\n\n\n/***/ },\n/* 48 */\n/***/ function(module, exports) {\n\n\tmodule.exports = function (it) {\n\t  if (typeof it != 'function') throw TypeError(it + ' is not a function!');\n\t  return it;\n\t};\n\n\n/***/ },\n/* 49 */\n/***/ function(module, exports, __webpack_require__) {\n\n\tvar isObject = __webpack_require__(12);\n\tmodule.exports = function (it) {\n\t  if (!isObject(it)) throw TypeError(it + ' is not an object!');\n\t  return it;\n\t};\n\n\n/***/ },\n/* 50 */\n/***/ function(module, exports, __webpack_require__) {\n\n\t// false -> Array#indexOf\n\t// true  -> Array#includes\n\tvar toIObject = __webpack_require__(25);\n\tvar toLength = __webpack_require__(68);\n\tvar toAbsoluteIndex = __webpack_require__(67);\n\tmodule.exports = function (IS_INCLUDES) {\n\t  return function ($this, el, fromIndex) {\n\t    var O = toIObject($this);\n\t    var length = toLength(O.length);\n\t    var index = toAbsoluteIndex(fromIndex, length);\n\t    var value;\n\t    // Array#includes uses SameValueZero equality algorithm\n\t    // eslint-disable-next-line no-self-compare\n\t    if (IS_INCLUDES && el != el) while (length > index) {\n\t      value = O[index++];\n\t      // eslint-disable-next-line no-self-compare\n\t      if (value != value) return true;\n\t    // Array#indexOf ignores holes, Array#includes - not\n\t    } else for (;length > index; index++) if (IS_INCLUDES || index in O) {\n\t      if (O[index] === el) return IS_INCLUDES || index || 0;\n\t    } return !IS_INCLUDES && -1;\n\t  };\n\t};\n\n\n/***/ },\n/* 51 */\n/***/ function(module, exports) {\n\n\tvar toString = {}.toString;\n\t\n\tmodule.exports = function (it) {\n\t  return toString.call(it).slice(8, -1);\n\t};\n\n\n/***/ },\n/* 52 */\n/***/ function(module, exports, __webpack_require__) {\n\n\t// optional / simple context binding\n\tvar aFunction = __webpack_require__(48);\n\tmodule.exports = function (fn, that, length) {\n\t  aFunction(fn);\n\t  if (that === undefined) return fn;\n\t  switch (length) {\n\t    case 1: return function (a) {\n\t      return fn.call(that, a);\n\t    };\n\t    case 2: return function (a, b) {\n\t      return fn.call(that, a, b);\n\t    };\n\t    case 3: return function (a, b, c) {\n\t      return fn.call(that, a, b, c);\n\t    };\n\t  }\n\t  return function (/* ...args */) {\n\t    return fn.apply(that, arguments);\n\t  };\n\t};\n\n\n/***/ },\n/* 53 */\n/***/ function(module, exports, __webpack_require__) {\n\n\tvar isObject = __webpack_require__(12);\n\tvar document = __webpack_require__(7).document;\n\t// typeof document.createElement is 'object' in old IE\n\tvar is = isObject(document) && isObject(document.createElement);\n\tmodule.exports = function (it) {\n\t  return is ? document.createElement(it) : {};\n\t};\n\n\n/***/ },\n/* 54 */\n/***/ function(module, exports) {\n\n\t// IE 8- don't enum bug keys\n\tmodule.exports = (\n\t  'constructor,hasOwnProperty,isPrototypeOf,propertyIsEnumerable,toLocaleString,toString,valueOf'\n\t).split(',');\n\n\n/***/ },\n/* 55 */\n/***/ function(module, exports, __webpack_require__) {\n\n\tvar global = __webpack_require__(7);\n\tvar core = __webpack_require__(19);\n\tvar hide = __webpack_require__(22);\n\tvar redefine = __webpack_require__(64);\n\tvar ctx = __webpack_require__(52);\n\tvar PROTOTYPE = 'prototype';\n\t\n\tvar $export = function (type, name, source) {\n\t  var IS_FORCED = type & $export.F;\n\t  var IS_GLOBAL = type & $export.G;\n\t  var IS_STATIC = type & $export.S;\n\t  var IS_PROTO = type & $export.P;\n\t  var IS_BIND = type & $export.B;\n\t  var target = IS_GLOBAL ? global : IS_STATIC ? global[name] || (global[name] = {}) : (global[name] || {})[PROTOTYPE];\n\t  var exports = IS_GLOBAL ? core : core[name] || (core[name] = {});\n\t  var expProto = exports[PROTOTYPE] || (exports[PROTOTYPE] = {});\n\t  var key, own, out, exp;\n\t  if (IS_GLOBAL) source = name;\n\t  for (key in source) {\n\t    // contains in native\n\t    own = !IS_FORCED && target && target[key] !== undefined;\n\t    // export native or passed\n\t    out = (own ? target : source)[key];\n\t    // bind timers to global for call from export context\n\t    exp = IS_BIND && own ? ctx(out, global) : IS_PROTO && typeof out == 'function' ? ctx(Function.call, out) : out;\n\t    // extend global\n\t    if (target) redefine(target, key, out, type & $export.U);\n\t    // export\n\t    if (exports[key] != out) hide(exports, key, exp);\n\t    if (IS_PROTO && expProto[key] != out) expProto[key] = out;\n\t  }\n\t};\n\tglobal.core = core;\n\t// type bitmap\n\t$export.F = 1;   // forced\n\t$export.G = 2;   // global\n\t$export.S = 4;   // static\n\t$export.P = 8;   // proto\n\t$export.B = 16;  // bind\n\t$export.W = 32;  // wrap\n\t$export.U = 64;  // safe\n\t$export.R = 128; // real proto method for `library`\n\tmodule.exports = $export;\n\n\n/***/ },\n/* 56 */\n/***/ function(module, exports, __webpack_require__) {\n\n\tmodule.exports = !__webpack_require__(10) && !__webpack_require__(11)(function () {\n\t  return Object.defineProperty(__webpack_require__(53)('div'), 'a', { get: function () { return 7; } }).a != 7;\n\t});\n\n\n/***/ },\n/* 57 */\n/***/ function(module, exports, __webpack_require__) {\n\n\t'use strict';\n\t// 19.1.2.1 Object.assign(target, source, ...)\n\tvar getKeys = __webpack_require__(61);\n\tvar gOPS = __webpack_require__(59);\n\tvar pIE = __webpack_require__(62);\n\tvar toObject = __webpack_require__(69);\n\tvar IObject = __webpack_require__(23);\n\tvar $assign = Object.assign;\n\t\n\t// should work with symbols and should have deterministic property order (V8 bug)\n\tmodule.exports = !$assign || __webpack_require__(11)(function () {\n\t  var A = {};\n\t  var B = {};\n\t  // eslint-disable-next-line no-undef\n\t  var S = Symbol();\n\t  var K = 'abcdefghijklmnopqrst';\n\t  A[S] = 7;\n\t  K.split('').forEach(function (k) { B[k] = k; });\n\t  return $assign({}, A)[S] != 7 || Object.keys($assign({}, B)).join('') != K;\n\t}) ? function assign(target, source) { // eslint-disable-line no-unused-vars\n\t  var T = toObject(target);\n\t  var aLen = arguments.length;\n\t  var index = 1;\n\t  var getSymbols = gOPS.f;\n\t  var isEnum = pIE.f;\n\t  while (aLen > index) {\n\t    var S = IObject(arguments[index++]);\n\t    var keys = getSymbols ? getKeys(S).concat(getSymbols(S)) : getKeys(S);\n\t    var length = keys.length;\n\t    var j = 0;\n\t    var key;\n\t    while (length > j) if (isEnum.call(S, key = keys[j++])) T[key] = S[key];\n\t  } return T;\n\t} : $assign;\n\n\n/***/ },\n/* 58 */\n/***/ function(module, exports, __webpack_require__) {\n\n\tvar anObject = __webpack_require__(49);\n\tvar IE8_DOM_DEFINE = __webpack_require__(56);\n\tvar toPrimitive = __webpack_require__(70);\n\tvar dP = Object.defineProperty;\n\t\n\texports.f = __webpack_require__(10) ? Object.defineProperty : function defineProperty(O, P, Attributes) {\n\t  anObject(O);\n\t  P = toPrimitive(P, true);\n\t  anObject(Attributes);\n\t  if (IE8_DOM_DEFINE) try {\n\t    return dP(O, P, Attributes);\n\t  } catch (e) { /* empty */ }\n\t  if ('get' in Attributes || 'set' in Attributes) throw TypeError('Accessors not supported!');\n\t  if ('value' in Attributes) O[P] = Attributes.value;\n\t  return O;\n\t};\n\n\n/***/ },\n/* 59 */\n/***/ function(module, exports) {\n\n\texports.f = Object.getOwnPropertySymbols;\n\n\n/***/ },\n/* 60 */\n/***/ function(module, exports, __webpack_require__) {\n\n\tvar has = __webpack_require__(21);\n\tvar toIObject = __webpack_require__(25);\n\tvar arrayIndexOf = __webpack_require__(50)(false);\n\tvar IE_PROTO = __webpack_require__(65)('IE_PROTO');\n\t\n\tmodule.exports = function (object, names) {\n\t  var O = toIObject(object);\n\t  var i = 0;\n\t  var result = [];\n\t  var key;\n\t  for (key in O) if (key != IE_PROTO) has(O, key) && result.push(key);\n\t  // Don't enum bug & hidden keys\n\t  while (names.length > i) if (has(O, key = names[i++])) {\n\t    ~arrayIndexOf(result, key) || result.push(key);\n\t  }\n\t  return result;\n\t};\n\n\n/***/ },\n/* 61 */\n/***/ function(module, exports, __webpack_require__) {\n\n\t// 19.1.2.14 / 15.2.3.14 Object.keys(O)\n\tvar $keys = __webpack_require__(60);\n\tvar enumBugKeys = __webpack_require__(54);\n\t\n\tmodule.exports = Object.keys || function keys(O) {\n\t  return $keys(O, enumBugKeys);\n\t};\n\n\n/***/ },\n/* 62 */\n/***/ function(module, exports) {\n\n\texports.f = {}.propertyIsEnumerable;\n\n\n/***/ },\n/* 63 */\n/***/ function(module, exports) {\n\n\tmodule.exports = function (bitmap, value) {\n\t  return {\n\t    enumerable: !(bitmap & 1),\n\t    configurable: !(bitmap & 2),\n\t    writable: !(bitmap & 4),\n\t    value: value\n\t  };\n\t};\n\n\n/***/ },\n/* 64 */\n/***/ function(module, exports, __webpack_require__) {\n\n\tvar global = __webpack_require__(7);\n\tvar hide = __webpack_require__(22);\n\tvar has = __webpack_require__(21);\n\tvar SRC = __webpack_require__(26)('src');\n\tvar TO_STRING = 'toString';\n\tvar $toString = Function[TO_STRING];\n\tvar TPL = ('' + $toString).split(TO_STRING);\n\t\n\t__webpack_require__(19).inspectSource = function (it) {\n\t  return $toString.call(it);\n\t};\n\t\n\t(module.exports = function (O, key, val, safe) {\n\t  var isFunction = typeof val == 'function';\n\t  if (isFunction) has(val, 'name') || hide(val, 'name', key);\n\t  if (O[key] === val) return;\n\t  if (isFunction) has(val, SRC) || hide(val, SRC, O[key] ? '' + O[key] : TPL.join(String(key)));\n\t  if (O === global) {\n\t    O[key] = val;\n\t  } else if (!safe) {\n\t    delete O[key];\n\t    hide(O, key, val);\n\t  } else if (O[key]) {\n\t    O[key] = val;\n\t  } else {\n\t    hide(O, key, val);\n\t  }\n\t// add fake Function#toString for correct work wrapped methods / constructors with methods like LoDash isNative\n\t})(Function.prototype, TO_STRING, function toString() {\n\t  return typeof this == 'function' && this[SRC] || $toString.call(this);\n\t});\n\n\n/***/ },\n/* 65 */\n/***/ function(module, exports, __webpack_require__) {\n\n\tvar shared = __webpack_require__(66)('keys');\n\tvar uid = __webpack_require__(26);\n\tmodule.exports = function (key) {\n\t  return shared[key] || (shared[key] = uid(key));\n\t};\n\n\n/***/ },\n/* 66 */\n/***/ function(module, exports, __webpack_require__) {\n\n\tvar global = __webpack_require__(7);\n\tvar SHARED = '__core-js_shared__';\n\tvar store = global[SHARED] || (global[SHARED] = {});\n\tmodule.exports = function (key) {\n\t  return store[key] || (store[key] = {});\n\t};\n\n\n/***/ },\n/* 67 */\n/***/ function(module, exports, __webpack_require__) {\n\n\tvar toInteger = __webpack_require__(24);\n\tvar max = Math.max;\n\tvar min = Math.min;\n\tmodule.exports = function (index, length) {\n\t  index = toInteger(index);\n\t  return index < 0 ? max(index + length, 0) : min(index, length);\n\t};\n\n\n/***/ },\n/* 68 */\n/***/ function(module, exports, __webpack_require__) {\n\n\t// 7.1.15 ToLength\n\tvar toInteger = __webpack_require__(24);\n\tvar min = Math.min;\n\tmodule.exports = function (it) {\n\t  return it > 0 ? min(toInteger(it), 0x1fffffffffffff) : 0; // pow(2, 53) - 1 == 9007199254740991\n\t};\n\n\n/***/ },\n/* 69 */\n/***/ function(module, exports, __webpack_require__) {\n\n\t// 7.1.13 ToObject(argument)\n\tvar defined = __webpack_require__(20);\n\tmodule.exports = function (it) {\n\t  return Object(defined(it));\n\t};\n\n\n/***/ },\n/* 70 */\n/***/ function(module, exports, __webpack_require__) {\n\n\t// 7.1.1 ToPrimitive(input [, PreferredType])\n\tvar isObject = __webpack_require__(12);\n\t// instead of the ES6 spec version, we didn't implement @@toPrimitive case\n\t// and the second argument - flag - preferred type is a string\n\tmodule.exports = function (it, S) {\n\t  if (!isObject(it)) return it;\n\t  var fn, val;\n\t  if (S && typeof (fn = it.toString) == 'function' && !isObject(val = fn.call(it))) return val;\n\t  if (typeof (fn = it.valueOf) == 'function' && !isObject(val = fn.call(it))) return val;\n\t  if (!S && typeof (fn = it.toString) == 'function' && !isObject(val = fn.call(it))) return val;\n\t  throw TypeError(\"Can't convert object to primitive value\");\n\t};\n\n\n/***/ },\n/* 71 */\n/***/ function(module, exports, __webpack_require__) {\n\n\t// 19.1.3.1 Object.assign(target, source)\n\tvar $export = __webpack_require__(55);\n\t\n\t$export($export.S + $export.F, 'Object', { assign: __webpack_require__(57) });\n\n\n/***/ },\n/* 72 */\n/***/ function(module, exports) {\n\n\t/**\n\t * Helpers.\n\t */\n\t\n\tvar s = 1000\n\tvar m = s * 60\n\tvar h = m * 60\n\tvar d = h * 24\n\tvar y = d * 365.25\n\t\n\t/**\n\t * Parse or format the given `val`.\n\t *\n\t * Options:\n\t *\n\t *  - `long` verbose formatting [false]\n\t *\n\t * @param {String|Number} val\n\t * @param {Object} options\n\t * @throws {Error} throw an error if val is not a non-empty string or a number\n\t * @return {String|Number}\n\t * @api public\n\t */\n\t\n\tmodule.exports = function (val, options) {\n\t  options = options || {}\n\t  var type = typeof val\n\t  if (type === 'string' && val.length > 0) {\n\t    return parse(val)\n\t  } else if (type === 'number' && isNaN(val) === false) {\n\t    return options.long ?\n\t\t\t\tfmtLong(val) :\n\t\t\t\tfmtShort(val)\n\t  }\n\t  throw new Error('val is not a non-empty string or a valid number. val=' + JSON.stringify(val))\n\t}\n\t\n\t/**\n\t * Parse the given `str` and return milliseconds.\n\t *\n\t * @param {String} str\n\t * @return {Number}\n\t * @api private\n\t */\n\t\n\tfunction parse(str) {\n\t  str = String(str)\n\t  if (str.length > 10000) {\n\t    return\n\t  }\n\t  var match = /^((?:\\d+)?\\.?\\d+) *(milliseconds?|msecs?|ms|seconds?|secs?|s|minutes?|mins?|m|hours?|hrs?|h|days?|d|years?|yrs?|y)?$/i.exec(str)\n\t  if (!match) {\n\t    return\n\t  }\n\t  var n = parseFloat(match[1])\n\t  var type = (match[2] || 'ms').toLowerCase()\n\t  switch (type) {\n\t    case 'years':\n\t    case 'year':\n\t    case 'yrs':\n\t    case 'yr':\n\t    case 'y':\n\t      return n * y\n\t    case 'days':\n\t    case 'day':\n\t    case 'd':\n\t      return n * d\n\t    case 'hours':\n\t    case 'hour':\n\t    case 'hrs':\n\t    case 'hr':\n\t    case 'h':\n\t      return n * h\n\t    case 'minutes':\n\t    case 'minute':\n\t    case 'mins':\n\t    case 'min':\n\t    case 'm':\n\t      return n * m\n\t    case 'seconds':\n\t    case 'second':\n\t    case 'secs':\n\t    case 'sec':\n\t    case 's':\n\t      return n * s\n\t    case 'milliseconds':\n\t    case 'millisecond':\n\t    case 'msecs':\n\t    case 'msec':\n\t    case 'ms':\n\t      return n\n\t    default:\n\t      return undefined\n\t  }\n\t}\n\t\n\t/**\n\t * Short format for `ms`.\n\t *\n\t * @param {Number} ms\n\t * @return {String}\n\t * @api private\n\t */\n\t\n\tfunction fmtShort(ms) {\n\t  if (ms >= d) {\n\t    return Math.round(ms / d) + 'd'\n\t  }\n\t  if (ms >= h) {\n\t    return Math.round(ms / h) + 'h'\n\t  }\n\t  if (ms >= m) {\n\t    return Math.round(ms / m) + 'm'\n\t  }\n\t  if (ms >= s) {\n\t    return Math.round(ms / s) + 's'\n\t  }\n\t  return ms + 'ms'\n\t}\n\t\n\t/**\n\t * Long format for `ms`.\n\t *\n\t * @param {Number} ms\n\t * @return {String}\n\t * @api private\n\t */\n\t\n\tfunction fmtLong(ms) {\n\t  return plural(ms, d, 'day') ||\n\t    plural(ms, h, 'hour') ||\n\t    plural(ms, m, 'minute') ||\n\t    plural(ms, s, 'second') ||\n\t    ms + ' ms'\n\t}\n\t\n\t/**\n\t * Pluralization helper.\n\t */\n\t\n\tfunction plural(ms, n, name) {\n\t  if (ms < n) {\n\t    return\n\t  }\n\t  if (ms < n * 1.5) {\n\t    return Math.floor(ms / n) + ' ' + name\n\t  }\n\t  return Math.ceil(ms / n) + ' ' + name + 's'\n\t}\n\n\n/***/ },\n/* 73 */\n/***/ function(module, exports, __webpack_require__) {\n\n\t\n\t/**\n\t * This is the common logic for both the Node.js and web browser\n\t * implementations of `debug()`.\n\t *\n\t * Expose `debug()` as the module.\n\t */\n\t\n\texports = module.exports = createDebug.debug = createDebug.default = createDebug;\n\texports.coerce = coerce;\n\texports.disable = disable;\n\texports.enable = enable;\n\texports.enabled = enabled;\n\texports.humanize = __webpack_require__(72);\n\t\n\t/**\n\t * The currently active debug mode names, and names to skip.\n\t */\n\t\n\texports.names = [];\n\texports.skips = [];\n\t\n\t/**\n\t * Map of special \"%n\" handling functions, for the debug \"format\" argument.\n\t *\n\t * Valid key names are a single, lower or upper-case letter, i.e. \"n\" and \"N\".\n\t */\n\t\n\texports.formatters = {};\n\t\n\t/**\n\t * Previous log timestamp.\n\t */\n\t\n\tvar prevTime;\n\t\n\t/**\n\t * Select a color.\n\t * @param {String} namespace\n\t * @return {Number}\n\t * @api private\n\t */\n\t\n\tfunction selectColor(namespace) {\n\t  var hash = 0, i;\n\t\n\t  for (i in namespace) {\n\t    hash  = ((hash << 5) - hash) + namespace.charCodeAt(i);\n\t    hash |= 0; // Convert to 32bit integer\n\t  }\n\t\n\t  return exports.colors[Math.abs(hash) % exports.colors.length];\n\t}\n\t\n\t/**\n\t * Create a debugger with the given `namespace`.\n\t *\n\t * @param {String} namespace\n\t * @return {Function}\n\t * @api public\n\t */\n\t\n\tfunction createDebug(namespace) {\n\t\n\t  function debug() {\n\t    // disabled?\n\t    if (!debug.enabled) return;\n\t\n\t    var self = debug;\n\t\n\t    // set `diff` timestamp\n\t    var curr = +new Date();\n\t    var ms = curr - (prevTime || curr);\n\t    self.diff = ms;\n\t    self.prev = prevTime;\n\t    self.curr = curr;\n\t    prevTime = curr;\n\t\n\t    // turn the `arguments` into a proper Array\n\t    var args = new Array(arguments.length);\n\t    for (var i = 0; i < args.length; i++) {\n\t      args[i] = arguments[i];\n\t    }\n\t\n\t    args[0] = exports.coerce(args[0]);\n\t\n\t    if ('string' !== typeof args[0]) {\n\t      // anything else let's inspect with %O\n\t      args.unshift('%O');\n\t    }\n\t\n\t    // apply any `formatters` transformations\n\t    var index = 0;\n\t    args[0] = args[0].replace(/%([a-zA-Z%])/g, function(match, format) {\n\t      // if we encounter an escaped % then don't increase the array index\n\t      if (match === '%%') return match;\n\t      index++;\n\t      var formatter = exports.formatters[format];\n\t      if ('function' === typeof formatter) {\n\t        var val = args[index];\n\t        match = formatter.call(self, val);\n\t\n\t        // now we need to remove `args[index]` since it's inlined in the `format`\n\t        args.splice(index, 1);\n\t        index--;\n\t      }\n\t      return match;\n\t    });\n\t\n\t    // apply env-specific formatting (colors, etc.)\n\t    exports.formatArgs.call(self, args);\n\t\n\t    var logFn = debug.log || exports.log || console.log.bind(console);\n\t    logFn.apply(self, args);\n\t  }\n\t\n\t  debug.namespace = namespace;\n\t  debug.enabled = exports.enabled(namespace);\n\t  debug.useColors = exports.useColors();\n\t  debug.color = selectColor(namespace);\n\t\n\t  // env-specific initialization logic for debug instances\n\t  if ('function' === typeof exports.init) {\n\t    exports.init(debug);\n\t  }\n\t\n\t  return debug;\n\t}\n\t\n\t/**\n\t * Enables a debug mode by namespaces. This can include modes\n\t * separated by a colon and wildcards.\n\t *\n\t * @param {String} namespaces\n\t * @api public\n\t */\n\t\n\tfunction enable(namespaces) {\n\t  exports.save(namespaces);\n\t\n\t  var split = (namespaces || '').split(/[\\s,]+/);\n\t  var len = split.length;\n\t\n\t  for (var i = 0; i < len; i++) {\n\t    if (!split[i]) continue; // ignore empty strings\n\t    namespaces = split[i].replace(/\\*/g, '.*?');\n\t    if (namespaces[0] === '-') {\n\t      exports.skips.push(new RegExp('^' + namespaces.substr(1) + '$'));\n\t    } else {\n\t      exports.names.push(new RegExp('^' + namespaces + '$'));\n\t    }\n\t  }\n\t}\n\t\n\t/**\n\t * Disable debug output.\n\t *\n\t * @api public\n\t */\n\t\n\tfunction disable() {\n\t  exports.enable('');\n\t}\n\t\n\t/**\n\t * Returns true if the given mode name is enabled, false otherwise.\n\t *\n\t * @param {String} name\n\t * @return {Boolean}\n\t * @api public\n\t */\n\t\n\tfunction enabled(name) {\n\t  var i, len;\n\t  for (i = 0, len = exports.skips.length; i < len; i++) {\n\t    if (exports.skips[i].test(name)) {\n\t      return false;\n\t    }\n\t  }\n\t  for (i = 0, len = exports.names.length; i < len; i++) {\n\t    if (exports.names[i].test(name)) {\n\t      return true;\n\t    }\n\t  }\n\t  return false;\n\t}\n\t\n\t/**\n\t * Coerce `val`.\n\t *\n\t * @param {Mixed} val\n\t * @return {Mixed}\n\t * @api private\n\t */\n\t\n\tfunction coerce(val) {\n\t  if (val instanceof Error) return val.stack || val.message;\n\t  return val;\n\t}\n\n\n/***/ },\n/* 74 */\n/***/ function(module, exports) {\n\n\t// Copyright Joyent, Inc. and other Node contributors.\n\t//\n\t// Permission is hereby granted, free of charge, to any person obtaining a\n\t// copy of this software and associated documentation files (the\n\t// \"Software\"), to deal in the Software without restriction, including\n\t// without limitation the rights to use, copy, modify, merge, publish,\n\t// distribute, sublicense, and/or sell copies of the Software, and to permit\n\t// persons to whom the Software is furnished to do so, subject to the\n\t// following conditions:\n\t//\n\t// The above copyright notice and this permission notice shall be included\n\t// in all copies or substantial portions of the Software.\n\t//\n\t// THE SOFTWARE IS PROVIDED \"AS IS\", WITHOUT WARRANTY OF ANY KIND, EXPRESS\n\t// OR IMPLIED, INCLUDING BUT NOT LIMITED TO THE WARRANTIES OF\n\t// MERCHANTABILITY, FITNESS FOR A PARTICULAR PURPOSE AND NONINFRINGEMENT. IN\n\t// NO EVENT SHALL THE AUTHORS OR COPYRIGHT HOLDERS BE LIABLE FOR ANY CLAIM,\n\t// DAMAGES OR OTHER LIABILITY, WHETHER IN AN ACTION OF CONTRACT, TORT OR\n\t// OTHERWISE, ARISING FROM, OUT OF OR IN CONNECTION WITH THE SOFTWARE OR THE\n\t// USE OR OTHER DEALINGS IN THE SOFTWARE.\n\t\n\tfunction EventEmitter() {\n\t  this._events = this._events || {};\n\t  this._maxListeners = this._maxListeners || undefined;\n\t}\n\tmodule.exports = EventEmitter;\n\t\n\t// Backwards-compat with node 0.10.x\n\tEventEmitter.EventEmitter = EventEmitter;\n\t\n\tEventEmitter.prototype._events = undefined;\n\tEventEmitter.prototype._maxListeners = undefined;\n\t\n\t// By default EventEmitters will print a warning if more than 10 listeners are\n\t// added to it. This is a useful default which helps finding memory leaks.\n\tEventEmitter.defaultMaxListeners = 10;\n\t\n\t// Obviously not all Emitters should be limited to 10. This function allows\n\t// that to be increased. Set to zero for unlimited.\n\tEventEmitter.prototype.setMaxListeners = function(n) {\n\t  if (!isNumber(n) || n < 0 || isNaN(n))\n\t    throw TypeError('n must be a positive number');\n\t  this._maxListeners = n;\n\t  return this;\n\t};\n\t\n\tEventEmitter.prototype.emit = function(type) {\n\t  var er, handler, len, args, i, listeners;\n\t\n\t  if (!this._events)\n\t    this._events = {};\n\t\n\t  // If there is no 'error' event listener then throw.\n\t  if (type === 'error') {\n\t    if (!this._events.error ||\n\t        (isObject(this._events.error) && !this._events.error.length)) {\n\t      er = arguments[1];\n\t      if (er instanceof Error) {\n\t        throw er; // Unhandled 'error' event\n\t      } else {\n\t        // At least give some kind of context to the user\n\t        var err = new Error('Uncaught, unspecified \"error\" event. (' + er + ')');\n\t        err.context = er;\n\t        throw err;\n\t      }\n\t    }\n\t  }\n\t\n\t  handler = this._events[type];\n\t\n\t  if (isUndefined(handler))\n\t    return false;\n\t\n\t  if (isFunction(handler)) {\n\t    switch (arguments.length) {\n\t      // fast cases\n\t      case 1:\n\t        handler.call(this);\n\t        break;\n\t      case 2:\n\t        handler.call(this, arguments[1]);\n\t        break;\n\t      case 3:\n\t        handler.call(this, arguments[1], arguments[2]);\n\t        break;\n\t      // slower\n\t      default:\n\t        args = Array.prototype.slice.call(arguments, 1);\n\t        handler.apply(this, args);\n\t    }\n\t  } else if (isObject(handler)) {\n\t    args = Array.prototype.slice.call(arguments, 1);\n\t    listeners = handler.slice();\n\t    len = listeners.length;\n\t    for (i = 0; i < len; i++)\n\t      listeners[i].apply(this, args);\n\t  }\n\t\n\t  return true;\n\t};\n\t\n\tEventEmitter.prototype.addListener = function(type, listener) {\n\t  var m;\n\t\n\t  if (!isFunction(listener))\n\t    throw TypeError('listener must be a function');\n\t\n\t  if (!this._events)\n\t    this._events = {};\n\t\n\t  // To avoid recursion in the case that type === \"newListener\"! Before\n\t  // adding it to the listeners, first emit \"newListener\".\n\t  if (this._events.newListener)\n\t    this.emit('newListener', type,\n\t              isFunction(listener.listener) ?\n\t              listener.listener : listener);\n\t\n\t  if (!this._events[type])\n\t    // Optimize the case of one listener. Don't need the extra array object.\n\t    this._events[type] = listener;\n\t  else if (isObject(this._events[type]))\n\t    // If we've already got an array, just append.\n\t    this._events[type].push(listener);\n\t  else\n\t    // Adding the second element, need to change to array.\n\t    this._events[type] = [this._events[type], listener];\n\t\n\t  // Check for listener leak\n\t  if (isObject(this._events[type]) && !this._events[type].warned) {\n\t    if (!isUndefined(this._maxListeners)) {\n\t      m = this._maxListeners;\n\t    } else {\n\t      m = EventEmitter.defaultMaxListeners;\n\t    }\n\t\n\t    if (m && m > 0 && this._events[type].length > m) {\n\t      this._events[type].warned = true;\n\t      console.error('(node) warning: possible EventEmitter memory ' +\n\t                    'leak detected. %d listeners added. ' +\n\t                    'Use emitter.setMaxListeners() to increase limit.',\n\t                    this._events[type].length);\n\t      if (typeof console.trace === 'function') {\n\t        // not supported in IE 10\n\t        console.trace();\n\t      }\n\t    }\n\t  }\n\t\n\t  return this;\n\t};\n\t\n\tEventEmitter.prototype.on = EventEmitter.prototype.addListener;\n\t\n\tEventEmitter.prototype.once = function(type, listener) {\n\t  if (!isFunction(listener))\n\t    throw TypeError('listener must be a function');\n\t\n\t  var fired = false;\n\t\n\t  function g() {\n\t    this.removeListener(type, g);\n\t\n\t    if (!fired) {\n\t      fired = true;\n\t      listener.apply(this, arguments);\n\t    }\n\t  }\n\t\n\t  g.listener = listener;\n\t  this.on(type, g);\n\t\n\t  return this;\n\t};\n\t\n\t// emits a 'removeListener' event iff the listener was removed\n\tEventEmitter.prototype.removeListener = function(type, listener) {\n\t  var list, position, length, i;\n\t\n\t  if (!isFunction(listener))\n\t    throw TypeError('listener must be a function');\n\t\n\t  if (!this._events || !this._events[type])\n\t    return this;\n\t\n\t  list = this._events[type];\n\t  length = list.length;\n\t  position = -1;\n\t\n\t  if (list === listener ||\n\t      (isFunction(list.listener) && list.listener === listener)) {\n\t    delete this._events[type];\n\t    if (this._events.removeListener)\n\t      this.emit('removeListener', type, listener);\n\t\n\t  } else if (isObject(list)) {\n\t    for (i = length; i-- > 0;) {\n\t      if (list[i] === listener ||\n\t          (list[i].listener && list[i].listener === listener)) {\n\t        position = i;\n\t        break;\n\t      }\n\t    }\n\t\n\t    if (position < 0)\n\t      return this;\n\t\n\t    if (list.length === 1) {\n\t      list.length = 0;\n\t      delete this._events[type];\n\t    } else {\n\t      list.splice(position, 1);\n\t    }\n\t\n\t    if (this._events.removeListener)\n\t      this.emit('removeListener', type, listener);\n\t  }\n\t\n\t  return this;\n\t};\n\t\n\tEventEmitter.prototype.removeAllListeners = function(type) {\n\t  var key, listeners;\n\t\n\t  if (!this._events)\n\t    return this;\n\t\n\t  // not listening for removeListener, no need to emit\n\t  if (!this._events.removeListener) {\n\t    if (arguments.length === 0)\n\t      this._events = {};\n\t    else if (this._events[type])\n\t      delete this._events[type];\n\t    return this;\n\t  }\n\t\n\t  // emit removeListener for all listeners on all events\n\t  if (arguments.length === 0) {\n\t    for (key in this._events) {\n\t      if (key === 'removeListener') continue;\n\t      this.removeAllListeners(key);\n\t    }\n\t    this.removeAllListeners('removeListener');\n\t    this._events = {};\n\t    return this;\n\t  }\n\t\n\t  listeners = this._events[type];\n\t\n\t  if (isFunction(listeners)) {\n\t    this.removeListener(type, listeners);\n\t  } else if (listeners) {\n\t    // LIFO order\n\t    while (listeners.length)\n\t      this.removeListener(type, listeners[listeners.length - 1]);\n\t  }\n\t  delete this._events[type];\n\t\n\t  return this;\n\t};\n\t\n\tEventEmitter.prototype.listeners = function(type) {\n\t  var ret;\n\t  if (!this._events || !this._events[type])\n\t    ret = [];\n\t  else if (isFunction(this._events[type]))\n\t    ret = [this._events[type]];\n\t  else\n\t    ret = this._events[type].slice();\n\t  return ret;\n\t};\n\t\n\tEventEmitter.prototype.listenerCount = function(type) {\n\t  if (this._events) {\n\t    var evlistener = this._events[type];\n\t\n\t    if (isFunction(evlistener))\n\t      return 1;\n\t    else if (evlistener)\n\t      return evlistener.length;\n\t  }\n\t  return 0;\n\t};\n\t\n\tEventEmitter.listenerCount = function(emitter, type) {\n\t  return emitter.listenerCount(type);\n\t};\n\t\n\tfunction isFunction(arg) {\n\t  return typeof arg === 'function';\n\t}\n\t\n\tfunction isNumber(arg) {\n\t  return typeof arg === 'number';\n\t}\n\t\n\tfunction isObject(arg) {\n\t  return typeof arg === 'object' && arg !== null;\n\t}\n\t\n\tfunction isUndefined(arg) {\n\t  return arg === void 0;\n\t}\n\n\n/***/ },\n/* 75 */\n/***/ function(module, exports) {\n\n\t\n\t/**\n\t * isArray\n\t */\n\t\n\tvar isArray = Array.isArray;\n\t\n\t/**\n\t * toString\n\t */\n\t\n\tvar str = Object.prototype.toString;\n\t\n\t/**\n\t * Whether or not the given `val`\n\t * is an array.\n\t *\n\t * example:\n\t *\n\t *        isArray([]);\n\t *        // > true\n\t *        isArray(arguments);\n\t *        // > false\n\t *        isArray('');\n\t *        // > false\n\t *\n\t * @param {mixed} val\n\t * @return {bool}\n\t */\n\t\n\tmodule.exports = isArray || function (val) {\n\t  return !! val && '[object Array]' == str.call(val);\n\t};\n\n\n/***/ },\n/* 76 */\n/***/ function(module, exports, __webpack_require__) {\n\n\t// the whatwg-fetch polyfill installs the fetch() function\n\t// on the global object (window or self)\n\t//\n\t// Return that as the export for use in Webpack, Browserify etc.\n\t__webpack_require__(97);\n\tmodule.exports = self.fetch.bind(self);\n\n\n/***/ },\n/* 77 */\n/***/ function(module, exports) {\n\n\t'use strict';\n\t\n\tfunction pad(str, padWith, upToLength) {\n\t  var padding = '';\n\t  var targetLength = upToLength - str.length;\n\t  while (padding.length < targetLength) {\n\t    padding += padWith;\n\t  }\n\t  return padding;\n\t}\n\t\n\texports.padLeft = function (str, padWith, upToLength) {\n\t  var padding = pad(str, padWith, upToLength);\n\t  return padding + str;\n\t};\n\t\n\texports.padRight = function (str, padWith, upToLength) {\n\t  var padding = pad(str, padWith, upToLength);\n\t  return str + padding;\n\t};\n\t\n\texports.stringLexCompare = function (a, b) {\n\t\n\t  var aLen = a.length;\n\t  var bLen = b.length;\n\t\n\t  var i;\n\t  for (i = 0; i < aLen; i++) {\n\t    if (i === bLen) {\n\t      // b is shorter substring of a\n\t      return 1;\n\t    }\n\t    var aChar = a.charAt(i);\n\t    var bChar = b.charAt(i);\n\t    if (aChar !== bChar) {\n\t      return aChar < bChar ? -1 : 1;\n\t    }\n\t  }\n\t\n\t  if (aLen < bLen) {\n\t    // a is shorter substring of b\n\t    return -1;\n\t  }\n\t\n\t  return 0;\n\t};\n\t\n\t/*\n\t * returns the decimal form for the given integer, i.e. writes\n\t * out all the digits (in base-10) instead of using scientific notation\n\t */\n\texports.intToDecimalForm = function (int) {\n\t\n\t  var isNeg = int < 0;\n\t  var result = '';\n\t\n\t  do {\n\t    var remainder = isNeg ? -Math.ceil(int % 10) : Math.floor(int % 10);\n\t\n\t    result = remainder + result;\n\t    int = isNeg ? Math.ceil(int / 10) : Math.floor(int / 10);\n\t  } while (int);\n\t\n\t\n\t  if (isNeg && result !== '0') {\n\t    result = '-' + result;\n\t  }\n\t\n\t  return result;\n\t};\n\n/***/ },\n/* 78 */\n/***/ function(module, exports, __webpack_require__) {\n\n\t'use strict';\n\t\n\tvar upsert = __webpack_require__(30);\n\tvar utils = __webpack_require__(15);\n\tvar Promise = utils.Promise;\n\t\n\tfunction stringify(input) {\n\t  if (!input) {\n\t    return 'undefined'; // backwards compat for empty reduce\n\t  }\n\t  // for backwards compat with mapreduce, functions/strings are stringified\n\t  // as-is. everything else is JSON-stringified.\n\t  switch (typeof input) {\n\t    case 'function':\n\t      // e.g. a mapreduce map\n\t      return input.toString();\n\t    case 'string':\n\t      // e.g. a mapreduce built-in _reduce function\n\t      return input.toString();\n\t    default:\n\t      // e.g. a JSON object in the case of mango queries\n\t      return JSON.stringify(input);\n\t  }\n\t}\n\t\n\tmodule.exports = function (opts) {\n\t  var sourceDB = opts.db;\n\t  var viewName = opts.viewName;\n\t  var mapFun = opts.map;\n\t  var reduceFun = opts.reduce;\n\t  var temporary = opts.temporary;\n\t  var pluginName = opts.pluginName;\n\t\n\t  // the \"undefined\" part is for backwards compatibility\n\t  var viewSignature = stringify(mapFun) + stringify(reduceFun) +\n\t    'undefined';\n\t\n\t  if (!temporary && sourceDB._cachedViews) {\n\t    var cachedView = sourceDB._cachedViews[viewSignature];\n\t    if (cachedView) {\n\t      return Promise.resolve(cachedView);\n\t    }\n\t  }\n\t\n\t  return sourceDB.info().then(function (info) {\n\t\n\t    var depDbName = info.db_name + '-mrview-' +\n\t      (temporary ? 'temp' : utils.MD5(viewSignature));\n\t\n\t    // save the view name in the source PouchDB so it can be cleaned up if necessary\n\t    // (e.g. when the _design doc is deleted, remove all associated view data)\n\t    function diffFunction(doc) {\n\t      doc.views = doc.views || {};\n\t      var fullViewName = viewName;\n\t      if (fullViewName.indexOf('/') === -1) {\n\t        fullViewName = viewName + '/' + viewName;\n\t      }\n\t      var depDbs = doc.views[fullViewName] = doc.views[fullViewName] || {};\n\t      /* istanbul ignore if */\n\t      if (depDbs[depDbName]) {\n\t        return; // no update necessary\n\t      }\n\t      depDbs[depDbName] = true;\n\t      return doc;\n\t    }\n\t    return upsert(sourceDB, '_local/' + pluginName, diffFunction).then(function () {\n\t      return sourceDB.registerDependentDatabase(depDbName).then(function (res) {\n\t        var db = res.db;\n\t        db.auto_compaction = true;\n\t        var view = {\n\t          name: depDbName,\n\t          db: db, \n\t          sourceDB: sourceDB,\n\t          adapter: sourceDB.adapter,\n\t          mapFun: mapFun,\n\t          reduceFun: reduceFun\n\t        };\n\t        return view.db.get('_local/lastSeq').catch(function (err) {\n\t          /* istanbul ignore if */\n\t          if (err.status !== 404) {\n\t            throw err;\n\t          }\n\t        }).then(function (lastSeqDoc) {\n\t          view.seq = lastSeqDoc ? lastSeqDoc.seq : 0;\n\t          if (!temporary) {\n\t            sourceDB._cachedViews = sourceDB._cachedViews || {};\n\t            sourceDB._cachedViews[viewSignature] = view;\n\t            view.db.on('destroyed', function () {\n\t              delete sourceDB._cachedViews[viewSignature];\n\t            });\n\t          }\n\t          return view;\n\t        });\n\t      });\n\t    });\n\t  });\n\t};\n\n\n/***/ },\n/* 79 */\n/***/ function(module, exports, __webpack_require__) {\n\n\t/* WEBPACK VAR INJECTION */(function(process) {'use strict';\n\t\n\tvar pouchCollate = __webpack_require__(8);\n\tvar TaskQueue = __webpack_require__(80);\n\tvar collate = pouchCollate.collate;\n\tvar toIndexableString = pouchCollate.toIndexableString;\n\tvar normalizeKey = pouchCollate.normalizeKey;\n\tvar createView = __webpack_require__(78);\n\tvar log;\n\t/* istanbul ignore else */\n\tif ((typeof console !== 'undefined') && (typeof console.log === 'function')) {\n\t  log = Function.prototype.bind.call(console.log, console);\n\t} else {\n\t  log = function () {};\n\t}\n\tvar utils = __webpack_require__(15);\n\tvar Promise = utils.Promise;\n\tvar persistentQueues = {};\n\tvar tempViewQueue = new TaskQueue();\n\tvar CHANGES_BATCH_SIZE = 50;\n\t\n\tfunction QueryParseError(message) {\n\t  this.status = 400;\n\t  this.name = 'query_parse_error';\n\t  this.message = message;\n\t  this.error = true;\n\t  try {\n\t    Error.captureStackTrace(this, QueryParseError);\n\t  } catch (e) {}\n\t}\n\t\n\tutils.inherits(QueryParseError, Error);\n\t\n\tfunction NotFoundError(message) {\n\t  this.status = 404;\n\t  this.name = 'not_found';\n\t  this.message = message;\n\t  this.error = true;\n\t  try {\n\t    Error.captureStackTrace(this, NotFoundError);\n\t  } catch (e) {}\n\t}\n\t\n\tutils.inherits(NotFoundError, Error);\n\t\n\tfunction parseViewName(name) {\n\t  // can be either 'ddocname/viewname' or just 'viewname'\n\t  // (where the ddoc name is the same)\n\t  return name.indexOf('/') === -1 ? [name, name] : name.split('/');\n\t}\n\t\n\tfunction isGenOne(changes) {\n\t  // only return true if the current change is 1-\n\t  // and there are no other leafs\n\t  return changes.length === 1 && /^1-/.test(changes[0].rev);\n\t}\n\t\n\tfunction sortByKeyThenValue(x, y) {\n\t  var keyCompare = collate(x.key, y.key);\n\t  return keyCompare !== 0 ? keyCompare : collate(x.value, y.value);\n\t}\n\t\n\tfunction sliceResults(results, limit, skip) {\n\t  skip = skip || 0;\n\t  if (typeof limit === 'number') {\n\t    return results.slice(skip, limit + skip);\n\t  } else if (skip > 0) {\n\t    return results.slice(skip);\n\t  }\n\t  return results;\n\t}\n\t\n\tfunction rowToDocId(row) {\n\t  var val = row.value;\n\t  // Users can explicitly specify a joined doc _id, or it\n\t  // defaults to the doc _id that emitted the key/value.\n\t  var docId = (val && typeof val === 'object' && val._id) || row.id;\n\t  return docId;\n\t}\n\t\n\tfunction emitError(db, e) {\n\t  try {\n\t    db.emit('error', e);\n\t  } catch (err) {\n\t    console.error(\n\t      'The user\\'s map/reduce function threw an uncaught error.\\n' +\n\t      'You can debug this error by doing:\\n' +\n\t      'myDatabase.on(\\'error\\', function (err) { debugger; });\\n' +\n\t      'Please double-check your map/reduce function.');\n\t    console.error(e);\n\t  }\n\t}\n\t\n\tfunction tryCode(db, fun, args) {\n\t  // emit an event if there was an error thrown by a map/reduce function.\n\t  // putting try/catches in a single function also avoids deoptimizations.\n\t  try {\n\t    return {\n\t      output : fun.apply(null, args)\n\t    };\n\t  } catch (e) {\n\t    emitError(db, e);\n\t    return {error: e};\n\t  }\n\t}\n\t\n\tfunction checkQueryParseError(options, fun) {\n\t  var startkeyName = options.descending ? 'endkey' : 'startkey';\n\t  var endkeyName = options.descending ? 'startkey' : 'endkey';\n\t\n\t  if (typeof options[startkeyName] !== 'undefined' &&\n\t    typeof options[endkeyName] !== 'undefined' &&\n\t    collate(options[startkeyName], options[endkeyName]) > 0) {\n\t    throw new QueryParseError('No rows can match your key range, reverse your ' +\n\t    'start_key and end_key or set {descending : true}');\n\t  } else if (fun.reduce && options.reduce !== false) {\n\t    if (options.include_docs) {\n\t      throw new QueryParseError('{include_docs:true} is invalid for reduce');\n\t    } else if (options.keys && options.keys.length > 1 &&\n\t      !options.group && !options.group_level) {\n\t      throw new QueryParseError('Multi-key fetches for reduce views must use {group: true}');\n\t    }\n\t  }\n\t  if (options.group_level) {\n\t    if (typeof options.group_level !== 'number') {\n\t      throw new QueryParseError('Invalid value for integer: \"' + options.group_level + '\"');\n\t    }\n\t    if (options.group_level < 0) {\n\t      throw new QueryParseError('Invalid value for positive integer: ' +\n\t      '\"' + options.group_level + '\"');\n\t    }\n\t  }\n\t}\n\t\n\tfunction defaultsTo(value) {\n\t  return function (reason) {\n\t    /* istanbul ignore else */\n\t    if (reason.status === 404) {\n\t      return value;\n\t    } else {\n\t      throw reason;\n\t    }\n\t  };\n\t}\n\t\n\tfunction createIndexer(def) {\n\t\n\t  var pluginName = def.name;\n\t  var mapper = def.mapper;\n\t  var reducer = def.reducer;\n\t  var ddocValidator = def.ddocValidator;\n\t\n\t\n\t  // returns a promise for a list of docs to update, based on the input docId.\n\t  // the order doesn't matter, because post-3.2.0, bulkDocs\n\t  // is an atomic operation in all three adapters.\n\t  function getDocsToPersist(docId, view, docIdsToChangesAndEmits) {\n\t    var metaDocId = '_local/doc_' + docId;\n\t    var defaultMetaDoc = {_id: metaDocId, keys: []};\n\t    var docData = docIdsToChangesAndEmits[docId];\n\t    var indexableKeysToKeyValues = docData.indexableKeysToKeyValues;\n\t    var changes = docData.changes;\n\t\n\t    function getMetaDoc() {\n\t      if (isGenOne(changes)) {\n\t        // generation 1, so we can safely assume initial state\n\t        // for performance reasons (avoids unnecessary GETs)\n\t        return Promise.resolve(defaultMetaDoc);\n\t      }\n\t      return view.db.get(metaDocId).catch(defaultsTo(defaultMetaDoc));\n\t    }\n\t\n\t    function getKeyValueDocs(metaDoc) {\n\t      if (!metaDoc.keys.length) {\n\t        // no keys, no need for a lookup\n\t        return Promise.resolve({rows: []});\n\t      }\n\t      return view.db.allDocs({\n\t        keys: metaDoc.keys,\n\t        include_docs: true\n\t      });\n\t    }\n\t\n\t    function processKvDocs(metaDoc, kvDocsRes) {\n\t      var kvDocs = [];\n\t      var oldKeysMap = {};\n\t\n\t      for (var i = 0, len = kvDocsRes.rows.length; i < len; i++) {\n\t        var row = kvDocsRes.rows[i];\n\t        var doc = row.doc;\n\t        if (!doc) { // deleted\n\t          continue;\n\t        }\n\t        kvDocs.push(doc);\n\t        oldKeysMap[doc._id] = true;\n\t        doc._deleted = !indexableKeysToKeyValues[doc._id];\n\t        if (!doc._deleted) {\n\t          var keyValue = indexableKeysToKeyValues[doc._id];\n\t          if ('value' in keyValue) {\n\t            doc.value = keyValue.value;\n\t          }\n\t        }\n\t      }\n\t\n\t      var newKeys = Object.keys(indexableKeysToKeyValues);\n\t      newKeys.forEach(function (key) {\n\t        if (!oldKeysMap[key]) {\n\t          // new doc\n\t          var kvDoc = {\n\t            _id: key\n\t          };\n\t          var keyValue = indexableKeysToKeyValues[key];\n\t          if ('value' in keyValue) {\n\t            kvDoc.value = keyValue.value;\n\t          }\n\t          kvDocs.push(kvDoc);\n\t        }\n\t      });\n\t      metaDoc.keys = utils.uniq(newKeys.concat(metaDoc.keys));\n\t      kvDocs.push(metaDoc);\n\t\n\t      return kvDocs;\n\t    }\n\t\n\t    return getMetaDoc().then(function (metaDoc) {\n\t      return getKeyValueDocs(metaDoc).then(function (kvDocsRes) {\n\t        return processKvDocs(metaDoc, kvDocsRes);\n\t      });\n\t    });\n\t  }\n\t\n\t  // updates all emitted key/value docs and metaDocs in the mrview database\n\t  // for the given batch of documents from the source database\n\t  function saveKeyValues(view, docIdsToChangesAndEmits, seq) {\n\t    var seqDocId = '_local/lastSeq';\n\t    return view.db.get(seqDocId)\n\t    .catch(defaultsTo({_id: seqDocId, seq: 0}))\n\t    .then(function (lastSeqDoc) {\n\t      var docIds = Object.keys(docIdsToChangesAndEmits);\n\t      return Promise.all(docIds.map(function (docId) {\n\t        return getDocsToPersist(docId, view, docIdsToChangesAndEmits);\n\t      })).then(function (listOfDocsToPersist) {\n\t        var docsToPersist = utils.flatten(listOfDocsToPersist);\n\t        lastSeqDoc.seq = seq;\n\t        docsToPersist.push(lastSeqDoc);\n\t        // write all docs in a single operation, update the seq once\n\t        return view.db.bulkDocs({docs : docsToPersist});\n\t      });\n\t    });\n\t  }\n\t\n\t  function getQueue(view) {\n\t    var viewName = typeof view === 'string' ? view : view.name;\n\t    var queue = persistentQueues[viewName];\n\t    if (!queue) {\n\t      queue = persistentQueues[viewName] = new TaskQueue();\n\t    }\n\t    return queue;\n\t  }\n\t\n\t  function updateView(view) {\n\t    return utils.sequentialize(getQueue(view), function () {\n\t      return updateViewInQueue(view);\n\t    })();\n\t  }\n\t\n\t  function updateViewInQueue(view) {\n\t    // bind the emit function once\n\t    var mapResults;\n\t    var doc;\n\t\n\t    function emit(key, value) {\n\t      var output = {id: doc._id, key: normalizeKey(key)};\n\t      // Don't explicitly store the value unless it's defined and non-null.\n\t      // This saves on storage space, because often people don't use it.\n\t      if (typeof value !== 'undefined' && value !== null) {\n\t        output.value = normalizeKey(value);\n\t      }\n\t      mapResults.push(output);\n\t    }\n\t\n\t    var mapFun = mapper(view.mapFun, emit);\n\t\n\t    var currentSeq = view.seq || 0;\n\t\n\t    function processChange(docIdsToChangesAndEmits, seq) {\n\t      return function () {\n\t        return saveKeyValues(view, docIdsToChangesAndEmits, seq);\n\t      };\n\t    }\n\t\n\t    var queue = new TaskQueue();\n\t\n\t    return new Promise(function (resolve, reject) {\n\t\n\t      function complete() {\n\t        queue.finish().then(function () {\n\t          view.seq = currentSeq;\n\t          resolve();\n\t        });\n\t      }\n\t\n\t      function processNextBatch() {\n\t        view.sourceDB.changes({\n\t          conflicts: true,\n\t          include_docs: true,\n\t          style: 'all_docs',\n\t          since: currentSeq,\n\t          limit: CHANGES_BATCH_SIZE\n\t        }).on('complete', function (response) {\n\t          var results = response.results;\n\t          if (!results.length) {\n\t            return complete();\n\t          }\n\t          var docIdsToChangesAndEmits = {};\n\t          for (var i = 0, l = results.length; i < l; i++) {\n\t            var change = results[i];\n\t            if (change.doc._id[0] !== '_') {\n\t              mapResults = [];\n\t              doc = change.doc;\n\t\n\t              if (!doc._deleted) {\n\t                tryCode(view.sourceDB, mapFun, [doc]);\n\t              }\n\t              mapResults.sort(sortByKeyThenValue);\n\t\n\t              var indexableKeysToKeyValues = {};\n\t              var lastKey;\n\t              for (var j = 0, jl = mapResults.length; j < jl; j++) {\n\t                var obj = mapResults[j];\n\t                var complexKey = [obj.key, obj.id];\n\t                if (collate(obj.key, lastKey) === 0) {\n\t                  complexKey.push(j); // dup key+id, so make it unique\n\t                }\n\t                var indexableKey = toIndexableString(complexKey);\n\t                indexableKeysToKeyValues[indexableKey] = obj;\n\t                lastKey = obj.key;\n\t              }\n\t              docIdsToChangesAndEmits[change.doc._id] = {\n\t                indexableKeysToKeyValues: indexableKeysToKeyValues,\n\t                changes: change.changes\n\t              };\n\t            }\n\t            currentSeq = change.seq;\n\t          }\n\t          queue.add(processChange(docIdsToChangesAndEmits, currentSeq));\n\t          if (results.length < CHANGES_BATCH_SIZE) {\n\t            return complete();\n\t          }\n\t          return processNextBatch();\n\t        }).on('error', onError);\n\t        /* istanbul ignore next */\n\t        function onError(err) {\n\t          reject(err);\n\t        }\n\t      }\n\t\n\t      processNextBatch();\n\t    });\n\t  }\n\t\n\t  function reduceView(view, results, options) {\n\t    if (options.group_level === 0) {\n\t      delete options.group_level;\n\t    }\n\t\n\t    var shouldGroup = options.group || options.group_level;\n\t\n\t    var reduceFun = reducer(view.reduceFun);\n\t\n\t    var groups = [];\n\t    var lvl = options.group_level;\n\t    results.forEach(function (e) {\n\t      var last = groups[groups.length - 1];\n\t      var key = shouldGroup ? e.key : null;\n\t\n\t      // only set group_level for array keys\n\t      if (shouldGroup && Array.isArray(key) && typeof lvl === 'number') {\n\t        key = key.length > lvl ? key.slice(0, lvl) : key;\n\t      }\n\t\n\t      if (last && collate(last.key[0][0], key) === 0) {\n\t        last.key.push([key, e.id]);\n\t        last.value.push(e.value);\n\t        return;\n\t      }\n\t      groups.push({key: [\n\t        [key, e.id]\n\t      ], value: [e.value]});\n\t    });\n\t    for (var i = 0, len = groups.length; i < len; i++) {\n\t      var e = groups[i];\n\t      var reduceTry = tryCode(view.sourceDB, reduceFun, [e.key, e.value, false]);\n\t      // TODO: can't do instanceof BuiltInError because this class is buried\n\t      // in mapreduce.js\n\t      if (reduceTry.error && /BuiltInError/.test(reduceTry.error.constructor)) {\n\t        // CouchDB returns an error if a built-in errors out\n\t        throw reduceTry.error;\n\t      }\n\t      // CouchDB just sets the value to null if a non-built-in errors out\n\t      e.value = reduceTry.error ? null : reduceTry.output;\n\t      e.key = e.key[0][0];\n\t    }\n\t    // no total_rows/offset when reducing\n\t    return {rows: sliceResults(groups, options.limit, options.skip)};\n\t  }\n\t\n\t  function queryView(view, opts) {\n\t    return utils.sequentialize(getQueue(view), function () {\n\t      return queryViewInQueue(view, opts);\n\t    })();\n\t  }\n\t\n\t  function queryViewInQueue(view, opts) {\n\t    var totalRows;\n\t    var shouldReduce = view.reduceFun && opts.reduce !== false;\n\t    var skip = opts.skip || 0;\n\t    if (typeof opts.keys !== 'undefined' && !opts.keys.length) {\n\t      // equivalent query\n\t      opts.limit = 0;\n\t      delete opts.keys;\n\t    }\n\t\n\t    function fetchFromView(viewOpts) {\n\t      viewOpts.include_docs = true;\n\t      return view.db.allDocs(viewOpts).then(function (res) {\n\t        totalRows = res.total_rows;\n\t        return res.rows.map(function (result) {\n\t\n\t          // implicit migration - in older versions of PouchDB,\n\t          // we explicitly stored the doc as {id: ..., key: ..., value: ...}\n\t          // this is tested in a migration test\n\t          /* istanbul ignore next */\n\t          if ('value' in result.doc && typeof result.doc.value === 'object' &&\n\t              result.doc.value !== null) {\n\t            var keys = Object.keys(result.doc.value).sort();\n\t            // this detection method is not perfect, but it's unlikely the user\n\t            // emitted a value which was an object with these 3 exact keys\n\t            var expectedKeys = ['id', 'key', 'value'];\n\t            if (!(keys < expectedKeys || keys > expectedKeys)) {\n\t              return result.doc.value;\n\t            }\n\t          }\n\t\n\t          var parsedKeyAndDocId = pouchCollate.parseIndexableString(result.doc._id);\n\t          return {\n\t            key: parsedKeyAndDocId[0],\n\t            id: parsedKeyAndDocId[1],\n\t            value: ('value' in result.doc ? result.doc.value : null)\n\t          };\n\t        });\n\t      });\n\t    }\n\t\n\t    function onMapResultsReady(rows) {\n\t      var finalResults;\n\t      if (shouldReduce) {\n\t        finalResults = reduceView(view, rows, opts);\n\t      } else {\n\t        finalResults = {\n\t          total_rows: totalRows,\n\t          offset: skip,\n\t          rows: rows\n\t        };\n\t      }\n\t      if (opts.include_docs) {\n\t        var docIds = utils.uniq(rows.map(rowToDocId));\n\t\n\t        return view.sourceDB.allDocs({\n\t          keys: docIds,\n\t          include_docs: true,\n\t          conflicts: opts.conflicts,\n\t          attachments: opts.attachments,\n\t          binary: opts.binary\n\t        }).then(function (allDocsRes) {\n\t          var docIdsToDocs = {};\n\t          allDocsRes.rows.forEach(function (row) {\n\t            if (row.doc) {\n\t              docIdsToDocs['$' + row.id] = row.doc;\n\t            }\n\t          });\n\t          rows.forEach(function (row) {\n\t            var docId = rowToDocId(row);\n\t            var doc = docIdsToDocs['$' + docId];\n\t            if (doc) {\n\t              row.doc = doc;\n\t            }\n\t          });\n\t          return finalResults;\n\t        });\n\t      } else {\n\t        return finalResults;\n\t      }\n\t    }\n\t\n\t    var flatten = function (array) {\n\t      return array.reduce(function (prev, cur) {\n\t        return prev.concat(cur);\n\t      });\n\t    };\n\t\n\t    if (typeof opts.keys !== 'undefined') {\n\t      var keys = opts.keys;\n\t      var fetchPromises = keys.map(function (key) {\n\t        var viewOpts = {\n\t          startkey : toIndexableString([key]),\n\t          endkey   : toIndexableString([key, {}])\n\t        };\n\t        return fetchFromView(viewOpts);\n\t      });\n\t      return Promise.all(fetchPromises).then(flatten).then(onMapResultsReady);\n\t    } else { // normal query, no 'keys'\n\t      var viewOpts = {\n\t        descending : opts.descending\n\t      };\n\t      if (typeof opts.startkey !== 'undefined') {\n\t        viewOpts.startkey = opts.descending ?\n\t          toIndexableString([opts.startkey, {}]) :\n\t          toIndexableString([opts.startkey]);\n\t      }\n\t      if (typeof opts.endkey !== 'undefined') {\n\t        var inclusiveEnd = opts.inclusive_end !== false;\n\t        if (opts.descending) {\n\t          inclusiveEnd = !inclusiveEnd;\n\t        }\n\t\n\t        viewOpts.endkey = toIndexableString(inclusiveEnd ? [opts.endkey, {}] : [opts.endkey]);\n\t      }\n\t      if (typeof opts.key !== 'undefined') {\n\t        var keyStart = toIndexableString([opts.key]);\n\t        var keyEnd = toIndexableString([opts.key, {}]);\n\t        if (viewOpts.descending) {\n\t          viewOpts.endkey = keyStart;\n\t          viewOpts.startkey = keyEnd;\n\t        } else {\n\t          viewOpts.startkey = keyStart;\n\t          viewOpts.endkey = keyEnd;\n\t        }\n\t      }\n\t      if (!shouldReduce) {\n\t        if (typeof opts.limit === 'number') {\n\t          viewOpts.limit = opts.limit;\n\t        }\n\t        viewOpts.skip = skip;\n\t      }\n\t      return fetchFromView(viewOpts).then(onMapResultsReady);\n\t    }\n\t  }\n\t\n\t  function localViewCleanup(db) {\n\t    return db.get('_local/' + pluginName).then(function (metaDoc) {\n\t      var docsToViews = {};\n\t      Object.keys(metaDoc.views).forEach(function (fullViewName) {\n\t        var parts = parseViewName(fullViewName);\n\t        var designDocName = '_design/' + parts[0];\n\t        var viewName = parts[1];\n\t        docsToViews[designDocName] = docsToViews[designDocName] || {};\n\t        docsToViews[designDocName][viewName] = true;\n\t      });\n\t      var opts = {\n\t        keys : Object.keys(docsToViews),\n\t        include_docs : true\n\t      };\n\t      return db.allDocs(opts).then(function (res) {\n\t        var viewsToStatus = {};\n\t        res.rows.forEach(function (row) {\n\t          var ddocName = row.key.substring(8);\n\t          Object.keys(docsToViews[row.key]).forEach(function (viewName) {\n\t            var fullViewName = ddocName + '/' + viewName;\n\t            /* istanbul ignore if */\n\t            if (!metaDoc.views[fullViewName]) {\n\t              // new format, without slashes, to support PouchDB 2.2.0\n\t              // migration test in pouchdb's browser.migration.js verifies this\n\t              fullViewName = viewName;\n\t            }\n\t            var viewDBNames = Object.keys(metaDoc.views[fullViewName]);\n\t            // design doc deleted, or view function nonexistent\n\t            var statusIsGood = row.doc && row.doc.views && row.doc.views[viewName];\n\t            viewDBNames.forEach(function (viewDBName) {\n\t              viewsToStatus[viewDBName] = viewsToStatus[viewDBName] || statusIsGood;\n\t            });\n\t          });\n\t        });\n\t        var dbsToDelete = Object.keys(viewsToStatus).filter(function (viewDBName) {\n\t          return !viewsToStatus[viewDBName];\n\t        });\n\t        var destroyPromises = dbsToDelete.map(function (viewDBName) {\n\t          return utils.sequentialize(getQueue(viewDBName), function () {\n\t            return new db.constructor(viewDBName, db.__opts).destroy();\n\t          })();\n\t        });\n\t        return Promise.all(destroyPromises).then(function () {\n\t          return {ok: true};\n\t        });\n\t      });\n\t    }, defaultsTo({ok: true}));\n\t  }\n\t\n\t  function queryPromised(db, fun, opts) {\n\t    if (typeof fun !== 'string') {\n\t      // temp_view\n\t      checkQueryParseError(opts, fun);\n\t\n\t      var createViewOpts = {\n\t        db : db,\n\t        viewName : 'temp_view/temp_view',\n\t        map : fun.map,\n\t        reduce : fun.reduce,\n\t        temporary : true,\n\t        pluginName: pluginName\n\t      };\n\t      tempViewQueue.add(function () {\n\t        return createView(createViewOpts).then(function (view) {\n\t          function cleanup() {\n\t            return view.db.destroy();\n\t          }\n\t          return utils.fin(updateView(view).then(function () {\n\t            return queryView(view, opts);\n\t          }), cleanup);\n\t        });\n\t      });\n\t      return tempViewQueue.finish();\n\t    } else {\n\t      // persistent view\n\t      var fullViewName = fun;\n\t      var parts = parseViewName(fullViewName);\n\t      var designDocName = parts[0];\n\t      var viewName = parts[1];\n\t      return db.get('_design/' + designDocName).then(function (doc) {\n\t        var fun = doc.views && doc.views[viewName];\n\t\n\t        if (!fun) {\n\t          // basic validator; it's assumed that every subclass would want this\n\t          throw new NotFoundError('ddoc ' + doc._id + ' has no view named ' +\n\t            viewName);\n\t        }\n\t\n\t        ddocValidator(doc, viewName);\n\t        checkQueryParseError(opts, fun);\n\t\n\t        var createViewOpts = {\n\t          db : db,\n\t          viewName : fullViewName,\n\t          map : fun.map,\n\t          reduce : fun.reduce,\n\t          pluginName: pluginName\n\t        };\n\t        return createView(createViewOpts).then(function (view) {\n\t          if (opts.stale === 'ok' || opts.stale === 'update_after') {\n\t            if (opts.stale === 'update_after') {\n\t              process.nextTick(function () {\n\t                updateView(view);\n\t              });\n\t            }\n\t            return queryView(view, opts);\n\t          } else { // stale not ok\n\t            return updateView(view).then(function () {\n\t              return queryView(view, opts);\n\t            });\n\t          }\n\t        });\n\t      });\n\t    }\n\t  }\n\t\n\t  var query = function (fun, opts, callback) {\n\t    var db = this;\n\t    if (typeof opts === 'function') {\n\t      callback = opts;\n\t      opts = {};\n\t    }\n\t    opts = utils.extend(true, {}, opts);\n\t\n\t    if (typeof fun === 'function') {\n\t      fun = {map : fun};\n\t    }\n\t\n\t    var promise = Promise.resolve().then(function () {\n\t      return queryPromised(db, fun, opts);\n\t    });\n\t    utils.promisedCallback(promise, callback);\n\t    return promise;\n\t  };\n\t\n\t  var viewCleanup = utils.callbackify(function () {\n\t    var db = this;\n\t    return localViewCleanup(db);\n\t  });\n\t\n\t  return {\n\t    query: query,\n\t    viewCleanup: viewCleanup\n\t  };\n\t}\n\t\n\tmodule.exports = createIndexer;\n\t\n\t/* WEBPACK VAR INJECTION */}.call(exports, __webpack_require__(5)))\n\n/***/ },\n/* 80 */\n/***/ function(module, exports, __webpack_require__) {\n\n\t'use strict';\n\t/*\n\t * Simple task queue to sequentialize actions. Assumes callbacks will eventually fire (once).\n\t */\n\t\n\tvar Promise = __webpack_require__(15).Promise;\n\t\n\tfunction TaskQueue() {\n\t  this.promise = new Promise(function (fulfill) {fulfill(); });\n\t}\n\tTaskQueue.prototype.add = function (promiseFactory) {\n\t  this.promise = this.promise.catch(function () {\n\t    // just recover\n\t  }).then(function () {\n\t    return promiseFactory();\n\t  });\n\t  return this.promise;\n\t};\n\tTaskQueue.prototype.finish = function () {\n\t  return this.promise;\n\t};\n\t\n\tmodule.exports = TaskQueue;\n\n\n/***/ },\n/* 81 */\n/***/ function(module, exports, __webpack_require__) {\n\n\t'use strict';\n\t\n\tvar massageCreateIndexRequest = __webpack_require__(32);\n\t\n\tfunction createIndex(db, requestDef, callback) {\n\t  requestDef = massageCreateIndexRequest(requestDef);\n\t\n\t  db.request({\n\t    method: 'POST',\n\t    url: '_index',\n\t    body: requestDef\n\t  }, callback);\n\t}\n\t\n\tfunction find(db, requestDef, callback) {\n\t  db.request({\n\t    method: 'POST',\n\t    url: '_find',\n\t    body: requestDef\n\t  }, callback);\n\t}\n\t\n\tfunction getIndexes(db, callback) {\n\t  db.request({\n\t    method: 'GET',\n\t    url: '_index'\n\t  }, callback);\n\t}\n\t\n\tfunction deleteIndex(db, indexDef, callback) {\n\t\n\t\n\t  var ddoc = indexDef.ddoc;\n\t  var type = indexDef.type || 'json';\n\t  var name = indexDef.name;\n\t\n\t  if (!ddoc) {\n\t    return callback(new Error('you must provide an index\\'s ddoc'));\n\t  }\n\t\n\t  if (!name) {\n\t    return callback(new Error('you must provide an index\\'s name'));\n\t  }\n\t\n\t  var url = '_index/' + [ddoc, type, name].map(encodeURIComponent).join('/');\n\t\n\t  db.request({\n\t    method: 'DELETE',\n\t    url: url\n\t  }, callback);\n\t}\n\t\n\texports.createIndex = createIndex;\n\texports.find = find;\n\texports.getIndexes = getIndexes;\n\texports.deleteIndex = deleteIndex;\n\n/***/ },\n/* 82 */\n/***/ function(module, exports, __webpack_require__) {\n\n\t'use strict';\n\t\n\tvar utils = __webpack_require__(2);\n\tvar log = utils.log;\n\t\n\tvar pouchUpsert = __webpack_require__(35);\n\tvar abstractMapper = __webpack_require__(16);\n\tvar localUtils = __webpack_require__(4);\n\tvar validateIndex = localUtils.validateIndex;\n\tvar massageIndexDef = localUtils.massageIndexDef;\n\tvar massageCreateIndexRequest = __webpack_require__(32);\n\t\n\tfunction upsert(db, docId, diffFun) {\n\t  return pouchUpsert.upsert.call(db, docId, diffFun);\n\t}\n\t\n\tfunction createIndex(db, requestDef) {\n\t  requestDef = massageCreateIndexRequest(requestDef);\n\t  var originalIndexDef = utils.clone(requestDef.index);\n\t  requestDef.index = massageIndexDef(requestDef.index);\n\t\n\t  validateIndex(requestDef.index);\n\t\n\t  var md5 = utils.MD5(JSON.stringify(requestDef));\n\t\n\t  var viewName = requestDef.name || ('idx-' + md5);\n\t\n\t  var ddocName = requestDef.ddoc || ('idx-' + md5);\n\t  var ddocId = '_design/' + ddocName;\n\t\n\t  var hasInvalidLanguage = false;\n\t  var viewExists = false;\n\t\n\t  function updateDdoc(doc) {\n\t    if (doc._rev && doc.language !== 'query') {\n\t      hasInvalidLanguage = true;\n\t    }\n\t    doc.language = 'query';\n\t    doc.views = doc.views || {};\n\t\n\t    viewExists = !!doc.views[viewName];\n\t\n\t    if (viewExists) {\n\t      return false;\n\t    }\n\t\n\t    doc.views[viewName] = {\n\t      map: {\n\t        fields: utils.mergeObjects(requestDef.index.fields)\n\t      },\n\t      reduce: '_count',\n\t      options: {\n\t        def: originalIndexDef\n\t      }\n\t    };\n\t\n\t    return doc;\n\t  }\n\t\n\t  log('creating index', ddocId);\n\t\n\t  return upsert(db, ddocId, updateDdoc).then(function () {\n\t    if (hasInvalidLanguage) {\n\t      throw new Error('invalid language for ddoc with id \"' +\n\t      ddocId +\n\t      '\" (should be \"query\")');\n\t    }\n\t  }).then(function () {\n\t    // kick off a build\n\t    // TODO: abstract-pouchdb-mapreduce should support auto-updating\n\t    // TODO: should also use update_after, but pouchdb/pouchdb#3415 blocks me\n\t    var signature = ddocName + '/' + viewName;\n\t    return abstractMapper.query.call(db, signature, {\n\t      limit: 0,\n\t      reduce: false\n\t    }).then(function () {\n\t      return {\n\t        id: ddocId,\n\t        name: viewName,\n\t        result: viewExists ? 'exists' : 'created'\n\t      };\n\t    });\n\t  });\n\t}\n\t\n\tmodule.exports = createIndex;\n\n\n/***/ },\n/* 83 */\n/***/ function(module, exports, __webpack_require__) {\n\n\t'use strict';\n\t\n\tvar abstractMapper = __webpack_require__(16);\n\tvar upsert = __webpack_require__(30);\n\t\n\tfunction deleteIndex(db, index) {\n\t\n\t  if (!index.ddoc) {\n\t    throw new Error('you must supply an index.ddoc when deleting');\n\t  }\n\t\n\t  if (!index.name) {\n\t    throw new Error('you must supply an index.name when deleting');\n\t  }\n\t\n\t  var docId = index.ddoc;\n\t  var viewName = index.name;\n\t\n\t  function deltaFun (doc) {\n\t    if (Object.keys(doc.views).length === 1 && doc.views[viewName]) {\n\t      // only one view in this ddoc, delete the whole ddoc\n\t      return {_id: docId, _deleted: true};\n\t    }\n\t    // more than one view here, just remove the view\n\t    delete doc.views[viewName];\n\t    return doc;\n\t  }\n\t\n\t  return upsert(db, docId, deltaFun).then(function () {\n\t    return abstractMapper.viewCleanup.apply(db);\n\t  }).then(function () {\n\t    return {ok: true};\n\t  });\n\t}\n\t\n\tmodule.exports = deleteIndex;\n\n/***/ },\n/* 84 */\n/***/ function(module, exports, __webpack_require__) {\n\n\t'use strict';\n\t\n\t//\n\t// Do an in-memory filtering of rows that aren't covered by the index.\n\t// E.g. if the user is asking for foo=1 and bar=2, but the index\n\t// only covers \"foo\", then this in-memory filter would take care of\n\t// \"bar\".\n\t//\n\t\n\tvar isArray = __webpack_require__(75);\n\tvar collate = __webpack_require__(8).collate;\n\tvar localUtils = __webpack_require__(4);\n\tvar isCombinationalField = localUtils.isCombinationalField;\n\tvar getKey = localUtils.getKey;\n\tvar getValue = localUtils.getValue;\n\tvar parseField = localUtils.parseField;\n\tvar utils = __webpack_require__(2);\n\tvar getFieldFromDoc = utils.getFieldFromDoc;\n\t\n\t// create a comparator based on the sort object\n\tfunction createFieldSorter(sort) {\n\t\n\t  function getFieldValuesAsArray(doc) {\n\t    return sort.map(function (sorting) {\n\t      var fieldName = getKey(sorting);\n\t      var parsedField = parseField(fieldName);\n\t      var docFieldValue = getFieldFromDoc(doc, parsedField);\n\t      return docFieldValue;\n\t    });\n\t  }\n\t\n\t  return function (aRow, bRow) {\n\t    var aFieldValues = getFieldValuesAsArray(aRow.doc);\n\t    var bFieldValues = getFieldValuesAsArray(bRow.doc);\n\t    var collation = collate(aFieldValues, bFieldValues);\n\t    if (collation !== 0) {\n\t      return collation;\n\t    }\n\t    // this is what mango seems to do\n\t    return utils.compare(aRow.doc._id, bRow.doc._id);\n\t  };\n\t}\n\t\n\tfunction filterInMemoryFields (rows, requestDef, inMemoryFields) {\n\t  rows = rows.filter(function (row) {\n\t    return rowFilter(row.doc, requestDef.selector, inMemoryFields);\n\t  });\n\t\n\t  if (requestDef.sort) {\n\t    // in-memory sort\n\t    var fieldSorter = createFieldSorter(requestDef.sort);\n\t    rows = rows.sort(fieldSorter);\n\t    if (typeof requestDef.sort[0] !== 'string' &&\n\t        getValue(requestDef.sort[0]) === 'desc') {\n\t      rows = rows.reverse();\n\t    }\n\t  }\n\t\n\t  if ('limit' in requestDef || 'skip' in requestDef) {\n\t    // have to do the limit in-memory\n\t    var skip = requestDef.skip || 0;\n\t    var limit = ('limit' in requestDef ? requestDef.limit : rows.length) + skip;\n\t    rows = rows.slice(skip, limit);\n\t  }\n\t  return rows;\n\t}\n\t\n\tfunction rowFilter (doc, selector, inMemoryFields) {\n\t  return inMemoryFields.every(function (field) {\n\t    var matcher = selector[field];\n\t    var parsedField = parseField(field);\n\t    var docFieldValue = getFieldFromDoc(doc, parsedField);\n\t    if (isCombinationalField(field)) {\n\t      return matchCominationalSelector(field, matcher, doc);\n\t    }\n\t\n\t    return matchSelector(matcher, doc, parsedField, docFieldValue);\n\t  });\n\t}\n\t\n\tfunction matchSelector (matcher, doc, parsedField, docFieldValue) {\n\t  if (!matcher) {\n\t    // no filtering necessary; this field is just needed for sorting\n\t    return true;\n\t  }\n\t\n\t  return Object.keys(matcher).every(function (userOperator) {\n\t    var userValue = matcher[userOperator];\n\t    return match(userOperator, doc, userValue, parsedField, docFieldValue);\n\t  });\n\t}\n\t\n\tfunction matchCominationalSelector (field, matcher, doc) {\n\t\n\t  if (field === '$or') {\n\t    return matcher.some(function (orMatchers) {\n\t      return rowFilter(doc, orMatchers, Object.keys(orMatchers));\n\t    });\n\t  }\n\t\n\t  if (field === '$not') {\n\t    return !rowFilter(doc, matcher, Object.keys(matcher));\n\t  }\n\t\n\t  //`$nor`\n\t  return !matcher.find(function (orMatchers) {\n\t    return rowFilter(doc, orMatchers, Object.keys(orMatchers));\n\t  });\n\t\n\t}\n\t\n\tfunction match(userOperator, doc, userValue, parsedField, docFieldValue) {\n\t  if (!matchers[userOperator]) {\n\t    throw new Error('unknown operator \"' + userOperator +\n\t      '\" - should be one of $eq, $lte, $lt, $gt, $gte, $exists, $ne, $in, ' +\n\t      '$nin, $size, $mod, $regex, $elemMatch, $type or $all');\n\t  }\n\t  return matchers[userOperator](doc, userValue, parsedField, docFieldValue);\n\t}\n\t\n\tfunction fieldExists(docFieldValue) {\n\t  return typeof docFieldValue !== 'undefined' && docFieldValue !== null;\n\t}\n\t\n\tfunction fieldIsNotUndefined(docFieldValue) {\n\t  return typeof docFieldValue !== 'undefined';\n\t}\n\t\n\tfunction modField (docFieldValue, userValue) {\n\t  var divisor = userValue[0];\n\t  var mod = userValue[1];\n\t  if (divisor === 0) {\n\t    throw new Error('Bad divisor, cannot divide by zero');\n\t  }\n\t\n\t  if (parseInt(divisor, 10) !== divisor ) {\n\t    throw new Error('Divisor is not an integer');\n\t  }\n\t\n\t  if (parseInt(mod, 10) !== mod ) {\n\t    throw new Error('Modulus is not an integer');\n\t  }\n\t\n\t  if (parseInt(docFieldValue, 10) !== docFieldValue) {\n\t    return false;\n\t  }\n\t\n\t  return docFieldValue % divisor === mod;\n\t}\n\t\n\tfunction arrayContainsValue (docFieldValue, userValue) {\n\t  return userValue.some(function (val) {\n\t    if (docFieldValue instanceof Array) {\n\t      return docFieldValue.indexOf(val) > -1;\n\t    }\n\t\n\t    return docFieldValue === val;\n\t  });\n\t}\n\t\n\tfunction arrayContainsAllValues (docFieldValue, userValue) {\n\t  return userValue.every(function (val) {\n\t    return docFieldValue.indexOf(val) > -1;\n\t  });\n\t}\n\t\n\tfunction arraySize (docFieldValue, userValue) {\n\t  return docFieldValue.length === userValue;\n\t}\n\t\n\tfunction regexMatch(docFieldValue, userValue) {\n\t  var re = new RegExp(userValue);\n\t\n\t  return re.test(docFieldValue);\n\t}\n\t\n\tfunction typeMatch(docFieldValue, userValue) {\n\t\n\t  switch (userValue) {\n\t    case 'null':\n\t      return docFieldValue === null;\n\t    case 'boolean':\n\t      return typeof(docFieldValue) === 'boolean';\n\t    case 'number':\n\t      return typeof(docFieldValue) === 'number';\n\t    case 'string':\n\t      return typeof(docFieldValue) === 'string';\n\t    case 'array':\n\t      return docFieldValue instanceof Array;\n\t    case 'object':\n\t      return ({}).toString.call(docFieldValue) === '[object Object]';\n\t  }\n\t\n\t  throw new Error(userValue + ' not supported as a type.' +\n\t                  'Please use one of object, string, array, number, boolean or null.');\n\t\n\t}\n\t\n\tvar matchers = {\n\t\n\t  '$elemMatch': function (doc, userValue, parsedField, docFieldValue) {\n\t    if (!isArray(docFieldValue)) {\n\t      return false;\n\t    }\n\t\n\t    if (docFieldValue.length === 0) {\n\t      return false;\n\t    }\n\t\n\t    if (typeof docFieldValue[0] === 'object') {\n\t      return docFieldValue.some(function (val) {\n\t        return rowFilter(val, userValue, Object.keys(userValue));\n\t      });\n\t    }\n\t\n\t    return docFieldValue.some(function (val) {\n\t      return matchSelector(userValue, doc, parsedField, val);\n\t    });\n\t  },\n\t\n\t  '$eq': function (doc, userValue, parsedField, docFieldValue) {\n\t    return fieldIsNotUndefined(docFieldValue) && collate(docFieldValue, userValue) === 0;\n\t  },\n\t\n\t  '$gte': function (doc, userValue, parsedField, docFieldValue) {\n\t    return fieldIsNotUndefined(docFieldValue) && collate(docFieldValue, userValue) >= 0;\n\t  },\n\t\n\t  '$gt': function (doc, userValue, parsedField, docFieldValue) {\n\t    return fieldIsNotUndefined(docFieldValue) && collate(docFieldValue, userValue) > 0;\n\t  },\n\t\n\t  '$lte': function (doc, userValue, parsedField, docFieldValue) {\n\t    return fieldIsNotUndefined(docFieldValue) && collate(docFieldValue, userValue) <= 0;\n\t  },\n\t\n\t  '$lt': function (doc, userValue, parsedField, docFieldValue) {\n\t    return fieldIsNotUndefined(docFieldValue) && collate(docFieldValue, userValue) < 0;\n\t  },\n\t\n\t  '$exists': function (doc, userValue, parsedField, docFieldValue) {\n\t    //a field that is null is still considered to exist\n\t    if (userValue) {\n\t      return fieldIsNotUndefined(docFieldValue);\n\t    }\n\t\n\t    return !fieldIsNotUndefined(docFieldValue);\n\t  },\n\t\n\t  '$mod': function (doc, userValue, parsedField, docFieldValue) {\n\t    return fieldExists(docFieldValue) && modField(docFieldValue, userValue);\n\t  },\n\t\n\t  '$ne': function (doc, userValue, parsedField, docFieldValue) {\n\t    return userValue.every(function (neValue) {\n\t      return collate(docFieldValue, neValue) !== 0;\n\t    });\n\t  },\n\t  '$in': function (doc, userValue, parsedField, docFieldValue) {\n\t    return fieldExists(docFieldValue) && arrayContainsValue(docFieldValue, userValue);\n\t  },\n\t\n\t  '$nin': function (doc, userValue, parsedField, docFieldValue) {\n\t    return fieldExists(docFieldValue) && !arrayContainsValue(docFieldValue, userValue);\n\t  },\n\t\n\t  '$size': function (doc, userValue, parsedField, docFieldValue) {\n\t    return fieldExists(docFieldValue) && arraySize(docFieldValue, userValue);\n\t  },\n\t\n\t  '$all': function (doc, userValue, parsedField, docFieldValue) {\n\t    return isArray(docFieldValue) && arrayContainsAllValues(docFieldValue, userValue);\n\t  },\n\t\n\t  '$regex': function (doc, userValue, parsedField, docFieldValue) {\n\t    return fieldExists(docFieldValue) && regexMatch(docFieldValue, userValue);\n\t  },\n\t\n\t  '$type': function (doc, userValue, parsedField, docFieldValue) {\n\t    return typeMatch(docFieldValue, userValue);\n\t  }\n\t};\n\t\n\tmodule.exports = filterInMemoryFields;\n\n\n/***/ },\n/* 85 */\n/***/ function(module, exports, __webpack_require__) {\n\n\t'use strict';\n\t\n\tvar utils = __webpack_require__(2);\n\tvar clone = utils.clone;\n\tvar getIndexes = __webpack_require__(31);\n\tvar collate = __webpack_require__(8).collate;\n\tvar abstractMapper = __webpack_require__(16);\n\tvar planQuery = __webpack_require__(86);\n\tvar localUtils = __webpack_require__(4);\n\tvar filterInMemoryFields = __webpack_require__(84);\n\tvar massageSelector = localUtils.massageSelector;\n\tvar massageSort = localUtils.massageSort;\n\tvar getValue = localUtils.getValue;\n\tvar validateFindRequest = localUtils.validateFindRequest;\n\tvar validateSort = localUtils.validateSort;\n\tvar reverseOptions = localUtils.reverseOptions;\n\tvar filterInclusiveStart = localUtils.filterInclusiveStart;\n\tvar Promise = utils.Promise;\n\t\n\tfunction indexToSignature(index) {\n\t  // remove '_design/'\n\t  return index.ddoc.substring(8) + '/' + index.name;\n\t}\n\t\n\tfunction doAllDocs(db, originalOpts) {\n\t  var opts = clone(originalOpts);\n\t\n\t  // CouchDB responds in weird ways when you provide a non-string to _id;\n\t  // we mimic the behavior for consistency. See issue66 tests for details.\n\t\n\t  if (opts.descending) {\n\t    if ('endkey' in opts && typeof opts.endkey !== 'string') {\n\t      opts.endkey = '';\n\t    }\n\t    if ('startkey' in opts && typeof opts.startkey !== 'string') {\n\t      opts.limit = 0;\n\t    }\n\t  } else {\n\t    if ('startkey' in opts && typeof opts.startkey !== 'string') {\n\t      opts.startkey = '';\n\t    }\n\t    if ('endkey' in opts && typeof opts.endkey !== 'string') {\n\t      opts.limit = 0;\n\t    }\n\t  }\n\t  if ('key' in opts && typeof opts.key !== 'string') {\n\t    opts.limit = 0;\n\t  }\n\t\n\t  return db.allDocs(opts);\n\t}\n\t\n\tfunction find(db, requestDef) {\n\t\n\t  if (requestDef.selector) {\n\t    requestDef.selector = massageSelector(requestDef.selector);\n\t  }\n\t  if (requestDef.sort) {\n\t    requestDef.sort = massageSort(requestDef.sort);\n\t  }\n\t\n\t  validateFindRequest(requestDef);\n\t\n\t  return getIndexes(db).then(function (getIndexesRes) {\n\t\n\t    var queryPlan = planQuery(requestDef, getIndexesRes.indexes);\n\t\n\t    var indexToUse = queryPlan.index;\n\t\n\t    validateSort(requestDef, indexToUse);\n\t\n\t    var opts = utils.extend(true, {\n\t      include_docs: true,\n\t      reduce: false\n\t    }, queryPlan.queryOpts);\n\t\n\t    if ('startkey' in opts && 'endkey' in opts &&\n\t        collate(opts.startkey, opts.endkey) > 0) {\n\t      // can't possibly return any results, startkey > endkey\n\t      return {docs: []};\n\t    }\n\t\n\t    var isDescending = requestDef.sort &&\n\t      typeof requestDef.sort[0] !== 'string' &&\n\t      getValue(requestDef.sort[0]) === 'desc';\n\t\n\t    if (isDescending) {\n\t      // either all descending or all ascending\n\t      opts.descending = true;\n\t      opts = reverseOptions(opts);\n\t    }\n\t\n\t    if (!queryPlan.inMemoryFields.length) {\n\t      // no in-memory filtering necessary, so we can let the\n\t      // database do the limit/skip for us\n\t      if ('limit' in requestDef) {\n\t        opts.limit = requestDef.limit;\n\t      }\n\t      if ('skip' in requestDef) {\n\t        opts.skip = requestDef.skip;\n\t      }\n\t    }\n\t\n\t    return Promise.resolve().then(function () {\n\t      if (indexToUse.name === '_all_docs') {\n\t        return doAllDocs(db, opts);\n\t      } else {\n\t        var signature = indexToSignature(indexToUse);\n\t        return abstractMapper.query.call(db, signature, opts);\n\t      }\n\t    }).then(function (res) {\n\t\n\t      if (opts.inclusive_start === false) {\n\t        // may have to manually filter the first one,\n\t        // since couchdb has no true inclusive_start option\n\t        res.rows = filterInclusiveStart(res.rows, opts.startkey, indexToUse);\n\t      }\n\t\n\t      if (queryPlan.inMemoryFields.length) {\n\t        // need to filter some stuff in-memory\n\t        res.rows = filterInMemoryFields(res.rows, requestDef, queryPlan.inMemoryFields);\n\t      }\n\t\n\t      var resp = {\n\t        docs: res.rows.map(function (row) {\n\t          var doc = row.doc;\n\t          if (requestDef.fields) {\n\t            return utils.pick(doc, requestDef.fields);\n\t          }\n\t          return doc;\n\t        })\n\t      };\n\t\n\t      if (indexToUse.defaultUsed) {\n\t        resp.warning = 'no matching index found, create an index to optimize query time';\n\t      }\n\t\n\t      return resp;\n\t    });\n\t  });\n\t}\n\t\n\tmodule.exports = find;\n\n\n/***/ },\n/* 86 */\n/***/ function(module, exports, __webpack_require__) {\n\n\t'use strict';\n\t\n\tvar utils = __webpack_require__(2);\n\tvar log = utils.log;\n\tvar localUtils = __webpack_require__(4);\n\tvar getKey = localUtils.getKey;\n\tvar getUserFields = localUtils.getUserFields;\n\t\n\t// couchdb lowest collation value\n\tvar COLLATE_LO = null;\n\t\n\t// couchdb highest collation value (TODO: well not really, but close enough amirite)\n\tvar COLLATE_HI = {\"\\uffff\": {}};\n\t\n\t// couchdb second-lowest collation value\n\t\n\tfunction checkFieldInIndex(index, field) {\n\t  var indexFields = index.def.fields.map(getKey);\n\t  for (var i = 0, len = indexFields.length; i < len; i++) {\n\t    var indexField = indexFields[i];\n\t    if (field === indexField) {\n\t      return true;\n\t    }\n\t  }\n\t  return false;\n\t}\n\t\n\t// so when you do e.g. $eq/$eq, we can do it entirely in the database.\n\t// but when you do e.g. $gt/$eq, the first part can be done\n\t// in the database, but the second part has to be done in-memory,\n\t// because $gt has forced us to lose precision.\n\t// so that's what this determines\n\tfunction userOperatorLosesPrecision(selector, field) {\n\t  var matcher = selector[field];\n\t  var userOperator = getKey(matcher);\n\t\n\t  return userOperator !== '$eq';\n\t}\n\t\n\t// sort the user fields by their position in the index,\n\t// if they're in the index\n\tfunction sortFieldsByIndex(userFields, index) {\n\t  var indexFields = index.def.fields.map(getKey);\n\t\n\t  return userFields.slice().sort(function (a, b) {\n\t    var aIdx = indexFields.indexOf(a);\n\t    var bIdx = indexFields.indexOf(b);\n\t    if (aIdx === -1) {\n\t      aIdx = Number.MAX_VALUE;\n\t    }\n\t    if (bIdx === -1) {\n\t      bIdx = Number.MAX_VALUE;\n\t    }\n\t    return utils.compare(aIdx, bIdx);\n\t  });\n\t}\n\t\n\t// first pass to try to find fields that will need to be sorted in-memory\n\tfunction getBasicInMemoryFields(index, selector, userFields) {\n\t\n\t  userFields = sortFieldsByIndex(userFields, index);\n\t\n\t  // check if any of the user selectors lose precision\n\t  var needToFilterInMemory = false;\n\t  for (var i = 0, len = userFields.length; i < len; i++) {\n\t    var field = userFields[i];\n\t    if (needToFilterInMemory || !checkFieldInIndex(index, field)) {\n\t      return userFields.slice(i);\n\t    }\n\t    if (i < len - 1 && userOperatorLosesPrecision(selector, field)) {\n\t      needToFilterInMemory = true;\n\t    }\n\t  }\n\t  return [];\n\t}\n\t\n\tfunction getInMemoryFieldsFromNe(selector) {\n\t  var fields = [];\n\t  Object.keys(selector).forEach(function (field) {\n\t    var matcher = selector[field];\n\t    Object.keys(matcher).forEach(function (operator) {\n\t      if (operator === '$ne') {\n\t        fields.push(field);\n\t      }\n\t    });\n\t  });\n\t  return fields;\n\t}\n\t\n\tfunction getInMemoryFields(coreInMemoryFields, index, selector, userFields) {\n\t  var result = utils.flatten(\n\t    // in-memory fields reported as necessary by the query planner\n\t    coreInMemoryFields,\n\t    // combine with another pass that checks for any we may have missed\n\t    getBasicInMemoryFields(index, selector, userFields),\n\t    // combine with another pass that checks for $ne's\n\t    getInMemoryFieldsFromNe(selector)\n\t  );\n\t\n\t  return sortFieldsByIndex(utils.uniq(result), index);\n\t}\n\t\n\t// check that at least one field in the user's query is represented\n\t// in the index. order matters in the case of sorts\n\tfunction checkIndexFieldsMatch(indexFields, sortOrder, fields) {\n\t  if (sortOrder) {\n\t    // array has to be a strict subarray of index array. furthermore,\n\t    // the sortOrder fields need to all be represented in the index\n\t    var sortMatches = utils.oneArrayIsStrictSubArrayOfOther(sortOrder, indexFields);\n\t    var selectorMatches = utils.oneArrayIsSubArrayOfOther(fields, indexFields);\n\t\n\t    return sortMatches && selectorMatches;\n\t  }\n\t\n\t  // all of the user's specified fields still need to be\n\t  // on the left side of the index array, although the order\n\t  // doesn't matter\n\t  return utils.oneSetIsSubArrayOfOther(fields, indexFields);\n\t}\n\t\n\tvar logicalMatchers = ['$eq', '$gt', '$gte', '$lt', '$lte'];\n\tfunction isNonLogicalMatcher (matcher) {\n\t  return logicalMatchers.indexOf(matcher) === -1;\n\t}\n\t\n\t// check all the index fields for usages of '$ne'\n\t// e.g. if the user queries {foo: {$ne: 'foo'}, bar: {$eq: 'bar'}},\n\t// then we can neither use an index on ['foo'] nor an index on\n\t// ['foo', 'bar'], but we can use an index on ['bar'] or ['bar', 'foo']\n\tfunction checkFieldsLogicallySound(indexFields, selector) {\n\t  var firstField = indexFields[0];\n\t  var matcher = selector[firstField];\n\t\n\t  var hasLogicalOperator = Object.keys(matcher).some(function (matcherKey) {\n\t    return !(isNonLogicalMatcher(matcherKey));\n\t  });\n\t\n\t  if (!hasLogicalOperator) {\n\t    return false;\n\t  }\n\t\n\t  var isInvalidNe = Object.keys(matcher).length === 1 &&\n\t    getKey(matcher) === '$ne';\n\t\n\t  return !isInvalidNe;\n\t}\n\t\n\tfunction checkIndexMatches(index, sortOrder, fields, selector) {\n\t\n\t  var indexFields = index.def.fields.map(getKey);\n\t\n\t  var fieldsMatch = checkIndexFieldsMatch(indexFields, sortOrder, fields);\n\t\n\t  if (!fieldsMatch) {\n\t    return false;\n\t  }\n\t\n\t  return checkFieldsLogicallySound(indexFields, selector);\n\t}\n\t\n\t//\n\t// the algorithm is very simple:\n\t// take all the fields the user supplies, and if those fields\n\t// are a strict subset of the fields in some index,\n\t// then use that index\n\t//\n\t//\n\tfunction findMatchingIndexes(selector, userFields, sortOrder, indexes) {\n\t\n\t  return indexes.reduce(function (res, index) {\n\t    var indexMatches = checkIndexMatches(index, sortOrder, userFields, selector);\n\t    if (indexMatches) {\n\t      res.push(index);\n\t    }\n\t    return res;\n\t  }, []);\n\t}\n\t\n\t// find the best index, i.e. the one that matches the most fields\n\t// in the user's query\n\tfunction findBestMatchingIndex(selector, userFields, sortOrder, indexes) {\n\t\n\t  var matchingIndexes = findMatchingIndexes(selector, userFields, sortOrder, indexes);\n\t\n\t  if (matchingIndexes.length === 0) {\n\t    //return `all_docs` as a default index;\n\t    //I'm assuming that _all_docs is always first\n\t    var defaultIndex = indexes[0];\n\t    defaultIndex.defaultUsed = true;\n\t    return defaultIndex;\n\t  }\n\t  if (matchingIndexes.length === 1) {\n\t    return matchingIndexes[0];\n\t  }\n\t\n\t  var userFieldsMap = utils.arrayToObject(userFields);\n\t\n\t  function scoreIndex(index) {\n\t    var indexFields = index.def.fields.map(getKey);\n\t    var score = 0;\n\t    for (var i = 0, len = indexFields.length; i < len; i++) {\n\t      var indexField = indexFields[i];\n\t      if (userFieldsMap[indexField]) {\n\t        score++;\n\t      }\n\t    }\n\t    return score;\n\t  }\n\t\n\t  return utils.max(matchingIndexes, scoreIndex);\n\t}\n\t\n\tfunction getSingleFieldQueryOptsFor(userOperator, userValue) {\n\t  switch (userOperator) {\n\t    case '$eq':\n\t      return {key: userValue};\n\t    case '$lte':\n\t      return {endkey: userValue};\n\t    case '$gte':\n\t      return {startkey: userValue};\n\t    case '$lt':\n\t      return {\n\t        endkey: userValue,\n\t        inclusive_end: false\n\t      };\n\t    case '$gt':\n\t      return {\n\t        startkey: userValue,\n\t        inclusive_start: false\n\t      };\n\t  }\n\t}\n\t\n\tfunction getSingleFieldCoreQueryPlan(selector, index) {\n\t  var field = getKey(index.def.fields[0]);\n\t  var matcher = selector[field];\n\t  var inMemoryFields = [];\n\t\n\t  var userOperators = Object.keys(matcher);\n\t\n\t  var combinedOpts;\n\t\n\t  userOperators.forEach(function (userOperator) {\n\t\n\t    if (isNonLogicalMatcher(userOperator)) {\n\t      inMemoryFields.push(field);\n\t      return;\n\t    }\n\t\n\t    var userValue = matcher[userOperator];\n\t\n\t    var newQueryOpts = getSingleFieldQueryOptsFor(userOperator, userValue);\n\t\n\t    if (combinedOpts) {\n\t      combinedOpts = utils.mergeObjects([combinedOpts, newQueryOpts]);\n\t    } else {\n\t      combinedOpts = newQueryOpts;\n\t    }\n\t  });\n\t\n\t  return {\n\t    queryOpts: combinedOpts,\n\t    inMemoryFields: inMemoryFields\n\t  };\n\t}\n\t\n\tfunction getMultiFieldCoreQueryPlan(userOperator, userValue) {\n\t  switch (userOperator) {\n\t    case '$eq':\n\t      return {\n\t        startkey: userValue,\n\t        endkey: userValue\n\t      };\n\t    case '$lte':\n\t      return {\n\t        endkey: userValue\n\t      };\n\t    case '$gte':\n\t      return {\n\t        startkey: userValue\n\t      };\n\t    case '$lt':\n\t      return {\n\t        endkey: userValue,\n\t        inclusive_end: false\n\t      };\n\t    case '$gt':\n\t      return {\n\t        startkey: userValue,\n\t        inclusive_start: false\n\t      };\n\t  }\n\t}\n\t\n\tfunction getMultiFieldQueryOpts(selector, index) {\n\t\n\t  var indexFields = index.def.fields.map(getKey);\n\t\n\t  var inMemoryFields = [];\n\t  var startkey = [];\n\t  var endkey = [];\n\t  var inclusiveStart;\n\t  var inclusiveEnd;\n\t\n\t\n\t  function finish(i) {\n\t\n\t    if (inclusiveStart !== false) {\n\t      startkey.push(COLLATE_LO);\n\t    }\n\t    if (inclusiveEnd !== false) {\n\t      endkey.push(COLLATE_HI);\n\t    }\n\t    // keep track of the fields where we lost specificity,\n\t    // and therefore need to filter in-memory\n\t    inMemoryFields = indexFields.slice(i);\n\t  }\n\t\n\t  for (var i = 0, len = indexFields.length; i < len; i++) {\n\t    var indexField = indexFields[i];\n\t\n\t    var matcher = selector[indexField];\n\t\n\t    if (!matcher) { // fewer fields in user query than in index\n\t      finish(i);\n\t      break;\n\t    } else if (i > 0) {\n\t      if ('$ne' in matcher) { // unusable $ne index\n\t        finish(i);\n\t        break;\n\t      }\n\t      var usingGtlt = (\n\t        '$gt' in matcher || '$gte' in matcher ||\n\t        '$lt' in matcher || '$lte' in matcher);\n\t      var previousKeys = Object.keys(selector[indexFields[i - 1]]);\n\t      var previousWasEq = utils.arrayEquals(previousKeys, ['$eq']);\n\t      var previousWasSame = utils.arrayEquals(previousKeys, Object.keys(matcher));\n\t      var gtltLostSpecificity = usingGtlt && !previousWasEq && !previousWasSame;\n\t      if (gtltLostSpecificity) {\n\t        finish(i);\n\t        break;\n\t      }\n\t    }\n\t\n\t    var userOperators = Object.keys(matcher);\n\t\n\t    var combinedOpts = null;\n\t\n\t    for (var j = 0; j < userOperators.length; j++) {\n\t      var userOperator = userOperators[j];\n\t      var userValue = matcher[userOperator];\n\t\n\t      var newOpts = getMultiFieldCoreQueryPlan(userOperator, userValue);\n\t\n\t      if (combinedOpts) {\n\t        combinedOpts = utils.mergeObjects([combinedOpts, newOpts]);\n\t      } else {\n\t        combinedOpts = newOpts;\n\t      }\n\t    }\n\t\n\t    startkey.push('startkey' in combinedOpts ? combinedOpts.startkey : COLLATE_LO);\n\t    endkey.push('endkey' in combinedOpts ? combinedOpts.endkey : COLLATE_HI);\n\t    if ('inclusive_start' in combinedOpts) {\n\t      inclusiveStart = combinedOpts.inclusive_start;\n\t    }\n\t    if ('inclusive_end' in combinedOpts) {\n\t      inclusiveEnd = combinedOpts.inclusive_end;\n\t    }\n\t  }\n\t\n\t  var res = {\n\t    startkey: startkey,\n\t    endkey: endkey\n\t  };\n\t\n\t  if (typeof inclusiveStart !== 'undefined') {\n\t    res.inclusive_start = inclusiveStart;\n\t  }\n\t  if (typeof inclusiveEnd !== 'undefined') {\n\t    res.inclusive_end = inclusiveEnd;\n\t  }\n\t\n\t  return {\n\t    queryOpts: res,\n\t    inMemoryFields: inMemoryFields\n\t  };\n\t}\n\t\n\tfunction getDefaultQueryPlan () {\n\t  return {\n\t    queryOpts: {startkey: null},\n\t    //getInMemoryFields will do the work here later\n\t    inMemoryFields: []\n\t  };\n\t}\n\t\n\tfunction getCoreQueryPlan(selector, index) {\n\t  if (index.defaultUsed) {\n\t    return getDefaultQueryPlan(selector, index);\n\t  }\n\t\n\t  if (index.def.fields.length === 1) {\n\t    // one field in index, so the value was indexed as a singleton\n\t    return getSingleFieldCoreQueryPlan(selector, index);\n\t  }\n\t  // else index has multiple fields, so the value was indexed as an array\n\t  return getMultiFieldQueryOpts(selector, index);\n\t}\n\t\n\tfunction planQuery(request, indexes) {\n\t\n\t  log('planning query', request);\n\t\n\t  var selector = request.selector;\n\t  var sort = request.sort;\n\t\n\t  var userFieldsRes = getUserFields(selector, sort);\n\t\n\t  var userFields = userFieldsRes.fields;\n\t  var sortOrder = userFieldsRes.sortOrder;\n\t  var index = findBestMatchingIndex(selector, userFields, sortOrder, indexes);\n\t\n\t  var coreQueryPlan = getCoreQueryPlan(selector, index);\n\t  var queryOpts = coreQueryPlan.queryOpts;\n\t  var coreInMemoryFields = coreQueryPlan.inMemoryFields;\n\t\n\t  var inMemoryFields = getInMemoryFields(coreInMemoryFields, index, selector, userFields);\n\t\n\t  var res = {\n\t    queryOpts: queryOpts,\n\t    index: index,\n\t    inMemoryFields: inMemoryFields\n\t  };\n\t  log('query plan', res);\n\t  return res;\n\t}\n\t\n\tmodule.exports = planQuery;\n\n\n/***/ },\n/* 87 */\n/***/ function(module, exports, __webpack_require__) {\n\n\t'use strict';\n\t\n\tvar utils = __webpack_require__(2);\n\tvar callbackify = utils.callbackify;\n\t\n\texports.createIndex = callbackify(__webpack_require__(82));\n\texports.find = callbackify(__webpack_require__(85));\n\texports.getIndexes = callbackify(__webpack_require__(31));\n\texports.deleteIndex = callbackify(__webpack_require__(83));\n\n/***/ },\n/* 88 */\n/***/ function(module, exports, __webpack_require__) {\n\n\t'use strict';\n\t\n\tvar utils = __webpack_require__(2);\n\t\n\tvar httpIndexes = __webpack_require__(81);\n\tvar localIndexes = __webpack_require__(87);\n\t\n\tvar plugin = {};\n\tplugin.createIndex = utils.toPromise(function (requestDef, callback) {\n\t\n\t  if (typeof requestDef !== 'object') {\n\t    return callback(new Error('you must provide an index to create'));\n\t  }\n\t\n\t  var adapter = this.type() === 'http' ? httpIndexes : localIndexes;\n\t\n\t  adapter.createIndex(this, requestDef, callback);\n\t});\n\t\n\tplugin.find = utils.toPromise(function (requestDef, callback) {\n\t\n\t  if (typeof callback === 'undefined') {\n\t    callback = requestDef;\n\t    requestDef = undefined;\n\t  }\n\t\n\t  if (typeof requestDef !== 'object') {\n\t    return callback(new Error('you must provide search parameters to find()'));\n\t  }\n\t\n\t  var adapter = this.type() === 'http' ? httpIndexes : localIndexes;\n\t\n\t  adapter.find(this, requestDef, callback);\n\t});\n\t\n\tplugin.getIndexes = utils.toPromise(function (callback) {\n\t\n\t  var adapter = this.type() === 'http' ? httpIndexes : localIndexes;\n\t\n\t  adapter.getIndexes(this, callback);\n\t});\n\t\n\tplugin.deleteIndex = utils.toPromise(function (indexDef, callback) {\n\t\n\t  if (typeof indexDef !== 'object') {\n\t    return callback(new Error('you must provide an index to delete'));\n\t  }\n\t\n\t  var adapter = this.type() === 'http' ? httpIndexes : localIndexes;\n\t\n\t  adapter.deleteIndex(this, indexDef, callback);\n\t});\n\t\n\tmodule.exports = plugin;\n\t\n\t/* istanbul ignore next */\n\tif (typeof window !== 'undefined' && window.PouchDB) {\n\t  window.PouchDB.plugin(plugin);\n\t}\n\n\n/***/ },\n/* 89 */\n33,\n/* 90 */\n/***/ function(module, exports, __webpack_require__) {\n\n\t/* WEBPACK VAR INJECTION */(function(global) {'use strict';\n\t\n\tfunction _interopDefault (ex) { return (ex && (typeof ex === 'object') && 'default' in ex) ? ex['default'] : ex; }\n\t\n\tvar lie = _interopDefault(__webpack_require__(91));\n\tvar getArguments = _interopDefault(__webpack_require__(17));\n\tvar debug = _interopDefault(__webpack_require__(27));\n\tvar events = __webpack_require__(74);\n\tvar inherits = _interopDefault(__webpack_require__(14));\n\tvar nextTick = _interopDefault(__webpack_require__(13));\n\tvar scopedEval = _interopDefault(__webpack_require__(94));\n\tvar Md5 = _interopDefault(__webpack_require__(95));\n\tvar vuvuzela = _interopDefault(__webpack_require__(96));\n\t\n\t/* istanbul ignore next */\n\tvar PouchPromise$1 = typeof Promise === 'function' ? Promise : lie;\n\t\n\tfunction isBinaryObject(object) {\n\t  return (typeof ArrayBuffer !== 'undefined' && object instanceof ArrayBuffer) ||\n\t    (typeof Blob !== 'undefined' && object instanceof Blob);\n\t}\n\t\n\tfunction cloneArrayBuffer(buff) {\n\t  if (typeof buff.slice === 'function') {\n\t    return buff.slice(0);\n\t  }\n\t  // IE10-11 slice() polyfill\n\t  var target = new ArrayBuffer(buff.byteLength);\n\t  var targetArray = new Uint8Array(target);\n\t  var sourceArray = new Uint8Array(buff);\n\t  targetArray.set(sourceArray);\n\t  return target;\n\t}\n\t\n\tfunction cloneBinaryObject(object) {\n\t  if (object instanceof ArrayBuffer) {\n\t    return cloneArrayBuffer(object);\n\t  }\n\t  var size = object.size;\n\t  var type = object.type;\n\t  // Blob\n\t  if (typeof object.slice === 'function') {\n\t    return object.slice(0, size, type);\n\t  }\n\t  // PhantomJS slice() replacement\n\t  return object.webkitSlice(0, size, type);\n\t}\n\t\n\t// most of this is borrowed from lodash.isPlainObject:\n\t// https://github.com/fis-components/lodash.isplainobject/\n\t// blob/29c358140a74f252aeb08c9eb28bef86f2217d4a/index.js\n\t\n\tvar funcToString = Function.prototype.toString;\n\tvar objectCtorString = funcToString.call(Object);\n\t\n\tfunction isPlainObject(value) {\n\t  var proto = Object.getPrototypeOf(value);\n\t  /* istanbul ignore if */\n\t  if (proto === null) { // not sure when this happens, but I guess it can\n\t    return true;\n\t  }\n\t  var Ctor = proto.constructor;\n\t  return (typeof Ctor == 'function' &&\n\t    Ctor instanceof Ctor && funcToString.call(Ctor) == objectCtorString);\n\t}\n\t\n\tfunction clone(object) {\n\t  var newObject;\n\t  var i;\n\t  var len;\n\t\n\t  if (!object || typeof object !== 'object') {\n\t    return object;\n\t  }\n\t\n\t  if (Array.isArray(object)) {\n\t    newObject = [];\n\t    for (i = 0, len = object.length; i < len; i++) {\n\t      newObject[i] = clone(object[i]);\n\t    }\n\t    return newObject;\n\t  }\n\t\n\t  // special case: to avoid inconsistencies between IndexedDB\n\t  // and other backends, we automatically stringify Dates\n\t  if (object instanceof Date) {\n\t    return object.toISOString();\n\t  }\n\t\n\t  if (isBinaryObject(object)) {\n\t    return cloneBinaryObject(object);\n\t  }\n\t\n\t  if (!isPlainObject(object)) {\n\t    return object; // don't clone objects like Workers\n\t  }\n\t\n\t  newObject = {};\n\t  for (i in object) {\n\t    /* istanbul ignore else */\n\t    if (Object.prototype.hasOwnProperty.call(object, i)) {\n\t      var value = clone(object[i]);\n\t      if (typeof value !== 'undefined') {\n\t        newObject[i] = value;\n\t      }\n\t    }\n\t  }\n\t  return newObject;\n\t}\n\t\n\tfunction once(fun) {\n\t  var called = false;\n\t  return getArguments(function (args) {\n\t    /* istanbul ignore if */\n\t    if (called) {\n\t      // this is a smoke test and should never actually happen\n\t      throw new Error('once called more than once');\n\t    } else {\n\t      called = true;\n\t      fun.apply(this, args);\n\t    }\n\t  });\n\t}\n\t\n\tfunction toPromise(func) {\n\t  //create the function we will be returning\n\t  return getArguments(function (args) {\n\t    // Clone arguments\n\t    args = clone(args);\n\t    var self = this;\n\t    // if the last argument is a function, assume its a callback\n\t    var usedCB = (typeof args[args.length - 1] === 'function') ? args.pop() : false;\n\t    var promise = new PouchPromise$1(function (fulfill, reject) {\n\t      var resp;\n\t      try {\n\t        var callback = once(function (err, mesg) {\n\t          if (err) {\n\t            reject(err);\n\t          } else {\n\t            fulfill(mesg);\n\t          }\n\t        });\n\t        // create a callback for this invocation\n\t        // apply the function in the orig context\n\t        args.push(callback);\n\t        resp = func.apply(self, args);\n\t        if (resp && typeof resp.then === 'function') {\n\t          fulfill(resp);\n\t        }\n\t      } catch (e) {\n\t        reject(e);\n\t      }\n\t    });\n\t    // if there is a callback, call it back\n\t    if (usedCB) {\n\t      promise.then(function (result) {\n\t        usedCB(null, result);\n\t      }, usedCB);\n\t    }\n\t    return promise;\n\t  });\n\t}\n\t\n\tvar log = debug('pouchdb:api');\n\t\n\tfunction adapterFun(name, callback) {\n\t  function logApiCall(self, name, args) {\n\t    /* istanbul ignore if */\n\t    if (log.enabled) {\n\t      var logArgs = [self.name, name];\n\t      for (var i = 0; i < args.length - 1; i++) {\n\t        logArgs.push(args[i]);\n\t      }\n\t      log.apply(null, logArgs);\n\t\n\t      // override the callback itself to log the response\n\t      var origCallback = args[args.length - 1];\n\t      args[args.length - 1] = function (err, res) {\n\t        var responseArgs = [self.name, name];\n\t        responseArgs = responseArgs.concat(\n\t          err ? ['error', err] : ['success', res]\n\t        );\n\t        log.apply(null, responseArgs);\n\t        origCallback(err, res);\n\t      };\n\t    }\n\t  }\n\t\n\t  return toPromise(getArguments(function (args) {\n\t    if (this._closed) {\n\t      return PouchPromise$1.reject(new Error('database is closed'));\n\t    }\n\t    if (this._destroyed) {\n\t      return PouchPromise$1.reject(new Error('database is destroyed'));\n\t    }\n\t    var self = this;\n\t    logApiCall(self, name, args);\n\t    if (!this.taskqueue.isReady) {\n\t      return new PouchPromise$1(function (fulfill, reject) {\n\t        self.taskqueue.addTask(function (failed) {\n\t          if (failed) {\n\t            reject(failed);\n\t          } else {\n\t            fulfill(self[name].apply(self, args));\n\t          }\n\t        });\n\t      });\n\t    }\n\t    return callback.apply(this, args);\n\t  }));\n\t}\n\t\n\t// like underscore/lodash _.pick()\n\tfunction pick(obj, arr) {\n\t  var res = {};\n\t  for (var i = 0, len = arr.length; i < len; i++) {\n\t    var prop = arr[i];\n\t    if (prop in obj) {\n\t      res[prop] = obj[prop];\n\t    }\n\t  }\n\t  return res;\n\t}\n\t\n\tfunction mangle(key) {\n\t  return '$' + key;\n\t}\n\tfunction unmangle(key) {\n\t  return key.substring(1);\n\t}\n\tfunction Map$1() {\n\t  this._store = {};\n\t}\n\tMap$1.prototype.get = function (key) {\n\t  var mangled = mangle(key);\n\t  return this._store[mangled];\n\t};\n\tMap$1.prototype.set = function (key, value) {\n\t  var mangled = mangle(key);\n\t  this._store[mangled] = value;\n\t  return true;\n\t};\n\tMap$1.prototype.has = function (key) {\n\t  var mangled = mangle(key);\n\t  return mangled in this._store;\n\t};\n\tMap$1.prototype.delete = function (key) {\n\t  var mangled = mangle(key);\n\t  var res = mangled in this._store;\n\t  delete this._store[mangled];\n\t  return res;\n\t};\n\tMap$1.prototype.forEach = function (cb) {\n\t  var keys = Object.keys(this._store);\n\t  for (var i = 0, len = keys.length; i < len; i++) {\n\t    var key = keys[i];\n\t    var value = this._store[key];\n\t    key = unmangle(key);\n\t    cb(value, key);\n\t  }\n\t};\n\tObject.defineProperty(Map$1.prototype, 'size', {\n\t  get: function () {\n\t    return Object.keys(this._store).length;\n\t  }\n\t});\n\t\n\tfunction Set$1(array) {\n\t  this._store = new Map$1();\n\t\n\t  // init with an array\n\t  if (array && Array.isArray(array)) {\n\t    for (var i = 0, len = array.length; i < len; i++) {\n\t      this.add(array[i]);\n\t    }\n\t  }\n\t}\n\tSet$1.prototype.add = function (key) {\n\t  return this._store.set(key, true);\n\t};\n\tSet$1.prototype.has = function (key) {\n\t  return this._store.has(key);\n\t};\n\tSet$1.prototype.forEach = function (cb) {\n\t  this._store.forEach(function (value, key) {\n\t    cb(key);\n\t  });\n\t};\n\tObject.defineProperty(Set$1.prototype, 'size', {\n\t  get: function () {\n\t    return this._store.size;\n\t  }\n\t});\n\t\n\t/* global Map,Set,Symbol */\n\t// Based on https://kangax.github.io/compat-table/es6/ we can sniff out\n\t// incomplete Map/Set implementations which would otherwise cause our tests to fail.\n\t// Notably they fail in IE11 and iOS 8.4, which this prevents.\n\tfunction supportsMapAndSet() {\n\t  if (typeof Symbol === 'undefined' || typeof Map === 'undefined' || typeof Set === 'undefined') {\n\t    return false;\n\t  }\n\t  var prop = Object.getOwnPropertyDescriptor(Map, Symbol.species);\n\t  return prop && 'get' in prop && Map[Symbol.species] === Map;\n\t}\n\t\n\t// based on https://github.com/montagejs/collections\n\t/* global Map,Set */\n\t\n\tvar ExportedSet;\n\tvar ExportedMap;\n\t\n\t{\n\t  if (supportsMapAndSet()) { // prefer built-in Map/Set\n\t    ExportedSet = Set;\n\t    ExportedMap = Map;\n\t  } else { // fall back to our polyfill\n\t    ExportedSet = Set$1;\n\t    ExportedMap = Map$1;\n\t  }\n\t}\n\t\n\t// Most browsers throttle concurrent requests at 6, so it's silly\n\t// to shim _bulk_get by trying to launch potentially hundreds of requests\n\t// and then letting the majority time out. We can handle this ourselves.\n\tvar MAX_NUM_CONCURRENT_REQUESTS = 6;\n\t\n\tfunction identityFunction(x) {\n\t  return x;\n\t}\n\t\n\tfunction formatResultForOpenRevsGet(result) {\n\t  return [{\n\t    ok: result\n\t  }];\n\t}\n\t\n\t// shim for P/CouchDB adapters that don't directly implement _bulk_get\n\tfunction bulkGet(db, opts, callback) {\n\t  var requests = opts.docs;\n\t\n\t  // consolidate into one request per doc if possible\n\t  var requestsById = new ExportedMap();\n\t  requests.forEach(function (request) {\n\t    if (requestsById.has(request.id)) {\n\t      requestsById.get(request.id).push(request);\n\t    } else {\n\t      requestsById.set(request.id, [request]);\n\t    }\n\t  });\n\t\n\t  var numDocs = requestsById.size;\n\t  var numDone = 0;\n\t  var perDocResults = new Array(numDocs);\n\t\n\t  function collapseResultsAndFinish() {\n\t    var results = [];\n\t    perDocResults.forEach(function (res) {\n\t      res.docs.forEach(function (info) {\n\t        results.push({\n\t          id: res.id,\n\t          docs: [info]\n\t        });\n\t      });\n\t    });\n\t    callback(null, {results: results});\n\t  }\n\t\n\t  function checkDone() {\n\t    if (++numDone === numDocs) {\n\t      collapseResultsAndFinish();\n\t    }\n\t  }\n\t\n\t  function gotResult(docIndex, id, docs) {\n\t    perDocResults[docIndex] = {id: id, docs: docs};\n\t    checkDone();\n\t  }\n\t\n\t  var allRequests = [];\n\t  requestsById.forEach(function (value, key) {\n\t    allRequests.push(key);\n\t  });\n\t\n\t  var i = 0;\n\t\n\t  function nextBatch() {\n\t\n\t    if (i >= allRequests.length) {\n\t      return;\n\t    }\n\t\n\t    var upTo = Math.min(i + MAX_NUM_CONCURRENT_REQUESTS, allRequests.length);\n\t    var batch = allRequests.slice(i, upTo);\n\t    processBatch(batch, i);\n\t    i += batch.length;\n\t  }\n\t\n\t  function processBatch(batch, offset) {\n\t    batch.forEach(function (docId, j) {\n\t      var docIdx = offset + j;\n\t      var docRequests = requestsById.get(docId);\n\t\n\t      // just use the first request as the \"template\"\n\t      // TODO: The _bulk_get API allows for more subtle use cases than this,\n\t      // but for now it is unlikely that there will be a mix of different\n\t      // \"atts_since\" or \"attachments\" in the same request, since it's just\n\t      // replicate.js that is using this for the moment.\n\t      // Also, atts_since is aspirational, since we don't support it yet.\n\t      var docOpts = pick(docRequests[0], ['atts_since', 'attachments']);\n\t      docOpts.open_revs = docRequests.map(function (request) {\n\t        // rev is optional, open_revs disallowed\n\t        return request.rev;\n\t      });\n\t\n\t      // remove falsey / undefined revisions\n\t      docOpts.open_revs = docOpts.open_revs.filter(identityFunction);\n\t\n\t      var formatResult = identityFunction;\n\t\n\t      if (docOpts.open_revs.length === 0) {\n\t        delete docOpts.open_revs;\n\t\n\t        // when fetching only the \"winning\" leaf,\n\t        // transform the result so it looks like an open_revs\n\t        // request\n\t        formatResult = formatResultForOpenRevsGet;\n\t      }\n\t\n\t      // globally-supplied options\n\t      ['revs', 'attachments', 'binary', 'ajax', 'latest'].forEach(function (param) {\n\t        if (param in opts) {\n\t          docOpts[param] = opts[param];\n\t        }\n\t      });\n\t      db.get(docId, docOpts, function (err, res) {\n\t        var result;\n\t        /* istanbul ignore if */\n\t        if (err) {\n\t          result = [{error: err}];\n\t        } else {\n\t          result = formatResult(res);\n\t        }\n\t        gotResult(docIdx, docId, result);\n\t        nextBatch();\n\t      });\n\t    });\n\t  }\n\t\n\t  nextBatch();\n\t\n\t}\n\t\n\tfunction isChromeApp() {\n\t  return (typeof chrome !== \"undefined\" &&\n\t    typeof chrome.storage !== \"undefined\" &&\n\t    typeof chrome.storage.local !== \"undefined\");\n\t}\n\t\n\tvar hasLocal;\n\t\n\tif (isChromeApp()) {\n\t  hasLocal = false;\n\t} else {\n\t  try {\n\t    localStorage.setItem('_pouch_check_localstorage', 1);\n\t    hasLocal = !!localStorage.getItem('_pouch_check_localstorage');\n\t  } catch (e) {\n\t    hasLocal = false;\n\t  }\n\t}\n\t\n\tfunction hasLocalStorage() {\n\t  return hasLocal;\n\t}\n\t\n\tinherits(Changes, events.EventEmitter);\n\t\n\t/* istanbul ignore next */\n\tfunction attachBrowserEvents(self) {\n\t  if (isChromeApp()) {\n\t    chrome.storage.onChanged.addListener(function (e) {\n\t      // make sure it's event addressed to us\n\t      if (e.db_name != null) {\n\t        //object only has oldValue, newValue members\n\t        self.emit(e.dbName.newValue);\n\t      }\n\t    });\n\t  } else if (hasLocalStorage()) {\n\t    if (typeof addEventListener !== 'undefined') {\n\t      addEventListener(\"storage\", function (e) {\n\t        self.emit(e.key);\n\t      });\n\t    } else { // old IE\n\t      window.attachEvent(\"storage\", function (e) {\n\t        self.emit(e.key);\n\t      });\n\t    }\n\t  }\n\t}\n\t\n\tfunction Changes() {\n\t  events.EventEmitter.call(this);\n\t  this._listeners = {};\n\t\n\t  attachBrowserEvents(this);\n\t}\n\tChanges.prototype.addListener = function (dbName, id, db, opts) {\n\t  /* istanbul ignore if */\n\t  if (this._listeners[id]) {\n\t    return;\n\t  }\n\t  var self = this;\n\t  var inprogress = false;\n\t  function eventFunction() {\n\t    /* istanbul ignore if */\n\t    if (!self._listeners[id]) {\n\t      return;\n\t    }\n\t    if (inprogress) {\n\t      inprogress = 'waiting';\n\t      return;\n\t    }\n\t    inprogress = true;\n\t    var changesOpts = pick(opts, [\n\t      'style', 'include_docs', 'attachments', 'conflicts', 'filter',\n\t      'doc_ids', 'view', 'since', 'query_params', 'binary'\n\t    ]);\n\t\n\t    /* istanbul ignore next */\n\t    function onError() {\n\t      inprogress = false;\n\t    }\n\t\n\t    db.changes(changesOpts).on('change', function (c) {\n\t      if (c.seq > opts.since && !opts.cancelled) {\n\t        opts.since = c.seq;\n\t        opts.onChange(c);\n\t      }\n\t    }).on('complete', function () {\n\t      if (inprogress === 'waiting') {\n\t        nextTick(eventFunction);\n\t      }\n\t      inprogress = false;\n\t    }).on('error', onError);\n\t  }\n\t  this._listeners[id] = eventFunction;\n\t  this.on(dbName, eventFunction);\n\t};\n\t\n\tChanges.prototype.removeListener = function (dbName, id) {\n\t  /* istanbul ignore if */\n\t  if (!(id in this._listeners)) {\n\t    return;\n\t  }\n\t  events.EventEmitter.prototype.removeListener.call(this, dbName,\n\t    this._listeners[id]);\n\t  delete this._listeners[id];\n\t};\n\t\n\t\n\t/* istanbul ignore next */\n\tChanges.prototype.notifyLocalWindows = function (dbName) {\n\t  //do a useless change on a storage thing\n\t  //in order to get other windows's listeners to activate\n\t  if (isChromeApp()) {\n\t    chrome.storage.local.set({dbName: dbName});\n\t  } else if (hasLocalStorage()) {\n\t    localStorage[dbName] = (localStorage[dbName] === \"a\") ? \"b\" : \"a\";\n\t  }\n\t};\n\t\n\tChanges.prototype.notify = function (dbName) {\n\t  this.emit(dbName);\n\t  this.notifyLocalWindows(dbName);\n\t};\n\t\n\tfunction guardedConsole(method) {\n\t  /* istanbul ignore else */\n\t  if (console !== 'undefined' && method in console) {\n\t    var args = Array.prototype.slice.call(arguments, 1);\n\t    console[method].apply(console, args);\n\t  }\n\t}\n\t\n\tfunction randomNumber(min, max) {\n\t  var maxTimeout = 600000; // Hard-coded default of 10 minutes\n\t  min = parseInt(min, 10) || 0;\n\t  max = parseInt(max, 10);\n\t  if (max !== max || max <= min) {\n\t    max = (min || 1) << 1; //doubling\n\t  } else {\n\t    max = max + 1;\n\t  }\n\t  // In order to not exceed maxTimeout, pick a random value between half of maxTimeout and maxTimeout\n\t  if(max > maxTimeout) {\n\t    min = maxTimeout >> 1; // divide by two\n\t    max = maxTimeout;\n\t  }\n\t  var ratio = Math.random();\n\t  var range = max - min;\n\t\n\t  return ~~(range * ratio + min); // ~~ coerces to an int, but fast.\n\t}\n\t\n\tfunction defaultBackOff(min) {\n\t  var max = 0;\n\t  if (!min) {\n\t    max = 2000;\n\t  }\n\t  return randomNumber(min, max);\n\t}\n\t\n\t// designed to give info to browser users, who are disturbed\n\t// when they see http errors in the console\n\tfunction explainError(status, str) {\n\t  guardedConsole('info', 'The above ' + status + ' is totally normal. ' + str);\n\t}\n\t\n\tvar assign;\n\t{\n\t  if (typeof Object.assign === 'function') {\n\t    assign = Object.assign;\n\t  } else {\n\t    // lite Object.assign polyfill based on\n\t    // https://developer.mozilla.org/en-US/docs/Web/JavaScript/Reference/Global_Objects/Object/assign\n\t    assign = function (target) {\n\t      var to = Object(target);\n\t\n\t      for (var index = 1; index < arguments.length; index++) {\n\t        var nextSource = arguments[index];\n\t\n\t        if (nextSource != null) { // Skip over if undefined or null\n\t          for (var nextKey in nextSource) {\n\t            // Avoid bugs when hasOwnProperty is shadowed\n\t            if (Object.prototype.hasOwnProperty.call(nextSource, nextKey)) {\n\t              to[nextKey] = nextSource[nextKey];\n\t            }\n\t          }\n\t        }\n\t      }\n\t      return to;\n\t    };\n\t  }\n\t}\n\t\n\tvar assign$1 = assign;\n\t\n\tinherits(PouchError, Error);\n\t\n\tfunction PouchError(status, error, reason) {\n\t  Error.call(this, reason);\n\t  this.status = status;\n\t  this.name = error;\n\t  this.message = reason;\n\t  this.error = true;\n\t}\n\t\n\tPouchError.prototype.toString = function () {\n\t  return JSON.stringify({\n\t    status: this.status,\n\t    name: this.name,\n\t    message: this.message,\n\t    reason: this.reason\n\t  });\n\t};\n\t\n\tvar UNAUTHORIZED = new PouchError(401, 'unauthorized', \"Name or password is incorrect.\");\n\tvar MISSING_BULK_DOCS = new PouchError(400, 'bad_request', \"Missing JSON list of 'docs'\");\n\tvar MISSING_DOC = new PouchError(404, 'not_found', 'missing');\n\tvar REV_CONFLICT = new PouchError(409, 'conflict', 'Document update conflict');\n\tvar INVALID_ID = new PouchError(400, 'bad_request', '_id field must contain a string');\n\tvar MISSING_ID = new PouchError(412, 'missing_id', '_id is required for puts');\n\tvar RESERVED_ID = new PouchError(400, 'bad_request', 'Only reserved document ids may start with underscore.');\n\tvar NOT_OPEN = new PouchError(412, 'precondition_failed', 'Database not open');\n\tvar UNKNOWN_ERROR = new PouchError(500, 'unknown_error', 'Database encountered an unknown error');\n\tvar BAD_ARG = new PouchError(500, 'badarg', 'Some query argument is invalid');\n\tvar INVALID_REQUEST = new PouchError(400, 'invalid_request', 'Request was invalid');\n\tvar QUERY_PARSE_ERROR = new PouchError(400, 'query_parse_error', 'Some query parameter is invalid');\n\tvar DOC_VALIDATION = new PouchError(500, 'doc_validation', 'Bad special document member');\n\tvar BAD_REQUEST = new PouchError(400, 'bad_request', 'Something wrong with the request');\n\tvar NOT_AN_OBJECT = new PouchError(400, 'bad_request', 'Document must be a JSON object');\n\tvar DB_MISSING = new PouchError(404, 'not_found', 'Database not found');\n\tvar IDB_ERROR = new PouchError(500, 'indexed_db_went_bad', 'unknown');\n\tvar WSQ_ERROR = new PouchError(500, 'web_sql_went_bad', 'unknown');\n\tvar LDB_ERROR = new PouchError(500, 'levelDB_went_went_bad', 'unknown');\n\tvar FORBIDDEN = new PouchError(403, 'forbidden', 'Forbidden by design doc validate_doc_update function');\n\tvar INVALID_REV = new PouchError(400, 'bad_request', 'Invalid rev format');\n\tvar FILE_EXISTS = new PouchError(412, 'file_exists', 'The database could not be created, the file already exists.');\n\tvar MISSING_STUB = new PouchError(412, 'missing_stub', 'A pre-existing attachment stub wasn\\'t found');\n\tvar INVALID_URL = new PouchError(413, 'invalid_url', 'Provided URL is invalid');\n\t\n\tfunction createError(error, reason) {\n\t  function CustomPouchError(reason) {\n\t    // inherit error properties from our parent error manually\n\t    // so as to allow proper JSON parsing.\n\t    /* jshint ignore:start */\n\t    for (var p in error) {\n\t      if (typeof error[p] !== 'function') {\n\t        this[p] = error[p];\n\t      }\n\t    }\n\t    /* jshint ignore:end */\n\t    if (reason !== undefined) {\n\t      this.reason = reason;\n\t    }\n\t  }\n\t  CustomPouchError.prototype = PouchError.prototype;\n\t  return new CustomPouchError(reason);\n\t}\n\t\n\tfunction generateErrorFromResponse(err) {\n\t\n\t  if (typeof err !== 'object') {\n\t    var data = err;\n\t    err = UNKNOWN_ERROR;\n\t    err.data = data;\n\t  }\n\t\n\t  if ('error' in err && err.error === 'conflict') {\n\t    err.name = 'conflict';\n\t    err.status = 409;\n\t  }\n\t\n\t  if (!('name' in err)) {\n\t    err.name = err.error || 'unknown';\n\t  }\n\t\n\t  if (!('status' in err)) {\n\t    err.status = 500;\n\t  }\n\t\n\t  if (!('message' in err)) {\n\t    err.message = err.message || err.reason;\n\t  }\n\t\n\t  return err;\n\t}\n\t\n\tfunction tryFilter(filter, doc, req) {\n\t  try {\n\t    return !filter(doc, req);\n\t  } catch (err) {\n\t    var msg = 'Filter function threw: ' + err.toString();\n\t    return createError(BAD_REQUEST, msg);\n\t  }\n\t}\n\t\n\tfunction filterChange(opts) {\n\t  var req = {};\n\t  var hasFilter = opts.filter && typeof opts.filter === 'function';\n\t  req.query = opts.query_params;\n\t\n\t  return function filter(change) {\n\t    if (!change.doc) {\n\t      // CSG sends events on the changes feed that don't have documents,\n\t      // this hack makes a whole lot of existing code robust.\n\t      change.doc = {};\n\t    }\n\t\n\t    var filterReturn = hasFilter && tryFilter(opts.filter, change.doc, req);\n\t\n\t    if (typeof filterReturn === 'object') {\n\t      return filterReturn;\n\t    }\n\t\n\t    if (filterReturn) {\n\t      return false;\n\t    }\n\t\n\t    if (!opts.include_docs) {\n\t      delete change.doc;\n\t    } else if (!opts.attachments) {\n\t      for (var att in change.doc._attachments) {\n\t        /* istanbul ignore else */\n\t        if (change.doc._attachments.hasOwnProperty(att)) {\n\t          change.doc._attachments[att].stub = true;\n\t        }\n\t      }\n\t    }\n\t    return true;\n\t  };\n\t}\n\t\n\tfunction flatten(arrs) {\n\t  var res = [];\n\t  for (var i = 0, len = arrs.length; i < len; i++) {\n\t    res = res.concat(arrs[i]);\n\t  }\n\t  return res;\n\t}\n\t\n\t// shim for Function.prototype.name,\n\t// for browsers that don't support it like IE\n\t\n\t/* istanbul ignore next */\n\tfunction f() {}\n\t\n\tvar hasName = f.name;\n\tvar res;\n\t\n\t// We dont run coverage in IE\n\t/* istanbul ignore else */\n\tif (hasName) {\n\t  res = function (fun) {\n\t    return fun.name;\n\t  };\n\t} else {\n\t  res = function (fun) {\n\t    return fun.toString().match(/^\\s*function\\s*(\\S*)\\s*\\(/)[1];\n\t  };\n\t}\n\t\n\t// Determine id an ID is valid\n\t//   - invalid IDs begin with an underescore that does not begin '_design' or\n\t//     '_local'\n\t//   - any other string value is a valid id\n\t// Returns the specific error object for each case\n\tfunction invalidIdError(id) {\n\t  var err;\n\t  if (!id) {\n\t    err = createError(MISSING_ID);\n\t  } else if (typeof id !== 'string') {\n\t    err = createError(INVALID_ID);\n\t  } else if (/^_/.test(id) && !(/^_(design|local)/).test(id)) {\n\t    err = createError(RESERVED_ID);\n\t  }\n\t  if (err) {\n\t    throw err;\n\t  }\n\t}\n\t\n\tfunction listenerCount(ee, type) {\n\t  return 'listenerCount' in ee ? ee.listenerCount(type) :\n\t                                 events.EventEmitter.listenerCount(ee, type);\n\t}\n\t\n\t// Custom nextTick() shim for browsers. In node, this will just be process.nextTick(). We\n\t// avoid using process.nextTick() directly because the polyfill is very large and we don't\n\t// need all of it (see: https://github.com/defunctzombie/node-process).\n\t// \"immediate\" 3.0.8 is used by lie, and it's a smaller version of the latest \"immediate\"\n\t// package, so it's the one we use.\n\t// When we use nextTick() in our codebase, we only care about not releasing Zalgo\n\t// (see: http://blog.izs.me/post/59142742143/designing-apis-for-asynchrony).\n\t// Microtask vs macrotask doesn't matter to us. So we're free to use the fastest\n\t// (least latency) option, which is \"immediate\" due to use of microtasks.\n\t// All of our nextTicks are isolated to this one function so we can easily swap out one\n\t// implementation for another.\n\t\n\tfunction parseDesignDocFunctionName(s) {\n\t  if (!s) {\n\t    return null;\n\t  }\n\t  var parts = s.split('/');\n\t  if (parts.length === 2) {\n\t    return parts;\n\t  }\n\t  if (parts.length === 1) {\n\t    return [s, s];\n\t  }\n\t  return null;\n\t}\n\t\n\tfunction normalizeDesignDocFunctionName(s) {\n\t  var normalized = parseDesignDocFunctionName(s);\n\t  return normalized ? normalized.join('/') : null;\n\t}\n\t\n\t// originally parseUri 1.2.2, now patched by us\n\t// (c) Steven Levithan <stevenlevithan.com>\n\t// MIT License\n\tvar keys = [\"source\", \"protocol\", \"authority\", \"userInfo\", \"user\", \"password\",\n\t    \"host\", \"port\", \"relative\", \"path\", \"directory\", \"file\", \"query\", \"anchor\"];\n\tvar qName =\"queryKey\";\n\tvar qParser = /(?:^|&)([^&=]*)=?([^&]*)/g;\n\t\n\t// use the \"loose\" parser\n\t/* jshint maxlen: false */\n\tvar parser = /^(?:(?![^:@]+:[^:@\\/]*@)([^:\\/?#.]+):)?(?:\\/\\/)?((?:(([^:@]*)(?::([^:@]*))?)?@)?([^:\\/?#]*)(?::(\\d*))?)(((\\/(?:[^?#](?![^?#\\/]*\\.[^?#\\/.]+(?:[?#]|$)))*\\/?)?([^?#\\/]*))(?:\\?([^#]*))?(?:#(.*))?)/;\n\t\n\tfunction parseUri(str) {\n\t  var m = parser.exec(str);\n\t  var uri = {};\n\t  var i = 14;\n\t\n\t  while (i--) {\n\t    var key = keys[i];\n\t    var value = m[i] || \"\";\n\t    var encoded = ['user', 'password'].indexOf(key) !== -1;\n\t    uri[key] = encoded ? decodeURIComponent(value) : value;\n\t  }\n\t\n\t  uri[qName] = {};\n\t  uri[keys[12]].replace(qParser, function ($0, $1, $2) {\n\t    if ($1) {\n\t      uri[qName][$1] = $2;\n\t    }\n\t  });\n\t\n\t  return uri;\n\t}\n\t\n\t// this is essentially the \"update sugar\" function from daleharvey/pouchdb#1388\n\t// the diffFun tells us what delta to apply to the doc.  it either returns\n\t// the doc, or false if it doesn't need to do an update after all\n\tfunction upsert(db, docId, diffFun) {\n\t  return new PouchPromise$1(function (fulfill, reject) {\n\t    db.get(docId, function (err, doc) {\n\t      if (err) {\n\t        /* istanbul ignore next */\n\t        if (err.status !== 404) {\n\t          return reject(err);\n\t        }\n\t        doc = {};\n\t      }\n\t\n\t      // the user might change the _rev, so save it for posterity\n\t      var docRev = doc._rev;\n\t      var newDoc = diffFun(doc);\n\t\n\t      if (!newDoc) {\n\t        // if the diffFun returns falsy, we short-circuit as\n\t        // an optimization\n\t        return fulfill({updated: false, rev: docRev});\n\t      }\n\t\n\t      // users aren't allowed to modify these values,\n\t      // so reset them here\n\t      newDoc._id = docId;\n\t      newDoc._rev = docRev;\n\t      fulfill(tryAndPut(db, newDoc, diffFun));\n\t    });\n\t  });\n\t}\n\t\n\tfunction tryAndPut(db, doc, diffFun) {\n\t  return db.put(doc).then(function (res) {\n\t    return {\n\t      updated: true,\n\t      rev: res.rev\n\t    };\n\t  }, function (err) {\n\t    /* istanbul ignore next */\n\t    if (err.status !== 409) {\n\t      throw err;\n\t    }\n\t    return upsert(db, doc._id, diffFun);\n\t  });\n\t}\n\t\n\t// BEGIN Math.uuid.js\n\t\n\t/*!\n\tMath.uuid.js (v1.4)\n\thttp://www.broofa.com\n\tmailto:robert@broofa.com\n\t\n\tCopyright (c) 2010 Robert Kieffer\n\tDual licensed under the MIT and GPL licenses.\n\t*/\n\t\n\t/*\n\t * Generate a random uuid.\n\t *\n\t * USAGE: Math.uuid(length, radix)\n\t *   length - the desired number of characters\n\t *   radix  - the number of allowable values for each character.\n\t *\n\t * EXAMPLES:\n\t *   // No arguments  - returns RFC4122, version 4 ID\n\t *   >>> Math.uuid()\n\t *   \"92329D39-6F5C-4520-ABFC-AAB64544E172\"\n\t *\n\t *   // One argument - returns ID of the specified length\n\t *   >>> Math.uuid(15)     // 15 character ID (default base=62)\n\t *   \"VcydxgltxrVZSTV\"\n\t *\n\t *   // Two arguments - returns ID of the specified length, and radix. \n\t *   // (Radix must be <= 62)\n\t *   >>> Math.uuid(8, 2)  // 8 character ID (base=2)\n\t *   \"01001010\"\n\t *   >>> Math.uuid(8, 10) // 8 character ID (base=10)\n\t *   \"47473046\"\n\t *   >>> Math.uuid(8, 16) // 8 character ID (base=16)\n\t *   \"098F4D35\"\n\t */\n\tvar chars = (\n\t  '0123456789ABCDEFGHIJKLMNOPQRSTUVWXYZ' +\n\t  'abcdefghijklmnopqrstuvwxyz'\n\t).split('');\n\tfunction getValue(radix) {\n\t  return 0 | Math.random() * radix;\n\t}\n\tfunction uuid(len, radix) {\n\t  radix = radix || chars.length;\n\t  var out = '';\n\t  var i = -1;\n\t\n\t  if (len) {\n\t    // Compact form\n\t    while (++i < len) {\n\t      out += chars[getValue(radix)];\n\t    }\n\t    return out;\n\t  }\n\t    // rfc4122, version 4 form\n\t    // Fill in random data.  At i==19 set the high bits of clock sequence as\n\t    // per rfc4122, sec. 4.1.5\n\t  while (++i < 36) {\n\t    switch (i) {\n\t      case 8:\n\t      case 13:\n\t      case 18:\n\t      case 23:\n\t        out += '-';\n\t        break;\n\t      case 19:\n\t        out += chars[(getValue(16) & 0x3) | 0x8];\n\t        break;\n\t      default:\n\t        out += chars[getValue(16)];\n\t    }\n\t  }\n\t\n\t  return out;\n\t}\n\t\n\t// We fetch all leafs of the revision tree, and sort them based on tree length\n\t// and whether they were deleted, undeleted documents with the longest revision\n\t// tree (most edits) win\n\t// The final sort algorithm is slightly documented in a sidebar here:\n\t// http://guide.couchdb.org/draft/conflicts.html\n\tfunction winningRev(metadata) {\n\t  var winningId;\n\t  var winningPos;\n\t  var winningDeleted;\n\t  var toVisit = metadata.rev_tree.slice();\n\t  var node;\n\t  while ((node = toVisit.pop())) {\n\t    var tree = node.ids;\n\t    var branches = tree[2];\n\t    var pos = node.pos;\n\t    if (branches.length) { // non-leaf\n\t      for (var i = 0, len = branches.length; i < len; i++) {\n\t        toVisit.push({pos: pos + 1, ids: branches[i]});\n\t      }\n\t      continue;\n\t    }\n\t    var deleted = !!tree[1].deleted;\n\t    var id = tree[0];\n\t    // sort by deleted, then pos, then id\n\t    if (!winningId || (winningDeleted !== deleted ? winningDeleted :\n\t        winningPos !== pos ? winningPos < pos : winningId < id)) {\n\t      winningId = id;\n\t      winningPos = pos;\n\t      winningDeleted = deleted;\n\t    }\n\t  }\n\t\n\t  return winningPos + '-' + winningId;\n\t}\n\t\n\t// Pretty much all below can be combined into a higher order function to\n\t// traverse revisions\n\t// The return value from the callback will be passed as context to all\n\t// children of that node\n\tfunction traverseRevTree(revs, callback) {\n\t  var toVisit = revs.slice();\n\t\n\t  var node;\n\t  while ((node = toVisit.pop())) {\n\t    var pos = node.pos;\n\t    var tree = node.ids;\n\t    var branches = tree[2];\n\t    var newCtx =\n\t      callback(branches.length === 0, pos, tree[0], node.ctx, tree[1]);\n\t    for (var i = 0, len = branches.length; i < len; i++) {\n\t      toVisit.push({pos: pos + 1, ids: branches[i], ctx: newCtx});\n\t    }\n\t  }\n\t}\n\t\n\tfunction sortByPos(a, b) {\n\t  return a.pos - b.pos;\n\t}\n\t\n\tfunction collectLeaves(revs) {\n\t  var leaves = [];\n\t  traverseRevTree(revs, function (isLeaf, pos, id, acc, opts) {\n\t    if (isLeaf) {\n\t      leaves.push({rev: pos + \"-\" + id, pos: pos, opts: opts});\n\t    }\n\t  });\n\t  leaves.sort(sortByPos).reverse();\n\t  for (var i = 0, len = leaves.length; i < len; i++) {\n\t    delete leaves[i].pos;\n\t  }\n\t  return leaves;\n\t}\n\t\n\t// returns revs of all conflicts that is leaves such that\n\t// 1. are not deleted and\n\t// 2. are different than winning revision\n\tfunction collectConflicts(metadata) {\n\t  var win = winningRev(metadata);\n\t  var leaves = collectLeaves(metadata.rev_tree);\n\t  var conflicts = [];\n\t  for (var i = 0, len = leaves.length; i < len; i++) {\n\t    var leaf = leaves[i];\n\t    if (leaf.rev !== win && !leaf.opts.deleted) {\n\t      conflicts.push(leaf.rev);\n\t    }\n\t  }\n\t  return conflicts;\n\t}\n\t\n\t// compact a tree by marking its non-leafs as missing,\n\t// and return a list of revs to delete\n\tfunction compactTree(metadata) {\n\t  var revs = [];\n\t  traverseRevTree(metadata.rev_tree, function (isLeaf, pos,\n\t                                               revHash, ctx, opts) {\n\t    if (opts.status === 'available' && !isLeaf) {\n\t      revs.push(pos + '-' + revHash);\n\t      opts.status = 'missing';\n\t    }\n\t  });\n\t  return revs;\n\t}\n\t\n\t// build up a list of all the paths to the leafs in this revision tree\n\tfunction rootToLeaf(revs) {\n\t  var paths = [];\n\t  var toVisit = revs.slice();\n\t  var node;\n\t  while ((node = toVisit.pop())) {\n\t    var pos = node.pos;\n\t    var tree = node.ids;\n\t    var id = tree[0];\n\t    var opts = tree[1];\n\t    var branches = tree[2];\n\t    var isLeaf = branches.length === 0;\n\t\n\t    var history = node.history ? node.history.slice() : [];\n\t    history.push({id: id, opts: opts});\n\t    if (isLeaf) {\n\t      paths.push({pos: (pos + 1 - history.length), ids: history});\n\t    }\n\t    for (var i = 0, len = branches.length; i < len; i++) {\n\t      toVisit.push({pos: pos + 1, ids: branches[i], history: history});\n\t    }\n\t  }\n\t  return paths.reverse();\n\t}\n\t\n\t// for a better overview of what this is doing, read:\n\t// https://github.com/apache/couchdb-couch/blob/master/src/couch_key_tree.erl\n\t//\n\t// But for a quick intro, CouchDB uses a revision tree to store a documents\n\t// history, A -> B -> C, when a document has conflicts, that is a branch in the\n\t// tree, A -> (B1 | B2 -> C), We store these as a nested array in the format\n\t//\n\t// KeyTree = [Path ... ]\n\t// Path = {pos: position_from_root, ids: Tree}\n\t// Tree = [Key, Opts, [Tree, ...]], in particular single node: [Key, []]\n\t\n\tfunction sortByPos$1(a, b) {\n\t  return a.pos - b.pos;\n\t}\n\t\n\t// classic binary search\n\tfunction binarySearch(arr, item, comparator) {\n\t  var low = 0;\n\t  var high = arr.length;\n\t  var mid;\n\t  while (low < high) {\n\t    mid = (low + high) >>> 1;\n\t    if (comparator(arr[mid], item) < 0) {\n\t      low = mid + 1;\n\t    } else {\n\t      high = mid;\n\t    }\n\t  }\n\t  return low;\n\t}\n\t\n\t// assuming the arr is sorted, insert the item in the proper place\n\tfunction insertSorted(arr, item, comparator) {\n\t  var idx = binarySearch(arr, item, comparator);\n\t  arr.splice(idx, 0, item);\n\t}\n\t\n\t// Turn a path as a flat array into a tree with a single branch.\n\t// If any should be stemmed from the beginning of the array, that's passed\n\t// in as the second argument\n\tfunction pathToTree(path, numStemmed) {\n\t  var root;\n\t  var leaf;\n\t  for (var i = numStemmed, len = path.length; i < len; i++) {\n\t    var node = path[i];\n\t    var currentLeaf = [node.id, node.opts, []];\n\t    if (leaf) {\n\t      leaf[2].push(currentLeaf);\n\t      leaf = currentLeaf;\n\t    } else {\n\t      root = leaf = currentLeaf;\n\t    }\n\t  }\n\t  return root;\n\t}\n\t\n\t// compare the IDs of two trees\n\tfunction compareTree(a, b) {\n\t  return a[0] < b[0] ? -1 : 1;\n\t}\n\t\n\t// Merge two trees together\n\t// The roots of tree1 and tree2 must be the same revision\n\tfunction mergeTree(in_tree1, in_tree2) {\n\t  var queue = [{tree1: in_tree1, tree2: in_tree2}];\n\t  var conflicts = false;\n\t  while (queue.length > 0) {\n\t    var item = queue.pop();\n\t    var tree1 = item.tree1;\n\t    var tree2 = item.tree2;\n\t\n\t    if (tree1[1].status || tree2[1].status) {\n\t      tree1[1].status =\n\t        (tree1[1].status ===  'available' ||\n\t        tree2[1].status === 'available') ? 'available' : 'missing';\n\t    }\n\t\n\t    for (var i = 0; i < tree2[2].length; i++) {\n\t      if (!tree1[2][0]) {\n\t        conflicts = 'new_leaf';\n\t        tree1[2][0] = tree2[2][i];\n\t        continue;\n\t      }\n\t\n\t      var merged = false;\n\t      for (var j = 0; j < tree1[2].length; j++) {\n\t        if (tree1[2][j][0] === tree2[2][i][0]) {\n\t          queue.push({tree1: tree1[2][j], tree2: tree2[2][i]});\n\t          merged = true;\n\t        }\n\t      }\n\t      if (!merged) {\n\t        conflicts = 'new_branch';\n\t        insertSorted(tree1[2], tree2[2][i], compareTree);\n\t      }\n\t    }\n\t  }\n\t  return {conflicts: conflicts, tree: in_tree1};\n\t}\n\t\n\tfunction doMerge(tree, path, dontExpand) {\n\t  var restree = [];\n\t  var conflicts = false;\n\t  var merged = false;\n\t  var res;\n\t\n\t  if (!tree.length) {\n\t    return {tree: [path], conflicts: 'new_leaf'};\n\t  }\n\t\n\t  for (var i = 0, len = tree.length; i < len; i++) {\n\t    var branch = tree[i];\n\t    if (branch.pos === path.pos && branch.ids[0] === path.ids[0]) {\n\t      // Paths start at the same position and have the same root, so they need\n\t      // merged\n\t      res = mergeTree(branch.ids, path.ids);\n\t      restree.push({pos: branch.pos, ids: res.tree});\n\t      conflicts = conflicts || res.conflicts;\n\t      merged = true;\n\t    } else if (dontExpand !== true) {\n\t      // The paths start at a different position, take the earliest path and\n\t      // traverse up until it as at the same point from root as the path we\n\t      // want to merge.  If the keys match we return the longer path with the\n\t      // other merged After stemming we dont want to expand the trees\n\t\n\t      var t1 = branch.pos < path.pos ? branch : path;\n\t      var t2 = branch.pos < path.pos ? path : branch;\n\t      var diff = t2.pos - t1.pos;\n\t\n\t      var candidateParents = [];\n\t\n\t      var trees = [];\n\t      trees.push({ids: t1.ids, diff: diff, parent: null, parentIdx: null});\n\t      while (trees.length > 0) {\n\t        var item = trees.pop();\n\t        if (item.diff === 0) {\n\t          if (item.ids[0] === t2.ids[0]) {\n\t            candidateParents.push(item);\n\t          }\n\t          continue;\n\t        }\n\t        var elements = item.ids[2];\n\t        for (var j = 0, elementsLen = elements.length; j < elementsLen; j++) {\n\t          trees.push({\n\t            ids: elements[j],\n\t            diff: item.diff - 1,\n\t            parent: item.ids,\n\t            parentIdx: j\n\t          });\n\t        }\n\t      }\n\t\n\t      var el = candidateParents[0];\n\t\n\t      if (!el) {\n\t        restree.push(branch);\n\t      } else {\n\t        res = mergeTree(el.ids, t2.ids);\n\t        el.parent[2][el.parentIdx] = res.tree;\n\t        restree.push({pos: t1.pos, ids: t1.ids});\n\t        conflicts = conflicts || res.conflicts;\n\t        merged = true;\n\t      }\n\t    } else {\n\t      restree.push(branch);\n\t    }\n\t  }\n\t\n\t  // We didnt find\n\t  if (!merged) {\n\t    restree.push(path);\n\t  }\n\t\n\t  restree.sort(sortByPos$1);\n\t\n\t  return {\n\t    tree: restree,\n\t    conflicts: conflicts || 'internal_node'\n\t  };\n\t}\n\t\n\t// To ensure we dont grow the revision tree infinitely, we stem old revisions\n\tfunction stem(tree, depth) {\n\t  // First we break out the tree into a complete list of root to leaf paths\n\t  var paths = rootToLeaf(tree);\n\t  var maybeStem = {};\n\t\n\t  var result;\n\t  for (var i = 0, len = paths.length; i < len; i++) {\n\t    // Then for each path, we cut off the start of the path based on the\n\t    // `depth` to stem to, and generate a new set of flat trees\n\t    var path = paths[i];\n\t    var stemmed = path.ids;\n\t    var numStemmed = Math.max(0, stemmed.length - depth);\n\t    var stemmedNode = {\n\t      pos: path.pos + numStemmed,\n\t      ids: pathToTree(stemmed, numStemmed)\n\t    };\n\t\n\t    for (var s = 0; s < numStemmed; s++) {\n\t      var rev = (path.pos + s) + '-' + stemmed[s].id;\n\t      maybeStem[rev] = true;\n\t    }\n\t\n\t    // Then we remerge all those flat trees together, ensuring that we dont\n\t    // connect trees that would go beyond the depth limit\n\t    if (result) {\n\t      result = doMerge(result, stemmedNode, true).tree;\n\t    } else {\n\t      result = [stemmedNode];\n\t    }\n\t  }\n\t\n\t  traverseRevTree(result, function (isLeaf, pos, revHash) {\n\t    // some revisions may have been removed in a branch but not in another\n\t    delete maybeStem[pos + '-' + revHash];\n\t  });\n\t\n\t  return {\n\t    tree: result,\n\t    revs: Object.keys(maybeStem)\n\t  };\n\t}\n\t\n\tfunction merge(tree, path, depth) {\n\t  var newTree = doMerge(tree, path);\n\t  var stemmed = stem(newTree.tree, depth);\n\t  return {\n\t    tree: stemmed.tree,\n\t    stemmedRevs: stemmed.revs,\n\t    conflicts: newTree.conflicts\n\t  };\n\t}\n\t\n\t// return true if a rev exists in the rev tree, false otherwise\n\tfunction revExists(revs, rev) {\n\t  var toVisit = revs.slice();\n\t  var splitRev = rev.split('-');\n\t  var targetPos = parseInt(splitRev[0], 10);\n\t  var targetId = splitRev[1];\n\t\n\t  var node;\n\t  while ((node = toVisit.pop())) {\n\t    if (node.pos === targetPos && node.ids[0] === targetId) {\n\t      return true;\n\t    }\n\t    var branches = node.ids[2];\n\t    for (var i = 0, len = branches.length; i < len; i++) {\n\t      toVisit.push({pos: node.pos + 1, ids: branches[i]});\n\t    }\n\t  }\n\t  return false;\n\t}\n\t\n\tfunction getTrees(node) {\n\t  return node.ids;\n\t}\n\t\n\t// check if a specific revision of a doc has been deleted\n\t//  - metadata: the metadata object from the doc store\n\t//  - rev: (optional) the revision to check. defaults to winning revision\n\tfunction isDeleted(metadata, rev) {\n\t  if (!rev) {\n\t    rev = winningRev(metadata);\n\t  }\n\t  var id = rev.substring(rev.indexOf('-') + 1);\n\t  var toVisit = metadata.rev_tree.map(getTrees);\n\t\n\t  var tree;\n\t  while ((tree = toVisit.pop())) {\n\t    if (tree[0] === id) {\n\t      return !!tree[1].deleted;\n\t    }\n\t    toVisit = toVisit.concat(tree[2]);\n\t  }\n\t}\n\t\n\tfunction isLocalId(id) {\n\t  return (/^_local/).test(id);\n\t}\n\t\n\t// returns the current leaf node for a given revision\n\tfunction latest(rev, metadata) {\n\t  var toVisit = metadata.rev_tree.slice();\n\t  var node;\n\t  while ((node = toVisit.pop())) {\n\t    var pos = node.pos;\n\t    var tree = node.ids;\n\t    var id = tree[0];\n\t    var opts = tree[1];\n\t    var branches = tree[2];\n\t    var isLeaf = branches.length === 0;\n\t\n\t    var history = node.history ? node.history.slice() : [];\n\t    history.push({id: id, pos: pos, opts: opts});\n\t\n\t    if (isLeaf) {\n\t      for (var i = 0, len = history.length; i < len; i++) {\n\t        var historyNode = history[i];\n\t        var historyRev = historyNode.pos + '-' + historyNode.id;\n\t\n\t        if (historyRev === rev) {\n\t          // return the rev of this leaf\n\t          return pos + '-' + id;\n\t        }\n\t      }\n\t    }\n\t\n\t    for (var j = 0, l = branches.length; j < l; j++) {\n\t      toVisit.push({pos: pos + 1, ids: branches[j], history: history});\n\t    }\n\t  }\n\t\n\t  /* istanbul ignore next */\n\t  throw new Error('Unable to resolve latest revision for id ' + metadata.id + ', rev ' + rev);\n\t}\n\t\n\tfunction evalFilter(input) {\n\t  return scopedEval('\"use strict\";\\nreturn ' + input + ';', {});\n\t}\n\t\n\tfunction evalView(input) {\n\t  var code = [\n\t    'return function(doc) {',\n\t    '  \"use strict\";',\n\t    '  var emitted = false;',\n\t    '  var emit = function (a, b) {',\n\t    '    emitted = true;',\n\t    '  };',\n\t    '  var view = ' + input + ';',\n\t    '  view(doc);',\n\t    '  if (emitted) {',\n\t    '    return true;',\n\t    '  }',\n\t    '};'\n\t  ].join('\\n');\n\t\n\t  return scopedEval(code, {});\n\t}\n\t\n\tinherits(Changes$2, events.EventEmitter);\n\t\n\tfunction tryCatchInChangeListener(self, change) {\n\t  // isolate try/catches to avoid V8 deoptimizations\n\t  try {\n\t    self.emit('change', change);\n\t  } catch (e) {\n\t    guardedConsole('error', 'Error in .on(\"change\", function):', e);\n\t  }\n\t}\n\t\n\tfunction Changes$2(db, opts, callback) {\n\t  events.EventEmitter.call(this);\n\t  var self = this;\n\t  this.db = db;\n\t  opts = opts ? clone(opts) : {};\n\t  var complete = opts.complete = once(function (err, resp) {\n\t    if (err) {\n\t      if (listenerCount(self, 'error') > 0) {\n\t        self.emit('error', err);\n\t      }\n\t    } else {\n\t      self.emit('complete', resp);\n\t    }\n\t    self.removeAllListeners();\n\t    db.removeListener('destroyed', onDestroy);\n\t  });\n\t  if (callback) {\n\t    self.on('complete', function (resp) {\n\t      callback(null, resp);\n\t    });\n\t    self.on('error', callback);\n\t  }\n\t  function onDestroy() {\n\t    self.cancel();\n\t  }\n\t  db.once('destroyed', onDestroy);\n\t\n\t  opts.onChange = function (change) {\n\t    /* istanbul ignore if */\n\t    if (self.isCancelled) {\n\t      return;\n\t    }\n\t    tryCatchInChangeListener(self, change);\n\t  };\n\t\n\t  var promise = new PouchPromise$1(function (fulfill, reject) {\n\t    opts.complete = function (err, res) {\n\t      if (err) {\n\t        reject(err);\n\t      } else {\n\t        fulfill(res);\n\t      }\n\t    };\n\t  });\n\t  self.once('cancel', function () {\n\t    db.removeListener('destroyed', onDestroy);\n\t    opts.complete(null, {status: 'cancelled'});\n\t  });\n\t  this.then = promise.then.bind(promise);\n\t  this['catch'] = promise['catch'].bind(promise);\n\t  this.then(function (result) {\n\t    complete(null, result);\n\t  }, complete);\n\t\n\t\n\t\n\t  if (!db.taskqueue.isReady) {\n\t    db.taskqueue.addTask(function (failed) {\n\t      if (failed) {\n\t        opts.complete(failed);\n\t      } else if (self.isCancelled) {\n\t        self.emit('cancel');\n\t      } else {\n\t        self.doChanges(opts);\n\t      }\n\t    });\n\t  } else {\n\t    self.doChanges(opts);\n\t  }\n\t}\n\tChanges$2.prototype.cancel = function () {\n\t  this.isCancelled = true;\n\t  if (this.db.taskqueue.isReady) {\n\t    this.emit('cancel');\n\t  }\n\t};\n\tfunction processChange(doc, metadata, opts) {\n\t  var changeList = [{rev: doc._rev}];\n\t  if (opts.style === 'all_docs') {\n\t    changeList = collectLeaves(metadata.rev_tree)\n\t    .map(function (x) { return {rev: x.rev}; });\n\t  }\n\t  var change = {\n\t    id: metadata.id,\n\t    changes: changeList,\n\t    doc: doc\n\t  };\n\t\n\t  if (isDeleted(metadata, doc._rev)) {\n\t    change.deleted = true;\n\t  }\n\t  if (opts.conflicts) {\n\t    change.doc._conflicts = collectConflicts(metadata);\n\t    if (!change.doc._conflicts.length) {\n\t      delete change.doc._conflicts;\n\t    }\n\t  }\n\t  return change;\n\t}\n\t\n\tChanges$2.prototype.doChanges = function (opts) {\n\t  var self = this;\n\t  var callback = opts.complete;\n\t\n\t  opts = clone(opts);\n\t  if ('live' in opts && !('continuous' in opts)) {\n\t    opts.continuous = opts.live;\n\t  }\n\t  opts.processChange = processChange;\n\t\n\t  if (opts.since === 'latest') {\n\t    opts.since = 'now';\n\t  }\n\t  if (!opts.since) {\n\t    opts.since = 0;\n\t  }\n\t  if (opts.since === 'now') {\n\t    this.db.info().then(function (info) {\n\t      /* istanbul ignore if */\n\t      if (self.isCancelled) {\n\t        callback(null, {status: 'cancelled'});\n\t        return;\n\t      }\n\t      opts.since = info.update_seq;\n\t      self.doChanges(opts);\n\t    }, callback);\n\t    return;\n\t  }\n\t\n\t\n\t  if (opts.view && !opts.filter) {\n\t    opts.filter = '_view';\n\t  }\n\t\n\t  if (opts.filter && typeof opts.filter === 'string') {\n\t    if (opts.filter === '_view') {\n\t      opts.view = normalizeDesignDocFunctionName(opts.view);\n\t    } else {\n\t      opts.filter = normalizeDesignDocFunctionName(opts.filter);\n\t    }\n\t\n\t    if (this.db.type() !== 'http' && !opts.doc_ids) {\n\t      return this.filterChanges(opts);\n\t    }\n\t  }\n\t\n\t  if (!('descending' in opts)) {\n\t    opts.descending = false;\n\t  }\n\t\n\t  // 0 and 1 should return 1 document\n\t  opts.limit = opts.limit === 0 ? 1 : opts.limit;\n\t  opts.complete = callback;\n\t  var newPromise = this.db._changes(opts);\n\t  /* istanbul ignore else */\n\t  if (newPromise && typeof newPromise.cancel === 'function') {\n\t    var cancel = self.cancel;\n\t    self.cancel = getArguments(function (args) {\n\t      newPromise.cancel();\n\t      cancel.apply(this, args);\n\t    });\n\t  }\n\t};\n\t\n\tChanges$2.prototype.filterChanges = function (opts) {\n\t  var self = this;\n\t  var callback = opts.complete;\n\t  if (opts.filter === '_view') {\n\t    if (!opts.view || typeof opts.view !== 'string') {\n\t      var err = createError(BAD_REQUEST,\n\t        '`view` filter parameter not found or invalid.');\n\t      return callback(err);\n\t    }\n\t    // fetch a view from a design doc, make it behave like a filter\n\t    var viewName = parseDesignDocFunctionName(opts.view);\n\t    this.db.get('_design/' + viewName[0], function (err, ddoc) {\n\t      /* istanbul ignore if */\n\t      if (self.isCancelled) {\n\t        return callback(null, {status: 'cancelled'});\n\t      }\n\t      /* istanbul ignore next */\n\t      if (err) {\n\t        return callback(generateErrorFromResponse(err));\n\t      }\n\t      var mapFun = ddoc && ddoc.views && ddoc.views[viewName[1]] &&\n\t        ddoc.views[viewName[1]].map;\n\t      if (!mapFun) {\n\t        return callback(createError(MISSING_DOC,\n\t          (ddoc.views ? 'missing json key: ' + viewName[1] :\n\t            'missing json key: views')));\n\t      }\n\t      opts.filter = evalView(mapFun);\n\t      self.doChanges(opts);\n\t    });\n\t  } else {\n\t    // fetch a filter from a design doc\n\t    var filterName = parseDesignDocFunctionName(opts.filter);\n\t    if (!filterName) {\n\t      return self.doChanges(opts);\n\t    }\n\t    this.db.get('_design/' + filterName[0], function (err, ddoc) {\n\t      /* istanbul ignore if */\n\t      if (self.isCancelled) {\n\t        return callback(null, {status: 'cancelled'});\n\t      }\n\t      /* istanbul ignore next */\n\t      if (err) {\n\t        return callback(generateErrorFromResponse(err));\n\t      }\n\t      var filterFun = ddoc && ddoc.filters && ddoc.filters[filterName[1]];\n\t      if (!filterFun) {\n\t        return callback(createError(MISSING_DOC,\n\t          ((ddoc && ddoc.filters) ? 'missing json key: ' + filterName[1]\n\t            : 'missing json key: filters')));\n\t      }\n\t      opts.filter = evalFilter(filterFun);\n\t      self.doChanges(opts);\n\t    });\n\t  }\n\t};\n\t\n\t/*\n\t * A generic pouch adapter\n\t */\n\t\n\tfunction compare(left, right) {\n\t  return left < right ? -1 : left > right ? 1 : 0;\n\t}\n\t\n\t// Wrapper for functions that call the bulkdocs api with a single doc,\n\t// if the first result is an error, return an error\n\tfunction yankError(callback) {\n\t  return function (err, results) {\n\t    if (err || (results[0] && results[0].error)) {\n\t      callback(err || results[0]);\n\t    } else {\n\t      callback(null, results.length ? results[0]  : results);\n\t    }\n\t  };\n\t}\n\t\n\t// clean docs given to us by the user\n\tfunction cleanDocs(docs) {\n\t  for (var i = 0; i < docs.length; i++) {\n\t    var doc = docs[i];\n\t    if (doc._deleted) {\n\t      delete doc._attachments; // ignore atts for deleted docs\n\t    } else if (doc._attachments) {\n\t      // filter out extraneous keys from _attachments\n\t      var atts = Object.keys(doc._attachments);\n\t      for (var j = 0; j < atts.length; j++) {\n\t        var att = atts[j];\n\t        doc._attachments[att] = pick(doc._attachments[att],\n\t          ['data', 'digest', 'content_type', 'length', 'revpos', 'stub']);\n\t      }\n\t    }\n\t  }\n\t}\n\t\n\t// compare two docs, first by _id then by _rev\n\tfunction compareByIdThenRev(a, b) {\n\t  var idCompare = compare(a._id, b._id);\n\t  if (idCompare !== 0) {\n\t    return idCompare;\n\t  }\n\t  var aStart = a._revisions ? a._revisions.start : 0;\n\t  var bStart = b._revisions ? b._revisions.start : 0;\n\t  return compare(aStart, bStart);\n\t}\n\t\n\t// for every node in a revision tree computes its distance from the closest\n\t// leaf\n\tfunction computeHeight(revs) {\n\t  var height = {};\n\t  var edges = [];\n\t  traverseRevTree(revs, function (isLeaf, pos, id, prnt) {\n\t    var rev = pos + \"-\" + id;\n\t    if (isLeaf) {\n\t      height[rev] = 0;\n\t    }\n\t    if (prnt !== undefined) {\n\t      edges.push({from: prnt, to: rev});\n\t    }\n\t    return rev;\n\t  });\n\t\n\t  edges.reverse();\n\t  edges.forEach(function (edge) {\n\t    if (height[edge.from] === undefined) {\n\t      height[edge.from] = 1 + height[edge.to];\n\t    } else {\n\t      height[edge.from] = Math.min(height[edge.from], 1 + height[edge.to]);\n\t    }\n\t  });\n\t  return height;\n\t}\n\t\n\tfunction allDocsKeysQuery(api, opts, callback) {\n\t  var keys =  ('limit' in opts) ?\n\t      opts.keys.slice(opts.skip, opts.limit + opts.skip) :\n\t      (opts.skip > 0) ? opts.keys.slice(opts.skip) : opts.keys;\n\t  if (opts.descending) {\n\t    keys.reverse();\n\t  }\n\t  if (!keys.length) {\n\t    return api._allDocs({limit: 0}, callback);\n\t  }\n\t  var finalResults = {\n\t    offset: opts.skip\n\t  };\n\t  return PouchPromise$1.all(keys.map(function (key) {\n\t    var subOpts = assign$1({key: key, deleted: 'ok'}, opts);\n\t    ['limit', 'skip', 'keys'].forEach(function (optKey) {\n\t      delete subOpts[optKey];\n\t    });\n\t    return new PouchPromise$1(function (resolve, reject) {\n\t      api._allDocs(subOpts, function (err, res) {\n\t        /* istanbul ignore if */\n\t        if (err) {\n\t          return reject(err);\n\t        }\n\t        finalResults.total_rows = res.total_rows;\n\t        resolve(res.rows[0] || {key: key, error: 'not_found'});\n\t      });\n\t    });\n\t  })).then(function (results) {\n\t    finalResults.rows = results;\n\t    return finalResults;\n\t  });\n\t}\n\t\n\t// all compaction is done in a queue, to avoid attaching\n\t// too many listeners at once\n\tfunction doNextCompaction(self) {\n\t  var task = self._compactionQueue[0];\n\t  var opts = task.opts;\n\t  var callback = task.callback;\n\t  self.get('_local/compaction').catch(function () {\n\t    return false;\n\t  }).then(function (doc) {\n\t    if (doc && doc.last_seq) {\n\t      opts.last_seq = doc.last_seq;\n\t    }\n\t    self._compact(opts, function (err, res) {\n\t      /* istanbul ignore if */\n\t      if (err) {\n\t        callback(err);\n\t      } else {\n\t        callback(null, res);\n\t      }\n\t      nextTick(function () {\n\t        self._compactionQueue.shift();\n\t        if (self._compactionQueue.length) {\n\t          doNextCompaction(self);\n\t        }\n\t      });\n\t    });\n\t  });\n\t}\n\t\n\tfunction attachmentNameError(name) {\n\t  if (name.charAt(0) === '_') {\n\t    return name + 'is not a valid attachment name, attachment ' +\n\t      'names cannot start with \\'_\\'';\n\t  }\n\t  return false;\n\t}\n\t\n\tinherits(AbstractPouchDB, events.EventEmitter);\n\t\n\tfunction AbstractPouchDB() {\n\t  events.EventEmitter.call(this);\n\t}\n\t\n\tAbstractPouchDB.prototype.post =\n\t  adapterFun('post', function (doc, opts, callback) {\n\t  if (typeof opts === 'function') {\n\t    callback = opts;\n\t    opts = {};\n\t  }\n\t  if (typeof doc !== 'object' || Array.isArray(doc)) {\n\t    return callback(createError(NOT_AN_OBJECT));\n\t  }\n\t  this.bulkDocs({docs: [doc]}, opts, yankError(callback));\n\t});\n\t\n\tAbstractPouchDB.prototype.put = adapterFun('put', function (doc, opts, cb) {\n\t  if (typeof opts === 'function') {\n\t    cb = opts;\n\t    opts = {};\n\t  }\n\t  if (typeof doc !== 'object' || Array.isArray(doc)) {\n\t    return cb(createError(NOT_AN_OBJECT));\n\t  }\n\t  invalidIdError(doc._id);\n\t  if (isLocalId(doc._id) && typeof this._putLocal === 'function') {\n\t    if (doc._deleted) {\n\t      return this._removeLocal(doc, cb);\n\t    } else {\n\t      return this._putLocal(doc, cb);\n\t    }\n\t  }\n\t  if (typeof this._put === 'function' && opts.new_edits !== false) {\n\t    this._put(doc, opts, cb);\n\t  } else {\n\t    this.bulkDocs({docs: [doc]}, opts, yankError(cb));\n\t  }\n\t});\n\t\n\tAbstractPouchDB.prototype.putAttachment =\n\t  adapterFun('putAttachment', function (docId, attachmentId, rev,\n\t                                              blob, type) {\n\t  var api = this;\n\t  if (typeof type === 'function') {\n\t    type = blob;\n\t    blob = rev;\n\t    rev = null;\n\t  }\n\t  // Lets fix in https://github.com/pouchdb/pouchdb/issues/3267\n\t  /* istanbul ignore if */\n\t  if (typeof type === 'undefined') {\n\t    type = blob;\n\t    blob = rev;\n\t    rev = null;\n\t  }\n\t  if (!type) {\n\t    guardedConsole('warn', 'Attachment', attachmentId, 'on document', docId, 'is missing content_type');\n\t  }\n\t\n\t  function createAttachment(doc) {\n\t    var prevrevpos = '_rev' in doc ? parseInt(doc._rev, 10) : 0;\n\t    doc._attachments = doc._attachments || {};\n\t    doc._attachments[attachmentId] = {\n\t      content_type: type,\n\t      data: blob,\n\t      revpos: ++prevrevpos\n\t    };\n\t    return api.put(doc);\n\t  }\n\t\n\t  return api.get(docId).then(function (doc) {\n\t    if (doc._rev !== rev) {\n\t      throw createError(REV_CONFLICT);\n\t    }\n\t\n\t    return createAttachment(doc);\n\t  }, function (err) {\n\t     // create new doc\n\t    /* istanbul ignore else */\n\t    if (err.reason === MISSING_DOC.message) {\n\t      return createAttachment({_id: docId});\n\t    } else {\n\t      throw err;\n\t    }\n\t  });\n\t});\n\t\n\tAbstractPouchDB.prototype.removeAttachment =\n\t  adapterFun('removeAttachment', function (docId, attachmentId, rev,\n\t                                                 callback) {\n\t  var self = this;\n\t  self.get(docId, function (err, obj) {\n\t    /* istanbul ignore if */\n\t    if (err) {\n\t      callback(err);\n\t      return;\n\t    }\n\t    if (obj._rev !== rev) {\n\t      callback(createError(REV_CONFLICT));\n\t      return;\n\t    }\n\t    /* istanbul ignore if */\n\t    if (!obj._attachments) {\n\t      return callback();\n\t    }\n\t    delete obj._attachments[attachmentId];\n\t    if (Object.keys(obj._attachments).length === 0) {\n\t      delete obj._attachments;\n\t    }\n\t    self.put(obj, callback);\n\t  });\n\t});\n\t\n\tAbstractPouchDB.prototype.remove =\n\t  adapterFun('remove', function (docOrId, optsOrRev, opts, callback) {\n\t  var doc;\n\t  if (typeof optsOrRev === 'string') {\n\t    // id, rev, opts, callback style\n\t    doc = {\n\t      _id: docOrId,\n\t      _rev: optsOrRev\n\t    };\n\t    if (typeof opts === 'function') {\n\t      callback = opts;\n\t      opts = {};\n\t    }\n\t  } else {\n\t    // doc, opts, callback style\n\t    doc = docOrId;\n\t    if (typeof optsOrRev === 'function') {\n\t      callback = optsOrRev;\n\t      opts = {};\n\t    } else {\n\t      callback = opts;\n\t      opts = optsOrRev;\n\t    }\n\t  }\n\t  opts = opts || {};\n\t  opts.was_delete = true;\n\t  var newDoc = {_id: doc._id, _rev: (doc._rev || opts.rev)};\n\t  newDoc._deleted = true;\n\t  if (isLocalId(newDoc._id) && typeof this._removeLocal === 'function') {\n\t    return this._removeLocal(doc, callback);\n\t  }\n\t  this.bulkDocs({docs: [newDoc]}, opts, yankError(callback));\n\t});\n\t\n\tAbstractPouchDB.prototype.revsDiff =\n\t  adapterFun('revsDiff', function (req, opts, callback) {\n\t  if (typeof opts === 'function') {\n\t    callback = opts;\n\t    opts = {};\n\t  }\n\t  var ids = Object.keys(req);\n\t\n\t  if (!ids.length) {\n\t    return callback(null, {});\n\t  }\n\t\n\t  var count = 0;\n\t  var missing = new ExportedMap();\n\t\n\t  function addToMissing(id, revId) {\n\t    if (!missing.has(id)) {\n\t      missing.set(id, {missing: []});\n\t    }\n\t    missing.get(id).missing.push(revId);\n\t  }\n\t\n\t  function processDoc(id, rev_tree) {\n\t    // Is this fast enough? Maybe we should switch to a set simulated by a map\n\t    var missingForId = req[id].slice(0);\n\t    traverseRevTree(rev_tree, function (isLeaf, pos, revHash, ctx,\n\t      opts) {\n\t        var rev = pos + '-' + revHash;\n\t        var idx = missingForId.indexOf(rev);\n\t        if (idx === -1) {\n\t          return;\n\t        }\n\t\n\t        missingForId.splice(idx, 1);\n\t        /* istanbul ignore if */\n\t        if (opts.status !== 'available') {\n\t          addToMissing(id, rev);\n\t        }\n\t      });\n\t\n\t    // Traversing the tree is synchronous, so now `missingForId` contains\n\t    // revisions that were not found in the tree\n\t    missingForId.forEach(function (rev) {\n\t      addToMissing(id, rev);\n\t    });\n\t  }\n\t\n\t  ids.map(function (id) {\n\t    this._getRevisionTree(id, function (err, rev_tree) {\n\t      if (err && err.status === 404 && err.message === 'missing') {\n\t        missing.set(id, {missing: req[id]});\n\t      } else if (err) {\n\t        /* istanbul ignore next */\n\t        return callback(err);\n\t      } else {\n\t        processDoc(id, rev_tree);\n\t      }\n\t\n\t      if (++count === ids.length) {\n\t        // convert LazyMap to object\n\t        var missingObj = {};\n\t        missing.forEach(function (value, key) {\n\t          missingObj[key] = value;\n\t        });\n\t        return callback(null, missingObj);\n\t      }\n\t    });\n\t  }, this);\n\t});\n\t\n\t// _bulk_get API for faster replication, as described in\n\t// https://github.com/apache/couchdb-chttpd/pull/33\n\t// At the \"abstract\" level, it will just run multiple get()s in\n\t// parallel, because this isn't much of a performance cost\n\t// for local databases (except the cost of multiple transactions, which is\n\t// small). The http adapter overrides this in order\n\t// to do a more efficient single HTTP request.\n\tAbstractPouchDB.prototype.bulkGet =\n\t  adapterFun('bulkGet', function (opts, callback) {\n\t  bulkGet(this, opts, callback);\n\t});\n\t\n\t// compact one document and fire callback\n\t// by compacting we mean removing all revisions which\n\t// are further from the leaf in revision tree than max_height\n\tAbstractPouchDB.prototype.compactDocument =\n\t  adapterFun('compactDocument', function (docId, maxHeight, callback) {\n\t  var self = this;\n\t  this._getRevisionTree(docId, function (err, revTree) {\n\t    /* istanbul ignore if */\n\t    if (err) {\n\t      return callback(err);\n\t    }\n\t    var height = computeHeight(revTree);\n\t    var candidates = [];\n\t    var revs = [];\n\t    Object.keys(height).forEach(function (rev) {\n\t      if (height[rev] > maxHeight) {\n\t        candidates.push(rev);\n\t      }\n\t    });\n\t\n\t    traverseRevTree(revTree, function (isLeaf, pos, revHash, ctx, opts) {\n\t      var rev = pos + '-' + revHash;\n\t      if (opts.status === 'available' && candidates.indexOf(rev) !== -1) {\n\t        revs.push(rev);\n\t      }\n\t    });\n\t    self._doCompaction(docId, revs, callback);\n\t  });\n\t});\n\t\n\t// compact the whole database using single document\n\t// compaction\n\tAbstractPouchDB.prototype.compact =\n\t  adapterFun('compact', function (opts, callback) {\n\t  if (typeof opts === 'function') {\n\t    callback = opts;\n\t    opts = {};\n\t  }\n\t\n\t  var self = this;\n\t  opts = opts || {};\n\t\n\t  self._compactionQueue = self._compactionQueue || [];\n\t  self._compactionQueue.push({opts: opts, callback: callback});\n\t  if (self._compactionQueue.length === 1) {\n\t    doNextCompaction(self);\n\t  }\n\t});\n\tAbstractPouchDB.prototype._compact = function (opts, callback) {\n\t  var self = this;\n\t  var changesOpts = {\n\t    return_docs: false,\n\t    last_seq: opts.last_seq || 0\n\t  };\n\t  var promises = [];\n\t\n\t  function onChange(row) {\n\t    promises.push(self.compactDocument(row.id, 0));\n\t  }\n\t  function onComplete(resp) {\n\t    var lastSeq = resp.last_seq;\n\t    PouchPromise$1.all(promises).then(function () {\n\t      return upsert(self, '_local/compaction', function deltaFunc(doc) {\n\t        if (!doc.last_seq || doc.last_seq < lastSeq) {\n\t          doc.last_seq = lastSeq;\n\t          return doc;\n\t        }\n\t        return false; // somebody else got here first, don't update\n\t      });\n\t    }).then(function () {\n\t      callback(null, {ok: true});\n\t    }).catch(callback);\n\t  }\n\t  self.changes(changesOpts)\n\t    .on('change', onChange)\n\t    .on('complete', onComplete)\n\t    .on('error', callback);\n\t};\n\t\n\t/* Begin api wrappers. Specific functionality to storage belongs in the\n\t   _[method] */\n\tAbstractPouchDB.prototype.get = adapterFun('get', function (id, opts, cb) {\n\t  if (typeof opts === 'function') {\n\t    cb = opts;\n\t    opts = {};\n\t  }\n\t  if (typeof id !== 'string') {\n\t    return cb(createError(INVALID_ID));\n\t  }\n\t  if (isLocalId(id) && typeof this._getLocal === 'function') {\n\t    return this._getLocal(id, cb);\n\t  }\n\t  var leaves = [], self = this;\n\t\n\t  function finishOpenRevs() {\n\t    var result = [];\n\t    var count = leaves.length;\n\t    /* istanbul ignore if */\n\t    if (!count) {\n\t      return cb(null, result);\n\t    }\n\t\n\t    // order with open_revs is unspecified\n\t    leaves.forEach(function (leaf) {\n\t      self.get(id, {\n\t        rev: leaf,\n\t        revs: opts.revs,\n\t        latest: opts.latest,\n\t        attachments: opts.attachments\n\t      }, function (err, doc) {\n\t        if (!err) {\n\t          // using latest=true can produce duplicates\n\t          var existing;\n\t          for (var i = 0, l = result.length; i < l; i++) {\n\t            if (result[i].ok && result[i].ok._rev === doc._rev) {\n\t              existing = true;\n\t              break;\n\t            }\n\t          }\n\t          if (!existing) {\n\t            result.push({ok: doc});\n\t          }\n\t        } else {\n\t          result.push({missing: leaf});\n\t        }\n\t        count--;\n\t        if (!count) {\n\t          cb(null, result);\n\t        }\n\t      });\n\t    });\n\t  }\n\t\n\t  if (opts.open_revs) {\n\t    if (opts.open_revs === \"all\") {\n\t      this._getRevisionTree(id, function (err, rev_tree) {\n\t        if (err) {\n\t          return cb(err);\n\t        }\n\t        leaves = collectLeaves(rev_tree).map(function (leaf) {\n\t          return leaf.rev;\n\t        });\n\t        finishOpenRevs();\n\t      });\n\t    } else {\n\t      if (Array.isArray(opts.open_revs)) {\n\t        leaves = opts.open_revs;\n\t        for (var i = 0; i < leaves.length; i++) {\n\t          var l = leaves[i];\n\t          // looks like it's the only thing couchdb checks\n\t          if (!(typeof (l) === \"string\" && /^\\d+-/.test(l))) {\n\t            return cb(createError(INVALID_REV));\n\t          }\n\t        }\n\t        finishOpenRevs();\n\t      } else {\n\t        return cb(createError(UNKNOWN_ERROR, 'function_clause'));\n\t      }\n\t    }\n\t    return; // open_revs does not like other options\n\t  }\n\t\n\t  return this._get(id, opts, function (err, result) {\n\t    if (err) {\n\t      return cb(err);\n\t    }\n\t\n\t    var doc = result.doc;\n\t    var metadata = result.metadata;\n\t    var ctx = result.ctx;\n\t\n\t    if (opts.conflicts) {\n\t      var conflicts = collectConflicts(metadata);\n\t      if (conflicts.length) {\n\t        doc._conflicts = conflicts;\n\t      }\n\t    }\n\t\n\t    if (isDeleted(metadata, doc._rev)) {\n\t      doc._deleted = true;\n\t    }\n\t\n\t    if (opts.revs || opts.revs_info) {\n\t      var splittedRev = doc._rev.split('-');\n\t      var revNo       = parseInt(splittedRev[0], 10);\n\t      var revHash     = splittedRev[1];\n\t\n\t      var paths = rootToLeaf(metadata.rev_tree);\n\t      var path = null;\n\t\n\t      for (var i = 0; i < paths.length; i++) {\n\t        var currentPath = paths[i];\n\t        var hashIndex = currentPath.ids.map(function (x) { return x.id; })\n\t          .indexOf(revHash);\n\t        var hashFoundAtRevPos = hashIndex === (revNo - 1);\n\t\n\t        if (hashFoundAtRevPos || (!path && hashIndex !== -1)) {\n\t          path = currentPath;\n\t        }\n\t      }\n\t\n\t      var indexOfRev = path.ids.map(function (x) { return x.id; })\n\t        .indexOf(doc._rev.split('-')[1]) + 1;\n\t      var howMany = path.ids.length - indexOfRev;\n\t      path.ids.splice(indexOfRev, howMany);\n\t      path.ids.reverse();\n\t\n\t      if (opts.revs) {\n\t        doc._revisions = {\n\t          start: (path.pos + path.ids.length) - 1,\n\t          ids: path.ids.map(function (rev) {\n\t            return rev.id;\n\t          })\n\t        };\n\t      }\n\t      if (opts.revs_info) {\n\t        var pos =  path.pos + path.ids.length;\n\t        doc._revs_info = path.ids.map(function (rev) {\n\t          pos--;\n\t          return {\n\t            rev: pos + '-' + rev.id,\n\t            status: rev.opts.status\n\t          };\n\t        });\n\t      }\n\t    }\n\t\n\t    if (opts.attachments && doc._attachments) {\n\t      var attachments = doc._attachments;\n\t      var count = Object.keys(attachments).length;\n\t      if (count === 0) {\n\t        return cb(null, doc);\n\t      }\n\t      Object.keys(attachments).forEach(function (key) {\n\t        this._getAttachment(doc._id, key, attachments[key], {\n\t          // Previously the revision handling was done in adapter.js\n\t          // getAttachment, however since idb-next doesnt we need to\n\t          // pass the rev through\n\t          rev: doc._rev,\n\t          binary: opts.binary,\n\t          ctx: ctx\n\t        }, function (err, data) {\n\t          var att = doc._attachments[key];\n\t          att.data = data;\n\t          delete att.stub;\n\t          delete att.length;\n\t          if (!--count) {\n\t            cb(null, doc);\n\t          }\n\t        });\n\t      }, self);\n\t    } else {\n\t      if (doc._attachments) {\n\t        for (var key in doc._attachments) {\n\t          /* istanbul ignore else */\n\t          if (doc._attachments.hasOwnProperty(key)) {\n\t            doc._attachments[key].stub = true;\n\t          }\n\t        }\n\t      }\n\t      cb(null, doc);\n\t    }\n\t  });\n\t});\n\t\n\t// TODO: I dont like this, it forces an extra read for every\n\t// attachment read and enforces a confusing api between\n\t// adapter.js and the adapter implementation\n\tAbstractPouchDB.prototype.getAttachment =\n\t  adapterFun('getAttachment', function (docId, attachmentId, opts, callback) {\n\t  var self = this;\n\t  if (opts instanceof Function) {\n\t    callback = opts;\n\t    opts = {};\n\t  }\n\t  this._get(docId, opts, function (err, res) {\n\t    if (err) {\n\t      return callback(err);\n\t    }\n\t    if (res.doc._attachments && res.doc._attachments[attachmentId]) {\n\t      opts.ctx = res.ctx;\n\t      opts.binary = true;\n\t      self._getAttachment(docId, attachmentId,\n\t                          res.doc._attachments[attachmentId], opts, callback);\n\t    } else {\n\t      return callback(createError(MISSING_DOC));\n\t    }\n\t  });\n\t});\n\t\n\tAbstractPouchDB.prototype.allDocs =\n\t  adapterFun('allDocs', function (opts, callback) {\n\t  if (typeof opts === 'function') {\n\t    callback = opts;\n\t    opts = {};\n\t  }\n\t  opts.skip = typeof opts.skip !== 'undefined' ? opts.skip : 0;\n\t  if (opts.start_key) {\n\t    opts.startkey = opts.start_key;\n\t  }\n\t  if (opts.end_key) {\n\t    opts.endkey = opts.end_key;\n\t  }\n\t  if ('keys' in opts) {\n\t    if (!Array.isArray(opts.keys)) {\n\t      return callback(new TypeError('options.keys must be an array'));\n\t    }\n\t    var incompatibleOpt =\n\t      ['startkey', 'endkey', 'key'].filter(function (incompatibleOpt) {\n\t      return incompatibleOpt in opts;\n\t    })[0];\n\t    if (incompatibleOpt) {\n\t      callback(createError(QUERY_PARSE_ERROR,\n\t        'Query parameter `' + incompatibleOpt +\n\t        '` is not compatible with multi-get'\n\t      ));\n\t      return;\n\t    }\n\t    if (this.type() !== 'http') {\n\t      return allDocsKeysQuery(this, opts, callback);\n\t    }\n\t  }\n\t\n\t  return this._allDocs(opts, callback);\n\t});\n\t\n\tAbstractPouchDB.prototype.changes = function (opts, callback) {\n\t  if (typeof opts === 'function') {\n\t    callback = opts;\n\t    opts = {};\n\t  }\n\t  return new Changes$2(this, opts, callback);\n\t};\n\t\n\tAbstractPouchDB.prototype.close = adapterFun('close', function (callback) {\n\t  this._closed = true;\n\t  this.emit('closed');\n\t  return this._close(callback);\n\t});\n\t\n\tAbstractPouchDB.prototype.info = adapterFun('info', function (callback) {\n\t  var self = this;\n\t  this._info(function (err, info) {\n\t    if (err) {\n\t      return callback(err);\n\t    }\n\t    // assume we know better than the adapter, unless it informs us\n\t    info.db_name = info.db_name || self.name;\n\t    info.auto_compaction = !!(self.auto_compaction && self.type() !== 'http');\n\t    info.adapter = self.type();\n\t    callback(null, info);\n\t  });\n\t});\n\t\n\tAbstractPouchDB.prototype.id = adapterFun('id', function (callback) {\n\t  return this._id(callback);\n\t});\n\t\n\t/* istanbul ignore next */\n\tAbstractPouchDB.prototype.type = function () {\n\t  return (typeof this._type === 'function') ? this._type() : this.adapter;\n\t};\n\t\n\tAbstractPouchDB.prototype.bulkDocs =\n\t  adapterFun('bulkDocs', function (req, opts, callback) {\n\t  if (typeof opts === 'function') {\n\t    callback = opts;\n\t    opts = {};\n\t  }\n\t\n\t  opts = opts || {};\n\t\n\t  if (Array.isArray(req)) {\n\t    req = {\n\t      docs: req\n\t    };\n\t  }\n\t\n\t  if (!req || !req.docs || !Array.isArray(req.docs)) {\n\t    return callback(createError(MISSING_BULK_DOCS));\n\t  }\n\t\n\t  for (var i = 0; i < req.docs.length; ++i) {\n\t    if (typeof req.docs[i] !== 'object' || Array.isArray(req.docs[i])) {\n\t      return callback(createError(NOT_AN_OBJECT));\n\t    }\n\t  }\n\t\n\t  var attachmentError;\n\t  req.docs.forEach(function (doc) {\n\t    if (doc._attachments) {\n\t      Object.keys(doc._attachments).forEach(function (name) {\n\t        attachmentError = attachmentError || attachmentNameError(name);\n\t        if (!doc._attachments[name].content_type) {\n\t          guardedConsole('warn', 'Attachment', name, 'on document', doc._id, 'is missing content_type');\n\t        }\n\t      });\n\t    }\n\t  });\n\t\n\t  if (attachmentError) {\n\t    return callback(createError(BAD_REQUEST, attachmentError));\n\t  }\n\t\n\t  if (!('new_edits' in opts)) {\n\t    if ('new_edits' in req) {\n\t      opts.new_edits = req.new_edits;\n\t    } else {\n\t      opts.new_edits = true;\n\t    }\n\t  }\n\t\n\t  var adapter = this;\n\t  if (!opts.new_edits && adapter.type() !== 'http') {\n\t    // ensure revisions of the same doc are sorted, so that\n\t    // the local adapter processes them correctly (#2935)\n\t    req.docs.sort(compareByIdThenRev);\n\t  }\n\t\n\t  cleanDocs(req.docs);\n\t\n\t  // in the case of conflicts, we want to return the _ids to the user\n\t  // however, the underlying adapter may destroy the docs array, so\n\t  // create a copy here\n\t  var ids = req.docs.map(function (doc) {\n\t    return doc._id;\n\t  });\n\t\n\t  return this._bulkDocs(req, opts, function (err, res) {\n\t    if (err) {\n\t      return callback(err);\n\t    }\n\t    if (!opts.new_edits) {\n\t      // this is what couch does when new_edits is false\n\t      res = res.filter(function (x) {\n\t        return x.error;\n\t      });\n\t    }\n\t    // add ids for error/conflict responses (not required for CouchDB)\n\t    if (adapter.type() !== 'http') {\n\t      for (var i = 0, l = res.length; i < l; i++) {\n\t        res[i].id = res[i].id || ids[i];\n\t      }\n\t    }\n\t\n\t    callback(null, res);\n\t  });\n\t});\n\t\n\tAbstractPouchDB.prototype.registerDependentDatabase =\n\t  adapterFun('registerDependentDatabase', function (dependentDb,\n\t                                                          callback) {\n\t  var depDB = new this.constructor(dependentDb, this.__opts);\n\t\n\t  function diffFun(doc) {\n\t    doc.dependentDbs = doc.dependentDbs || {};\n\t    if (doc.dependentDbs[dependentDb]) {\n\t      return false; // no update required\n\t    }\n\t    doc.dependentDbs[dependentDb] = true;\n\t    return doc;\n\t  }\n\t  upsert(this, '_local/_pouch_dependentDbs', diffFun)\n\t    .then(function () {\n\t      callback(null, {db: depDB});\n\t    }).catch(callback);\n\t});\n\t\n\tAbstractPouchDB.prototype.destroy =\n\t  adapterFun('destroy', function (opts, callback) {\n\t\n\t  if (typeof opts === 'function') {\n\t    callback = opts;\n\t    opts = {};\n\t  }\n\t\n\t  var self = this;\n\t  var usePrefix = 'use_prefix' in self ? self.use_prefix : true;\n\t\n\t  function destroyDb() {\n\t    // call destroy method of the particular adaptor\n\t    self._destroy(opts, function (err, resp) {\n\t      if (err) {\n\t        return callback(err);\n\t      }\n\t      self._destroyed = true;\n\t      self.emit('destroyed');\n\t      callback(null, resp || { 'ok': true });\n\t    });\n\t  }\n\t\n\t  if (self.type() === 'http') {\n\t    // no need to check for dependent DBs if it's a remote DB\n\t    return destroyDb();\n\t  }\n\t\n\t  self.get('_local/_pouch_dependentDbs', function (err, localDoc) {\n\t    if (err) {\n\t      /* istanbul ignore if */\n\t      if (err.status !== 404) {\n\t        return callback(err);\n\t      } else { // no dependencies\n\t        return destroyDb();\n\t      }\n\t    }\n\t    var dependentDbs = localDoc.dependentDbs;\n\t    var PouchDB = self.constructor;\n\t    var deletedMap = Object.keys(dependentDbs).map(function (name) {\n\t      // use_prefix is only false in the browser\n\t      /* istanbul ignore next */\n\t      var trueName = usePrefix ?\n\t        name.replace(new RegExp('^' + PouchDB.prefix), '') : name;\n\t      return new PouchDB(trueName, self.__opts).destroy();\n\t    });\n\t    PouchPromise$1.all(deletedMap).then(destroyDb, callback);\n\t  });\n\t});\n\t\n\tfunction TaskQueue$1() {\n\t  this.isReady = false;\n\t  this.failed = false;\n\t  this.queue = [];\n\t}\n\t\n\tTaskQueue$1.prototype.execute = function () {\n\t  var fun;\n\t  if (this.failed) {\n\t    while ((fun = this.queue.shift())) {\n\t      fun(this.failed);\n\t    }\n\t  } else {\n\t    while ((fun = this.queue.shift())) {\n\t      fun();\n\t    }\n\t  }\n\t};\n\t\n\tTaskQueue$1.prototype.fail = function (err) {\n\t  this.failed = err;\n\t  this.execute();\n\t};\n\t\n\tTaskQueue$1.prototype.ready = function (db) {\n\t  this.isReady = true;\n\t  this.db = db;\n\t  this.execute();\n\t};\n\t\n\tTaskQueue$1.prototype.addTask = function (fun) {\n\t  this.queue.push(fun);\n\t  if (this.failed) {\n\t    this.execute();\n\t  }\n\t};\n\t\n\tfunction parseAdapter(name, opts) {\n\t  var match = name.match(/([a-z\\-]*):\\/\\/(.*)/);\n\t  if (match) {\n\t    // the http adapter expects the fully qualified name\n\t    return {\n\t      name: /https?/.test(match[1]) ? match[1] + '://' + match[2] : match[2],\n\t      adapter: match[1]\n\t    };\n\t  }\n\t\n\t  var adapters = PouchDB$5.adapters;\n\t  var preferredAdapters = PouchDB$5.preferredAdapters;\n\t  var prefix = PouchDB$5.prefix;\n\t  var adapterName = opts.adapter;\n\t\n\t  if (!adapterName) { // automatically determine adapter\n\t    for (var i = 0; i < preferredAdapters.length; ++i) {\n\t      adapterName = preferredAdapters[i];\n\t      // check for browsers that have been upgraded from websql-only to websql+idb\n\t      /* istanbul ignore if */\n\t      if (adapterName === 'idb' && 'websql' in adapters &&\n\t          hasLocalStorage() && localStorage['_pouch__websqldb_' + prefix + name]) {\n\t        // log it, because this can be confusing during development\n\t        guardedConsole('log', 'PouchDB is downgrading \"' + name + '\" to WebSQL to' +\n\t          ' avoid data loss, because it was already opened with WebSQL.');\n\t        continue; // keep using websql to avoid user data loss\n\t      }\n\t      break;\n\t    }\n\t  }\n\t\n\t  var adapter = adapters[adapterName];\n\t\n\t  // if adapter is invalid, then an error will be thrown later\n\t  var usePrefix = (adapter && 'use_prefix' in adapter) ?\n\t    adapter.use_prefix : true;\n\t\n\t  return {\n\t    name: usePrefix ? (prefix + name) : name,\n\t    adapter: adapterName\n\t  };\n\t}\n\t\n\t// OK, so here's the deal. Consider this code:\n\t//     var db1 = new PouchDB('foo');\n\t//     var db2 = new PouchDB('foo');\n\t//     db1.destroy();\n\t// ^ these two both need to emit 'destroyed' events,\n\t// as well as the PouchDB constructor itself.\n\t// So we have one db object (whichever one got destroy() called on it)\n\t// responsible for emitting the initial event, which then gets emitted\n\t// by the constructor, which then broadcasts it to any other dbs\n\t// that may have been created with the same name.\n\tfunction prepareForDestruction(self) {\n\t\n\t  var destructionListeners = self.constructor._destructionListeners;\n\t\n\t  function onDestroyed() {\n\t    self.removeListener('closed', onClosed);\n\t    self.constructor.emit('destroyed', self.name);\n\t  }\n\t\n\t  function onConstructorDestroyed() {\n\t    self.removeListener('destroyed', onDestroyed);\n\t    self.removeListener('closed', onClosed);\n\t    self.emit('destroyed');\n\t  }\n\t\n\t  function onClosed() {\n\t    self.removeListener('destroyed', onDestroyed);\n\t    destructionListeners.delete(self.name);\n\t  }\n\t\n\t  self.once('destroyed', onDestroyed);\n\t  self.once('closed', onClosed);\n\t\n\t  // in setup.js, the constructor is primed to listen for destroy events\n\t  if (!destructionListeners.has(self.name)) {\n\t    destructionListeners.set(self.name, []);\n\t  }\n\t  destructionListeners.get(self.name).push(onConstructorDestroyed);\n\t}\n\t\n\tinherits(PouchDB$5, AbstractPouchDB);\n\tfunction PouchDB$5(name, opts) {\n\t  // In Node our test suite only tests this for PouchAlt unfortunately\n\t  /* istanbul ignore if */\n\t  if (!(this instanceof PouchDB$5)) {\n\t    return new PouchDB$5(name, opts);\n\t  }\n\t\n\t  var self = this;\n\t  opts = opts || {};\n\t\n\t  if (name && typeof name === 'object') {\n\t    opts = name;\n\t    name = opts.name;\n\t    delete opts.name;\n\t  }\n\t\n\t  this.__opts = opts = clone(opts);\n\t\n\t  self.auto_compaction = opts.auto_compaction;\n\t  self.prefix = PouchDB$5.prefix;\n\t\n\t  if (typeof name !== 'string') {\n\t    throw new Error('Missing/invalid DB name');\n\t  }\n\t\n\t  var prefixedName = (opts.prefix || '') + name;\n\t  var backend = parseAdapter(prefixedName, opts);\n\t\n\t  opts.name = backend.name;\n\t  opts.adapter = opts.adapter || backend.adapter;\n\t\n\t  self.name = name;\n\t  self._adapter = opts.adapter;\n\t  debug('pouchdb:adapter')('Picked adapter: ' + opts.adapter);\n\t\n\t  if (!PouchDB$5.adapters[opts.adapter] ||\n\t      !PouchDB$5.adapters[opts.adapter].valid()) {\n\t    throw new Error('Invalid Adapter: ' + opts.adapter);\n\t  }\n\t\n\t  AbstractPouchDB.call(self);\n\t  self.taskqueue = new TaskQueue$1();\n\t\n\t  self.adapter = opts.adapter;\n\t\n\t  PouchDB$5.adapters[opts.adapter].call(self, opts, function (err) {\n\t    if (err) {\n\t      return self.taskqueue.fail(err);\n\t    }\n\t    prepareForDestruction(self);\n\t\n\t    self.emit('created', self);\n\t    PouchDB$5.emit('created', self.name);\n\t    self.taskqueue.ready(self);\n\t  });\n\t\n\t}\n\t\n\tPouchDB$5.debug = debug;\n\t\n\tPouchDB$5.adapters = {};\n\tPouchDB$5.preferredAdapters = [];\n\t\n\tPouchDB$5.prefix = '_pouch_';\n\t\n\tvar eventEmitter = new events.EventEmitter();\n\t\n\tfunction setUpEventEmitter(Pouch) {\n\t  Object.keys(events.EventEmitter.prototype).forEach(function (key) {\n\t    if (typeof events.EventEmitter.prototype[key] === 'function') {\n\t      Pouch[key] = eventEmitter[key].bind(eventEmitter);\n\t    }\n\t  });\n\t\n\t  // these are created in constructor.js, and allow us to notify each DB with\n\t  // the same name that it was destroyed, via the constructor object\n\t  var destructListeners = Pouch._destructionListeners = new ExportedMap();\n\t  Pouch.on('destroyed', function onConstructorDestroyed(name) {\n\t    destructListeners.get(name).forEach(function (callback) {\n\t      callback();\n\t    });\n\t    destructListeners.delete(name);\n\t  });\n\t}\n\t\n\tsetUpEventEmitter(PouchDB$5);\n\t\n\tPouchDB$5.adapter = function (id, obj, addToPreferredAdapters) {\n\t  /* istanbul ignore else */\n\t  if (obj.valid()) {\n\t    PouchDB$5.adapters[id] = obj;\n\t    if (addToPreferredAdapters) {\n\t      PouchDB$5.preferredAdapters.push(id);\n\t    }\n\t  }\n\t};\n\t\n\tPouchDB$5.plugin = function (obj) {\n\t  if (typeof obj === 'function') { // function style for plugins\n\t    obj(PouchDB$5);\n\t  } else if (typeof obj !== 'object' || Object.keys(obj).length === 0){\n\t    throw new Error('Invalid plugin: got \\\"' + obj + '\\\", expected an object or a function');\n\t  } else {\n\t    Object.keys(obj).forEach(function (id) { // object style for plugins\n\t      PouchDB$5.prototype[id] = obj[id];\n\t    });\n\t  }\n\t  return PouchDB$5;\n\t};\n\t\n\tPouchDB$5.defaults = function (defaultOpts) {\n\t  function PouchAlt(name, opts) {\n\t    if (!(this instanceof PouchAlt)) {\n\t      return new PouchAlt(name, opts);\n\t    }\n\t\n\t    opts = opts || {};\n\t\n\t    if (name && typeof name === 'object') {\n\t      opts = name;\n\t      name = opts.name;\n\t      delete opts.name;\n\t    }\n\t\n\t    opts = assign$1({}, PouchAlt.__defaults, opts);\n\t    PouchDB$5.call(this, name, opts);\n\t  }\n\t\n\t  inherits(PouchAlt, PouchDB$5);\n\t\n\t  PouchAlt.preferredAdapters = PouchDB$5.preferredAdapters.slice();\n\t  Object.keys(PouchDB$5).forEach(function (key) {\n\t    if (!(key in PouchAlt)) {\n\t      PouchAlt[key] = PouchDB$5[key];\n\t    }\n\t  });\n\t\n\t  // make default options transitive\n\t  // https://github.com/pouchdb/pouchdb/issues/5922\n\t  PouchAlt.__defaults = assign$1({}, this.__defaults, defaultOpts);\n\t\n\t  return PouchAlt;\n\t};\n\t\n\t// managed automatically by set-version.js\n\tvar version = \"6.1.1\";\n\t\n\tPouchDB$5.version = version;\n\t\n\tfunction toObject(array) {\n\t  return array.reduce(function (obj, item) {\n\t    obj[item] = true;\n\t    return obj;\n\t  }, {});\n\t}\n\t// List of top level reserved words for doc\n\tvar reservedWords = toObject([\n\t  '_id',\n\t  '_rev',\n\t  '_attachments',\n\t  '_deleted',\n\t  '_revisions',\n\t  '_revs_info',\n\t  '_conflicts',\n\t  '_deleted_conflicts',\n\t  '_local_seq',\n\t  '_rev_tree',\n\t  //replication documents\n\t  '_replication_id',\n\t  '_replication_state',\n\t  '_replication_state_time',\n\t  '_replication_state_reason',\n\t  '_replication_stats',\n\t  // Specific to Couchbase Sync Gateway\n\t  '_removed'\n\t]);\n\t\n\t// List of reserved words that should end up the document\n\tvar dataWords = toObject([\n\t  '_attachments',\n\t  //replication documents\n\t  '_replication_id',\n\t  '_replication_state',\n\t  '_replication_state_time',\n\t  '_replication_state_reason',\n\t  '_replication_stats'\n\t]);\n\t\n\tfunction parseRevisionInfo(rev) {\n\t  if (!/^\\d+\\-./.test(rev)) {\n\t    return createError(INVALID_REV);\n\t  }\n\t  var idx = rev.indexOf('-');\n\t  var left = rev.substring(0, idx);\n\t  var right = rev.substring(idx + 1);\n\t  return {\n\t    prefix: parseInt(left, 10),\n\t    id: right\n\t  };\n\t}\n\t\n\tfunction makeRevTreeFromRevisions(revisions, opts) {\n\t  var pos = revisions.start - revisions.ids.length + 1;\n\t\n\t  var revisionIds = revisions.ids;\n\t  var ids = [revisionIds[0], opts, []];\n\t\n\t  for (var i = 1, len = revisionIds.length; i < len; i++) {\n\t    ids = [revisionIds[i], {status: 'missing'}, [ids]];\n\t  }\n\t\n\t  return [{\n\t    pos: pos,\n\t    ids: ids\n\t  }];\n\t}\n\t\n\t// Preprocess documents, parse their revisions, assign an id and a\n\t// revision for new writes that are missing them, etc\n\tfunction parseDoc(doc, newEdits) {\n\t\n\t  var nRevNum;\n\t  var newRevId;\n\t  var revInfo;\n\t  var opts = {status: 'available'};\n\t  if (doc._deleted) {\n\t    opts.deleted = true;\n\t  }\n\t\n\t  if (newEdits) {\n\t    if (!doc._id) {\n\t      doc._id = uuid();\n\t    }\n\t    newRevId = uuid(32, 16).toLowerCase();\n\t    if (doc._rev) {\n\t      revInfo = parseRevisionInfo(doc._rev);\n\t      if (revInfo.error) {\n\t        return revInfo;\n\t      }\n\t      doc._rev_tree = [{\n\t        pos: revInfo.prefix,\n\t        ids: [revInfo.id, {status: 'missing'}, [[newRevId, opts, []]]]\n\t      }];\n\t      nRevNum = revInfo.prefix + 1;\n\t    } else {\n\t      doc._rev_tree = [{\n\t        pos: 1,\n\t        ids : [newRevId, opts, []]\n\t      }];\n\t      nRevNum = 1;\n\t    }\n\t  } else {\n\t    if (doc._revisions) {\n\t      doc._rev_tree = makeRevTreeFromRevisions(doc._revisions, opts);\n\t      nRevNum = doc._revisions.start;\n\t      newRevId = doc._revisions.ids[0];\n\t    }\n\t    if (!doc._rev_tree) {\n\t      revInfo = parseRevisionInfo(doc._rev);\n\t      if (revInfo.error) {\n\t        return revInfo;\n\t      }\n\t      nRevNum = revInfo.prefix;\n\t      newRevId = revInfo.id;\n\t      doc._rev_tree = [{\n\t        pos: nRevNum,\n\t        ids: [newRevId, opts, []]\n\t      }];\n\t    }\n\t  }\n\t\n\t  invalidIdError(doc._id);\n\t\n\t  doc._rev = nRevNum + '-' + newRevId;\n\t\n\t  var result = {metadata : {}, data : {}};\n\t  for (var key in doc) {\n\t    /* istanbul ignore else */\n\t    if (Object.prototype.hasOwnProperty.call(doc, key)) {\n\t      var specialKey = key[0] === '_';\n\t      if (specialKey && !reservedWords[key]) {\n\t        var error = createError(DOC_VALIDATION, key);\n\t        error.message = DOC_VALIDATION.message + ': ' + key;\n\t        throw error;\n\t      } else if (specialKey && !dataWords[key]) {\n\t        result.metadata[key.slice(1)] = doc[key];\n\t      } else {\n\t        result.data[key] = doc[key];\n\t      }\n\t    }\n\t  }\n\t  return result;\n\t}\n\t\n\tvar thisAtob = function (str) {\n\t  return atob(str);\n\t};\n\t\n\tvar thisBtoa = function (str) {\n\t  return btoa(str);\n\t};\n\t\n\t// Abstracts constructing a Blob object, so it also works in older\n\t// browsers that don't support the native Blob constructor (e.g.\n\t// old QtWebKit versions, Android < 4.4).\n\tfunction createBlob(parts, properties) {\n\t  /* global BlobBuilder,MSBlobBuilder,MozBlobBuilder,WebKitBlobBuilder */\n\t  parts = parts || [];\n\t  properties = properties || {};\n\t  try {\n\t    return new Blob(parts, properties);\n\t  } catch (e) {\n\t    if (e.name !== \"TypeError\") {\n\t      throw e;\n\t    }\n\t    var Builder = typeof BlobBuilder !== 'undefined' ? BlobBuilder :\n\t                  typeof MSBlobBuilder !== 'undefined' ? MSBlobBuilder :\n\t                  typeof MozBlobBuilder !== 'undefined' ? MozBlobBuilder :\n\t                  WebKitBlobBuilder;\n\t    var builder = new Builder();\n\t    for (var i = 0; i < parts.length; i += 1) {\n\t      builder.append(parts[i]);\n\t    }\n\t    return builder.getBlob(properties.type);\n\t  }\n\t}\n\t\n\t// From http://stackoverflow.com/questions/14967647/ (continues on next line)\n\t// encode-decode-image-with-base64-breaks-image (2013-04-21)\n\tfunction binaryStringToArrayBuffer(bin) {\n\t  var length = bin.length;\n\t  var buf = new ArrayBuffer(length);\n\t  var arr = new Uint8Array(buf);\n\t  for (var i = 0; i < length; i++) {\n\t    arr[i] = bin.charCodeAt(i);\n\t  }\n\t  return buf;\n\t}\n\t\n\tfunction binStringToBluffer(binString, type) {\n\t  return createBlob([binaryStringToArrayBuffer(binString)], {type: type});\n\t}\n\t\n\tfunction b64ToBluffer(b64, type) {\n\t  return binStringToBluffer(thisAtob(b64), type);\n\t}\n\t\n\t//Can't find original post, but this is close\n\t//http://stackoverflow.com/questions/6965107/ (continues on next line)\n\t//converting-between-strings-and-arraybuffers\n\tfunction arrayBufferToBinaryString(buffer) {\n\t  var binary = '';\n\t  var bytes = new Uint8Array(buffer);\n\t  var length = bytes.byteLength;\n\t  for (var i = 0; i < length; i++) {\n\t    binary += String.fromCharCode(bytes[i]);\n\t  }\n\t  return binary;\n\t}\n\t\n\t// shim for browsers that don't support it\n\tfunction readAsBinaryString(blob, callback) {\n\t  if (typeof FileReader === 'undefined') {\n\t    // fix for Firefox in a web worker\n\t    // https://bugzilla.mozilla.org/show_bug.cgi?id=901097\n\t    return callback(arrayBufferToBinaryString(\n\t      new FileReaderSync().readAsArrayBuffer(blob)));\n\t  }\n\t\n\t  var reader = new FileReader();\n\t  var hasBinaryString = typeof reader.readAsBinaryString === 'function';\n\t  reader.onloadend = function (e) {\n\t    var result = e.target.result || '';\n\t    if (hasBinaryString) {\n\t      return callback(result);\n\t    }\n\t    callback(arrayBufferToBinaryString(result));\n\t  };\n\t  if (hasBinaryString) {\n\t    reader.readAsBinaryString(blob);\n\t  } else {\n\t    reader.readAsArrayBuffer(blob);\n\t  }\n\t}\n\t\n\tfunction blobToBinaryString(blobOrBuffer, callback) {\n\t  readAsBinaryString(blobOrBuffer, function (bin) {\n\t    callback(bin);\n\t  });\n\t}\n\t\n\tfunction blobToBase64(blobOrBuffer, callback) {\n\t  blobToBinaryString(blobOrBuffer, function (base64) {\n\t    callback(thisBtoa(base64));\n\t  });\n\t}\n\t\n\t// simplified API. universal browser support is assumed\n\tfunction readAsArrayBuffer(blob, callback) {\n\t  if (typeof FileReader === 'undefined') {\n\t    // fix for Firefox in a web worker:\n\t    // https://bugzilla.mozilla.org/show_bug.cgi?id=901097\n\t    return callback(new FileReaderSync().readAsArrayBuffer(blob));\n\t  }\n\t\n\t  var reader = new FileReader();\n\t  reader.onloadend = function (e) {\n\t    var result = e.target.result || new ArrayBuffer(0);\n\t    callback(result);\n\t  };\n\t  reader.readAsArrayBuffer(blob);\n\t}\n\t\n\t// this is not used in the browser\n\t\n\tvar setImmediateShim = global.setImmediate || global.setTimeout;\n\tvar MD5_CHUNK_SIZE = 32768;\n\t\n\tfunction rawToBase64(raw) {\n\t  return thisBtoa(raw);\n\t}\n\t\n\tfunction sliceBlob(blob$$1, start, end) {\n\t  if (blob$$1.webkitSlice) {\n\t    return blob$$1.webkitSlice(start, end);\n\t  }\n\t  return blob$$1.slice(start, end);\n\t}\n\t\n\tfunction appendBlob(buffer, blob$$1, start, end, callback) {\n\t  if (start > 0 || end < blob$$1.size) {\n\t    // only slice blob if we really need to\n\t    blob$$1 = sliceBlob(blob$$1, start, end);\n\t  }\n\t  readAsArrayBuffer(blob$$1, function (arrayBuffer) {\n\t    buffer.append(arrayBuffer);\n\t    callback();\n\t  });\n\t}\n\t\n\tfunction appendString(buffer, string, start, end, callback) {\n\t  if (start > 0 || end < string.length) {\n\t    // only create a substring if we really need to\n\t    string = string.substring(start, end);\n\t  }\n\t  buffer.appendBinary(string);\n\t  callback();\n\t}\n\t\n\tfunction binaryMd5(data, callback) {\n\t  var inputIsString = typeof data === 'string';\n\t  var len = inputIsString ? data.length : data.size;\n\t  var chunkSize = Math.min(MD5_CHUNK_SIZE, len);\n\t  var chunks = Math.ceil(len / chunkSize);\n\t  var currentChunk = 0;\n\t  var buffer = inputIsString ? new Md5() : new Md5.ArrayBuffer();\n\t\n\t  var append = inputIsString ? appendString : appendBlob;\n\t\n\t  function next() {\n\t    setImmediateShim(loadNextChunk);\n\t  }\n\t\n\t  function done() {\n\t    var raw = buffer.end(true);\n\t    var base64 = rawToBase64(raw);\n\t    callback(base64);\n\t    buffer.destroy();\n\t  }\n\t\n\t  function loadNextChunk() {\n\t    var start = currentChunk * chunkSize;\n\t    var end = start + chunkSize;\n\t    currentChunk++;\n\t    if (currentChunk < chunks) {\n\t      append(buffer, data, start, end, next);\n\t    } else {\n\t      append(buffer, data, start, end, done);\n\t    }\n\t  }\n\t  loadNextChunk();\n\t}\n\t\n\tfunction stringMd5(string) {\n\t  return Md5.hash(string);\n\t}\n\t\n\tfunction parseBase64(data) {\n\t  try {\n\t    return thisAtob(data);\n\t  } catch (e) {\n\t    var err = createError(BAD_ARG,\n\t      'Attachment is not a valid base64 string');\n\t    return {error: err};\n\t  }\n\t}\n\t\n\tfunction preprocessString(att, blobType, callback) {\n\t  var asBinary = parseBase64(att.data);\n\t  if (asBinary.error) {\n\t    return callback(asBinary.error);\n\t  }\n\t\n\t  att.length = asBinary.length;\n\t  if (blobType === 'blob') {\n\t    att.data = binStringToBluffer(asBinary, att.content_type);\n\t  } else if (blobType === 'base64') {\n\t    att.data = thisBtoa(asBinary);\n\t  } else { // binary\n\t    att.data = asBinary;\n\t  }\n\t  binaryMd5(asBinary, function (result) {\n\t    att.digest = 'md5-' + result;\n\t    callback();\n\t  });\n\t}\n\t\n\tfunction preprocessBlob(att, blobType, callback) {\n\t  binaryMd5(att.data, function (md5) {\n\t    att.digest = 'md5-' + md5;\n\t    // size is for blobs (browser), length is for buffers (node)\n\t    att.length = att.data.size || att.data.length || 0;\n\t    if (blobType === 'binary') {\n\t      blobToBinaryString(att.data, function (binString) {\n\t        att.data = binString;\n\t        callback();\n\t      });\n\t    } else if (blobType === 'base64') {\n\t      blobToBase64(att.data, function (b64) {\n\t        att.data = b64;\n\t        callback();\n\t      });\n\t    } else {\n\t      callback();\n\t    }\n\t  });\n\t}\n\t\n\tfunction preprocessAttachment(att, blobType, callback) {\n\t  if (att.stub) {\n\t    return callback();\n\t  }\n\t  if (typeof att.data === 'string') { // input is a base64 string\n\t    preprocessString(att, blobType, callback);\n\t  } else { // input is a blob\n\t    preprocessBlob(att, blobType, callback);\n\t  }\n\t}\n\t\n\tfunction preprocessAttachments(docInfos, blobType, callback) {\n\t\n\t  if (!docInfos.length) {\n\t    return callback();\n\t  }\n\t\n\t  var docv = 0;\n\t  var overallErr;\n\t\n\t  docInfos.forEach(function (docInfo) {\n\t    var attachments = docInfo.data && docInfo.data._attachments ?\n\t      Object.keys(docInfo.data._attachments) : [];\n\t    var recv = 0;\n\t\n\t    if (!attachments.length) {\n\t      return done();\n\t    }\n\t\n\t    function processedAttachment(err) {\n\t      overallErr = err;\n\t      recv++;\n\t      if (recv === attachments.length) {\n\t        done();\n\t      }\n\t    }\n\t\n\t    for (var key in docInfo.data._attachments) {\n\t      if (docInfo.data._attachments.hasOwnProperty(key)) {\n\t        preprocessAttachment(docInfo.data._attachments[key],\n\t          blobType, processedAttachment);\n\t      }\n\t    }\n\t  });\n\t\n\t  function done() {\n\t    docv++;\n\t    if (docInfos.length === docv) {\n\t      if (overallErr) {\n\t        callback(overallErr);\n\t      } else {\n\t        callback();\n\t      }\n\t    }\n\t  }\n\t}\n\t\n\tfunction updateDoc(revLimit, prev, docInfo, results,\n\t                   i, cb, writeDoc, newEdits) {\n\t\n\t  if (revExists(prev.rev_tree, docInfo.metadata.rev)) {\n\t    results[i] = docInfo;\n\t    return cb();\n\t  }\n\t\n\t  // sometimes this is pre-calculated. historically not always\n\t  var previousWinningRev = prev.winningRev || winningRev(prev);\n\t  var previouslyDeleted = 'deleted' in prev ? prev.deleted :\n\t    isDeleted(prev, previousWinningRev);\n\t  var deleted = 'deleted' in docInfo.metadata ? docInfo.metadata.deleted :\n\t    isDeleted(docInfo.metadata);\n\t  var isRoot = /^1-/.test(docInfo.metadata.rev);\n\t\n\t  if (previouslyDeleted && !deleted && newEdits && isRoot) {\n\t    var newDoc = docInfo.data;\n\t    newDoc._rev = previousWinningRev;\n\t    newDoc._id = docInfo.metadata.id;\n\t    docInfo = parseDoc(newDoc, newEdits);\n\t  }\n\t\n\t  var merged = merge(prev.rev_tree, docInfo.metadata.rev_tree[0], revLimit);\n\t\n\t  var inConflict = newEdits && (((previouslyDeleted && deleted) ||\n\t    (!previouslyDeleted && merged.conflicts !== 'new_leaf') ||\n\t    (previouslyDeleted && !deleted && merged.conflicts === 'new_branch')));\n\t\n\t  if (inConflict) {\n\t    var err = createError(REV_CONFLICT);\n\t    results[i] = err;\n\t    return cb();\n\t  }\n\t\n\t  var newRev = docInfo.metadata.rev;\n\t  docInfo.metadata.rev_tree = merged.tree;\n\t  docInfo.stemmedRevs = merged.stemmedRevs || [];\n\t  /* istanbul ignore else */\n\t  if (prev.rev_map) {\n\t    docInfo.metadata.rev_map = prev.rev_map; // used only by leveldb\n\t  }\n\t\n\t  // recalculate\n\t  var winningRev$$1 = winningRev(docInfo.metadata);\n\t  var winningRevIsDeleted = isDeleted(docInfo.metadata, winningRev$$1);\n\t\n\t  // calculate the total number of documents that were added/removed,\n\t  // from the perspective of total_rows/doc_count\n\t  var delta = (previouslyDeleted === winningRevIsDeleted) ? 0 :\n\t    previouslyDeleted < winningRevIsDeleted ? -1 : 1;\n\t\n\t  var newRevIsDeleted;\n\t  if (newRev === winningRev$$1) {\n\t    // if the new rev is the same as the winning rev, we can reuse that value\n\t    newRevIsDeleted = winningRevIsDeleted;\n\t  } else {\n\t    // if they're not the same, then we need to recalculate\n\t    newRevIsDeleted = isDeleted(docInfo.metadata, newRev);\n\t  }\n\t\n\t  writeDoc(docInfo, winningRev$$1, winningRevIsDeleted, newRevIsDeleted,\n\t    true, delta, i, cb);\n\t}\n\t\n\tfunction rootIsMissing(docInfo) {\n\t  return docInfo.metadata.rev_tree[0].ids[1].status === 'missing';\n\t}\n\t\n\tfunction processDocs(revLimit, docInfos, api, fetchedDocs, tx, results,\n\t                     writeDoc, opts, overallCallback) {\n\t\n\t  // Default to 1000 locally\n\t  revLimit = revLimit || 1000;\n\t\n\t  function insertDoc(docInfo, resultsIdx, callback) {\n\t    // Cant insert new deleted documents\n\t    var winningRev$$1 = winningRev(docInfo.metadata);\n\t    var deleted = isDeleted(docInfo.metadata, winningRev$$1);\n\t    if ('was_delete' in opts && deleted) {\n\t      results[resultsIdx] = createError(MISSING_DOC, 'deleted');\n\t      return callback();\n\t    }\n\t\n\t    // 4712 - detect whether a new document was inserted with a _rev\n\t    var inConflict = newEdits && rootIsMissing(docInfo);\n\t\n\t    if (inConflict) {\n\t      var err = createError(REV_CONFLICT);\n\t      results[resultsIdx] = err;\n\t      return callback();\n\t    }\n\t\n\t    var delta = deleted ? 0 : 1;\n\t\n\t    writeDoc(docInfo, winningRev$$1, deleted, deleted, false,\n\t      delta, resultsIdx, callback);\n\t  }\n\t\n\t  var newEdits = opts.new_edits;\n\t  var idsToDocs = new ExportedMap();\n\t\n\t  var docsDone = 0;\n\t  var docsToDo = docInfos.length;\n\t\n\t  function checkAllDocsDone() {\n\t    if (++docsDone === docsToDo && overallCallback) {\n\t      overallCallback();\n\t    }\n\t  }\n\t\n\t  docInfos.forEach(function (currentDoc, resultsIdx) {\n\t\n\t    if (currentDoc._id && isLocalId(currentDoc._id)) {\n\t      var fun = currentDoc._deleted ? '_removeLocal' : '_putLocal';\n\t      api[fun](currentDoc, {ctx: tx}, function (err, res) {\n\t        results[resultsIdx] = err || res;\n\t        checkAllDocsDone();\n\t      });\n\t      return;\n\t    }\n\t\n\t    var id = currentDoc.metadata.id;\n\t    if (idsToDocs.has(id)) {\n\t      docsToDo--; // duplicate\n\t      idsToDocs.get(id).push([currentDoc, resultsIdx]);\n\t    } else {\n\t      idsToDocs.set(id, [[currentDoc, resultsIdx]]);\n\t    }\n\t  });\n\t\n\t  // in the case of new_edits, the user can provide multiple docs\n\t  // with the same id. these need to be processed sequentially\n\t  idsToDocs.forEach(function (docs, id) {\n\t    var numDone = 0;\n\t\n\t    function docWritten() {\n\t      if (++numDone < docs.length) {\n\t        nextDoc();\n\t      } else {\n\t        checkAllDocsDone();\n\t      }\n\t    }\n\t    function nextDoc() {\n\t      var value = docs[numDone];\n\t      var currentDoc = value[0];\n\t      var resultsIdx = value[1];\n\t\n\t      if (fetchedDocs.has(id)) {\n\t        updateDoc(revLimit, fetchedDocs.get(id), currentDoc, results,\n\t          resultsIdx, docWritten, writeDoc, newEdits);\n\t      } else {\n\t        // Ensure stemming applies to new writes as well\n\t        var merged = merge([], currentDoc.metadata.rev_tree[0], revLimit);\n\t        currentDoc.metadata.rev_tree = merged.tree;\n\t        currentDoc.stemmedRevs = merged.stemmedRevs || [];\n\t        insertDoc(currentDoc, resultsIdx, docWritten);\n\t      }\n\t    }\n\t    nextDoc();\n\t  });\n\t}\n\t\n\t// IndexedDB requires a versioned database structure, so we use the\n\t// version here to manage migrations.\n\tvar ADAPTER_VERSION = 5;\n\t\n\t// The object stores created for each database\n\t// DOC_STORE stores the document meta data, its revision history and state\n\t// Keyed by document id\n\tvar DOC_STORE = 'document-store';\n\t// BY_SEQ_STORE stores a particular version of a document, keyed by its\n\t// sequence id\n\tvar BY_SEQ_STORE = 'by-sequence';\n\t// Where we store attachments\n\tvar ATTACH_STORE = 'attach-store';\n\t// Where we store many-to-many relations\n\t// between attachment digests and seqs\n\tvar ATTACH_AND_SEQ_STORE = 'attach-seq-store';\n\t\n\t// Where we store database-wide meta data in a single record\n\t// keyed by id: META_STORE\n\tvar META_STORE = 'meta-store';\n\t// Where we store local documents\n\tvar LOCAL_STORE = 'local-store';\n\t// Where we detect blob support\n\tvar DETECT_BLOB_SUPPORT_STORE = 'detect-blob-support';\n\t\n\tfunction safeJsonParse(str) {\n\t  // This try/catch guards against stack overflow errors.\n\t  // JSON.parse() is faster than vuvuzela.parse() but vuvuzela\n\t  // cannot overflow.\n\t  try {\n\t    return JSON.parse(str);\n\t  } catch (e) {\n\t    /* istanbul ignore next */\n\t    return vuvuzela.parse(str);\n\t  }\n\t}\n\t\n\tfunction safeJsonStringify(json) {\n\t  try {\n\t    return JSON.stringify(json);\n\t  } catch (e) {\n\t    /* istanbul ignore next */\n\t    return vuvuzela.stringify(json);\n\t  }\n\t}\n\t\n\tfunction idbError(callback) {\n\t  return function (evt) {\n\t    var message = 'unknown_error';\n\t    if (evt.target && evt.target.error) {\n\t      message = evt.target.error.name || evt.target.error.message;\n\t    }\n\t    callback(createError(IDB_ERROR, message, evt.type));\n\t  };\n\t}\n\t\n\t// Unfortunately, the metadata has to be stringified\n\t// when it is put into the database, because otherwise\n\t// IndexedDB can throw errors for deeply-nested objects.\n\t// Originally we just used JSON.parse/JSON.stringify; now\n\t// we use this custom vuvuzela library that avoids recursion.\n\t// If we could do it all over again, we'd probably use a\n\t// format for the revision trees other than JSON.\n\tfunction encodeMetadata(metadata, winningRev, deleted) {\n\t  return {\n\t    data: safeJsonStringify(metadata),\n\t    winningRev: winningRev,\n\t    deletedOrLocal: deleted ? '1' : '0',\n\t    seq: metadata.seq, // highest seq for this doc\n\t    id: metadata.id\n\t  };\n\t}\n\t\n\tfunction decodeMetadata(storedObject) {\n\t  if (!storedObject) {\n\t    return null;\n\t  }\n\t  var metadata = safeJsonParse(storedObject.data);\n\t  metadata.winningRev = storedObject.winningRev;\n\t  metadata.deleted = storedObject.deletedOrLocal === '1';\n\t  metadata.seq = storedObject.seq;\n\t  return metadata;\n\t}\n\t\n\t// read the doc back out from the database. we don't store the\n\t// _id or _rev because we already have _doc_id_rev.\n\tfunction decodeDoc(doc) {\n\t  if (!doc) {\n\t    return doc;\n\t  }\n\t  var idx = doc._doc_id_rev.lastIndexOf(':');\n\t  doc._id = doc._doc_id_rev.substring(0, idx - 1);\n\t  doc._rev = doc._doc_id_rev.substring(idx + 1);\n\t  delete doc._doc_id_rev;\n\t  return doc;\n\t}\n\t\n\t// Read a blob from the database, encoding as necessary\n\t// and translating from base64 if the IDB doesn't support\n\t// native Blobs\n\tfunction readBlobData(body, type, asBlob, callback) {\n\t  if (asBlob) {\n\t    if (!body) {\n\t      callback(createBlob([''], {type: type}));\n\t    } else if (typeof body !== 'string') { // we have blob support\n\t      callback(body);\n\t    } else { // no blob support\n\t      callback(b64ToBluffer(body, type));\n\t    }\n\t  } else { // as base64 string\n\t    if (!body) {\n\t      callback('');\n\t    } else if (typeof body !== 'string') { // we have blob support\n\t      readAsBinaryString(body, function (binary) {\n\t        callback(thisBtoa(binary));\n\t      });\n\t    } else { // no blob support\n\t      callback(body);\n\t    }\n\t  }\n\t}\n\t\n\tfunction fetchAttachmentsIfNecessary(doc, opts, txn, cb) {\n\t  var attachments = Object.keys(doc._attachments || {});\n\t  if (!attachments.length) {\n\t    return cb && cb();\n\t  }\n\t  var numDone = 0;\n\t\n\t  function checkDone() {\n\t    if (++numDone === attachments.length && cb) {\n\t      cb();\n\t    }\n\t  }\n\t\n\t  function fetchAttachment(doc, att) {\n\t    var attObj = doc._attachments[att];\n\t    var digest = attObj.digest;\n\t    var req = txn.objectStore(ATTACH_STORE).get(digest);\n\t    req.onsuccess = function (e) {\n\t      attObj.body = e.target.result.body;\n\t      checkDone();\n\t    };\n\t  }\n\t\n\t  attachments.forEach(function (att) {\n\t    if (opts.attachments && opts.include_docs) {\n\t      fetchAttachment(doc, att);\n\t    } else {\n\t      doc._attachments[att].stub = true;\n\t      checkDone();\n\t    }\n\t  });\n\t}\n\t\n\t// IDB-specific postprocessing necessary because\n\t// we don't know whether we stored a true Blob or\n\t// a base64-encoded string, and if it's a Blob it\n\t// needs to be read outside of the transaction context\n\tfunction postProcessAttachments(results, asBlob) {\n\t  return PouchPromise$1.all(results.map(function (row) {\n\t    if (row.doc && row.doc._attachments) {\n\t      var attNames = Object.keys(row.doc._attachments);\n\t      return PouchPromise$1.all(attNames.map(function (att) {\n\t        var attObj = row.doc._attachments[att];\n\t        if (!('body' in attObj)) { // already processed\n\t          return;\n\t        }\n\t        var body = attObj.body;\n\t        var type = attObj.content_type;\n\t        return new PouchPromise$1(function (resolve) {\n\t          readBlobData(body, type, asBlob, function (data) {\n\t            row.doc._attachments[att] = assign$1(\n\t              pick(attObj, ['digest', 'content_type']),\n\t              {data: data}\n\t            );\n\t            resolve();\n\t          });\n\t        });\n\t      }));\n\t    }\n\t  }));\n\t}\n\t\n\tfunction compactRevs(revs, docId, txn) {\n\t\n\t  var possiblyOrphanedDigests = [];\n\t  var seqStore = txn.objectStore(BY_SEQ_STORE);\n\t  var attStore = txn.objectStore(ATTACH_STORE);\n\t  var attAndSeqStore = txn.objectStore(ATTACH_AND_SEQ_STORE);\n\t  var count = revs.length;\n\t\n\t  function checkDone() {\n\t    count--;\n\t    if (!count) { // done processing all revs\n\t      deleteOrphanedAttachments();\n\t    }\n\t  }\n\t\n\t  function deleteOrphanedAttachments() {\n\t    if (!possiblyOrphanedDigests.length) {\n\t      return;\n\t    }\n\t    possiblyOrphanedDigests.forEach(function (digest) {\n\t      var countReq = attAndSeqStore.index('digestSeq').count(\n\t        IDBKeyRange.bound(\n\t          digest + '::', digest + '::\\uffff', false, false));\n\t      countReq.onsuccess = function (e) {\n\t        var count = e.target.result;\n\t        if (!count) {\n\t          // orphaned\n\t          attStore.delete(digest);\n\t        }\n\t      };\n\t    });\n\t  }\n\t\n\t  revs.forEach(function (rev) {\n\t    var index = seqStore.index('_doc_id_rev');\n\t    var key = docId + \"::\" + rev;\n\t    index.getKey(key).onsuccess = function (e) {\n\t      var seq = e.target.result;\n\t      if (typeof seq !== 'number') {\n\t        return checkDone();\n\t      }\n\t      seqStore.delete(seq);\n\t\n\t      var cursor = attAndSeqStore.index('seq')\n\t        .openCursor(IDBKeyRange.only(seq));\n\t\n\t      cursor.onsuccess = function (event) {\n\t        var cursor = event.target.result;\n\t        if (cursor) {\n\t          var digest = cursor.value.digestSeq.split('::')[0];\n\t          possiblyOrphanedDigests.push(digest);\n\t          attAndSeqStore.delete(cursor.primaryKey);\n\t          cursor.continue();\n\t        } else { // done\n\t          checkDone();\n\t        }\n\t      };\n\t    };\n\t  });\n\t}\n\t\n\tfunction openTransactionSafely(idb, stores, mode) {\n\t  try {\n\t    return {\n\t      txn: idb.transaction(stores, mode)\n\t    };\n\t  } catch (err) {\n\t    return {\n\t      error: err\n\t    };\n\t  }\n\t}\n\t\n\tvar changesHandler$$1 = new Changes();\n\t\n\tfunction idbBulkDocs(dbOpts, req, opts, api, idb, callback) {\n\t  var docInfos = req.docs;\n\t  var txn;\n\t  var docStore;\n\t  var bySeqStore;\n\t  var attachStore;\n\t  var attachAndSeqStore;\n\t  var metaStore;\n\t  var docInfoError;\n\t  var metaDoc;\n\t\n\t  for (var i = 0, len = docInfos.length; i < len; i++) {\n\t    var doc = docInfos[i];\n\t    if (doc._id && isLocalId(doc._id)) {\n\t      continue;\n\t    }\n\t    doc = docInfos[i] = parseDoc(doc, opts.new_edits);\n\t    if (doc.error && !docInfoError) {\n\t      docInfoError = doc;\n\t    }\n\t  }\n\t\n\t  if (docInfoError) {\n\t    return callback(docInfoError);\n\t  }\n\t\n\t  var allDocsProcessed = false;\n\t  var docCountDelta = 0;\n\t  var results = new Array(docInfos.length);\n\t  var fetchedDocs = new ExportedMap();\n\t  var preconditionErrored = false;\n\t  var blobType = api._meta.blobSupport ? 'blob' : 'base64';\n\t\n\t  preprocessAttachments(docInfos, blobType, function (err) {\n\t    if (err) {\n\t      return callback(err);\n\t    }\n\t    startTransaction();\n\t  });\n\t\n\t  function startTransaction() {\n\t\n\t    var stores = [\n\t      DOC_STORE, BY_SEQ_STORE,\n\t      ATTACH_STORE,\n\t      LOCAL_STORE, ATTACH_AND_SEQ_STORE,\n\t      META_STORE\n\t    ];\n\t    var txnResult = openTransactionSafely(idb, stores, 'readwrite');\n\t    if (txnResult.error) {\n\t      return callback(txnResult.error);\n\t    }\n\t    txn = txnResult.txn;\n\t    txn.onabort = idbError(callback);\n\t    txn.ontimeout = idbError(callback);\n\t    txn.oncomplete = complete;\n\t    docStore = txn.objectStore(DOC_STORE);\n\t    bySeqStore = txn.objectStore(BY_SEQ_STORE);\n\t    attachStore = txn.objectStore(ATTACH_STORE);\n\t    attachAndSeqStore = txn.objectStore(ATTACH_AND_SEQ_STORE);\n\t    metaStore = txn.objectStore(META_STORE);\n\t\n\t    metaStore.get(META_STORE).onsuccess = function (e) {\n\t      metaDoc = e.target.result;\n\t      updateDocCountIfReady();\n\t    };\n\t\n\t    verifyAttachments(function (err) {\n\t      if (err) {\n\t        preconditionErrored = true;\n\t        return callback(err);\n\t      }\n\t      fetchExistingDocs();\n\t    });\n\t  }\n\t\n\t  function onAllDocsProcessed() {\n\t    allDocsProcessed = true;\n\t    updateDocCountIfReady();\n\t  }\n\t\n\t  function idbProcessDocs() {\n\t    processDocs(dbOpts.revs_limit, docInfos, api, fetchedDocs,\n\t                txn, results, writeDoc, opts, onAllDocsProcessed);\n\t  }\n\t\n\t  function updateDocCountIfReady() {\n\t    if (!metaDoc || !allDocsProcessed) {\n\t      return;\n\t    }\n\t    // caching the docCount saves a lot of time in allDocs() and\n\t    // info(), which is why we go to all the trouble of doing this\n\t    metaDoc.docCount += docCountDelta;\n\t    metaStore.put(metaDoc);\n\t  }\n\t\n\t  function fetchExistingDocs() {\n\t\n\t    if (!docInfos.length) {\n\t      return;\n\t    }\n\t\n\t    var numFetched = 0;\n\t\n\t    function checkDone() {\n\t      if (++numFetched === docInfos.length) {\n\t        idbProcessDocs();\n\t      }\n\t    }\n\t\n\t    function readMetadata(event) {\n\t      var metadata = decodeMetadata(event.target.result);\n\t\n\t      if (metadata) {\n\t        fetchedDocs.set(metadata.id, metadata);\n\t      }\n\t      checkDone();\n\t    }\n\t\n\t    for (var i = 0, len = docInfos.length; i < len; i++) {\n\t      var docInfo = docInfos[i];\n\t      if (docInfo._id && isLocalId(docInfo._id)) {\n\t        checkDone(); // skip local docs\n\t        continue;\n\t      }\n\t      var req = docStore.get(docInfo.metadata.id);\n\t      req.onsuccess = readMetadata;\n\t    }\n\t  }\n\t\n\t  function complete() {\n\t    if (preconditionErrored) {\n\t      return;\n\t    }\n\t\n\t    changesHandler$$1.notify(api._meta.name);\n\t    callback(null, results);\n\t  }\n\t\n\t  function verifyAttachment(digest, callback) {\n\t\n\t    var req = attachStore.get(digest);\n\t    req.onsuccess = function (e) {\n\t      if (!e.target.result) {\n\t        var err = createError(MISSING_STUB,\n\t          'unknown stub attachment with digest ' +\n\t          digest);\n\t        err.status = 412;\n\t        callback(err);\n\t      } else {\n\t        callback();\n\t      }\n\t    };\n\t  }\n\t\n\t  function verifyAttachments(finish) {\n\t\n\t\n\t    var digests = [];\n\t    docInfos.forEach(function (docInfo) {\n\t      if (docInfo.data && docInfo.data._attachments) {\n\t        Object.keys(docInfo.data._attachments).forEach(function (filename) {\n\t          var att = docInfo.data._attachments[filename];\n\t          if (att.stub) {\n\t            digests.push(att.digest);\n\t          }\n\t        });\n\t      }\n\t    });\n\t    if (!digests.length) {\n\t      return finish();\n\t    }\n\t    var numDone = 0;\n\t    var err;\n\t\n\t    function checkDone() {\n\t      if (++numDone === digests.length) {\n\t        finish(err);\n\t      }\n\t    }\n\t    digests.forEach(function (digest) {\n\t      verifyAttachment(digest, function (attErr) {\n\t        if (attErr && !err) {\n\t          err = attErr;\n\t        }\n\t        checkDone();\n\t      });\n\t    });\n\t  }\n\t\n\t  function writeDoc(docInfo, winningRev$$1, winningRevIsDeleted, newRevIsDeleted,\n\t                    isUpdate, delta, resultsIdx, callback) {\n\t\n\t    docInfo.metadata.winningRev = winningRev$$1;\n\t    docInfo.metadata.deleted = winningRevIsDeleted;\n\t\n\t    var doc = docInfo.data;\n\t    doc._id = docInfo.metadata.id;\n\t    doc._rev = docInfo.metadata.rev;\n\t\n\t    if (newRevIsDeleted) {\n\t      doc._deleted = true;\n\t    }\n\t\n\t    var hasAttachments = doc._attachments &&\n\t      Object.keys(doc._attachments).length;\n\t    if (hasAttachments) {\n\t      return writeAttachments(docInfo, winningRev$$1, winningRevIsDeleted,\n\t        isUpdate, resultsIdx, callback);\n\t    }\n\t\n\t    docCountDelta += delta;\n\t    updateDocCountIfReady();\n\t\n\t    finishDoc(docInfo, winningRev$$1, winningRevIsDeleted,\n\t      isUpdate, resultsIdx, callback);\n\t  }\n\t\n\t  function finishDoc(docInfo, winningRev$$1, winningRevIsDeleted,\n\t                     isUpdate, resultsIdx, callback) {\n\t\n\t    var doc = docInfo.data;\n\t    var metadata = docInfo.metadata;\n\t\n\t    doc._doc_id_rev = metadata.id + '::' + metadata.rev;\n\t    delete doc._id;\n\t    delete doc._rev;\n\t\n\t    function afterPutDoc(e) {\n\t      var revsToDelete = docInfo.stemmedRevs || [];\n\t\n\t      if (isUpdate && api.auto_compaction) {\n\t        revsToDelete = revsToDelete.concat(compactTree(docInfo.metadata));\n\t      }\n\t\n\t      if (revsToDelete && revsToDelete.length) {\n\t        compactRevs(revsToDelete, docInfo.metadata.id, txn);\n\t      }\n\t\n\t      metadata.seq = e.target.result;\n\t      // Current _rev is calculated from _rev_tree on read\n\t      // delete metadata.rev;\n\t      var metadataToStore = encodeMetadata(metadata, winningRev$$1,\n\t        winningRevIsDeleted);\n\t      var metaDataReq = docStore.put(metadataToStore);\n\t      metaDataReq.onsuccess = afterPutMetadata;\n\t    }\n\t\n\t    function afterPutDocError(e) {\n\t      // ConstraintError, need to update, not put (see #1638 for details)\n\t      e.preventDefault(); // avoid transaction abort\n\t      e.stopPropagation(); // avoid transaction onerror\n\t      var index = bySeqStore.index('_doc_id_rev');\n\t      var getKeyReq = index.getKey(doc._doc_id_rev);\n\t      getKeyReq.onsuccess = function (e) {\n\t        var putReq = bySeqStore.put(doc, e.target.result);\n\t        putReq.onsuccess = afterPutDoc;\n\t      };\n\t    }\n\t\n\t    function afterPutMetadata() {\n\t      results[resultsIdx] = {\n\t        ok: true,\n\t        id: metadata.id,\n\t        rev: metadata.rev\n\t      };\n\t      fetchedDocs.set(docInfo.metadata.id, docInfo.metadata);\n\t      insertAttachmentMappings(docInfo, metadata.seq, callback);\n\t    }\n\t\n\t    var putReq = bySeqStore.put(doc);\n\t\n\t    putReq.onsuccess = afterPutDoc;\n\t    putReq.onerror = afterPutDocError;\n\t  }\n\t\n\t  function writeAttachments(docInfo, winningRev$$1, winningRevIsDeleted,\n\t                            isUpdate, resultsIdx, callback) {\n\t\n\t\n\t    var doc = docInfo.data;\n\t\n\t    var numDone = 0;\n\t    var attachments = Object.keys(doc._attachments);\n\t\n\t    function collectResults() {\n\t      if (numDone === attachments.length) {\n\t        finishDoc(docInfo, winningRev$$1, winningRevIsDeleted,\n\t          isUpdate, resultsIdx, callback);\n\t      }\n\t    }\n\t\n\t    function attachmentSaved() {\n\t      numDone++;\n\t      collectResults();\n\t    }\n\t\n\t    attachments.forEach(function (key) {\n\t      var att = docInfo.data._attachments[key];\n\t      if (!att.stub) {\n\t        var data = att.data;\n\t        delete att.data;\n\t        att.revpos = parseInt(winningRev$$1, 10);\n\t        var digest = att.digest;\n\t        saveAttachment(digest, data, attachmentSaved);\n\t      } else {\n\t        numDone++;\n\t        collectResults();\n\t      }\n\t    });\n\t  }\n\t\n\t  // map seqs to attachment digests, which\n\t  // we will need later during compaction\n\t  function insertAttachmentMappings(docInfo, seq, callback) {\n\t\n\t    var attsAdded = 0;\n\t    var attsToAdd = Object.keys(docInfo.data._attachments || {});\n\t\n\t    if (!attsToAdd.length) {\n\t      return callback();\n\t    }\n\t\n\t    function checkDone() {\n\t      if (++attsAdded === attsToAdd.length) {\n\t        callback();\n\t      }\n\t    }\n\t\n\t    function add(att) {\n\t      var digest = docInfo.data._attachments[att].digest;\n\t      var req = attachAndSeqStore.put({\n\t        seq: seq,\n\t        digestSeq: digest + '::' + seq\n\t      });\n\t\n\t      req.onsuccess = checkDone;\n\t      req.onerror = function (e) {\n\t        // this callback is for a constaint error, which we ignore\n\t        // because this docid/rev has already been associated with\n\t        // the digest (e.g. when new_edits == false)\n\t        e.preventDefault(); // avoid transaction abort\n\t        e.stopPropagation(); // avoid transaction onerror\n\t        checkDone();\n\t      };\n\t    }\n\t    for (var i = 0; i < attsToAdd.length; i++) {\n\t      add(attsToAdd[i]); // do in parallel\n\t    }\n\t  }\n\t\n\t  function saveAttachment(digest, data, callback) {\n\t\n\t\n\t    var getKeyReq = attachStore.count(digest);\n\t    getKeyReq.onsuccess = function (e) {\n\t      var count = e.target.result;\n\t      if (count) {\n\t        return callback(); // already exists\n\t      }\n\t      var newAtt = {\n\t        digest: digest,\n\t        body: data\n\t      };\n\t      var putReq = attachStore.put(newAtt);\n\t      putReq.onsuccess = callback;\n\t    };\n\t  }\n\t}\n\t\n\t// Abstraction over IDBCursor and getAll()/getAllKeys() that allows us to batch our operations\n\t// while falling back to a normal IDBCursor operation on browsers that don't support getAll() or\n\t// getAllKeys(). This allows for a much faster implementation than just straight-up cursors, because\n\t// we're not processing each document one-at-a-time.\n\tfunction runBatchedCursor(objectStore, keyRange, descending, batchSize, onBatch) {\n\t\n\t  // Bail out of getAll()/getAllKeys() in the following cases:\n\t  // 1) either method is unsupported - we need both\n\t  // 2) batchSize is 1 (might as well use IDBCursor), or batchSize is -1 (i.e. batchSize unlimited,\n\t  //    not really clear the user wants a batched approach where the entire DB is read into memory,\n\t  //    perhaps they are filtering on a per-doc basis)\n\t  // 3) descending â no real way to do this via getAll()/getAllKeys()\n\t\n\t  var useGetAll = typeof objectStore.getAll === 'function' &&\n\t    typeof objectStore.getAllKeys === 'function' &&\n\t    batchSize > 1 && !descending;\n\t\n\t  var keysBatch;\n\t  var valuesBatch;\n\t  var pseudoCursor;\n\t\n\t  function onGetAll(e) {\n\t    valuesBatch = e.target.result;\n\t    if (keysBatch) {\n\t      onBatch(keysBatch, valuesBatch, pseudoCursor);\n\t    }\n\t  }\n\t\n\t  function onGetAllKeys(e) {\n\t    keysBatch = e.target.result;\n\t    if (valuesBatch) {\n\t      onBatch(keysBatch, valuesBatch, pseudoCursor);\n\t    }\n\t  }\n\t\n\t  function continuePseudoCursor() {\n\t    if (!keysBatch.length) { // no more results\n\t      return onBatch();\n\t    }\n\t    // fetch next batch, exclusive start\n\t    var lastKey = keysBatch[keysBatch.length - 1];\n\t    var newKeyRange;\n\t    if (keyRange && keyRange.upper) {\n\t      try {\n\t        newKeyRange = IDBKeyRange.bound(lastKey, keyRange.upper,\n\t          true, keyRange.upperOpen);\n\t      } catch (e) {\n\t        if (e.name === \"DataError\" && e.code === 0) {\n\t          return onBatch(); // we're done, startkey and endkey are equal\n\t        }\n\t      }\n\t    } else {\n\t      newKeyRange = IDBKeyRange.lowerBound(lastKey, true);\n\t    }\n\t    keyRange = newKeyRange;\n\t    keysBatch = null;\n\t    valuesBatch = null;\n\t    objectStore.getAll(keyRange, batchSize).onsuccess = onGetAll;\n\t    objectStore.getAllKeys(keyRange, batchSize).onsuccess = onGetAllKeys;\n\t  }\n\t\n\t  function onCursor(e) {\n\t    var cursor = e.target.result;\n\t    if (!cursor) { // done\n\t      return onBatch();\n\t    }\n\t    // regular IDBCursor acts like a batch where batch size is always 1\n\t    onBatch([cursor.key], [cursor.value], cursor);\n\t  }\n\t\n\t  if (useGetAll) {\n\t    pseudoCursor = {\"continue\": continuePseudoCursor};\n\t    objectStore.getAll(keyRange, batchSize).onsuccess = onGetAll;\n\t    objectStore.getAllKeys(keyRange, batchSize).onsuccess = onGetAllKeys;\n\t  } else if (descending) {\n\t    objectStore.openCursor(keyRange, 'prev').onsuccess = onCursor;\n\t  } else {\n\t    objectStore.openCursor(keyRange).onsuccess = onCursor;\n\t  }\n\t}\n\t\n\t// simple shim for objectStore.getAll(), falling back to IDBCursor\n\tfunction getAll(objectStore, keyRange, onSuccess) {\n\t  if (typeof objectStore.getAll === 'function') {\n\t    // use native getAll\n\t    objectStore.getAll(keyRange).onsuccess = onSuccess;\n\t    return;\n\t  }\n\t  // fall back to cursors\n\t  var values = [];\n\t\n\t  function onCursor(e) {\n\t    var cursor = e.target.result;\n\t    if (cursor) {\n\t      values.push(cursor.value);\n\t      cursor.continue();\n\t    } else {\n\t      onSuccess({\n\t        target: {\n\t          result: values\n\t        }\n\t      });\n\t    }\n\t  }\n\t\n\t  objectStore.openCursor(keyRange).onsuccess = onCursor;\n\t}\n\t\n\tfunction createKeyRange(start, end, inclusiveEnd, key, descending) {\n\t  try {\n\t    if (start && end) {\n\t      if (descending) {\n\t        return IDBKeyRange.bound(end, start, !inclusiveEnd, false);\n\t      } else {\n\t        return IDBKeyRange.bound(start, end, false, !inclusiveEnd);\n\t      }\n\t    } else if (start) {\n\t      if (descending) {\n\t        return IDBKeyRange.upperBound(start);\n\t      } else {\n\t        return IDBKeyRange.lowerBound(start);\n\t      }\n\t    } else if (end) {\n\t      if (descending) {\n\t        return IDBKeyRange.lowerBound(end, !inclusiveEnd);\n\t      } else {\n\t        return IDBKeyRange.upperBound(end, !inclusiveEnd);\n\t      }\n\t    } else if (key) {\n\t      return IDBKeyRange.only(key);\n\t    }\n\t  } catch (e) {\n\t    return {error: e};\n\t  }\n\t  return null;\n\t}\n\t\n\tfunction idbAllDocs(opts, idb, callback) {\n\t  var start = 'startkey' in opts ? opts.startkey : false;\n\t  var end = 'endkey' in opts ? opts.endkey : false;\n\t  var key = 'key' in opts ? opts.key : false;\n\t  var skip = opts.skip || 0;\n\t  var limit = typeof opts.limit === 'number' ? opts.limit : -1;\n\t  var inclusiveEnd = opts.inclusive_end !== false;\n\t\n\t  var keyRange = createKeyRange(start, end, inclusiveEnd, key, opts.descending);\n\t  var keyRangeError = keyRange && keyRange.error;\n\t  if (keyRangeError && !(keyRangeError.name === \"DataError\" &&\n\t      keyRangeError.code === 0)) {\n\t    // DataError with error code 0 indicates start is less than end, so\n\t    // can just do an empty query. Else need to throw\n\t    return callback(createError(IDB_ERROR,\n\t      keyRangeError.name, keyRangeError.message));\n\t  }\n\t\n\t  var stores = [DOC_STORE, BY_SEQ_STORE, META_STORE];\n\t\n\t  if (opts.attachments) {\n\t    stores.push(ATTACH_STORE);\n\t  }\n\t  var txnResult = openTransactionSafely(idb, stores, 'readonly');\n\t  if (txnResult.error) {\n\t    return callback(txnResult.error);\n\t  }\n\t  var txn = txnResult.txn;\n\t  txn.oncomplete = onTxnComplete;\n\t  txn.onabort = idbError(callback);\n\t  var docStore = txn.objectStore(DOC_STORE);\n\t  var seqStore = txn.objectStore(BY_SEQ_STORE);\n\t  var metaStore = txn.objectStore(META_STORE);\n\t  var docIdRevIndex = seqStore.index('_doc_id_rev');\n\t  var results = [];\n\t  var docCount;\n\t\n\t  metaStore.get(META_STORE).onsuccess = function (e) {\n\t    docCount = e.target.result.docCount;\n\t  };\n\t\n\t  // if the user specifies include_docs=true, then we don't\n\t  // want to block the main cursor while we're fetching the doc\n\t  function fetchDocAsynchronously(metadata, row, winningRev$$1) {\n\t    var key = metadata.id + \"::\" + winningRev$$1;\n\t    docIdRevIndex.get(key).onsuccess =  function onGetDoc(e) {\n\t      row.doc = decodeDoc(e.target.result);\n\t      if (opts.conflicts) {\n\t        var conflicts = collectConflicts(metadata);\n\t        if (conflicts.length) {\n\t          row.doc._conflicts = conflicts;\n\t        }\n\t      }\n\t      fetchAttachmentsIfNecessary(row.doc, opts, txn);\n\t    };\n\t  }\n\t\n\t  function allDocsInner(winningRev$$1, metadata) {\n\t    var row = {\n\t      id: metadata.id,\n\t      key: metadata.id,\n\t      value: {\n\t        rev: winningRev$$1\n\t      }\n\t    };\n\t    var deleted = metadata.deleted;\n\t    if (opts.deleted === 'ok') {\n\t      results.push(row);\n\t      // deleted docs are okay with \"keys\" requests\n\t      if (deleted) {\n\t        row.value.deleted = true;\n\t        row.doc = null;\n\t      } else if (opts.include_docs) {\n\t        fetchDocAsynchronously(metadata, row, winningRev$$1);\n\t      }\n\t    } else if (!deleted && skip-- <= 0) {\n\t      results.push(row);\n\t      if (opts.include_docs) {\n\t        fetchDocAsynchronously(metadata, row, winningRev$$1);\n\t      }\n\t    }\n\t  }\n\t\n\t  function processBatch(batchValues) {\n\t    for (var i = 0, len = batchValues.length; i < len; i++) {\n\t      if (results.length === limit) {\n\t        break;\n\t      }\n\t      var batchValue = batchValues[i];\n\t      var metadata = decodeMetadata(batchValue);\n\t      var winningRev$$1 = metadata.winningRev;\n\t      allDocsInner(winningRev$$1, metadata);\n\t    }\n\t  }\n\t\n\t  function onBatch(batchKeys, batchValues, cursor) {\n\t    if (!cursor) {\n\t      return;\n\t    }\n\t    processBatch(batchValues);\n\t    if (results.length < limit) {\n\t      cursor.continue();\n\t    }\n\t  }\n\t\n\t  function onGetAll(e) {\n\t    var values = e.target.result;\n\t    if (opts.descending) {\n\t      values = values.reverse();\n\t    }\n\t    processBatch(values);\n\t  }\n\t\n\t  function onResultsReady() {\n\t    callback(null, {\n\t      total_rows: docCount,\n\t      offset: opts.skip,\n\t      rows: results\n\t    });\n\t  }\n\t\n\t  function onTxnComplete() {\n\t    if (opts.attachments) {\n\t      postProcessAttachments(results, opts.binary).then(onResultsReady);\n\t    } else {\n\t      onResultsReady();\n\t    }\n\t  }\n\t\n\t  // don't bother doing any requests if start > end or limit === 0\n\t  if (keyRangeError || limit === 0) {\n\t    return;\n\t  }\n\t  if (limit === -1) { // just fetch everything\n\t    return getAll(docStore, keyRange, onGetAll);\n\t  }\n\t  // else do a cursor\n\t  // choose a batch size based on the skip, since we'll need to skip that many\n\t  runBatchedCursor(docStore, keyRange, opts.descending, limit + skip, onBatch);\n\t}\n\t\n\t//\n\t// Blobs are not supported in all versions of IndexedDB, notably\n\t// Chrome <37 and Android <5. In those versions, storing a blob will throw.\n\t//\n\t// Various other blob bugs exist in Chrome v37-42 (inclusive).\n\t// Detecting them is expensive and confusing to users, and Chrome 37-42\n\t// is at very low usage worldwide, so we do a hacky userAgent check instead.\n\t//\n\t// content-type bug: https://code.google.com/p/chromium/issues/detail?id=408120\n\t// 404 bug: https://code.google.com/p/chromium/issues/detail?id=447916\n\t// FileReader bug: https://code.google.com/p/chromium/issues/detail?id=447836\n\t//\n\tfunction checkBlobSupport(txn) {\n\t  return new PouchPromise$1(function (resolve) {\n\t    var blob$$1 = createBlob(['']);\n\t    var req = txn.objectStore(DETECT_BLOB_SUPPORT_STORE).put(blob$$1, 'key');\n\t\n\t    req.onsuccess = function () {\n\t      var matchedChrome = navigator.userAgent.match(/Chrome\\/(\\d+)/);\n\t      var matchedEdge = navigator.userAgent.match(/Edge\\//);\n\t      // MS Edge pretends to be Chrome 42:\n\t      // https://msdn.microsoft.com/en-us/library/hh869301%28v=vs.85%29.aspx\n\t      resolve(matchedEdge || !matchedChrome ||\n\t        parseInt(matchedChrome[1], 10) >= 43);\n\t    };\n\t\n\t    txn.onabort = function (e) {\n\t      // If the transaction aborts now its due to not being able to\n\t      // write to the database, likely due to the disk being full\n\t      e.preventDefault();\n\t      e.stopPropagation();\n\t      resolve(false);\n\t    };\n\t  }).catch(function () {\n\t    return false; // error, so assume unsupported\n\t  });\n\t}\n\t\n\tfunction countDocs(txn, cb) {\n\t  var index = txn.objectStore(DOC_STORE).index('deletedOrLocal');\n\t  index.count(IDBKeyRange.only('0')).onsuccess = function (e) {\n\t    cb(e.target.result);\n\t  };\n\t}\n\t\n\t// This task queue ensures that IDB open calls are done in their own tick\n\t// and sequentially - i.e. we wait for the async IDB open to *fully* complete\n\t// before calling the next one. This works around IE/Edge race conditions in IDB.\n\t\n\tvar running = false;\n\tvar queue = [];\n\t\n\tfunction tryCode(fun, err, res, PouchDB) {\n\t  try {\n\t    fun(err, res);\n\t  } catch (err) {\n\t    // Shouldn't happen, but in some odd cases\n\t    // IndexedDB implementations might throw a sync\n\t    // error, in which case this will at least log it.\n\t    PouchDB.emit('error', err);\n\t  }\n\t}\n\t\n\tfunction applyNext() {\n\t  if (running || !queue.length) {\n\t    return;\n\t  }\n\t  running = true;\n\t  queue.shift()();\n\t}\n\t\n\tfunction enqueueTask(action, callback, PouchDB) {\n\t  queue.push(function runAction() {\n\t    action(function runCallback(err, res) {\n\t      tryCode(callback, err, res, PouchDB);\n\t      running = false;\n\t      nextTick(function runNext() {\n\t        applyNext(PouchDB);\n\t      });\n\t    });\n\t  });\n\t  applyNext();\n\t}\n\t\n\tfunction changes(opts, api, dbName, idb) {\n\t  opts = clone(opts);\n\t\n\t  if (opts.continuous) {\n\t    var id = dbName + ':' + uuid();\n\t    changesHandler$$1.addListener(dbName, id, api, opts);\n\t    changesHandler$$1.notify(dbName);\n\t    return {\n\t      cancel: function () {\n\t        changesHandler$$1.removeListener(dbName, id);\n\t      }\n\t    };\n\t  }\n\t\n\t  var docIds = opts.doc_ids && new ExportedSet(opts.doc_ids);\n\t\n\t  opts.since = opts.since || 0;\n\t  var lastSeq = opts.since;\n\t\n\t  var limit = 'limit' in opts ? opts.limit : -1;\n\t  if (limit === 0) {\n\t    limit = 1; // per CouchDB _changes spec\n\t  }\n\t  var returnDocs;\n\t  if ('return_docs' in opts) {\n\t    returnDocs = opts.return_docs;\n\t  } else if ('returnDocs' in opts) {\n\t    // TODO: Remove 'returnDocs' in favor of 'return_docs' in a future release\n\t    returnDocs = opts.returnDocs;\n\t  } else {\n\t    returnDocs = true;\n\t  }\n\t\n\t  var results = [];\n\t  var numResults = 0;\n\t  var filter = filterChange(opts);\n\t  var docIdsToMetadata = new ExportedMap();\n\t\n\t  var txn;\n\t  var bySeqStore;\n\t  var docStore;\n\t  var docIdRevIndex;\n\t\n\t  function onBatch(batchKeys, batchValues, cursor) {\n\t    if (!cursor || !batchKeys.length) { // done\n\t      return;\n\t    }\n\t\n\t    var winningDocs = new Array(batchKeys.length);\n\t    var metadatas = new Array(batchKeys.length);\n\t\n\t    function processMetadataAndWinningDoc(metadata, winningDoc) {\n\t      var change = opts.processChange(winningDoc, metadata, opts);\n\t      lastSeq = change.seq = metadata.seq;\n\t\n\t      var filtered = filter(change);\n\t      if (typeof filtered === 'object') { // anything but true/false indicates error\n\t        return opts.complete(filtered);\n\t      }\n\t\n\t      if (filtered) {\n\t        numResults++;\n\t        if (returnDocs) {\n\t          results.push(change);\n\t        }\n\t        // process the attachment immediately\n\t        // for the benefit of live listeners\n\t        if (opts.attachments && opts.include_docs) {\n\t          fetchAttachmentsIfNecessary(winningDoc, opts, txn, function () {\n\t            postProcessAttachments([change], opts.binary).then(function () {\n\t              opts.onChange(change);\n\t            });\n\t          });\n\t        } else {\n\t          opts.onChange(change);\n\t        }\n\t      }\n\t    }\n\t\n\t    function onBatchDone() {\n\t      for (var i = 0, len = winningDocs.length; i < len; i++) {\n\t        if (numResults === limit) {\n\t          break;\n\t        }\n\t        var winningDoc = winningDocs[i];\n\t        if (!winningDoc) {\n\t          continue;\n\t        }\n\t        var metadata = metadatas[i];\n\t        processMetadataAndWinningDoc(metadata, winningDoc);\n\t      }\n\t\n\t      if (numResults !== limit) {\n\t        cursor.continue();\n\t      }\n\t    }\n\t\n\t    // Fetch all metadatas/winningdocs from this batch in parallel, then process\n\t    // them all only once all data has been collected. This is done in parallel\n\t    // because it's faster than doing it one-at-a-time.\n\t    var numDone = 0;\n\t    batchValues.forEach(function (value, i) {\n\t      var doc = decodeDoc(value);\n\t      var seq = batchKeys[i];\n\t      fetchWinningDocAndMetadata(doc, seq, function (metadata, winningDoc) {\n\t        metadatas[i] = metadata;\n\t        winningDocs[i] = winningDoc;\n\t        if (++numDone === batchKeys.length) {\n\t          onBatchDone();\n\t        }\n\t      });\n\t    });\n\t  }\n\t\n\t  function onGetMetadata(doc, seq, metadata, cb) {\n\t    if (metadata.seq !== seq) {\n\t      // some other seq is later\n\t      return cb();\n\t    }\n\t\n\t    if (metadata.winningRev === doc._rev) {\n\t      // this is the winning doc\n\t      return cb(metadata, doc);\n\t    }\n\t\n\t    // fetch winning doc in separate request\n\t    var docIdRev = doc._id + '::' + metadata.winningRev;\n\t    var req = docIdRevIndex.get(docIdRev);\n\t    req.onsuccess = function (e) {\n\t      cb(metadata, decodeDoc(e.target.result));\n\t    };\n\t  }\n\t\n\t  function fetchWinningDocAndMetadata(doc, seq, cb) {\n\t    if (docIds && !docIds.has(doc._id)) {\n\t      return cb();\n\t    }\n\t\n\t    var metadata = docIdsToMetadata.get(doc._id);\n\t    if (metadata) { // cached\n\t      return onGetMetadata(doc, seq, metadata, cb);\n\t    }\n\t    // metadata not cached, have to go fetch it\n\t    docStore.get(doc._id).onsuccess = function (e) {\n\t      metadata = decodeMetadata(e.target.result);\n\t      docIdsToMetadata.set(doc._id, metadata);\n\t      onGetMetadata(doc, seq, metadata, cb);\n\t    };\n\t  }\n\t\n\t  function finish() {\n\t    opts.complete(null, {\n\t      results: results,\n\t      last_seq: lastSeq\n\t    });\n\t  }\n\t\n\t  function onTxnComplete() {\n\t    if (!opts.continuous && opts.attachments) {\n\t      // cannot guarantee that postProcessing was already done,\n\t      // so do it again\n\t      postProcessAttachments(results).then(finish);\n\t    } else {\n\t      finish();\n\t    }\n\t  }\n\t\n\t  var objectStores = [DOC_STORE, BY_SEQ_STORE];\n\t  if (opts.attachments) {\n\t    objectStores.push(ATTACH_STORE);\n\t  }\n\t  var txnResult = openTransactionSafely(idb, objectStores, 'readonly');\n\t  if (txnResult.error) {\n\t    return opts.complete(txnResult.error);\n\t  }\n\t  txn = txnResult.txn;\n\t  txn.onabort = idbError(opts.complete);\n\t  txn.oncomplete = onTxnComplete;\n\t\n\t  bySeqStore = txn.objectStore(BY_SEQ_STORE);\n\t  docStore = txn.objectStore(DOC_STORE);\n\t  docIdRevIndex = bySeqStore.index('_doc_id_rev');\n\t\n\t  var keyRange = (opts.since && !opts.descending) ?\n\t    IDBKeyRange.lowerBound(opts.since, true) : null;\n\t\n\t  runBatchedCursor(bySeqStore, keyRange, opts.descending, limit, onBatch);\n\t}\n\t\n\tvar cachedDBs = new ExportedMap();\n\tvar blobSupportPromise;\n\tvar openReqList = new ExportedMap();\n\t\n\tfunction IdbPouch(opts, callback) {\n\t  var api = this;\n\t\n\t  enqueueTask(function (thisCallback) {\n\t    init(api, opts, thisCallback);\n\t  }, callback, api.constructor);\n\t}\n\t\n\tfunction init(api, opts, callback) {\n\t\n\t  var dbName = opts.name;\n\t\n\t  var idb = null;\n\t  api._meta = null;\n\t\n\t  // called when creating a fresh new database\n\t  function createSchema(db) {\n\t    var docStore = db.createObjectStore(DOC_STORE, {keyPath : 'id'});\n\t    db.createObjectStore(BY_SEQ_STORE, {autoIncrement: true})\n\t      .createIndex('_doc_id_rev', '_doc_id_rev', {unique: true});\n\t    db.createObjectStore(ATTACH_STORE, {keyPath: 'digest'});\n\t    db.createObjectStore(META_STORE, {keyPath: 'id', autoIncrement: false});\n\t    db.createObjectStore(DETECT_BLOB_SUPPORT_STORE);\n\t\n\t    // added in v2\n\t    docStore.createIndex('deletedOrLocal', 'deletedOrLocal', {unique : false});\n\t\n\t    // added in v3\n\t    db.createObjectStore(LOCAL_STORE, {keyPath: '_id'});\n\t\n\t    // added in v4\n\t    var attAndSeqStore = db.createObjectStore(ATTACH_AND_SEQ_STORE,\n\t      {autoIncrement: true});\n\t    attAndSeqStore.createIndex('seq', 'seq');\n\t    attAndSeqStore.createIndex('digestSeq', 'digestSeq', {unique: true});\n\t  }\n\t\n\t  // migration to version 2\n\t  // unfortunately \"deletedOrLocal\" is a misnomer now that we no longer\n\t  // store local docs in the main doc-store, but whaddyagonnado\n\t  function addDeletedOrLocalIndex(txn, callback) {\n\t    var docStore = txn.objectStore(DOC_STORE);\n\t    docStore.createIndex('deletedOrLocal', 'deletedOrLocal', {unique : false});\n\t\n\t    docStore.openCursor().onsuccess = function (event) {\n\t      var cursor = event.target.result;\n\t      if (cursor) {\n\t        var metadata = cursor.value;\n\t        var deleted = isDeleted(metadata);\n\t        metadata.deletedOrLocal = deleted ? \"1\" : \"0\";\n\t        docStore.put(metadata);\n\t        cursor.continue();\n\t      } else {\n\t        callback();\n\t      }\n\t    };\n\t  }\n\t\n\t  // migration to version 3 (part 1)\n\t  function createLocalStoreSchema(db) {\n\t    db.createObjectStore(LOCAL_STORE, {keyPath: '_id'})\n\t      .createIndex('_doc_id_rev', '_doc_id_rev', {unique: true});\n\t  }\n\t\n\t  // migration to version 3 (part 2)\n\t  function migrateLocalStore(txn, cb) {\n\t    var localStore = txn.objectStore(LOCAL_STORE);\n\t    var docStore = txn.objectStore(DOC_STORE);\n\t    var seqStore = txn.objectStore(BY_SEQ_STORE);\n\t\n\t    var cursor = docStore.openCursor();\n\t    cursor.onsuccess = function (event) {\n\t      var cursor = event.target.result;\n\t      if (cursor) {\n\t        var metadata = cursor.value;\n\t        var docId = metadata.id;\n\t        var local = isLocalId(docId);\n\t        var rev = winningRev(metadata);\n\t        if (local) {\n\t          var docIdRev = docId + \"::\" + rev;\n\t          // remove all seq entries\n\t          // associated with this docId\n\t          var start = docId + \"::\";\n\t          var end = docId + \"::~\";\n\t          var index = seqStore.index('_doc_id_rev');\n\t          var range = IDBKeyRange.bound(start, end, false, false);\n\t          var seqCursor = index.openCursor(range);\n\t          seqCursor.onsuccess = function (e) {\n\t            seqCursor = e.target.result;\n\t            if (!seqCursor) {\n\t              // done\n\t              docStore.delete(cursor.primaryKey);\n\t              cursor.continue();\n\t            } else {\n\t              var data = seqCursor.value;\n\t              if (data._doc_id_rev === docIdRev) {\n\t                localStore.put(data);\n\t              }\n\t              seqStore.delete(seqCursor.primaryKey);\n\t              seqCursor.continue();\n\t            }\n\t          };\n\t        } else {\n\t          cursor.continue();\n\t        }\n\t      } else if (cb) {\n\t        cb();\n\t      }\n\t    };\n\t  }\n\t\n\t  // migration to version 4 (part 1)\n\t  function addAttachAndSeqStore(db) {\n\t    var attAndSeqStore = db.createObjectStore(ATTACH_AND_SEQ_STORE,\n\t      {autoIncrement: true});\n\t    attAndSeqStore.createIndex('seq', 'seq');\n\t    attAndSeqStore.createIndex('digestSeq', 'digestSeq', {unique: true});\n\t  }\n\t\n\t  // migration to version 4 (part 2)\n\t  function migrateAttsAndSeqs(txn, callback) {\n\t    var seqStore = txn.objectStore(BY_SEQ_STORE);\n\t    var attStore = txn.objectStore(ATTACH_STORE);\n\t    var attAndSeqStore = txn.objectStore(ATTACH_AND_SEQ_STORE);\n\t\n\t    // need to actually populate the table. this is the expensive part,\n\t    // so as an optimization, check first that this database even\n\t    // contains attachments\n\t    var req = attStore.count();\n\t    req.onsuccess = function (e) {\n\t      var count = e.target.result;\n\t      if (!count) {\n\t        return callback(); // done\n\t      }\n\t\n\t      seqStore.openCursor().onsuccess = function (e) {\n\t        var cursor = e.target.result;\n\t        if (!cursor) {\n\t          return callback(); // done\n\t        }\n\t        var doc = cursor.value;\n\t        var seq = cursor.primaryKey;\n\t        var atts = Object.keys(doc._attachments || {});\n\t        var digestMap = {};\n\t        for (var j = 0; j < atts.length; j++) {\n\t          var att = doc._attachments[atts[j]];\n\t          digestMap[att.digest] = true; // uniq digests, just in case\n\t        }\n\t        var digests = Object.keys(digestMap);\n\t        for (j = 0; j < digests.length; j++) {\n\t          var digest = digests[j];\n\t          attAndSeqStore.put({\n\t            seq: seq,\n\t            digestSeq: digest + '::' + seq\n\t          });\n\t        }\n\t        cursor.continue();\n\t      };\n\t    };\n\t  }\n\t\n\t  // migration to version 5\n\t  // Instead of relying on on-the-fly migration of metadata,\n\t  // this brings the doc-store to its modern form:\n\t  // - metadata.winningrev\n\t  // - metadata.seq\n\t  // - stringify the metadata when storing it\n\t  function migrateMetadata(txn) {\n\t\n\t    function decodeMetadataCompat(storedObject) {\n\t      if (!storedObject.data) {\n\t        // old format, when we didn't store it stringified\n\t        storedObject.deleted = storedObject.deletedOrLocal === '1';\n\t        return storedObject;\n\t      }\n\t      return decodeMetadata(storedObject);\n\t    }\n\t\n\t    // ensure that every metadata has a winningRev and seq,\n\t    // which was previously created on-the-fly but better to migrate\n\t    var bySeqStore = txn.objectStore(BY_SEQ_STORE);\n\t    var docStore = txn.objectStore(DOC_STORE);\n\t    var cursor = docStore.openCursor();\n\t    cursor.onsuccess = function (e) {\n\t      var cursor = e.target.result;\n\t      if (!cursor) {\n\t        return; // done\n\t      }\n\t      var metadata = decodeMetadataCompat(cursor.value);\n\t\n\t      metadata.winningRev = metadata.winningRev ||\n\t        winningRev(metadata);\n\t\n\t      function fetchMetadataSeq() {\n\t        // metadata.seq was added post-3.2.0, so if it's missing,\n\t        // we need to fetch it manually\n\t        var start = metadata.id + '::';\n\t        var end = metadata.id + '::\\uffff';\n\t        var req = bySeqStore.index('_doc_id_rev').openCursor(\n\t          IDBKeyRange.bound(start, end));\n\t\n\t        var metadataSeq = 0;\n\t        req.onsuccess = function (e) {\n\t          var cursor = e.target.result;\n\t          if (!cursor) {\n\t            metadata.seq = metadataSeq;\n\t            return onGetMetadataSeq();\n\t          }\n\t          var seq = cursor.primaryKey;\n\t          if (seq > metadataSeq) {\n\t            metadataSeq = seq;\n\t          }\n\t          cursor.continue();\n\t        };\n\t      }\n\t\n\t      function onGetMetadataSeq() {\n\t        var metadataToStore = encodeMetadata(metadata,\n\t          metadata.winningRev, metadata.deleted);\n\t\n\t        var req = docStore.put(metadataToStore);\n\t        req.onsuccess = function () {\n\t          cursor.continue();\n\t        };\n\t      }\n\t\n\t      if (metadata.seq) {\n\t        return onGetMetadataSeq();\n\t      }\n\t\n\t      fetchMetadataSeq();\n\t    };\n\t\n\t  }\n\t\n\t  api.type = function () {\n\t    return 'idb';\n\t  };\n\t\n\t  api._id = toPromise(function (callback) {\n\t    callback(null, api._meta.instanceId);\n\t  });\n\t\n\t  api._bulkDocs = function idb_bulkDocs(req, reqOpts, callback) {\n\t    idbBulkDocs(opts, req, reqOpts, api, idb, callback);\n\t  };\n\t\n\t  // First we look up the metadata in the ids database, then we fetch the\n\t  // current revision(s) from the by sequence store\n\t  api._get = function idb_get(id, opts, callback) {\n\t    var doc;\n\t    var metadata;\n\t    var err;\n\t    var txn = opts.ctx;\n\t    if (!txn) {\n\t      var txnResult = openTransactionSafely(idb,\n\t        [DOC_STORE, BY_SEQ_STORE, ATTACH_STORE], 'readonly');\n\t      if (txnResult.error) {\n\t        return callback(txnResult.error);\n\t      }\n\t      txn = txnResult.txn;\n\t    }\n\t\n\t    function finish() {\n\t      callback(err, {doc: doc, metadata: metadata, ctx: txn});\n\t    }\n\t\n\t    txn.objectStore(DOC_STORE).get(id).onsuccess = function (e) {\n\t      metadata = decodeMetadata(e.target.result);\n\t      // we can determine the result here if:\n\t      // 1. there is no such document\n\t      // 2. the document is deleted and we don't ask about specific rev\n\t      // When we ask with opts.rev we expect the answer to be either\n\t      // doc (possibly with _deleted=true) or missing error\n\t      if (!metadata) {\n\t        err = createError(MISSING_DOC, 'missing');\n\t        return finish();\n\t      }\n\t\n\t      var rev;\n\t      if(!opts.rev) {\n\t        rev = metadata.winningRev;\n\t        var deleted = isDeleted(metadata);\n\t        if (deleted) {\n\t          err = createError(MISSING_DOC, \"deleted\");\n\t          return finish();\n\t        }\n\t      } else {\n\t        rev = opts.latest ? latest(opts.rev, metadata) : opts.rev;\n\t      }\n\t\n\t      var objectStore = txn.objectStore(BY_SEQ_STORE);\n\t      var key = metadata.id + '::' + rev;\n\t\n\t      objectStore.index('_doc_id_rev').get(key).onsuccess = function (e) {\n\t        doc = e.target.result;\n\t        if (doc) {\n\t          doc = decodeDoc(doc);\n\t        }\n\t        if (!doc) {\n\t          err = createError(MISSING_DOC, 'missing');\n\t          return finish();\n\t        }\n\t        finish();\n\t      };\n\t    };\n\t  };\n\t\n\t  api._getAttachment = function (docId, attachId, attachment, opts, callback) {\n\t    var txn;\n\t    if (opts.ctx) {\n\t      txn = opts.ctx;\n\t    } else {\n\t      var txnResult = openTransactionSafely(idb,\n\t        [DOC_STORE, BY_SEQ_STORE, ATTACH_STORE], 'readonly');\n\t      if (txnResult.error) {\n\t        return callback(txnResult.error);\n\t      }\n\t      txn = txnResult.txn;\n\t    }\n\t    var digest = attachment.digest;\n\t    var type = attachment.content_type;\n\t\n\t    txn.objectStore(ATTACH_STORE).get(digest).onsuccess = function (e) {\n\t      var body = e.target.result.body;\n\t      readBlobData(body, type, opts.binary, function (blobData) {\n\t        callback(null, blobData);\n\t      });\n\t    };\n\t  };\n\t\n\t  api._info = function idb_info(callback) {\n\t    var updateSeq;\n\t    var docCount;\n\t\n\t    var txnResult = openTransactionSafely(idb, [META_STORE, BY_SEQ_STORE], 'readonly');\n\t    if (txnResult.error) {\n\t      return callback(txnResult.error);\n\t    }\n\t    var txn = txnResult.txn;\n\t    txn.objectStore(META_STORE).get(META_STORE).onsuccess = function (e) {\n\t      docCount = e.target.result.docCount;\n\t    };\n\t    txn.objectStore(BY_SEQ_STORE).openCursor(null, 'prev').onsuccess = function (e) {\n\t      var cursor = e.target.result;\n\t      updateSeq = cursor ? cursor.key : 0;\n\t    };\n\t\n\t    txn.oncomplete = function () {\n\t      callback(null, {\n\t        doc_count: docCount,\n\t        update_seq: updateSeq,\n\t        // for debugging\n\t        idb_attachment_format: (api._meta.blobSupport ? 'binary' : 'base64')\n\t      });\n\t    };\n\t  };\n\t\n\t  api._allDocs = function idb_allDocs(opts, callback) {\n\t    idbAllDocs(opts, idb, callback);\n\t  };\n\t\n\t  api._changes = function idbChanges(opts) {\n\t    changes(opts, api, dbName, idb);\n\t  };\n\t\n\t  api._close = function (callback) {\n\t    // https://developer.mozilla.org/en-US/docs/IndexedDB/IDBDatabase#close\n\t    // \"Returns immediately and closes the connection in a separate thread...\"\n\t    idb.close();\n\t    cachedDBs.delete(dbName);\n\t    callback();\n\t  };\n\t\n\t  api._getRevisionTree = function (docId, callback) {\n\t    var txnResult = openTransactionSafely(idb, [DOC_STORE], 'readonly');\n\t    if (txnResult.error) {\n\t      return callback(txnResult.error);\n\t    }\n\t    var txn = txnResult.txn;\n\t    var req = txn.objectStore(DOC_STORE).get(docId);\n\t    req.onsuccess = function (event) {\n\t      var doc = decodeMetadata(event.target.result);\n\t      if (!doc) {\n\t        callback(createError(MISSING_DOC));\n\t      } else {\n\t        callback(null, doc.rev_tree);\n\t      }\n\t    };\n\t  };\n\t\n\t  // This function removes revisions of document docId\n\t  // which are listed in revs and sets this document\n\t  // revision to to rev_tree\n\t  api._doCompaction = function (docId, revs, callback) {\n\t    var stores = [\n\t      DOC_STORE,\n\t      BY_SEQ_STORE,\n\t      ATTACH_STORE,\n\t      ATTACH_AND_SEQ_STORE\n\t    ];\n\t    var txnResult = openTransactionSafely(idb, stores, 'readwrite');\n\t    if (txnResult.error) {\n\t      return callback(txnResult.error);\n\t    }\n\t    var txn = txnResult.txn;\n\t\n\t    var docStore = txn.objectStore(DOC_STORE);\n\t\n\t    docStore.get(docId).onsuccess = function (event) {\n\t      var metadata = decodeMetadata(event.target.result);\n\t      traverseRevTree(metadata.rev_tree, function (isLeaf, pos,\n\t                                                         revHash, ctx, opts) {\n\t        var rev = pos + '-' + revHash;\n\t        if (revs.indexOf(rev) !== -1) {\n\t          opts.status = 'missing';\n\t        }\n\t      });\n\t      compactRevs(revs, docId, txn);\n\t      var winningRev$$1 = metadata.winningRev;\n\t      var deleted = metadata.deleted;\n\t      txn.objectStore(DOC_STORE).put(\n\t        encodeMetadata(metadata, winningRev$$1, deleted));\n\t    };\n\t    txn.onabort = idbError(callback);\n\t    txn.oncomplete = function () {\n\t      callback();\n\t    };\n\t  };\n\t\n\t\n\t  api._getLocal = function (id, callback) {\n\t    var txnResult = openTransactionSafely(idb, [LOCAL_STORE], 'readonly');\n\t    if (txnResult.error) {\n\t      return callback(txnResult.error);\n\t    }\n\t    var tx = txnResult.txn;\n\t    var req = tx.objectStore(LOCAL_STORE).get(id);\n\t\n\t    req.onerror = idbError(callback);\n\t    req.onsuccess = function (e) {\n\t      var doc = e.target.result;\n\t      if (!doc) {\n\t        callback(createError(MISSING_DOC));\n\t      } else {\n\t        delete doc['_doc_id_rev']; // for backwards compat\n\t        callback(null, doc);\n\t      }\n\t    };\n\t  };\n\t\n\t  api._putLocal = function (doc, opts, callback) {\n\t    if (typeof opts === 'function') {\n\t      callback = opts;\n\t      opts = {};\n\t    }\n\t    delete doc._revisions; // ignore this, trust the rev\n\t    var oldRev = doc._rev;\n\t    var id = doc._id;\n\t    if (!oldRev) {\n\t      doc._rev = '0-1';\n\t    } else {\n\t      doc._rev = '0-' + (parseInt(oldRev.split('-')[1], 10) + 1);\n\t    }\n\t\n\t    var tx = opts.ctx;\n\t    var ret;\n\t    if (!tx) {\n\t      var txnResult = openTransactionSafely(idb, [LOCAL_STORE], 'readwrite');\n\t      if (txnResult.error) {\n\t        return callback(txnResult.error);\n\t      }\n\t      tx = txnResult.txn;\n\t      tx.onerror = idbError(callback);\n\t      tx.oncomplete = function () {\n\t        if (ret) {\n\t          callback(null, ret);\n\t        }\n\t      };\n\t    }\n\t\n\t    var oStore = tx.objectStore(LOCAL_STORE);\n\t    var req;\n\t    if (oldRev) {\n\t      req = oStore.get(id);\n\t      req.onsuccess = function (e) {\n\t        var oldDoc = e.target.result;\n\t        if (!oldDoc || oldDoc._rev !== oldRev) {\n\t          callback(createError(REV_CONFLICT));\n\t        } else { // update\n\t          var req = oStore.put(doc);\n\t          req.onsuccess = function () {\n\t            ret = {ok: true, id: doc._id, rev: doc._rev};\n\t            if (opts.ctx) { // return immediately\n\t              callback(null, ret);\n\t            }\n\t          };\n\t        }\n\t      };\n\t    } else { // new doc\n\t      req = oStore.add(doc);\n\t      req.onerror = function (e) {\n\t        // constraint error, already exists\n\t        callback(createError(REV_CONFLICT));\n\t        e.preventDefault(); // avoid transaction abort\n\t        e.stopPropagation(); // avoid transaction onerror\n\t      };\n\t      req.onsuccess = function () {\n\t        ret = {ok: true, id: doc._id, rev: doc._rev};\n\t        if (opts.ctx) { // return immediately\n\t          callback(null, ret);\n\t        }\n\t      };\n\t    }\n\t  };\n\t\n\t  api._removeLocal = function (doc, opts, callback) {\n\t    if (typeof opts === 'function') {\n\t      callback = opts;\n\t      opts = {};\n\t    }\n\t    var tx = opts.ctx;\n\t    if (!tx) {\n\t      var txnResult = openTransactionSafely(idb, [LOCAL_STORE], 'readwrite');\n\t      if (txnResult.error) {\n\t        return callback(txnResult.error);\n\t      }\n\t      tx = txnResult.txn;\n\t      tx.oncomplete = function () {\n\t        if (ret) {\n\t          callback(null, ret);\n\t        }\n\t      };\n\t    }\n\t    var ret;\n\t    var id = doc._id;\n\t    var oStore = tx.objectStore(LOCAL_STORE);\n\t    var req = oStore.get(id);\n\t\n\t    req.onerror = idbError(callback);\n\t    req.onsuccess = function (e) {\n\t      var oldDoc = e.target.result;\n\t      if (!oldDoc || oldDoc._rev !== doc._rev) {\n\t        callback(createError(MISSING_DOC));\n\t      } else {\n\t        oStore.delete(id);\n\t        ret = {ok: true, id: id, rev: '0-0'};\n\t        if (opts.ctx) { // return immediately\n\t          callback(null, ret);\n\t        }\n\t      }\n\t    };\n\t  };\n\t\n\t  api._destroy = function (opts, callback) {\n\t    changesHandler$$1.removeAllListeners(dbName);\n\t\n\t    //Close open request for \"dbName\" database to fix ie delay.\n\t    var openReq = openReqList.get(dbName);\n\t    if (openReq && openReq.result) {\n\t      openReq.result.close();\n\t      cachedDBs.delete(dbName);\n\t    }\n\t    var req = indexedDB.deleteDatabase(dbName);\n\t\n\t    req.onsuccess = function () {\n\t      //Remove open request from the list.\n\t      openReqList.delete(dbName);\n\t      if (hasLocalStorage() && (dbName in localStorage)) {\n\t        delete localStorage[dbName];\n\t      }\n\t      callback(null, { 'ok': true });\n\t    };\n\t\n\t    req.onerror = idbError(callback);\n\t  };\n\t\n\t  var cached = cachedDBs.get(dbName);\n\t\n\t  if (cached) {\n\t    idb = cached.idb;\n\t    api._meta = cached.global;\n\t    return nextTick(function () {\n\t      callback(null, api);\n\t    });\n\t  }\n\t\n\t  var req;\n\t  if (opts.storage) {\n\t    req = tryStorageOption(dbName, opts.storage);\n\t  } else {\n\t    req = indexedDB.open(dbName, ADAPTER_VERSION);\n\t  }\n\t\n\t  openReqList.set(dbName, req);\n\t\n\t  req.onupgradeneeded = function (e) {\n\t    var db = e.target.result;\n\t    if (e.oldVersion < 1) {\n\t      return createSchema(db); // new db, initial schema\n\t    }\n\t    // do migrations\n\t\n\t    var txn = e.currentTarget.transaction;\n\t    // these migrations have to be done in this function, before\n\t    // control is returned to the event loop, because IndexedDB\n\t\n\t    if (e.oldVersion < 3) {\n\t      createLocalStoreSchema(db); // v2 -> v3\n\t    }\n\t    if (e.oldVersion < 4) {\n\t      addAttachAndSeqStore(db); // v3 -> v4\n\t    }\n\t\n\t    var migrations = [\n\t      addDeletedOrLocalIndex, // v1 -> v2\n\t      migrateLocalStore,      // v2 -> v3\n\t      migrateAttsAndSeqs,     // v3 -> v4\n\t      migrateMetadata         // v4 -> v5\n\t    ];\n\t\n\t    var i = e.oldVersion;\n\t\n\t    function next() {\n\t      var migration = migrations[i - 1];\n\t      i++;\n\t      if (migration) {\n\t        migration(txn, next);\n\t      }\n\t    }\n\t\n\t    next();\n\t  };\n\t\n\t  req.onsuccess = function (e) {\n\t\n\t    idb = e.target.result;\n\t\n\t    idb.onversionchange = function () {\n\t      idb.close();\n\t      cachedDBs.delete(dbName);\n\t    };\n\t\n\t    idb.onabort = function (e) {\n\t      guardedConsole('error', 'Database has a global failure', e.target.error);\n\t      idb.close();\n\t      cachedDBs.delete(dbName);\n\t    };\n\t\n\t    // Do a few setup operations (in parallel as much as possible):\n\t    // 1. Fetch meta doc\n\t    // 2. Check blob support\n\t    // 3. Calculate docCount\n\t    // 4. Generate an instanceId if necessary\n\t    // 5. Store docCount and instanceId on meta doc\n\t\n\t    var txn = idb.transaction([\n\t      META_STORE,\n\t      DETECT_BLOB_SUPPORT_STORE,\n\t      DOC_STORE\n\t    ], 'readwrite');\n\t\n\t    var storedMetaDoc = false;\n\t    var metaDoc;\n\t    var docCount;\n\t    var blobSupport;\n\t    var instanceId;\n\t\n\t    function completeSetup() {\n\t      if (typeof blobSupport === 'undefined' || !storedMetaDoc) {\n\t        return;\n\t      }\n\t      api._meta = {\n\t        name: dbName,\n\t        instanceId: instanceId,\n\t        blobSupport: blobSupport\n\t      };\n\t\n\t      cachedDBs.set(dbName, {\n\t        idb: idb,\n\t        global: api._meta\n\t      });\n\t      callback(null, api);\n\t    }\n\t\n\t    function storeMetaDocIfReady() {\n\t      if (typeof docCount === 'undefined' || typeof metaDoc === 'undefined') {\n\t        return;\n\t      }\n\t      var instanceKey = dbName + '_id';\n\t      if (instanceKey in metaDoc) {\n\t        instanceId = metaDoc[instanceKey];\n\t      } else {\n\t        metaDoc[instanceKey] = instanceId = uuid();\n\t      }\n\t      metaDoc.docCount = docCount;\n\t      txn.objectStore(META_STORE).put(metaDoc);\n\t    }\n\t\n\t    //\n\t    // fetch or generate the instanceId\n\t    //\n\t    txn.objectStore(META_STORE).get(META_STORE).onsuccess = function (e) {\n\t      metaDoc = e.target.result || { id: META_STORE };\n\t      storeMetaDocIfReady();\n\t    };\n\t\n\t    //\n\t    // countDocs\n\t    //\n\t    countDocs(txn, function (count) {\n\t      docCount = count;\n\t      storeMetaDocIfReady();\n\t    });\n\t\n\t    //\n\t    // check blob support\n\t    //\n\t    if (!blobSupportPromise) {\n\t      // make sure blob support is only checked once\n\t      blobSupportPromise = checkBlobSupport(txn);\n\t    }\n\t\n\t    blobSupportPromise.then(function (val) {\n\t      blobSupport = val;\n\t      completeSetup();\n\t    });\n\t\n\t    // only when the metadata put transaction has completed,\n\t    // consider the setup done\n\t    txn.oncomplete = function () {\n\t      storedMetaDoc = true;\n\t      completeSetup();\n\t    };\n\t  };\n\t\n\t  req.onerror = function () {\n\t    var msg = 'Failed to open indexedDB, are you in private browsing mode?';\n\t    guardedConsole('error', msg);\n\t    callback(createError(IDB_ERROR, msg));\n\t  };\n\t}\n\t\n\tIdbPouch.valid = function () {\n\t  // Issue #2533, we finally gave up on doing bug\n\t  // detection instead of browser sniffing. Safari brought us\n\t  // to our knees.\n\t  var isSafari = typeof openDatabase !== 'undefined' &&\n\t    /(Safari|iPhone|iPad|iPod)/.test(navigator.userAgent) &&\n\t    !/Chrome/.test(navigator.userAgent) &&\n\t    !/BlackBerry/.test(navigator.platform);\n\t\n\t  // some outdated implementations of IDB that appear on Samsung\n\t  // and HTC Android devices <4.4 are missing IDBKeyRange\n\t  return !isSafari && typeof indexedDB !== 'undefined' &&\n\t    typeof IDBKeyRange !== 'undefined';\n\t};\n\t\n\tfunction tryStorageOption(dbName, storage) {\n\t  try { // option only available in Firefox 26+\n\t    return indexedDB.open(dbName, {\n\t      version: ADAPTER_VERSION,\n\t      storage: storage\n\t    });\n\t  } catch(err) {\n\t      return indexedDB.open(dbName, ADAPTER_VERSION);\n\t  }\n\t}\n\t\n\tvar IDBPouch = function (PouchDB) {\n\t  PouchDB.adapter('idb', IdbPouch, true);\n\t};\n\t\n\t//\n\t// Parsing hex strings. Yeah.\n\t//\n\t// So basically we need this because of a bug in WebSQL:\n\t// https://code.google.com/p/chromium/issues/detail?id=422690\n\t// https://bugs.webkit.org/show_bug.cgi?id=137637\n\t//\n\t// UTF-8 and UTF-16 are provided as separate functions\n\t// for meager performance improvements\n\t//\n\t\n\tfunction decodeUtf8(str) {\n\t  return decodeURIComponent(escape(str));\n\t}\n\t\n\tfunction hexToInt(charCode) {\n\t  // '0'-'9' is 48-57\n\t  // 'A'-'F' is 65-70\n\t  // SQLite will only give us uppercase hex\n\t  return charCode < 65 ? (charCode - 48) : (charCode - 55);\n\t}\n\t\n\t\n\t// Example:\n\t// pragma encoding=utf8;\n\t// select hex('A');\n\t// returns '41'\n\tfunction parseHexUtf8(str, start, end) {\n\t  var result = '';\n\t  while (start < end) {\n\t    result += String.fromCharCode(\n\t      (hexToInt(str.charCodeAt(start++)) << 4) |\n\t        hexToInt(str.charCodeAt(start++)));\n\t  }\n\t  return result;\n\t}\n\t\n\t// Example:\n\t// pragma encoding=utf16;\n\t// select hex('A');\n\t// returns '4100'\n\t// notice that the 00 comes after the 41 (i.e. it's swizzled)\n\tfunction parseHexUtf16(str, start, end) {\n\t  var result = '';\n\t  while (start < end) {\n\t    // UTF-16, so swizzle the bytes\n\t    result += String.fromCharCode(\n\t      (hexToInt(str.charCodeAt(start + 2)) << 12) |\n\t        (hexToInt(str.charCodeAt(start + 3)) << 8) |\n\t        (hexToInt(str.charCodeAt(start)) << 4) |\n\t        hexToInt(str.charCodeAt(start + 1)));\n\t    start += 4;\n\t  }\n\t  return result;\n\t}\n\t\n\tfunction parseHexString(str, encoding) {\n\t  if (encoding === 'UTF-8') {\n\t    return decodeUtf8(parseHexUtf8(str, 0, str.length));\n\t  } else {\n\t    return parseHexUtf16(str, 0, str.length);\n\t  }\n\t}\n\t\n\tfunction quote(str) {\n\t  return \"'\" + str + \"'\";\n\t}\n\t\n\tvar ADAPTER_VERSION$1 = 7; // used to manage migrations\n\t\n\t// The object stores created for each database\n\t// DOC_STORE stores the document meta data, its revision history and state\n\tvar DOC_STORE$1 = quote('document-store');\n\t// BY_SEQ_STORE stores a particular version of a document, keyed by its\n\t// sequence id\n\tvar BY_SEQ_STORE$1 = quote('by-sequence');\n\t// Where we store attachments\n\tvar ATTACH_STORE$1 = quote('attach-store');\n\tvar LOCAL_STORE$1 = quote('local-store');\n\tvar META_STORE$1 = quote('metadata-store');\n\t// where we store many-to-many relations between attachment\n\t// digests and seqs\n\tvar ATTACH_AND_SEQ_STORE$1 = quote('attach-seq-store');\n\t\n\t// escapeBlob and unescapeBlob are workarounds for a websql bug:\n\t// https://code.google.com/p/chromium/issues/detail?id=422690\n\t// https://bugs.webkit.org/show_bug.cgi?id=137637\n\t// The goal is to never actually insert the \\u0000 character\n\t// in the database.\n\tfunction escapeBlob(str) {\n\t  return str\n\t    .replace(/\\u0002/g, '\\u0002\\u0002')\n\t    .replace(/\\u0001/g, '\\u0001\\u0002')\n\t    .replace(/\\u0000/g, '\\u0001\\u0001');\n\t}\n\t\n\tfunction unescapeBlob(str) {\n\t  return str\n\t    .replace(/\\u0001\\u0001/g, '\\u0000')\n\t    .replace(/\\u0001\\u0002/g, '\\u0001')\n\t    .replace(/\\u0002\\u0002/g, '\\u0002');\n\t}\n\t\n\tfunction stringifyDoc(doc) {\n\t  // don't bother storing the id/rev. it uses lots of space,\n\t  // in persistent map/reduce especially\n\t  delete doc._id;\n\t  delete doc._rev;\n\t  return JSON.stringify(doc);\n\t}\n\t\n\tfunction unstringifyDoc(doc, id, rev) {\n\t  doc = JSON.parse(doc);\n\t  doc._id = id;\n\t  doc._rev = rev;\n\t  return doc;\n\t}\n\t\n\t// question mark groups IN queries, e.g. 3 -> '(?,?,?)'\n\tfunction qMarks(num) {\n\t  var s = '(';\n\t  while (num--) {\n\t    s += '?';\n\t    if (num) {\n\t      s += ',';\n\t    }\n\t  }\n\t  return s + ')';\n\t}\n\t\n\tfunction select(selector, table, joiner, where, orderBy) {\n\t  return 'SELECT ' + selector + ' FROM ' +\n\t    (typeof table === 'string' ? table : table.join(' JOIN ')) +\n\t    (joiner ? (' ON ' + joiner) : '') +\n\t    (where ? (' WHERE ' +\n\t    (typeof where === 'string' ? where : where.join(' AND '))) : '') +\n\t    (orderBy ? (' ORDER BY ' + orderBy) : '');\n\t}\n\t\n\tfunction compactRevs$1(revs, docId, tx) {\n\t\n\t  if (!revs.length) {\n\t    return;\n\t  }\n\t\n\t  var numDone = 0;\n\t  var seqs = [];\n\t\n\t  function checkDone() {\n\t    if (++numDone === revs.length) { // done\n\t      deleteOrphans();\n\t    }\n\t  }\n\t\n\t  function deleteOrphans() {\n\t    // find orphaned attachment digests\n\t\n\t    if (!seqs.length) {\n\t      return;\n\t    }\n\t\n\t    var sql = 'SELECT DISTINCT digest AS digest FROM ' +\n\t      ATTACH_AND_SEQ_STORE$1 + ' WHERE seq IN ' + qMarks(seqs.length);\n\t\n\t    tx.executeSql(sql, seqs, function (tx, res) {\n\t\n\t      var digestsToCheck = [];\n\t      for (var i = 0; i < res.rows.length; i++) {\n\t        digestsToCheck.push(res.rows.item(i).digest);\n\t      }\n\t      if (!digestsToCheck.length) {\n\t        return;\n\t      }\n\t\n\t      var sql = 'DELETE FROM ' + ATTACH_AND_SEQ_STORE$1 +\n\t        ' WHERE seq IN (' +\n\t        seqs.map(function () { return '?'; }).join(',') +\n\t        ')';\n\t      tx.executeSql(sql, seqs, function (tx) {\n\t\n\t        var sql = 'SELECT digest FROM ' + ATTACH_AND_SEQ_STORE$1 +\n\t          ' WHERE digest IN (' +\n\t          digestsToCheck.map(function () { return '?'; }).join(',') +\n\t          ')';\n\t        tx.executeSql(sql, digestsToCheck, function (tx, res) {\n\t          var nonOrphanedDigests = new ExportedSet();\n\t          for (var i = 0; i < res.rows.length; i++) {\n\t            nonOrphanedDigests.add(res.rows.item(i).digest);\n\t          }\n\t          digestsToCheck.forEach(function (digest) {\n\t            if (nonOrphanedDigests.has(digest)) {\n\t              return;\n\t            }\n\t            tx.executeSql(\n\t              'DELETE FROM ' + ATTACH_AND_SEQ_STORE$1 + ' WHERE digest=?',\n\t              [digest]);\n\t            tx.executeSql(\n\t              'DELETE FROM ' + ATTACH_STORE$1 + ' WHERE digest=?', [digest]);\n\t          });\n\t        });\n\t      });\n\t    });\n\t  }\n\t\n\t  // update by-seq and attach stores in parallel\n\t  revs.forEach(function (rev) {\n\t    var sql = 'SELECT seq FROM ' + BY_SEQ_STORE$1 +\n\t      ' WHERE doc_id=? AND rev=?';\n\t\n\t    tx.executeSql(sql, [docId, rev], function (tx, res) {\n\t      if (!res.rows.length) { // already deleted\n\t        return checkDone();\n\t      }\n\t      var seq = res.rows.item(0).seq;\n\t      seqs.push(seq);\n\t\n\t      tx.executeSql(\n\t        'DELETE FROM ' + BY_SEQ_STORE$1 + ' WHERE seq=?', [seq], checkDone);\n\t    });\n\t  });\n\t}\n\t\n\tfunction websqlError(callback) {\n\t  return function (event) {\n\t    guardedConsole('error', 'WebSQL threw an error', event);\n\t    // event may actually be a SQLError object, so report is as such\n\t    var errorNameMatch = event && event.constructor.toString()\n\t        .match(/function ([^\\(]+)/);\n\t    var errorName = (errorNameMatch && errorNameMatch[1]) || event.type;\n\t    var errorReason = event.target || event.message;\n\t    callback(createError(WSQ_ERROR, errorReason, errorName));\n\t  };\n\t}\n\t\n\tfunction getSize(opts) {\n\t  if ('size' in opts) {\n\t    // triggers immediate popup in iOS, fixes #2347\n\t    // e.g. 5000001 asks for 5 MB, 10000001 asks for 10 MB,\n\t    return opts.size * 1000000;\n\t  }\n\t  // In iOS, doesn't matter as long as it's <= 5000000.\n\t  // Except that if you request too much, our tests fail\n\t  // because of the native \"do you accept?\" popup.\n\t  // In Android <=4.3, this value is actually used as an\n\t  // honest-to-god ceiling for data, so we need to\n\t  // set it to a decently high number.\n\t  var isAndroid = typeof navigator !== 'undefined' &&\n\t    /Android/.test(navigator.userAgent);\n\t  return isAndroid ? 5000000 : 1; // in PhantomJS, if you use 0 it will crash\n\t}\n\t\n\tfunction websqlBulkDocs(dbOpts, req, opts, api, db, websqlChanges, callback) {\n\t  var newEdits = opts.new_edits;\n\t  var userDocs = req.docs;\n\t\n\t  // Parse the docs, give them a sequence number for the result\n\t  var docInfos = userDocs.map(function (doc) {\n\t    if (doc._id && isLocalId(doc._id)) {\n\t      return doc;\n\t    }\n\t    var newDoc = parseDoc(doc, newEdits);\n\t    return newDoc;\n\t  });\n\t\n\t  var docInfoErrors = docInfos.filter(function (docInfo) {\n\t    return docInfo.error;\n\t  });\n\t  if (docInfoErrors.length) {\n\t    return callback(docInfoErrors[0]);\n\t  }\n\t\n\t  var tx;\n\t  var results = new Array(docInfos.length);\n\t  var fetchedDocs = new ExportedMap();\n\t\n\t  var preconditionErrored;\n\t  function complete() {\n\t    if (preconditionErrored) {\n\t      return callback(preconditionErrored);\n\t    }\n\t    websqlChanges.notify(api._name);\n\t    callback(null, results);\n\t  }\n\t\n\t  function verifyAttachment(digest, callback) {\n\t    var sql = 'SELECT count(*) as cnt FROM ' + ATTACH_STORE$1 +\n\t      ' WHERE digest=?';\n\t    tx.executeSql(sql, [digest], function (tx, result) {\n\t      if (result.rows.item(0).cnt === 0) {\n\t        var err = createError(MISSING_STUB,\n\t          'unknown stub attachment with digest ' +\n\t          digest);\n\t        callback(err);\n\t      } else {\n\t        callback();\n\t      }\n\t    });\n\t  }\n\t\n\t  function verifyAttachments(finish) {\n\t    var digests = [];\n\t    docInfos.forEach(function (docInfo) {\n\t      if (docInfo.data && docInfo.data._attachments) {\n\t        Object.keys(docInfo.data._attachments).forEach(function (filename) {\n\t          var att = docInfo.data._attachments[filename];\n\t          if (att.stub) {\n\t            digests.push(att.digest);\n\t          }\n\t        });\n\t      }\n\t    });\n\t    if (!digests.length) {\n\t      return finish();\n\t    }\n\t    var numDone = 0;\n\t    var err;\n\t\n\t    function checkDone() {\n\t      if (++numDone === digests.length) {\n\t        finish(err);\n\t      }\n\t    }\n\t    digests.forEach(function (digest) {\n\t      verifyAttachment(digest, function (attErr) {\n\t        if (attErr && !err) {\n\t          err = attErr;\n\t        }\n\t        checkDone();\n\t      });\n\t    });\n\t  }\n\t\n\t  function writeDoc(docInfo, winningRev$$1, winningRevIsDeleted, newRevIsDeleted,\n\t                    isUpdate, delta, resultsIdx, callback) {\n\t\n\t    function finish() {\n\t      var data = docInfo.data;\n\t      var deletedInt = newRevIsDeleted ? 1 : 0;\n\t\n\t      var id = data._id;\n\t      var rev = data._rev;\n\t      var json = stringifyDoc(data);\n\t      var sql = 'INSERT INTO ' + BY_SEQ_STORE$1 +\n\t        ' (doc_id, rev, json, deleted) VALUES (?, ?, ?, ?);';\n\t      var sqlArgs = [id, rev, json, deletedInt];\n\t\n\t      // map seqs to attachment digests, which\n\t      // we will need later during compaction\n\t      function insertAttachmentMappings(seq, callback) {\n\t        var attsAdded = 0;\n\t        var attsToAdd = Object.keys(data._attachments || {});\n\t\n\t        if (!attsToAdd.length) {\n\t          return callback();\n\t        }\n\t        function checkDone() {\n\t          if (++attsAdded === attsToAdd.length) {\n\t            callback();\n\t          }\n\t          return false; // ack handling a constraint error\n\t        }\n\t        function add(att) {\n\t          var sql = 'INSERT INTO ' + ATTACH_AND_SEQ_STORE$1 +\n\t            ' (digest, seq) VALUES (?,?)';\n\t          var sqlArgs = [data._attachments[att].digest, seq];\n\t          tx.executeSql(sql, sqlArgs, checkDone, checkDone);\n\t          // second callback is for a constaint error, which we ignore\n\t          // because this docid/rev has already been associated with\n\t          // the digest (e.g. when new_edits == false)\n\t        }\n\t        for (var i = 0; i < attsToAdd.length; i++) {\n\t          add(attsToAdd[i]); // do in parallel\n\t        }\n\t      }\n\t\n\t      tx.executeSql(sql, sqlArgs, function (tx, result) {\n\t        var seq = result.insertId;\n\t        insertAttachmentMappings(seq, function () {\n\t          dataWritten(tx, seq);\n\t        });\n\t      }, function () {\n\t        // constraint error, recover by updating instead (see #1638)\n\t        var fetchSql = select('seq', BY_SEQ_STORE$1, null,\n\t          'doc_id=? AND rev=?');\n\t        tx.executeSql(fetchSql, [id, rev], function (tx, res) {\n\t          var seq = res.rows.item(0).seq;\n\t          var sql = 'UPDATE ' + BY_SEQ_STORE$1 +\n\t            ' SET json=?, deleted=? WHERE doc_id=? AND rev=?;';\n\t          var sqlArgs = [json, deletedInt, id, rev];\n\t          tx.executeSql(sql, sqlArgs, function (tx) {\n\t            insertAttachmentMappings(seq, function () {\n\t              dataWritten(tx, seq);\n\t            });\n\t          });\n\t        });\n\t        return false; // ack that we've handled the error\n\t      });\n\t    }\n\t\n\t    function collectResults(attachmentErr) {\n\t      if (!err) {\n\t        if (attachmentErr) {\n\t          err = attachmentErr;\n\t          callback(err);\n\t        } else if (recv === attachments.length) {\n\t          finish();\n\t        }\n\t      }\n\t    }\n\t\n\t    var err = null;\n\t    var recv = 0;\n\t\n\t    docInfo.data._id = docInfo.metadata.id;\n\t    docInfo.data._rev = docInfo.metadata.rev;\n\t    var attachments = Object.keys(docInfo.data._attachments || {});\n\t\n\t\n\t    if (newRevIsDeleted) {\n\t      docInfo.data._deleted = true;\n\t    }\n\t\n\t    function attachmentSaved(err) {\n\t      recv++;\n\t      collectResults(err);\n\t    }\n\t\n\t    attachments.forEach(function (key) {\n\t      var att = docInfo.data._attachments[key];\n\t      if (!att.stub) {\n\t        var data = att.data;\n\t        delete att.data;\n\t        att.revpos = parseInt(winningRev$$1, 10);\n\t        var digest = att.digest;\n\t        saveAttachment(digest, data, attachmentSaved);\n\t      } else {\n\t        recv++;\n\t        collectResults();\n\t      }\n\t    });\n\t\n\t    if (!attachments.length) {\n\t      finish();\n\t    }\n\t\n\t    function dataWritten(tx, seq) {\n\t      var id = docInfo.metadata.id;\n\t\n\t      var revsToCompact = docInfo.stemmedRevs || [];\n\t      if (isUpdate && api.auto_compaction) {\n\t        revsToCompact = compactTree(docInfo.metadata).concat(revsToCompact);\n\t      }\n\t      if (revsToCompact.length) {\n\t        compactRevs$1(revsToCompact, id, tx);\n\t      }\n\t\n\t      docInfo.metadata.seq = seq;\n\t      var rev = docInfo.metadata.rev;\n\t      delete docInfo.metadata.rev;\n\t\n\t      var sql = isUpdate ?\n\t      'UPDATE ' + DOC_STORE$1 +\n\t      ' SET json=?, max_seq=?, winningseq=' +\n\t      '(SELECT seq FROM ' + BY_SEQ_STORE$1 +\n\t      ' WHERE doc_id=' + DOC_STORE$1 + '.id AND rev=?) WHERE id=?'\n\t        : 'INSERT INTO ' + DOC_STORE$1 +\n\t      ' (id, winningseq, max_seq, json) VALUES (?,?,?,?);';\n\t      var metadataStr = safeJsonStringify(docInfo.metadata);\n\t      var params = isUpdate ?\n\t        [metadataStr, seq, winningRev$$1, id] :\n\t        [id, seq, seq, metadataStr];\n\t      tx.executeSql(sql, params, function () {\n\t        results[resultsIdx] = {\n\t          ok: true,\n\t          id: docInfo.metadata.id,\n\t          rev: rev\n\t        };\n\t        fetchedDocs.set(id, docInfo.metadata);\n\t        callback();\n\t      });\n\t    }\n\t  }\n\t\n\t  function websqlProcessDocs() {\n\t    processDocs(dbOpts.revs_limit, docInfos, api, fetchedDocs, tx,\n\t                results, writeDoc, opts);\n\t  }\n\t\n\t  function fetchExistingDocs(callback) {\n\t    if (!docInfos.length) {\n\t      return callback();\n\t    }\n\t\n\t    var numFetched = 0;\n\t\n\t    function checkDone() {\n\t      if (++numFetched === docInfos.length) {\n\t        callback();\n\t      }\n\t    }\n\t\n\t    docInfos.forEach(function (docInfo) {\n\t      if (docInfo._id && isLocalId(docInfo._id)) {\n\t        return checkDone(); // skip local docs\n\t      }\n\t      var id = docInfo.metadata.id;\n\t      tx.executeSql('SELECT json FROM ' + DOC_STORE$1 +\n\t      ' WHERE id = ?', [id], function (tx, result) {\n\t        if (result.rows.length) {\n\t          var metadata = safeJsonParse(result.rows.item(0).json);\n\t          fetchedDocs.set(id, metadata);\n\t        }\n\t        checkDone();\n\t      });\n\t    });\n\t  }\n\t\n\t  function saveAttachment(digest, data, callback) {\n\t    var sql = 'SELECT digest FROM ' + ATTACH_STORE$1 + ' WHERE digest=?';\n\t    tx.executeSql(sql, [digest], function (tx, result) {\n\t      if (result.rows.length) { // attachment already exists\n\t        return callback();\n\t      }\n\t      // we could just insert before selecting and catch the error,\n\t      // but my hunch is that it's cheaper not to serialize the blob\n\t      // from JS to C if we don't have to (TODO: confirm this)\n\t      sql = 'INSERT INTO ' + ATTACH_STORE$1 +\n\t      ' (digest, body, escaped) VALUES (?,?,1)';\n\t      tx.executeSql(sql, [digest, escapeBlob(data)], function () {\n\t        callback();\n\t      }, function () {\n\t        // ignore constaint errors, means it already exists\n\t        callback();\n\t        return false; // ack we handled the error\n\t      });\n\t    });\n\t  }\n\t\n\t  preprocessAttachments(docInfos, 'binary', function (err) {\n\t    if (err) {\n\t      return callback(err);\n\t    }\n\t    db.transaction(function (txn) {\n\t      tx = txn;\n\t      verifyAttachments(function (err) {\n\t        if (err) {\n\t          preconditionErrored = err;\n\t        } else {\n\t          fetchExistingDocs(websqlProcessDocs);\n\t        }\n\t      });\n\t    }, websqlError(callback), complete);\n\t  });\n\t}\n\t\n\tvar cachedDatabases = new ExportedMap();\n\t\n\t// openDatabase passed in through opts (e.g. for node-websql)\n\tfunction openDatabaseWithOpts(opts) {\n\t  return opts.websql(opts.name, opts.version, opts.description, opts.size);\n\t}\n\t\n\tfunction openDBSafely(opts) {\n\t  try {\n\t    return {\n\t      db: openDatabaseWithOpts(opts)\n\t    };\n\t  } catch (err) {\n\t    return {\n\t      error: err\n\t    };\n\t  }\n\t}\n\t\n\tfunction openDB$1(opts) {\n\t  var cachedResult = cachedDatabases.get(opts.name);\n\t  if (!cachedResult) {\n\t    cachedResult = openDBSafely(opts);\n\t    cachedDatabases.set(opts.name, cachedResult);\n\t  }\n\t  return cachedResult;\n\t}\n\t\n\tvar websqlChanges = new Changes();\n\t\n\tfunction fetchAttachmentsIfNecessary$1(doc, opts, api, txn, cb) {\n\t  var attachments = Object.keys(doc._attachments || {});\n\t  if (!attachments.length) {\n\t    return cb && cb();\n\t  }\n\t  var numDone = 0;\n\t\n\t  function checkDone() {\n\t    if (++numDone === attachments.length && cb) {\n\t      cb();\n\t    }\n\t  }\n\t\n\t  function fetchAttachment(doc, att) {\n\t    var attObj = doc._attachments[att];\n\t    var attOpts = {binary: opts.binary, ctx: txn};\n\t    api._getAttachment(doc._id, att, attObj, attOpts, function (_, data) {\n\t      doc._attachments[att] = assign$1(\n\t        pick(attObj, ['digest', 'content_type']),\n\t        { data: data }\n\t      );\n\t      checkDone();\n\t    });\n\t  }\n\t\n\t  attachments.forEach(function (att) {\n\t    if (opts.attachments && opts.include_docs) {\n\t      fetchAttachment(doc, att);\n\t    } else {\n\t      doc._attachments[att].stub = true;\n\t      checkDone();\n\t    }\n\t  });\n\t}\n\t\n\tvar POUCH_VERSION = 1;\n\t\n\t// these indexes cover the ground for most allDocs queries\n\tvar BY_SEQ_STORE_DELETED_INDEX_SQL =\n\t  'CREATE INDEX IF NOT EXISTS \\'by-seq-deleted-idx\\' ON ' +\n\t  BY_SEQ_STORE$1 + ' (seq, deleted)';\n\tvar BY_SEQ_STORE_DOC_ID_REV_INDEX_SQL =\n\t  'CREATE UNIQUE INDEX IF NOT EXISTS \\'by-seq-doc-id-rev\\' ON ' +\n\t    BY_SEQ_STORE$1 + ' (doc_id, rev)';\n\tvar DOC_STORE_WINNINGSEQ_INDEX_SQL =\n\t  'CREATE INDEX IF NOT EXISTS \\'doc-winningseq-idx\\' ON ' +\n\t  DOC_STORE$1 + ' (winningseq)';\n\tvar ATTACH_AND_SEQ_STORE_SEQ_INDEX_SQL =\n\t  'CREATE INDEX IF NOT EXISTS \\'attach-seq-seq-idx\\' ON ' +\n\t    ATTACH_AND_SEQ_STORE$1 + ' (seq)';\n\tvar ATTACH_AND_SEQ_STORE_ATTACH_INDEX_SQL =\n\t  'CREATE UNIQUE INDEX IF NOT EXISTS \\'attach-seq-digest-idx\\' ON ' +\n\t    ATTACH_AND_SEQ_STORE$1 + ' (digest, seq)';\n\t\n\tvar DOC_STORE_AND_BY_SEQ_JOINER = BY_SEQ_STORE$1 +\n\t  '.seq = ' + DOC_STORE$1 + '.winningseq';\n\t\n\tvar SELECT_DOCS = BY_SEQ_STORE$1 + '.seq AS seq, ' +\n\t  BY_SEQ_STORE$1 + '.deleted AS deleted, ' +\n\t  BY_SEQ_STORE$1 + '.json AS data, ' +\n\t  BY_SEQ_STORE$1 + '.rev AS rev, ' +\n\t  DOC_STORE$1 + '.json AS metadata';\n\t\n\tfunction WebSqlPouch$1(opts, callback) {\n\t  var api = this;\n\t  var instanceId = null;\n\t  var size = getSize(opts);\n\t  var idRequests = [];\n\t  var encoding;\n\t\n\t  api._name = opts.name;\n\t\n\t  // extend the options here, because sqlite plugin has a ton of options\n\t  // and they are constantly changing, so it's more prudent to allow anything\n\t  var websqlOpts = assign$1({}, opts, {\n\t    version: POUCH_VERSION,\n\t    description: opts.name,\n\t    size: size\n\t  });\n\t  var openDBResult = openDB$1(websqlOpts);\n\t  if (openDBResult.error) {\n\t    return websqlError(callback)(openDBResult.error);\n\t  }\n\t  var db = openDBResult.db;\n\t  if (typeof db.readTransaction !== 'function') {\n\t    // doesn't exist in sqlite plugin\n\t    db.readTransaction = db.transaction;\n\t  }\n\t\n\t  function dbCreated() {\n\t    // note the db name in case the browser upgrades to idb\n\t    if (hasLocalStorage()) {\n\t      window.localStorage['_pouch__websqldb_' + api._name] = true;\n\t    }\n\t    callback(null, api);\n\t  }\n\t\n\t  // In this migration, we added the 'deleted' and 'local' columns to the\n\t  // by-seq and doc store tables.\n\t  // To preserve existing user data, we re-process all the existing JSON\n\t  // and add these values.\n\t  // Called migration2 because it corresponds to adapter version (db_version) #2\n\t  function runMigration2(tx, callback) {\n\t    // index used for the join in the allDocs query\n\t    tx.executeSql(DOC_STORE_WINNINGSEQ_INDEX_SQL);\n\t\n\t    tx.executeSql('ALTER TABLE ' + BY_SEQ_STORE$1 +\n\t      ' ADD COLUMN deleted TINYINT(1) DEFAULT 0', [], function () {\n\t      tx.executeSql(BY_SEQ_STORE_DELETED_INDEX_SQL);\n\t      tx.executeSql('ALTER TABLE ' + DOC_STORE$1 +\n\t        ' ADD COLUMN local TINYINT(1) DEFAULT 0', [], function () {\n\t        tx.executeSql('CREATE INDEX IF NOT EXISTS \\'doc-store-local-idx\\' ON ' +\n\t          DOC_STORE$1 + ' (local, id)');\n\t\n\t        var sql = 'SELECT ' + DOC_STORE$1 + '.winningseq AS seq, ' + DOC_STORE$1 +\n\t          '.json AS metadata FROM ' + BY_SEQ_STORE$1 + ' JOIN ' + DOC_STORE$1 +\n\t          ' ON ' + BY_SEQ_STORE$1 + '.seq = ' + DOC_STORE$1 + '.winningseq';\n\t\n\t        tx.executeSql(sql, [], function (tx, result) {\n\t\n\t          var deleted = [];\n\t          var local = [];\n\t\n\t          for (var i = 0; i < result.rows.length; i++) {\n\t            var item = result.rows.item(i);\n\t            var seq = item.seq;\n\t            var metadata = JSON.parse(item.metadata);\n\t            if (isDeleted(metadata)) {\n\t              deleted.push(seq);\n\t            }\n\t            if (isLocalId(metadata.id)) {\n\t              local.push(metadata.id);\n\t            }\n\t          }\n\t          tx.executeSql('UPDATE ' + DOC_STORE$1 + 'SET local = 1 WHERE id IN ' +\n\t            qMarks(local.length), local, function () {\n\t            tx.executeSql('UPDATE ' + BY_SEQ_STORE$1 +\n\t              ' SET deleted = 1 WHERE seq IN ' +\n\t              qMarks(deleted.length), deleted, callback);\n\t          });\n\t        });\n\t      });\n\t    });\n\t  }\n\t\n\t  // in this migration, we make all the local docs unversioned\n\t  function runMigration3(tx, callback) {\n\t    var local = 'CREATE TABLE IF NOT EXISTS ' + LOCAL_STORE$1 +\n\t      ' (id UNIQUE, rev, json)';\n\t    tx.executeSql(local, [], function () {\n\t      var sql = 'SELECT ' + DOC_STORE$1 + '.id AS id, ' +\n\t        BY_SEQ_STORE$1 + '.json AS data ' +\n\t        'FROM ' + BY_SEQ_STORE$1 + ' JOIN ' +\n\t        DOC_STORE$1 + ' ON ' + BY_SEQ_STORE$1 + '.seq = ' +\n\t        DOC_STORE$1 + '.winningseq WHERE local = 1';\n\t      tx.executeSql(sql, [], function (tx, res) {\n\t        var rows = [];\n\t        for (var i = 0; i < res.rows.length; i++) {\n\t          rows.push(res.rows.item(i));\n\t        }\n\t        function doNext() {\n\t          if (!rows.length) {\n\t            return callback(tx);\n\t          }\n\t          var row = rows.shift();\n\t          var rev = JSON.parse(row.data)._rev;\n\t          tx.executeSql('INSERT INTO ' + LOCAL_STORE$1 +\n\t              ' (id, rev, json) VALUES (?,?,?)',\n\t              [row.id, rev, row.data], function (tx) {\n\t            tx.executeSql('DELETE FROM ' + DOC_STORE$1 + ' WHERE id=?',\n\t                [row.id], function (tx) {\n\t              tx.executeSql('DELETE FROM ' + BY_SEQ_STORE$1 + ' WHERE seq=?',\n\t                  [row.seq], function () {\n\t                doNext();\n\t              });\n\t            });\n\t          });\n\t        }\n\t        doNext();\n\t      });\n\t    });\n\t  }\n\t\n\t  // in this migration, we remove doc_id_rev and just use rev\n\t  function runMigration4(tx, callback) {\n\t\n\t    function updateRows(rows) {\n\t      function doNext() {\n\t        if (!rows.length) {\n\t          return callback(tx);\n\t        }\n\t        var row = rows.shift();\n\t        var doc_id_rev = parseHexString(row.hex, encoding);\n\t        var idx = doc_id_rev.lastIndexOf('::');\n\t        var doc_id = doc_id_rev.substring(0, idx);\n\t        var rev = doc_id_rev.substring(idx + 2);\n\t        var sql = 'UPDATE ' + BY_SEQ_STORE$1 +\n\t          ' SET doc_id=?, rev=? WHERE doc_id_rev=?';\n\t        tx.executeSql(sql, [doc_id, rev, doc_id_rev], function () {\n\t          doNext();\n\t        });\n\t      }\n\t      doNext();\n\t    }\n\t\n\t    var sql = 'ALTER TABLE ' + BY_SEQ_STORE$1 + ' ADD COLUMN doc_id';\n\t    tx.executeSql(sql, [], function (tx) {\n\t      var sql = 'ALTER TABLE ' + BY_SEQ_STORE$1 + ' ADD COLUMN rev';\n\t      tx.executeSql(sql, [], function (tx) {\n\t        tx.executeSql(BY_SEQ_STORE_DOC_ID_REV_INDEX_SQL, [], function (tx) {\n\t          var sql = 'SELECT hex(doc_id_rev) as hex FROM ' + BY_SEQ_STORE$1;\n\t          tx.executeSql(sql, [], function (tx, res) {\n\t            var rows = [];\n\t            for (var i = 0; i < res.rows.length; i++) {\n\t              rows.push(res.rows.item(i));\n\t            }\n\t            updateRows(rows);\n\t          });\n\t        });\n\t      });\n\t    });\n\t  }\n\t\n\t  // in this migration, we add the attach_and_seq table\n\t  // for issue #2818\n\t  function runMigration5(tx, callback) {\n\t\n\t    function migrateAttsAndSeqs(tx) {\n\t      // need to actually populate the table. this is the expensive part,\n\t      // so as an optimization, check first that this database even\n\t      // contains attachments\n\t      var sql = 'SELECT COUNT(*) AS cnt FROM ' + ATTACH_STORE$1;\n\t      tx.executeSql(sql, [], function (tx, res) {\n\t        var count = res.rows.item(0).cnt;\n\t        if (!count) {\n\t          return callback(tx);\n\t        }\n\t\n\t        var offset = 0;\n\t        var pageSize = 10;\n\t        function nextPage() {\n\t          var sql = select(\n\t            SELECT_DOCS + ', ' + DOC_STORE$1 + '.id AS id',\n\t            [DOC_STORE$1, BY_SEQ_STORE$1],\n\t            DOC_STORE_AND_BY_SEQ_JOINER,\n\t            null,\n\t            DOC_STORE$1 + '.id '\n\t          );\n\t          sql += ' LIMIT ' + pageSize + ' OFFSET ' + offset;\n\t          offset += pageSize;\n\t          tx.executeSql(sql, [], function (tx, res) {\n\t            if (!res.rows.length) {\n\t              return callback(tx);\n\t            }\n\t            var digestSeqs = {};\n\t            function addDigestSeq(digest, seq) {\n\t              // uniq digest/seq pairs, just in case there are dups\n\t              var seqs = digestSeqs[digest] = (digestSeqs[digest] || []);\n\t              if (seqs.indexOf(seq) === -1) {\n\t                seqs.push(seq);\n\t              }\n\t            }\n\t            for (var i = 0; i < res.rows.length; i++) {\n\t              var row = res.rows.item(i);\n\t              var doc = unstringifyDoc(row.data, row.id, row.rev);\n\t              var atts = Object.keys(doc._attachments || {});\n\t              for (var j = 0; j < atts.length; j++) {\n\t                var att = doc._attachments[atts[j]];\n\t                addDigestSeq(att.digest, row.seq);\n\t              }\n\t            }\n\t            var digestSeqPairs = [];\n\t            Object.keys(digestSeqs).forEach(function (digest) {\n\t              var seqs = digestSeqs[digest];\n\t              seqs.forEach(function (seq) {\n\t                digestSeqPairs.push([digest, seq]);\n\t              });\n\t            });\n\t            if (!digestSeqPairs.length) {\n\t              return nextPage();\n\t            }\n\t            var numDone = 0;\n\t            digestSeqPairs.forEach(function (pair) {\n\t              var sql = 'INSERT INTO ' + ATTACH_AND_SEQ_STORE$1 +\n\t                ' (digest, seq) VALUES (?,?)';\n\t              tx.executeSql(sql, pair, function () {\n\t                if (++numDone === digestSeqPairs.length) {\n\t                  nextPage();\n\t                }\n\t              });\n\t            });\n\t          });\n\t        }\n\t        nextPage();\n\t      });\n\t    }\n\t\n\t    var attachAndRev = 'CREATE TABLE IF NOT EXISTS ' +\n\t      ATTACH_AND_SEQ_STORE$1 + ' (digest, seq INTEGER)';\n\t    tx.executeSql(attachAndRev, [], function (tx) {\n\t      tx.executeSql(\n\t        ATTACH_AND_SEQ_STORE_ATTACH_INDEX_SQL, [], function (tx) {\n\t          tx.executeSql(\n\t            ATTACH_AND_SEQ_STORE_SEQ_INDEX_SQL, [],\n\t            migrateAttsAndSeqs);\n\t        });\n\t    });\n\t  }\n\t\n\t  // in this migration, we use escapeBlob() and unescapeBlob()\n\t  // instead of reading out the binary as HEX, which is slow\n\t  function runMigration6(tx, callback) {\n\t    var sql = 'ALTER TABLE ' + ATTACH_STORE$1 +\n\t      ' ADD COLUMN escaped TINYINT(1) DEFAULT 0';\n\t    tx.executeSql(sql, [], callback);\n\t  }\n\t\n\t  // issue #3136, in this migration we need a \"latest seq\" as well\n\t  // as the \"winning seq\" in the doc store\n\t  function runMigration7(tx, callback) {\n\t    var sql = 'ALTER TABLE ' + DOC_STORE$1 +\n\t      ' ADD COLUMN max_seq INTEGER';\n\t    tx.executeSql(sql, [], function (tx) {\n\t      var sql = 'UPDATE ' + DOC_STORE$1 + ' SET max_seq=(SELECT MAX(seq) FROM ' +\n\t        BY_SEQ_STORE$1 + ' WHERE doc_id=id)';\n\t      tx.executeSql(sql, [], function (tx) {\n\t        // add unique index after filling, else we'll get a constraint\n\t        // error when we do the ALTER TABLE\n\t        var sql =\n\t          'CREATE UNIQUE INDEX IF NOT EXISTS \\'doc-max-seq-idx\\' ON ' +\n\t          DOC_STORE$1 + ' (max_seq)';\n\t        tx.executeSql(sql, [], callback);\n\t      });\n\t    });\n\t  }\n\t\n\t  function checkEncoding(tx, cb) {\n\t    // UTF-8 on chrome/android, UTF-16 on safari < 7.1\n\t    tx.executeSql('SELECT HEX(\"a\") AS hex', [], function (tx, res) {\n\t        var hex = res.rows.item(0).hex;\n\t        encoding = hex.length === 2 ? 'UTF-8' : 'UTF-16';\n\t        cb();\n\t      }\n\t    );\n\t  }\n\t\n\t  function onGetInstanceId() {\n\t    while (idRequests.length > 0) {\n\t      var idCallback = idRequests.pop();\n\t      idCallback(null, instanceId);\n\t    }\n\t  }\n\t\n\t  function onGetVersion(tx, dbVersion) {\n\t    if (dbVersion === 0) {\n\t      // initial schema\n\t\n\t      var meta = 'CREATE TABLE IF NOT EXISTS ' + META_STORE$1 +\n\t        ' (dbid, db_version INTEGER)';\n\t      var attach = 'CREATE TABLE IF NOT EXISTS ' + ATTACH_STORE$1 +\n\t        ' (digest UNIQUE, escaped TINYINT(1), body BLOB)';\n\t      var attachAndRev = 'CREATE TABLE IF NOT EXISTS ' +\n\t        ATTACH_AND_SEQ_STORE$1 + ' (digest, seq INTEGER)';\n\t      // TODO: migrate winningseq to INTEGER\n\t      var doc = 'CREATE TABLE IF NOT EXISTS ' + DOC_STORE$1 +\n\t        ' (id unique, json, winningseq, max_seq INTEGER UNIQUE)';\n\t      var seq = 'CREATE TABLE IF NOT EXISTS ' + BY_SEQ_STORE$1 +\n\t        ' (seq INTEGER NOT NULL PRIMARY KEY AUTOINCREMENT, ' +\n\t        'json, deleted TINYINT(1), doc_id, rev)';\n\t      var local = 'CREATE TABLE IF NOT EXISTS ' + LOCAL_STORE$1 +\n\t        ' (id UNIQUE, rev, json)';\n\t\n\t      // creates\n\t      tx.executeSql(attach);\n\t      tx.executeSql(local);\n\t      tx.executeSql(attachAndRev, [], function () {\n\t        tx.executeSql(ATTACH_AND_SEQ_STORE_SEQ_INDEX_SQL);\n\t        tx.executeSql(ATTACH_AND_SEQ_STORE_ATTACH_INDEX_SQL);\n\t      });\n\t      tx.executeSql(doc, [], function () {\n\t        tx.executeSql(DOC_STORE_WINNINGSEQ_INDEX_SQL);\n\t        tx.executeSql(seq, [], function () {\n\t          tx.executeSql(BY_SEQ_STORE_DELETED_INDEX_SQL);\n\t          tx.executeSql(BY_SEQ_STORE_DOC_ID_REV_INDEX_SQL);\n\t          tx.executeSql(meta, [], function () {\n\t            // mark the db version, and new dbid\n\t            var initSeq = 'INSERT INTO ' + META_STORE$1 +\n\t              ' (db_version, dbid) VALUES (?,?)';\n\t            instanceId = uuid();\n\t            var initSeqArgs = [ADAPTER_VERSION$1, instanceId];\n\t            tx.executeSql(initSeq, initSeqArgs, function () {\n\t              onGetInstanceId();\n\t            });\n\t          });\n\t        });\n\t      });\n\t    } else { // version > 0\n\t\n\t      var setupDone = function () {\n\t        var migrated = dbVersion < ADAPTER_VERSION$1;\n\t        if (migrated) {\n\t          // update the db version within this transaction\n\t          tx.executeSql('UPDATE ' + META_STORE$1 + ' SET db_version = ' +\n\t            ADAPTER_VERSION$1);\n\t        }\n\t        // notify db.id() callers\n\t        var sql = 'SELECT dbid FROM ' + META_STORE$1;\n\t        tx.executeSql(sql, [], function (tx, result) {\n\t          instanceId = result.rows.item(0).dbid;\n\t          onGetInstanceId();\n\t        });\n\t      };\n\t\n\t      // would love to use promises here, but then websql\n\t      // ends the transaction early\n\t      var tasks = [\n\t        runMigration2,\n\t        runMigration3,\n\t        runMigration4,\n\t        runMigration5,\n\t        runMigration6,\n\t        runMigration7,\n\t        setupDone\n\t      ];\n\t\n\t      // run each migration sequentially\n\t      var i = dbVersion;\n\t      var nextMigration = function (tx) {\n\t        tasks[i - 1](tx, nextMigration);\n\t        i++;\n\t      };\n\t      nextMigration(tx);\n\t    }\n\t  }\n\t\n\t  function setup() {\n\t    db.transaction(function (tx) {\n\t      // first check the encoding\n\t      checkEncoding(tx, function () {\n\t        // then get the version\n\t        fetchVersion(tx);\n\t      });\n\t    }, websqlError(callback), dbCreated);\n\t  }\n\t\n\t  function fetchVersion(tx) {\n\t    var sql = 'SELECT sql FROM sqlite_master WHERE tbl_name = ' + META_STORE$1;\n\t    tx.executeSql(sql, [], function (tx, result) {\n\t      if (!result.rows.length) {\n\t        // database hasn't even been created yet (version 0)\n\t        onGetVersion(tx, 0);\n\t      } else if (!/db_version/.test(result.rows.item(0).sql)) {\n\t        // table was created, but without the new db_version column,\n\t        // so add it.\n\t        tx.executeSql('ALTER TABLE ' + META_STORE$1 +\n\t          ' ADD COLUMN db_version INTEGER', [], function () {\n\t          // before version 2, this column didn't even exist\n\t          onGetVersion(tx, 1);\n\t        });\n\t      } else { // column exists, we can safely get it\n\t        tx.executeSql('SELECT db_version FROM ' + META_STORE$1,\n\t          [], function (tx, result) {\n\t          var dbVersion = result.rows.item(0).db_version;\n\t          onGetVersion(tx, dbVersion);\n\t        });\n\t      }\n\t    });\n\t  }\n\t\n\t  setup();\n\t\n\t  function getMaxSeq(tx, callback) {\n\t    var sql = 'SELECT MAX(seq) AS seq FROM ' + BY_SEQ_STORE$1;\n\t    tx.executeSql(sql, [], function (tx, res) {\n\t      var updateSeq = res.rows.item(0).seq || 0;\n\t      callback(updateSeq);\n\t    });\n\t  }\n\t\n\t  function countDocs(tx, callback) {\n\t    // count the total rows\n\t    var sql = select(\n\t      'COUNT(' + DOC_STORE$1 + '.id) AS \\'num\\'',\n\t      [DOC_STORE$1, BY_SEQ_STORE$1],\n\t      DOC_STORE_AND_BY_SEQ_JOINER,\n\t      BY_SEQ_STORE$1 + '.deleted=0');\n\t\n\t    tx.executeSql(sql, [], function (tx, result) {\n\t      callback(result.rows.item(0).num);\n\t    });\n\t  }\n\t\n\t  api.type = function () {\n\t    return 'websql';\n\t  };\n\t\n\t  api._id = toPromise(function (callback) {\n\t    callback(null, instanceId);\n\t  });\n\t\n\t  api._info = function (callback) {\n\t    var seq;\n\t    var docCount;\n\t    db.readTransaction(function (tx) {\n\t      getMaxSeq(tx, function (theSeq) {\n\t        seq = theSeq;\n\t      });\n\t      countDocs(tx, function (theDocCount) {\n\t        docCount = theDocCount;\n\t      });\n\t    }, websqlError(callback), function () {\n\t      callback(null, {\n\t        doc_count: docCount,\n\t        update_seq: seq,\n\t        websql_encoding: encoding\n\t      });\n\t    });\n\t  };\n\t\n\t  api._bulkDocs = function (req, reqOpts, callback) {\n\t    websqlBulkDocs(opts, req, reqOpts, api, db, websqlChanges, callback);\n\t  };\n\t\n\t  function latest$$1(tx, id, rev, callback, finish) {\n\t    var sql = select(\n\t        SELECT_DOCS,\n\t        [DOC_STORE$1, BY_SEQ_STORE$1],\n\t        DOC_STORE_AND_BY_SEQ_JOINER,\n\t        DOC_STORE$1 + '.id=?');\n\t    var sqlArgs = [id];\n\t\n\t    tx.executeSql(sql, sqlArgs, function (a, results) {\n\t      if (!results.rows.length) {\n\t        var err = createError(MISSING_DOC, 'missing');\n\t        return finish(err);\n\t      }\n\t      var item = results.rows.item(0);\n\t      var metadata = safeJsonParse(item.metadata);\n\t      callback(latest(rev, metadata));\n\t    });\n\t  }\n\t\n\t  api._get = function (id, opts, callback) {\n\t    var doc;\n\t    var metadata;\n\t    var tx = opts.ctx;\n\t    if (!tx) {\n\t      return db.readTransaction(function (txn) {\n\t        api._get(id, assign$1({ctx: txn}, opts), callback);\n\t      });\n\t    }\n\t\n\t    function finish(err) {\n\t      callback(err, {doc: doc, metadata: metadata, ctx: tx});\n\t    }\n\t\n\t    var sql;\n\t    var sqlArgs;\n\t\n\t    if(!opts.rev) {\n\t      sql = select(\n\t        SELECT_DOCS,\n\t        [DOC_STORE$1, BY_SEQ_STORE$1],\n\t        DOC_STORE_AND_BY_SEQ_JOINER,\n\t        DOC_STORE$1 + '.id=?');\n\t      sqlArgs = [id];\n\t    } else if (opts.latest) {\n\t      latest$$1(tx, id, opts.rev, function (latestRev) {\n\t        opts.latest = false;\n\t        opts.rev = latestRev;\n\t        api._get(id, opts, callback);\n\t      }, finish);\n\t      return;\n\t    } else {\n\t      sql = select(\n\t        SELECT_DOCS,\n\t        [DOC_STORE$1, BY_SEQ_STORE$1],\n\t        DOC_STORE$1 + '.id=' + BY_SEQ_STORE$1 + '.doc_id',\n\t        [BY_SEQ_STORE$1 + '.doc_id=?', BY_SEQ_STORE$1 + '.rev=?']);\n\t      sqlArgs = [id, opts.rev];\n\t    }\n\t\n\t    tx.executeSql(sql, sqlArgs, function (a, results) {\n\t      if (!results.rows.length) {\n\t        var missingErr = createError(MISSING_DOC, 'missing');\n\t        return finish(missingErr);\n\t      }\n\t      var item = results.rows.item(0);\n\t      metadata = safeJsonParse(item.metadata);\n\t      if (item.deleted && !opts.rev) {\n\t        var deletedErr = createError(MISSING_DOC, 'deleted');\n\t        return finish(deletedErr);\n\t      }\n\t      doc = unstringifyDoc(item.data, metadata.id, item.rev);\n\t      finish();\n\t    });\n\t  };\n\t\n\t  api._allDocs = function (opts, callback) {\n\t    var results = [];\n\t    var totalRows;\n\t\n\t    var start = 'startkey' in opts ? opts.startkey : false;\n\t    var end = 'endkey' in opts ? opts.endkey : false;\n\t    var key = 'key' in opts ? opts.key : false;\n\t    var descending = 'descending' in opts ? opts.descending : false;\n\t    var limit = 'limit' in opts ? opts.limit : -1;\n\t    var offset = 'skip' in opts ? opts.skip : 0;\n\t    var inclusiveEnd = opts.inclusive_end !== false;\n\t\n\t    var sqlArgs = [];\n\t    var criteria = [];\n\t\n\t    if (key !== false) {\n\t      criteria.push(DOC_STORE$1 + '.id = ?');\n\t      sqlArgs.push(key);\n\t    } else if (start !== false || end !== false) {\n\t      if (start !== false) {\n\t        criteria.push(DOC_STORE$1 + '.id ' + (descending ? '<=' : '>=') + ' ?');\n\t        sqlArgs.push(start);\n\t      }\n\t      if (end !== false) {\n\t        var comparator = descending ? '>' : '<';\n\t        if (inclusiveEnd) {\n\t          comparator += '=';\n\t        }\n\t        criteria.push(DOC_STORE$1 + '.id ' + comparator + ' ?');\n\t        sqlArgs.push(end);\n\t      }\n\t      if (key !== false) {\n\t        criteria.push(DOC_STORE$1 + '.id = ?');\n\t        sqlArgs.push(key);\n\t      }\n\t    }\n\t\n\t    if (opts.deleted !== 'ok') {\n\t      // report deleted if keys are specified\n\t      criteria.push(BY_SEQ_STORE$1 + '.deleted = 0');\n\t    }\n\t\n\t    db.readTransaction(function (tx) {\n\t      // count the docs in parallel to other operations\n\t      countDocs(tx, function (docCount) {\n\t        totalRows = docCount;\n\t      });\n\t\n\t      if (limit === 0) {\n\t        return;\n\t      }\n\t\n\t      // do a single query to fetch the documents\n\t      var sql = select(\n\t        SELECT_DOCS,\n\t        [DOC_STORE$1, BY_SEQ_STORE$1],\n\t        DOC_STORE_AND_BY_SEQ_JOINER,\n\t        criteria,\n\t        DOC_STORE$1 + '.id ' + (descending ? 'DESC' : 'ASC')\n\t        );\n\t      sql += ' LIMIT ' + limit + ' OFFSET ' + offset;\n\t\n\t      tx.executeSql(sql, sqlArgs, function (tx, result) {\n\t        for (var i = 0, l = result.rows.length; i < l; i++) {\n\t          var item = result.rows.item(i);\n\t          var metadata = safeJsonParse(item.metadata);\n\t          var id = metadata.id;\n\t          var data = unstringifyDoc(item.data, id, item.rev);\n\t          var winningRev$$1 = data._rev;\n\t          var doc = {\n\t            id: id,\n\t            key: id,\n\t            value: {rev: winningRev$$1}\n\t          };\n\t          if (opts.include_docs) {\n\t            doc.doc = data;\n\t            doc.doc._rev = winningRev$$1;\n\t            if (opts.conflicts) {\n\t              var conflicts = collectConflicts(metadata);\n\t              if (conflicts.length) {\n\t                doc.doc._conflicts = conflicts;\n\t              }\n\t            }\n\t            fetchAttachmentsIfNecessary$1(doc.doc, opts, api, tx);\n\t          }\n\t          if (item.deleted) {\n\t            if (opts.deleted === 'ok') {\n\t              doc.value.deleted = true;\n\t              doc.doc = null;\n\t            } else {\n\t              continue;\n\t            }\n\t          }\n\t          results.push(doc);\n\t        }\n\t      });\n\t    }, websqlError(callback), function () {\n\t      callback(null, {\n\t        total_rows: totalRows,\n\t        offset: opts.skip,\n\t        rows: results\n\t      });\n\t    });\n\t  };\n\t\n\t  api._changes = function (opts) {\n\t    opts = clone(opts);\n\t\n\t    if (opts.continuous) {\n\t      var id = api._name + ':' + uuid();\n\t      websqlChanges.addListener(api._name, id, api, opts);\n\t      websqlChanges.notify(api._name);\n\t      return {\n\t        cancel: function () {\n\t          websqlChanges.removeListener(api._name, id);\n\t        }\n\t      };\n\t    }\n\t\n\t    var descending = opts.descending;\n\t\n\t    // Ignore the `since` parameter when `descending` is true\n\t    opts.since = opts.since && !descending ? opts.since : 0;\n\t\n\t    var limit = 'limit' in opts ? opts.limit : -1;\n\t    if (limit === 0) {\n\t      limit = 1; // per CouchDB _changes spec\n\t    }\n\t\n\t    var returnDocs;\n\t    if ('return_docs' in opts) {\n\t      returnDocs = opts.return_docs;\n\t    } else if ('returnDocs' in opts) {\n\t      // TODO: Remove 'returnDocs' in favor of 'return_docs' in a future release\n\t      returnDocs = opts.returnDocs;\n\t    } else {\n\t      returnDocs = true;\n\t    }\n\t    var results = [];\n\t    var numResults = 0;\n\t\n\t    function fetchChanges() {\n\t\n\t      var selectStmt =\n\t        DOC_STORE$1 + '.json AS metadata, ' +\n\t        DOC_STORE$1 + '.max_seq AS maxSeq, ' +\n\t        BY_SEQ_STORE$1 + '.json AS winningDoc, ' +\n\t        BY_SEQ_STORE$1 + '.rev AS winningRev ';\n\t\n\t      var from = DOC_STORE$1 + ' JOIN ' + BY_SEQ_STORE$1;\n\t\n\t      var joiner = DOC_STORE$1 + '.id=' + BY_SEQ_STORE$1 + '.doc_id' +\n\t        ' AND ' + DOC_STORE$1 + '.winningseq=' + BY_SEQ_STORE$1 + '.seq';\n\t\n\t      var criteria = ['maxSeq > ?'];\n\t      var sqlArgs = [opts.since];\n\t\n\t      if (opts.doc_ids) {\n\t        criteria.push(DOC_STORE$1 + '.id IN ' + qMarks(opts.doc_ids.length));\n\t        sqlArgs = sqlArgs.concat(opts.doc_ids);\n\t      }\n\t\n\t      var orderBy = 'maxSeq ' + (descending ? 'DESC' : 'ASC');\n\t\n\t      var sql = select(selectStmt, from, joiner, criteria, orderBy);\n\t\n\t      var filter = filterChange(opts);\n\t      if (!opts.view && !opts.filter) {\n\t        // we can just limit in the query\n\t        sql += ' LIMIT ' + limit;\n\t      }\n\t\n\t      var lastSeq = opts.since || 0;\n\t      db.readTransaction(function (tx) {\n\t        tx.executeSql(sql, sqlArgs, function (tx, result) {\n\t          function reportChange(change) {\n\t            return function () {\n\t              opts.onChange(change);\n\t            };\n\t          }\n\t          for (var i = 0, l = result.rows.length; i < l; i++) {\n\t            var item = result.rows.item(i);\n\t            var metadata = safeJsonParse(item.metadata);\n\t            lastSeq = item.maxSeq;\n\t\n\t            var doc = unstringifyDoc(item.winningDoc, metadata.id,\n\t              item.winningRev);\n\t            var change = opts.processChange(doc, metadata, opts);\n\t            change.seq = item.maxSeq;\n\t\n\t            var filtered = filter(change);\n\t            if (typeof filtered === 'object') {\n\t              return opts.complete(filtered);\n\t            }\n\t\n\t            if (filtered) {\n\t              numResults++;\n\t              if (returnDocs) {\n\t                results.push(change);\n\t              }\n\t              // process the attachment immediately\n\t              // for the benefit of live listeners\n\t              if (opts.attachments && opts.include_docs) {\n\t                fetchAttachmentsIfNecessary$1(doc, opts, api, tx,\n\t                  reportChange(change));\n\t              } else {\n\t                reportChange(change)();\n\t              }\n\t            }\n\t            if (numResults === limit) {\n\t              break;\n\t            }\n\t          }\n\t        });\n\t      }, websqlError(opts.complete), function () {\n\t        if (!opts.continuous) {\n\t          opts.complete(null, {\n\t            results: results,\n\t            last_seq: lastSeq\n\t          });\n\t        }\n\t      });\n\t    }\n\t\n\t    fetchChanges();\n\t  };\n\t\n\t  api._close = function (callback) {\n\t    //WebSQL databases do not need to be closed\n\t    callback();\n\t  };\n\t\n\t  api._getAttachment = function (docId, attachId, attachment, opts, callback) {\n\t    var res;\n\t    var tx = opts.ctx;\n\t    var digest = attachment.digest;\n\t    var type = attachment.content_type;\n\t    var sql = 'SELECT escaped, ' +\n\t      'CASE WHEN escaped = 1 THEN body ELSE HEX(body) END AS body FROM ' +\n\t      ATTACH_STORE$1 + ' WHERE digest=?';\n\t    tx.executeSql(sql, [digest], function (tx, result) {\n\t      // websql has a bug where \\u0000 causes early truncation in strings\n\t      // and blobs. to work around this, we used to use the hex() function,\n\t      // but that's not performant. after migration 6, we remove \\u0000\n\t      // and add it back in afterwards\n\t      var item = result.rows.item(0);\n\t      var data = item.escaped ? unescapeBlob(item.body) :\n\t        parseHexString(item.body, encoding);\n\t      if (opts.binary) {\n\t        res = binStringToBluffer(data, type);\n\t      } else {\n\t        res = thisBtoa(data);\n\t      }\n\t      callback(null, res);\n\t    });\n\t  };\n\t\n\t  api._getRevisionTree = function (docId, callback) {\n\t    db.readTransaction(function (tx) {\n\t      var sql = 'SELECT json AS metadata FROM ' + DOC_STORE$1 + ' WHERE id = ?';\n\t      tx.executeSql(sql, [docId], function (tx, result) {\n\t        if (!result.rows.length) {\n\t          callback(createError(MISSING_DOC));\n\t        } else {\n\t          var data = safeJsonParse(result.rows.item(0).metadata);\n\t          callback(null, data.rev_tree);\n\t        }\n\t      });\n\t    });\n\t  };\n\t\n\t  api._doCompaction = function (docId, revs, callback) {\n\t    if (!revs.length) {\n\t      return callback();\n\t    }\n\t    db.transaction(function (tx) {\n\t\n\t      // update doc store\n\t      var sql = 'SELECT json AS metadata FROM ' + DOC_STORE$1 + ' WHERE id = ?';\n\t      tx.executeSql(sql, [docId], function (tx, result) {\n\t        var metadata = safeJsonParse(result.rows.item(0).metadata);\n\t        traverseRevTree(metadata.rev_tree, function (isLeaf, pos,\n\t                                                           revHash, ctx, opts) {\n\t          var rev = pos + '-' + revHash;\n\t          if (revs.indexOf(rev) !== -1) {\n\t            opts.status = 'missing';\n\t          }\n\t        });\n\t\n\t        var sql = 'UPDATE ' + DOC_STORE$1 + ' SET json = ? WHERE id = ?';\n\t        tx.executeSql(sql, [safeJsonStringify(metadata), docId]);\n\t      });\n\t\n\t      compactRevs$1(revs, docId, tx);\n\t    }, websqlError(callback), function () {\n\t      callback();\n\t    });\n\t  };\n\t\n\t  api._getLocal = function (id, callback) {\n\t    db.readTransaction(function (tx) {\n\t      var sql = 'SELECT json, rev FROM ' + LOCAL_STORE$1 + ' WHERE id=?';\n\t      tx.executeSql(sql, [id], function (tx, res) {\n\t        if (res.rows.length) {\n\t          var item = res.rows.item(0);\n\t          var doc = unstringifyDoc(item.json, id, item.rev);\n\t          callback(null, doc);\n\t        } else {\n\t          callback(createError(MISSING_DOC));\n\t        }\n\t      });\n\t    });\n\t  };\n\t\n\t  api._putLocal = function (doc, opts, callback) {\n\t    if (typeof opts === 'function') {\n\t      callback = opts;\n\t      opts = {};\n\t    }\n\t    delete doc._revisions; // ignore this, trust the rev\n\t    var oldRev = doc._rev;\n\t    var id = doc._id;\n\t    var newRev;\n\t    if (!oldRev) {\n\t      newRev = doc._rev = '0-1';\n\t    } else {\n\t      newRev = doc._rev = '0-' + (parseInt(oldRev.split('-')[1], 10) + 1);\n\t    }\n\t    var json = stringifyDoc(doc);\n\t\n\t    var ret;\n\t    function putLocal(tx) {\n\t      var sql;\n\t      var values;\n\t      if (oldRev) {\n\t        sql = 'UPDATE ' + LOCAL_STORE$1 + ' SET rev=?, json=? ' +\n\t          'WHERE id=? AND rev=?';\n\t        values = [newRev, json, id, oldRev];\n\t      } else {\n\t        sql = 'INSERT INTO ' + LOCAL_STORE$1 + ' (id, rev, json) VALUES (?,?,?)';\n\t        values = [id, newRev, json];\n\t      }\n\t      tx.executeSql(sql, values, function (tx, res) {\n\t        if (res.rowsAffected) {\n\t          ret = {ok: true, id: id, rev: newRev};\n\t          if (opts.ctx) { // return immediately\n\t            callback(null, ret);\n\t          }\n\t        } else {\n\t          callback(createError(REV_CONFLICT));\n\t        }\n\t      }, function () {\n\t        callback(createError(REV_CONFLICT));\n\t        return false; // ack that we handled the error\n\t      });\n\t    }\n\t\n\t    if (opts.ctx) {\n\t      putLocal(opts.ctx);\n\t    } else {\n\t      db.transaction(putLocal, websqlError(callback), function () {\n\t        if (ret) {\n\t          callback(null, ret);\n\t        }\n\t      });\n\t    }\n\t  };\n\t\n\t  api._removeLocal = function (doc, opts, callback) {\n\t    if (typeof opts === 'function') {\n\t      callback = opts;\n\t      opts = {};\n\t    }\n\t    var ret;\n\t\n\t    function removeLocal(tx) {\n\t      var sql = 'DELETE FROM ' + LOCAL_STORE$1 + ' WHERE id=? AND rev=?';\n\t      var params = [doc._id, doc._rev];\n\t      tx.executeSql(sql, params, function (tx, res) {\n\t        if (!res.rowsAffected) {\n\t          return callback(createError(MISSING_DOC));\n\t        }\n\t        ret = {ok: true, id: doc._id, rev: '0-0'};\n\t        if (opts.ctx) { // return immediately\n\t          callback(null, ret);\n\t        }\n\t      });\n\t    }\n\t\n\t    if (opts.ctx) {\n\t      removeLocal(opts.ctx);\n\t    } else {\n\t      db.transaction(removeLocal, websqlError(callback), function () {\n\t        if (ret) {\n\t          callback(null, ret);\n\t        }\n\t      });\n\t    }\n\t  };\n\t\n\t  api._destroy = function (opts, callback) {\n\t    websqlChanges.removeAllListeners(api._name);\n\t    db.transaction(function (tx) {\n\t      var stores = [DOC_STORE$1, BY_SEQ_STORE$1, ATTACH_STORE$1, META_STORE$1,\n\t        LOCAL_STORE$1, ATTACH_AND_SEQ_STORE$1];\n\t      stores.forEach(function (store) {\n\t        tx.executeSql('DROP TABLE IF EXISTS ' + store, []);\n\t      });\n\t    }, websqlError(callback), function () {\n\t      if (hasLocalStorage()) {\n\t        delete window.localStorage['_pouch__websqldb_' + api._name];\n\t        delete window.localStorage[api._name];\n\t      }\n\t      callback(null, {'ok': true});\n\t    });\n\t  };\n\t}\n\t\n\tfunction canOpenTestDB() {\n\t  try {\n\t    openDatabase('_pouch_validate_websql', 1, '', 1);\n\t    return true;\n\t  } catch (err) {\n\t    return false;\n\t  }\n\t}\n\t\n\t// WKWebView had a bug where WebSQL would throw a DOM Exception 18\n\t// (see https://bugs.webkit.org/show_bug.cgi?id=137760 and\n\t// https://github.com/pouchdb/pouchdb/issues/5079)\n\t// This has been fixed in latest WebKit, so we try to detect it here.\n\tfunction isValidWebSQL() {\n\t  // WKWebView UA:\n\t  //   Mozilla/5.0 (iPhone; CPU iPhone OS 9_2 like Mac OS X)\n\t  //   AppleWebKit/601.1.46 (KHTML, like Gecko) Mobile/13C75\n\t  // Chrome for iOS UA:\n\t  //   Mozilla/5.0 (iPhone; U; CPU iPhone OS 5_1_1 like Mac OS X; en)\n\t  //   AppleWebKit/534.46.0 (KHTML, like Gecko) CriOS/19.0.1084.60\n\t  //   Mobile/9B206 Safari/7534.48.3\n\t  // Firefox for iOS UA:\n\t  //   Mozilla/5.0 (iPhone; CPU iPhone OS 8_3 like Mac OS X) AppleWebKit/600.1.4\n\t  //   (KHTML, like Gecko) FxiOS/1.0 Mobile/12F69 Safari/600.1.4\n\t\n\t  // indexedDB is null on some UIWebViews and undefined in others\n\t  // see: https://bugs.webkit.org/show_bug.cgi?id=137034\n\t  if (typeof indexedDB === 'undefined' || indexedDB === null ||\n\t      !/iP(hone|od|ad)/.test(navigator.userAgent)) {\n\t    // definitely not WKWebView, avoid creating an unnecessary database\n\t    return true;\n\t  }\n\t  // Cache the result in LocalStorage. Reason we do this is because if we\n\t  // call openDatabase() too many times, Safari craps out in SauceLabs and\n\t  // starts throwing DOM Exception 14s.\n\t  var hasLS = hasLocalStorage();\n\t  // Include user agent in the hash, so that if Safari is upgraded, we don't\n\t  // continually think it's broken.\n\t  var localStorageKey = '_pouch__websqldb_valid_' + navigator.userAgent;\n\t  if (hasLS && localStorage[localStorageKey]) {\n\t    return localStorage[localStorageKey] === '1';\n\t  }\n\t  var openedTestDB = canOpenTestDB();\n\t  if (hasLS) {\n\t    localStorage[localStorageKey] = openedTestDB ? '1' : '0';\n\t  }\n\t  return openedTestDB;\n\t}\n\t\n\tfunction valid() {\n\t  if (typeof openDatabase !== 'function') {\n\t    return false;\n\t  }\n\t  return isValidWebSQL();\n\t}\n\t\n\tfunction openDB(name, version, description, size) {\n\t  // Traditional WebSQL API\n\t  return openDatabase(name, version, description, size);\n\t}\n\t\n\tfunction WebSQLPouch(opts, callback) {\n\t  var _opts = assign$1({\n\t    websql: openDB\n\t  }, opts);\n\t\n\t  WebSqlPouch$1.call(this, _opts, callback);\n\t}\n\t\n\tWebSQLPouch.valid = valid;\n\t\n\tWebSQLPouch.use_prefix = true;\n\t\n\tvar WebSqlPouch = function (PouchDB) {\n\t  PouchDB.adapter('websql', WebSQLPouch, true);\n\t};\n\t\n\t/* global fetch */\n\t/* global Headers */\n\tfunction wrappedFetch() {\n\t  var wrappedPromise = {};\n\t\n\t  var promise = new PouchPromise$1(function (resolve, reject) {\n\t    wrappedPromise.resolve = resolve;\n\t    wrappedPromise.reject = reject;\n\t  });\n\t\n\t  var args = new Array(arguments.length);\n\t\n\t  for (var i = 0; i < args.length; i++) {\n\t    args[i] = arguments[i];\n\t  }\n\t\n\t  wrappedPromise.promise = promise;\n\t\n\t  PouchPromise$1.resolve().then(function () {\n\t    return fetch.apply(null, args);\n\t  }).then(function (response) {\n\t    wrappedPromise.resolve(response);\n\t  }).catch(function (error) {\n\t    wrappedPromise.reject(error);\n\t  });\n\t\n\t  return wrappedPromise;\n\t}\n\t\n\tfunction fetchRequest(options, callback) {\n\t  var wrappedPromise, timer, response;\n\t\n\t  var headers = new Headers();\n\t\n\t  var fetchOptions = {\n\t    method: options.method,\n\t    credentials: 'include',\n\t    headers: headers\n\t  };\n\t\n\t  if (options.json) {\n\t    headers.set('Accept', 'application/json');\n\t    headers.set('Content-Type', options.headers['Content-Type'] ||\n\t      'application/json');\n\t  }\n\t\n\t  if (options.body &&\n\t      options.processData &&\n\t      typeof options.body !== 'string') {\n\t    fetchOptions.body = JSON.stringify(options.body);\n\t  } else if ('body' in options) {\n\t    fetchOptions.body = options.body;\n\t  } else {\n\t    fetchOptions.body = null;\n\t  }\n\t\n\t  Object.keys(options.headers).forEach(function (key) {\n\t    if (options.headers.hasOwnProperty(key)) {\n\t      headers.set(key, options.headers[key]);\n\t    }\n\t  });\n\t\n\t  wrappedPromise = wrappedFetch(options.url, fetchOptions);\n\t\n\t  if (options.timeout > 0) {\n\t    timer = setTimeout(function () {\n\t      wrappedPromise.reject(new Error('Load timeout for resource: ' +\n\t        options.url));\n\t    }, options.timeout);\n\t  }\n\t\n\t  wrappedPromise.promise.then(function (fetchResponse) {\n\t    response = {\n\t      statusCode: fetchResponse.status\n\t    };\n\t\n\t    if (options.timeout > 0) {\n\t      clearTimeout(timer);\n\t    }\n\t\n\t    if (response.statusCode >= 200 && response.statusCode < 300) {\n\t      return options.binary ? fetchResponse.blob() : fetchResponse.text();\n\t    }\n\t\n\t    return fetchResponse.json();\n\t  }).then(function (result) {\n\t    if (response.statusCode >= 200 && response.statusCode < 300) {\n\t      callback(null, response, result);\n\t    } else {\n\t      result.status = response.statusCode;\n\t      callback(result);\n\t    }\n\t  }).catch(function (error) {\n\t    if (!error) {\n\t      // this happens when the listener is canceled\n\t      error = new Error('canceled');\n\t    }\n\t    callback(error);\n\t  });\n\t\n\t  return {abort: wrappedPromise.reject};\n\t}\n\t\n\tfunction xhRequest(options, callback) {\n\t\n\t  var xhr, timer;\n\t  var timedout = false;\n\t\n\t  var abortReq = function () {\n\t    xhr.abort();\n\t    cleanUp();\n\t  };\n\t\n\t  var timeoutReq = function () {\n\t    timedout = true;\n\t    xhr.abort();\n\t    cleanUp();\n\t  };\n\t\n\t  var ret = {abort: abortReq};\n\t\n\t  var cleanUp = function () {\n\t    clearTimeout(timer);\n\t    ret.abort = function () {};\n\t    if (xhr) {\n\t      xhr.onprogress = undefined;\n\t      if (xhr.upload) {\n\t        xhr.upload.onprogress = undefined;\n\t      }\n\t      xhr.onreadystatechange = undefined;\n\t      xhr = undefined;\n\t    }\n\t  };\n\t\n\t  if (options.xhr) {\n\t    xhr = new options.xhr();\n\t  } else {\n\t    xhr = new XMLHttpRequest();\n\t  }\n\t\n\t  try {\n\t    xhr.open(options.method, options.url);\n\t  } catch (exception) {\n\t    return callback(new Error(exception.name || 'Url is invalid'));\n\t  }\n\t\n\t  xhr.withCredentials = ('withCredentials' in options) ?\n\t    options.withCredentials : true;\n\t\n\t  if (options.method === 'GET') {\n\t    delete options.headers['Content-Type'];\n\t  } else if (options.json) {\n\t    options.headers.Accept = 'application/json';\n\t    options.headers['Content-Type'] = options.headers['Content-Type'] ||\n\t      'application/json';\n\t    if (options.body &&\n\t        options.processData &&\n\t        typeof options.body !== \"string\") {\n\t      options.body = JSON.stringify(options.body);\n\t    }\n\t  }\n\t\n\t  if (options.binary) {\n\t    xhr.responseType = 'arraybuffer';\n\t  }\n\t\n\t  if (!('body' in options)) {\n\t    options.body = null;\n\t  }\n\t\n\t  for (var key in options.headers) {\n\t    if (options.headers.hasOwnProperty(key)) {\n\t      xhr.setRequestHeader(key, options.headers[key]);\n\t    }\n\t  }\n\t\n\t  if (options.timeout > 0) {\n\t    timer = setTimeout(timeoutReq, options.timeout);\n\t    xhr.onprogress = function () {\n\t      clearTimeout(timer);\n\t      if(xhr.readyState !== 4) {\n\t        timer = setTimeout(timeoutReq, options.timeout);\n\t      }\n\t    };\n\t    if (typeof xhr.upload !== 'undefined') { // does not exist in ie9\n\t      xhr.upload.onprogress = xhr.onprogress;\n\t    }\n\t  }\n\t\n\t  xhr.onreadystatechange = function () {\n\t    if (xhr.readyState !== 4) {\n\t      return;\n\t    }\n\t\n\t    var response = {\n\t      statusCode: xhr.status\n\t    };\n\t\n\t    if (xhr.status >= 200 && xhr.status < 300) {\n\t      var data;\n\t      if (options.binary) {\n\t        data = createBlob([xhr.response || ''], {\n\t          type: xhr.getResponseHeader('Content-Type')\n\t        });\n\t      } else {\n\t        data = xhr.responseText;\n\t      }\n\t      callback(null, response, data);\n\t    } else {\n\t      var err = {};\n\t      if (timedout) {\n\t        err = new Error('ETIMEDOUT');\n\t        err.code = 'ETIMEDOUT';\n\t      } else if (typeof xhr.response === 'string') {\n\t        try {\n\t          err = JSON.parse(xhr.response);\n\t        } catch(e) {}\n\t      }\n\t      err.status = xhr.status;\n\t      callback(err);\n\t    }\n\t    cleanUp();\n\t  };\n\t\n\t  if (options.body && (options.body instanceof Blob)) {\n\t    readAsArrayBuffer(options.body, function (arrayBuffer) {\n\t      xhr.send(arrayBuffer);\n\t    });\n\t  } else {\n\t    xhr.send(options.body);\n\t  }\n\t\n\t  return ret;\n\t}\n\t\n\tfunction testXhr() {\n\t  try {\n\t    new XMLHttpRequest();\n\t    return true;\n\t  } catch (err) {\n\t    return false;\n\t  }\n\t}\n\t\n\tvar hasXhr = testXhr();\n\t\n\tfunction ajax$1(options, callback) {\n\t  if (!false && (hasXhr || options.xhr)) {\n\t    return xhRequest(options, callback);\n\t  } else {\n\t    return fetchRequest(options, callback);\n\t  }\n\t}\n\t\n\t// the blob already has a type; do nothing\n\tvar res$2 = function () {};\n\t\n\tfunction defaultBody() {\n\t  return '';\n\t}\n\t\n\tfunction ajaxCore$1(options, callback) {\n\t\n\t  options = clone(options);\n\t\n\t  var defaultOptions = {\n\t    method : \"GET\",\n\t    headers: {},\n\t    json: true,\n\t    processData: true,\n\t    timeout: 10000,\n\t    cache: false\n\t  };\n\t\n\t  options = assign$1(defaultOptions, options);\n\t\n\t  function onSuccess(obj, resp, cb) {\n\t    if (!options.binary && options.json && typeof obj === 'string') {\n\t      /* istanbul ignore next */\n\t      try {\n\t        obj = JSON.parse(obj);\n\t      } catch (e) {\n\t        // Probably a malformed JSON from server\n\t        return cb(e);\n\t      }\n\t    }\n\t    if (Array.isArray(obj)) {\n\t      obj = obj.map(function (v) {\n\t        if (v.error || v.missing) {\n\t          return generateErrorFromResponse(v);\n\t        } else {\n\t          return v;\n\t        }\n\t      });\n\t    }\n\t    if (options.binary) {\n\t      res$2(obj, resp);\n\t    }\n\t    cb(null, obj, resp);\n\t  }\n\t\n\t  if (options.json) {\n\t    if (!options.binary) {\n\t      options.headers.Accept = 'application/json';\n\t    }\n\t    options.headers['Content-Type'] = options.headers['Content-Type'] ||\n\t      'application/json';\n\t  }\n\t\n\t  if (options.binary) {\n\t    options.encoding = null;\n\t    options.json = false;\n\t  }\n\t\n\t  if (!options.processData) {\n\t    options.json = false;\n\t  }\n\t\n\t  return ajax$1(options, function (err, response, body) {\n\t\n\t    if (err) {\n\t      return callback(generateErrorFromResponse(err));\n\t    }\n\t\n\t    var error;\n\t    var content_type = response.headers && response.headers['content-type'];\n\t    var data = body || defaultBody();\n\t\n\t    // CouchDB doesn't always return the right content-type for JSON data, so\n\t    // we check for ^{ and }$ (ignoring leading/trailing whitespace)\n\t    if (!options.binary && (options.json || !options.processData) &&\n\t        typeof data !== 'object' &&\n\t        (/json/.test(content_type) ||\n\t         (/^[\\s]*\\{/.test(data) && /\\}[\\s]*$/.test(data)))) {\n\t      try {\n\t        data = JSON.parse(data.toString());\n\t      } catch (e) {}\n\t    }\n\t\n\t    if (response.statusCode >= 200 && response.statusCode < 300) {\n\t      onSuccess(data, response, callback);\n\t    } else {\n\t      error = generateErrorFromResponse(data);\n\t      error.status = response.statusCode;\n\t      callback(error);\n\t    }\n\t  });\n\t}\n\t\n\tfunction ajax(opts, callback) {\n\t\n\t  // cache-buster, specifically designed to work around IE's aggressive caching\n\t  // see http://www.dashbay.com/2011/05/internet-explorer-caches-ajax/\n\t  // Also Safari caches POSTs, so we need to cache-bust those too.\n\t  var ua = (navigator && navigator.userAgent) ?\n\t    navigator.userAgent.toLowerCase() : '';\n\t\n\t  var isSafari = ua.indexOf('safari') !== -1 && ua.indexOf('chrome') === -1;\n\t  var isIE = ua.indexOf('msie') !== -1;\n\t  var isEdge = ua.indexOf('edge') !== -1;\n\t\n\t  // it appears the new version of safari also caches GETs,\n\t  // see https://github.com/pouchdb/pouchdb/issues/5010\n\t  var shouldCacheBust = (isSafari ||\n\t    ((isIE || isEdge) && opts.method === 'GET'));\n\t\n\t  var cache = 'cache' in opts ? opts.cache : true;\n\t\n\t  var isBlobUrl = /^blob:/.test(opts.url); // don't append nonces for blob URLs\n\t\n\t  if (!isBlobUrl && (shouldCacheBust || !cache)) {\n\t    var hasArgs = opts.url.indexOf('?') !== -1;\n\t    opts.url += (hasArgs ? '&' : '?') + '_nonce=' + Date.now();\n\t  }\n\t\n\t  return ajaxCore$1(opts, callback);\n\t}\n\t\n\t// dead simple promise pool, inspired by https://github.com/timdp/es6-promise-pool\n\t// but much smaller in code size. limits the number of concurrent promises that are executed\n\t\n\tfunction pool(promiseFactories, limit) {\n\t  return new PouchPromise$1(function (resolve, reject) {\n\t    var running = 0;\n\t    var current = 0;\n\t    var done = 0;\n\t    var len = promiseFactories.length;\n\t    var err;\n\t\n\t    function runNext() {\n\t      running++;\n\t      promiseFactories[current++]().then(onSuccess, onError);\n\t    }\n\t\n\t    function doNext() {\n\t      if (++done === len) {\n\t        /* istanbul ignore if */\n\t        if (err) {\n\t          reject(err);\n\t        } else {\n\t          resolve();\n\t        }\n\t      } else {\n\t        runNextBatch();\n\t      }\n\t    }\n\t\n\t    function onSuccess() {\n\t      running--;\n\t      doNext();\n\t    }\n\t\n\t    /* istanbul ignore next */\n\t    function onError(thisErr) {\n\t      running--;\n\t      err = err || thisErr;\n\t      doNext();\n\t    }\n\t\n\t    function runNextBatch() {\n\t      while (running < limit && current < len) {\n\t        runNext();\n\t      }\n\t    }\n\t\n\t    runNextBatch();\n\t  });\n\t}\n\t\n\tvar CHANGES_BATCH_SIZE = 25;\n\tvar MAX_SIMULTANEOUS_REVS = 50;\n\t\n\tvar supportsBulkGetMap = {};\n\t\n\tvar log$1 = debug('pouchdb:http');\n\t\n\tfunction readAttachmentsAsBlobOrBuffer(row) {\n\t  var atts = row.doc && row.doc._attachments;\n\t  if (!atts) {\n\t    return;\n\t  }\n\t  Object.keys(atts).forEach(function (filename) {\n\t    var att = atts[filename];\n\t    att.data = b64ToBluffer(att.data, att.content_type);\n\t  });\n\t}\n\t\n\tfunction encodeDocId(id) {\n\t  if (/^_design/.test(id)) {\n\t    return '_design/' + encodeURIComponent(id.slice(8));\n\t  }\n\t  if (/^_local/.test(id)) {\n\t    return '_local/' + encodeURIComponent(id.slice(7));\n\t  }\n\t  return encodeURIComponent(id);\n\t}\n\t\n\tfunction preprocessAttachments$2(doc) {\n\t  if (!doc._attachments || !Object.keys(doc._attachments)) {\n\t    return PouchPromise$1.resolve();\n\t  }\n\t\n\t  return PouchPromise$1.all(Object.keys(doc._attachments).map(function (key) {\n\t    var attachment = doc._attachments[key];\n\t    if (attachment.data && typeof attachment.data !== 'string') {\n\t      return new PouchPromise$1(function (resolve) {\n\t        blobToBase64(attachment.data, resolve);\n\t      }).then(function (b64) {\n\t        attachment.data = b64;\n\t      });\n\t    }\n\t  }));\n\t}\n\t\n\tfunction hasUrlPrefix(opts) {\n\t  if (!opts.prefix) {\n\t    return false;\n\t  }\n\t\n\t  var protocol = parseUri(opts.prefix).protocol;\n\t\n\t  return protocol === 'http' || protocol === 'https';\n\t}\n\t\n\t// Get all the information you possibly can about the URI given by name and\n\t// return it as a suitable object.\n\tfunction getHost(name, opts) {\n\t\n\t  // encode db name if opts.prefix is a url (#5574)\n\t  if (hasUrlPrefix(opts)) {\n\t    var dbName = opts.name.substr(opts.prefix.length);\n\t    name = opts.prefix + encodeURIComponent(dbName);\n\t  }\n\t\n\t  // Prase the URI into all its little bits\n\t  var uri = parseUri(name);\n\t\n\t  // Store the user and password as a separate auth object\n\t  if (uri.user || uri.password) {\n\t    uri.auth = {username: uri.user, password: uri.password};\n\t  }\n\t\n\t  // Split the path part of the URI into parts using '/' as the delimiter\n\t  // after removing any leading '/' and any trailing '/'\n\t  var parts = uri.path.replace(/(^\\/|\\/$)/g, '').split('/');\n\t\n\t  // Store the first part as the database name and remove it from the parts\n\t  // array\n\t  uri.db = parts.pop();\n\t  // Prevent double encoding of URI component\n\t  if (uri.db.indexOf('%') === -1) {\n\t    uri.db = encodeURIComponent(uri.db);\n\t  }\n\t\n\t  // Restore the path by joining all the remaining parts (all the parts\n\t  // except for the database name) with '/'s\n\t  uri.path = parts.join('/');\n\t\n\t  return uri;\n\t}\n\t\n\t// Generate a URL with the host data given by opts and the given path\n\tfunction genDBUrl(opts, path) {\n\t  return genUrl(opts, opts.db + '/' + path);\n\t}\n\t\n\t// Generate a URL with the host data given by opts and the given path\n\tfunction genUrl(opts, path) {\n\t  // If the host already has a path, then we need to have a path delimiter\n\t  // Otherwise, the path delimiter is the empty string\n\t  var pathDel = !opts.path ? '' : '/';\n\t\n\t  // If the host already has a path, then we need to have a path delimiter\n\t  // Otherwise, the path delimiter is the empty string\n\t  return opts.protocol + '://' + opts.host +\n\t         (opts.port ? (':' + opts.port) : '') +\n\t         '/' + opts.path + pathDel + path;\n\t}\n\t\n\tfunction paramsToStr(params) {\n\t  return '?' + Object.keys(params).map(function (k) {\n\t    return k + '=' + encodeURIComponent(params[k]);\n\t  }).join('&');\n\t}\n\t\n\t// Implements the PouchDB API for dealing with CouchDB instances over HTTP\n\tfunction HttpPouch(opts, callback) {\n\t\n\t  // The functions that will be publicly available for HttpPouch\n\t  var api = this;\n\t\n\t  var host = getHost(opts.name, opts);\n\t  var dbUrl = genDBUrl(host, '');\n\t\n\t  opts = clone(opts);\n\t  var ajaxOpts = opts.ajax || {};\n\t\n\t  if (opts.auth || host.auth) {\n\t    var nAuth = opts.auth || host.auth;\n\t    var str = nAuth.username + ':' + nAuth.password;\n\t    var token = thisBtoa(unescape(encodeURIComponent(str)));\n\t    ajaxOpts.headers = ajaxOpts.headers || {};\n\t    ajaxOpts.headers.Authorization = 'Basic ' + token;\n\t  }\n\t\n\t  // Not strictly necessary, but we do this because numerous tests\n\t  // rely on swapping ajax in and out.\n\t  api._ajax = ajax;\n\t\n\t  function ajax$$1(userOpts, options, callback) {\n\t    var reqAjax = userOpts.ajax || {};\n\t    var reqOpts = assign$1(clone(ajaxOpts), reqAjax, options);\n\t    log$1(reqOpts.method + ' ' + reqOpts.url);\n\t    return api._ajax(reqOpts, callback);\n\t  }\n\t\n\t  function ajaxPromise(userOpts, opts) {\n\t    return new PouchPromise$1(function (resolve, reject) {\n\t      ajax$$1(userOpts, opts, function (err, res) {\n\t        /* istanbul ignore if */\n\t        if (err) {\n\t          return reject(err);\n\t        }\n\t        resolve(res);\n\t      });\n\t    });\n\t  }\n\t\n\t  function adapterFun$$1(name, fun) {\n\t    return adapterFun(name, getArguments(function (args) {\n\t      setup().then(function () {\n\t        return fun.apply(this, args);\n\t      }).catch(function (e) {\n\t        var callback = args.pop();\n\t        callback(e);\n\t      });\n\t    }));\n\t  }\n\t\n\t  var setupPromise;\n\t\n\t  function setup() {\n\t    // TODO: Remove `skipSetup` in favor of `skip_setup` in a future release\n\t    if (opts.skipSetup || opts.skip_setup) {\n\t      return PouchPromise$1.resolve();\n\t    }\n\t\n\t    // If there is a setup in process or previous successful setup\n\t    // done then we will use that\n\t    // If previous setups have been rejected we will try again\n\t    if (setupPromise) {\n\t      return setupPromise;\n\t    }\n\t\n\t    var checkExists = {method: 'GET', url: dbUrl};\n\t    setupPromise = ajaxPromise({}, checkExists).catch(function (err) {\n\t      if (err && err.status && err.status === 404) {\n\t        // Doesnt exist, create it\n\t        explainError(404, 'PouchDB is just detecting if the remote exists.');\n\t        return ajaxPromise({}, {method: 'PUT', url: dbUrl});\n\t      } else {\n\t        return PouchPromise$1.reject(err);\n\t      }\n\t    }).catch(function (err) {\n\t      // If we try to create a database that already exists, skipped in\n\t      // istanbul since its catching a race condition.\n\t      /* istanbul ignore if */\n\t      if (err && err.status && err.status === 412) {\n\t        return true;\n\t      }\n\t      return PouchPromise$1.reject(err);\n\t    });\n\t\n\t    setupPromise.catch(function () {\n\t      setupPromise = null;\n\t    });\n\t\n\t    return setupPromise;\n\t  }\n\t\n\t  nextTick(function () {\n\t    callback(null, api);\n\t  });\n\t\n\t  api.type = function () {\n\t    return 'http';\n\t  };\n\t\n\t  api.id = adapterFun$$1('id', function (callback) {\n\t    ajax$$1({}, {method: 'GET', url: genUrl(host, '')}, function (err, result) {\n\t      var uuid$$1 = (result && result.uuid) ?\n\t        (result.uuid + host.db) : genDBUrl(host, '');\n\t      callback(null, uuid$$1);\n\t    });\n\t  });\n\t\n\t  api.request = adapterFun$$1('request', function (options, callback) {\n\t    options.url = genDBUrl(host, options.url);\n\t    ajax$$1({}, options, callback);\n\t  });\n\t\n\t  // Sends a POST request to the host calling the couchdb _compact function\n\t  //    version: The version of CouchDB it is running\n\t  api.compact = adapterFun$$1('compact', function (opts, callback) {\n\t    if (typeof opts === 'function') {\n\t      callback = opts;\n\t      opts = {};\n\t    }\n\t    opts = clone(opts);\n\t    ajax$$1(opts, {\n\t      url: genDBUrl(host, '_compact'),\n\t      method: 'POST'\n\t    }, function () {\n\t      function ping() {\n\t        api.info(function (err, res) {\n\t          if (res && !res.compact_running) {\n\t            callback(null, {ok: true});\n\t          } else {\n\t            setTimeout(ping, opts.interval || 200);\n\t          }\n\t        });\n\t      }\n\t      // Ping the http if it's finished compaction\n\t      ping();\n\t    });\n\t  });\n\t\n\t  api.bulkGet = adapterFun('bulkGet', function (opts, callback) {\n\t    var self = this;\n\t\n\t    function doBulkGet(cb) {\n\t      var params = {};\n\t      if (opts.revs) {\n\t        params.revs = true;\n\t      }\n\t      if (opts.attachments) {\n\t        /* istanbul ignore next */\n\t        params.attachments = true;\n\t      }\n\t      if (opts.latest) {\n\t        params.latest = true;\n\t      }\n\t      ajax$$1(opts, {\n\t        url: genDBUrl(host, '_bulk_get' + paramsToStr(params)),\n\t        method: 'POST',\n\t        body: { docs: opts.docs}\n\t      }, cb);\n\t    }\n\t\n\t    function doBulkGetShim() {\n\t      // avoid \"url too long error\" by splitting up into multiple requests\n\t      var batchSize = MAX_SIMULTANEOUS_REVS;\n\t      var numBatches = Math.ceil(opts.docs.length / batchSize);\n\t      var numDone = 0;\n\t      var results = new Array(numBatches);\n\t\n\t      function onResult(batchNum) {\n\t        return function (err, res) {\n\t          // err is impossible because shim returns a list of errs in that case\n\t          results[batchNum] = res.results;\n\t          if (++numDone === numBatches) {\n\t            callback(null, {results: flatten(results)});\n\t          }\n\t        };\n\t      }\n\t\n\t      for (var i = 0; i < numBatches; i++) {\n\t        var subOpts = pick(opts, ['revs', 'attachments', 'latest']);\n\t        subOpts.ajax = ajaxOpts;\n\t        subOpts.docs = opts.docs.slice(i * batchSize,\n\t          Math.min(opts.docs.length, (i + 1) * batchSize));\n\t        bulkGet(self, subOpts, onResult(i));\n\t      }\n\t    }\n\t\n\t    // mark the whole database as either supporting or not supporting _bulk_get\n\t    var dbUrl = genUrl(host, '');\n\t    var supportsBulkGet = supportsBulkGetMap[dbUrl];\n\t\n\t    if (typeof supportsBulkGet !== 'boolean') {\n\t      // check if this database supports _bulk_get\n\t      doBulkGet(function (err, res) {\n\t        /* istanbul ignore else */\n\t        if (err) {\n\t          supportsBulkGetMap[dbUrl] = false;\n\t          explainError(\n\t            err.status,\n\t            'PouchDB is just detecting if the remote ' +\n\t            'supports the _bulk_get API.'\n\t          );\n\t          doBulkGetShim();\n\t        } else {\n\t          supportsBulkGetMap[dbUrl] = true;\n\t          callback(null, res);\n\t        }\n\t      });\n\t    } else if (supportsBulkGet) {\n\t      /* istanbul ignore next */\n\t      doBulkGet(callback);\n\t    } else {\n\t      doBulkGetShim();\n\t    }\n\t  });\n\t\n\t  // Calls GET on the host, which gets back a JSON string containing\n\t  //    couchdb: A welcome string\n\t  //    version: The version of CouchDB it is running\n\t  api._info = function (callback) {\n\t    setup().then(function () {\n\t      ajax$$1({}, {\n\t        method: 'GET',\n\t        url: genDBUrl(host, '')\n\t      }, function (err, res) {\n\t        /* istanbul ignore next */\n\t        if (err) {\n\t        return callback(err);\n\t        }\n\t        res.host = genDBUrl(host, '');\n\t        callback(null, res);\n\t      });\n\t    }).catch(callback);\n\t  };\n\t\n\t  // Get the document with the given id from the database given by host.\n\t  // The id could be solely the _id in the database, or it may be a\n\t  // _design/ID or _local/ID path\n\t  api.get = adapterFun$$1('get', function (id, opts, callback) {\n\t    // If no options were given, set the callback to the second parameter\n\t    if (typeof opts === 'function') {\n\t      callback = opts;\n\t      opts = {};\n\t    }\n\t    opts = clone(opts);\n\t\n\t    // List of parameters to add to the GET request\n\t    var params = {};\n\t\n\t    if (opts.revs) {\n\t      params.revs = true;\n\t    }\n\t\n\t    if (opts.revs_info) {\n\t      params.revs_info = true;\n\t    }\n\t\n\t    if (opts.latest) {\n\t      params.latest = true;\n\t    }\n\t\n\t    if (opts.open_revs) {\n\t      if (opts.open_revs !== \"all\") {\n\t        opts.open_revs = JSON.stringify(opts.open_revs);\n\t      }\n\t      params.open_revs = opts.open_revs;\n\t    }\n\t\n\t    if (opts.rev) {\n\t      params.rev = opts.rev;\n\t    }\n\t\n\t    if (opts.conflicts) {\n\t      params.conflicts = opts.conflicts;\n\t    }\n\t\n\t    id = encodeDocId(id);\n\t\n\t    // Set the options for the ajax call\n\t    var options = {\n\t      method: 'GET',\n\t      url: genDBUrl(host, id + paramsToStr(params))\n\t    };\n\t\n\t    function fetchAttachments(doc) {\n\t      var atts = doc._attachments;\n\t      var filenames = atts && Object.keys(atts);\n\t      if (!atts || !filenames.length) {\n\t        return;\n\t      }\n\t      // we fetch these manually in separate XHRs, because\n\t      // Sync Gateway would normally send it back as multipart/mixed,\n\t      // which we cannot parse. Also, this is more efficient than\n\t      // receiving attachments as base64-encoded strings.\n\t      function fetch(filename) {\n\t        var att = atts[filename];\n\t        var path = encodeDocId(doc._id) + '/' + encodeAttachmentId(filename) +\n\t          '?rev=' + doc._rev;\n\t        return ajaxPromise(opts, {\n\t          method: 'GET',\n\t          url: genDBUrl(host, path),\n\t          binary: true\n\t        }).then(function (blob$$1) {\n\t          if (opts.binary) {\n\t            return blob$$1;\n\t          }\n\t          return new PouchPromise$1(function (resolve) {\n\t            blobToBase64(blob$$1, resolve);\n\t          });\n\t        }).then(function (data) {\n\t          delete att.stub;\n\t          delete att.length;\n\t          att.data = data;\n\t        });\n\t      }\n\t\n\t      var promiseFactories = filenames.map(function (filename) {\n\t        return function () {\n\t          return fetch(filename);\n\t        };\n\t      });\n\t\n\t      // This limits the number of parallel xhr requests to 5 any time\n\t      // to avoid issues with maximum browser request limits\n\t      return pool(promiseFactories, 5);\n\t    }\n\t\n\t    function fetchAllAttachments(docOrDocs) {\n\t      if (Array.isArray(docOrDocs)) {\n\t        return PouchPromise$1.all(docOrDocs.map(function (doc) {\n\t          if (doc.ok) {\n\t            return fetchAttachments(doc.ok);\n\t          }\n\t        }));\n\t      }\n\t      return fetchAttachments(docOrDocs);\n\t    }\n\t\n\t    ajaxPromise(opts, options).then(function (res) {\n\t      return PouchPromise$1.resolve().then(function () {\n\t        if (opts.attachments) {\n\t          return fetchAllAttachments(res);\n\t        }\n\t      }).then(function () {\n\t        callback(null, res);\n\t      });\n\t    }).catch(callback);\n\t  });\n\t\n\t  // Delete the document given by doc from the database given by host.\n\t  api.remove = adapterFun$$1('remove',\n\t      function (docOrId, optsOrRev, opts, callback) {\n\t    var doc;\n\t    if (typeof optsOrRev === 'string') {\n\t      // id, rev, opts, callback style\n\t      doc = {\n\t        _id: docOrId,\n\t        _rev: optsOrRev\n\t      };\n\t      if (typeof opts === 'function') {\n\t        callback = opts;\n\t        opts = {};\n\t      }\n\t    } else {\n\t      // doc, opts, callback style\n\t      doc = docOrId;\n\t      if (typeof optsOrRev === 'function') {\n\t        callback = optsOrRev;\n\t        opts = {};\n\t      } else {\n\t        callback = opts;\n\t        opts = optsOrRev;\n\t      }\n\t    }\n\t\n\t    var rev = (doc._rev || opts.rev);\n\t\n\t    // Delete the document\n\t    ajax$$1(opts, {\n\t      method: 'DELETE',\n\t      url: genDBUrl(host, encodeDocId(doc._id)) + '?rev=' + rev\n\t    }, callback);\n\t  });\n\t\n\t  function encodeAttachmentId(attachmentId) {\n\t    return attachmentId.split(\"/\").map(encodeURIComponent).join(\"/\");\n\t  }\n\t\n\t  // Get the attachment\n\t  api.getAttachment =\n\t    adapterFun$$1('getAttachment', function (docId, attachmentId, opts,\n\t                                                callback) {\n\t    if (typeof opts === 'function') {\n\t      callback = opts;\n\t      opts = {};\n\t    }\n\t    var params = opts.rev ? ('?rev=' + opts.rev) : '';\n\t    var url = genDBUrl(host, encodeDocId(docId)) + '/' +\n\t      encodeAttachmentId(attachmentId) + params;\n\t    ajax$$1(opts, {\n\t      method: 'GET',\n\t      url: url,\n\t      binary: true\n\t    }, callback);\n\t  });\n\t\n\t  // Remove the attachment given by the id and rev\n\t  api.removeAttachment =\n\t    adapterFun$$1('removeAttachment', function (docId, attachmentId, rev,\n\t                                                   callback) {\n\t\n\t    var url = genDBUrl(host, encodeDocId(docId) + '/' +\n\t      encodeAttachmentId(attachmentId)) + '?rev=' + rev;\n\t\n\t    ajax$$1({}, {\n\t      method: 'DELETE',\n\t      url: url\n\t    }, callback);\n\t  });\n\t\n\t  // Add the attachment given by blob and its contentType property\n\t  // to the document with the given id, the revision given by rev, and\n\t  // add it to the database given by host.\n\t  api.putAttachment =\n\t    adapterFun$$1('putAttachment', function (docId, attachmentId, rev, blob$$1,\n\t                                                type, callback) {\n\t    if (typeof type === 'function') {\n\t      callback = type;\n\t      type = blob$$1;\n\t      blob$$1 = rev;\n\t      rev = null;\n\t    }\n\t    var id = encodeDocId(docId) + '/' + encodeAttachmentId(attachmentId);\n\t    var url = genDBUrl(host, id);\n\t    if (rev) {\n\t      url += '?rev=' + rev;\n\t    }\n\t\n\t    if (typeof blob$$1 === 'string') {\n\t      // input is assumed to be a base64 string\n\t      var binary;\n\t      try {\n\t        binary = thisAtob(blob$$1);\n\t      } catch (err) {\n\t        return callback(createError(BAD_ARG,\n\t                        'Attachment is not a valid base64 string'));\n\t      }\n\t      blob$$1 = binary ? binStringToBluffer(binary, type) : '';\n\t    }\n\t\n\t    var opts = {\n\t      headers: {'Content-Type': type},\n\t      method: 'PUT',\n\t      url: url,\n\t      processData: false,\n\t      body: blob$$1,\n\t      timeout: ajaxOpts.timeout || 60000\n\t    };\n\t    // Add the attachment\n\t    ajax$$1({}, opts, callback);\n\t  });\n\t\n\t  // Update/create multiple documents given by req in the database\n\t  // given by host.\n\t  api._bulkDocs = function (req, opts, callback) {\n\t    // If new_edits=false then it prevents the database from creating\n\t    // new revision numbers for the documents. Instead it just uses\n\t    // the old ones. This is used in database replication.\n\t    req.new_edits = opts.new_edits;\n\t\n\t    setup().then(function () {\n\t      return PouchPromise$1.all(req.docs.map(preprocessAttachments$2));\n\t    }).then(function () {\n\t      // Update/create the documents\n\t      ajax$$1(opts, {\n\t        method: 'POST',\n\t        url: genDBUrl(host, '_bulk_docs'),\n\t        timeout: opts.timeout,\n\t        body: req\n\t      }, function (err, results) {\n\t        if (err) {\n\t          return callback(err);\n\t        }\n\t        results.forEach(function (result) {\n\t          result.ok = true; // smooths out cloudant not adding this\n\t        });\n\t        callback(null, results);\n\t      });\n\t    }).catch(callback);\n\t  };\n\t\n\t\n\t  // Update/create document\n\t  api._put = function (doc, opts, callback) {\n\t    setup().then(function () {\n\t      return preprocessAttachments$2(doc);\n\t    }).then(function () {\n\t      // Update/create the document\n\t      ajax$$1(opts, {\n\t        method: 'PUT',\n\t        url: genDBUrl(host, encodeDocId(doc._id)),\n\t        body: doc\n\t      }, function (err, result) {\n\t        if (err) {\n\t          return callback(err);\n\t        }\n\t        callback(null, result);\n\t      });\n\t    }).catch(callback);\n\t  };\n\t\n\t\n\t  // Get a listing of the documents in the database given\n\t  // by host and ordered by increasing id.\n\t  api.allDocs = adapterFun$$1('allDocs', function (opts, callback) {\n\t    if (typeof opts === 'function') {\n\t      callback = opts;\n\t      opts = {};\n\t    }\n\t    opts = clone(opts);\n\t\n\t    // List of parameters to add to the GET request\n\t    var params = {};\n\t    var body;\n\t    var method = 'GET';\n\t\n\t    if (opts.conflicts) {\n\t      params.conflicts = true;\n\t    }\n\t\n\t    if (opts.descending) {\n\t      params.descending = true;\n\t    }\n\t\n\t    if (opts.include_docs) {\n\t      params.include_docs = true;\n\t    }\n\t\n\t    // added in CouchDB 1.6.0\n\t    if (opts.attachments) {\n\t      params.attachments = true;\n\t    }\n\t\n\t    if (opts.key) {\n\t      params.key = JSON.stringify(opts.key);\n\t    }\n\t\n\t    if (opts.start_key) {\n\t      opts.startkey = opts.start_key;\n\t    }\n\t\n\t    if (opts.startkey) {\n\t      params.startkey = JSON.stringify(opts.startkey);\n\t    }\n\t\n\t    if (opts.end_key) {\n\t      opts.endkey = opts.end_key;\n\t    }\n\t\n\t    if (opts.endkey) {\n\t      params.endkey = JSON.stringify(opts.endkey);\n\t    }\n\t\n\t    if (typeof opts.inclusive_end !== 'undefined') {\n\t      params.inclusive_end = !!opts.inclusive_end;\n\t    }\n\t\n\t    if (typeof opts.limit !== 'undefined') {\n\t      params.limit = opts.limit;\n\t    }\n\t\n\t    if (typeof opts.skip !== 'undefined') {\n\t      params.skip = opts.skip;\n\t    }\n\t\n\t    var paramStr = paramsToStr(params);\n\t\n\t    if (typeof opts.keys !== 'undefined') {\n\t      method = 'POST';\n\t      body = {keys: opts.keys};\n\t    }\n\t\n\t    // Get the document listing\n\t    ajaxPromise(opts, {\n\t      method: method,\n\t      url: genDBUrl(host, '_all_docs' + paramStr),\n\t      body: body\n\t    }).then(function (res) {\n\t      if (opts.include_docs && opts.attachments && opts.binary) {\n\t        res.rows.forEach(readAttachmentsAsBlobOrBuffer);\n\t      }\n\t      callback(null, res);\n\t    }).catch(callback);\n\t  });\n\t\n\t  // Get a list of changes made to documents in the database given by host.\n\t  // TODO According to the README, there should be two other methods here,\n\t  // api.changes.addListener and api.changes.removeListener.\n\t  api._changes = function (opts) {\n\t\n\t    // We internally page the results of a changes request, this means\n\t    // if there is a large set of changes to be returned we can start\n\t    // processing them quicker instead of waiting on the entire\n\t    // set of changes to return and attempting to process them at once\n\t    var batchSize = 'batch_size' in opts ? opts.batch_size : CHANGES_BATCH_SIZE;\n\t\n\t    opts = clone(opts);\n\t    opts.timeout = ('timeout' in opts) ? opts.timeout :\n\t      ('timeout' in ajaxOpts) ? ajaxOpts.timeout :\n\t      30 * 1000;\n\t\n\t    // We give a 5 second buffer for CouchDB changes to respond with\n\t    // an ok timeout (if a timeout it set)\n\t    var params = opts.timeout ? {timeout: opts.timeout - (5 * 1000)} : {};\n\t    var limit = (typeof opts.limit !== 'undefined') ? opts.limit : false;\n\t    var returnDocs;\n\t    if ('return_docs' in opts) {\n\t      returnDocs = opts.return_docs;\n\t    } else if ('returnDocs' in opts) {\n\t      // TODO: Remove 'returnDocs' in favor of 'return_docs' in a future release\n\t      returnDocs = opts.returnDocs;\n\t    } else {\n\t      returnDocs = true;\n\t    }\n\t    //\n\t    var leftToFetch = limit;\n\t\n\t    if (opts.style) {\n\t      params.style = opts.style;\n\t    }\n\t\n\t    if (opts.include_docs || opts.filter && typeof opts.filter === 'function') {\n\t      params.include_docs = true;\n\t    }\n\t\n\t    if (opts.attachments) {\n\t      params.attachments = true;\n\t    }\n\t\n\t    if (opts.continuous) {\n\t      params.feed = 'longpoll';\n\t    }\n\t\n\t    if (opts.conflicts) {\n\t      params.conflicts = true;\n\t    }\n\t\n\t    if (opts.descending) {\n\t      params.descending = true;\n\t    }\n\t\n\t    if ('heartbeat' in opts) {\n\t      // If the heartbeat value is false, it disables the default heartbeat\n\t      if (opts.heartbeat) {\n\t        params.heartbeat = opts.heartbeat;\n\t      }\n\t    } else if (opts.continuous) {\n\t      // Default heartbeat to 10 seconds\n\t      params.heartbeat = 10000;\n\t    }\n\t\n\t    if (opts.filter && typeof opts.filter === 'string') {\n\t      params.filter = opts.filter;\n\t    }\n\t\n\t    if (opts.view && typeof opts.view === 'string') {\n\t      params.filter = '_view';\n\t      params.view = opts.view;\n\t    }\n\t\n\t    // If opts.query_params exists, pass it through to the changes request.\n\t    // These parameters may be used by the filter on the source database.\n\t    if (opts.query_params && typeof opts.query_params === 'object') {\n\t      for (var param_name in opts.query_params) {\n\t        /* istanbul ignore else */\n\t        if (opts.query_params.hasOwnProperty(param_name)) {\n\t          params[param_name] = opts.query_params[param_name];\n\t        }\n\t      }\n\t    }\n\t\n\t    var method = 'GET';\n\t    var body;\n\t\n\t    if (opts.doc_ids) {\n\t      // set this automagically for the user; it's annoying that couchdb\n\t      // requires both a \"filter\" and a \"doc_ids\" param.\n\t      params.filter = '_doc_ids';\n\t      method = 'POST';\n\t      body = {doc_ids: opts.doc_ids };\n\t    }\n\t\n\t    var xhr;\n\t    var lastFetchedSeq;\n\t\n\t    // Get all the changes starting wtih the one immediately after the\n\t    // sequence number given by since.\n\t    var fetch = function (since, callback) {\n\t      if (opts.aborted) {\n\t        return;\n\t      }\n\t      params.since = since;\n\t      // \"since\" can be any kind of json object in Coudant/CouchDB 2.x\n\t      /* istanbul ignore next */\n\t      if (typeof params.since === \"object\") {\n\t        params.since = JSON.stringify(params.since);\n\t      }\n\t\n\t      if (opts.descending) {\n\t        if (limit) {\n\t          params.limit = leftToFetch;\n\t        }\n\t      } else {\n\t        params.limit = (!limit || leftToFetch > batchSize) ?\n\t          batchSize : leftToFetch;\n\t      }\n\t\n\t      // Set the options for the ajax call\n\t      var xhrOpts = {\n\t        method: method,\n\t        url: genDBUrl(host, '_changes' + paramsToStr(params)),\n\t        timeout: opts.timeout,\n\t        body: body\n\t      };\n\t      lastFetchedSeq = since;\n\t\n\t      /* istanbul ignore if */\n\t      if (opts.aborted) {\n\t        return;\n\t      }\n\t\n\t      // Get the changes\n\t      setup().then(function () {\n\t        xhr = ajax$$1(opts, xhrOpts, callback);\n\t      }).catch(callback);\n\t    };\n\t\n\t    // If opts.since exists, get all the changes from the sequence\n\t    // number given by opts.since. Otherwise, get all the changes\n\t    // from the sequence number 0.\n\t    var results = {results: []};\n\t\n\t    var fetched = function (err, res) {\n\t      if (opts.aborted) {\n\t        return;\n\t      }\n\t      var raw_results_length = 0;\n\t      // If the result of the ajax call (res) contains changes (res.results)\n\t      if (res && res.results) {\n\t        raw_results_length = res.results.length;\n\t        results.last_seq = res.last_seq;\n\t        // For each change\n\t        var req = {};\n\t        req.query = opts.query_params;\n\t        res.results = res.results.filter(function (c) {\n\t          leftToFetch--;\n\t          var ret = filterChange(opts)(c);\n\t          if (ret) {\n\t            if (opts.include_docs && opts.attachments && opts.binary) {\n\t              readAttachmentsAsBlobOrBuffer(c);\n\t            }\n\t            if (returnDocs) {\n\t              results.results.push(c);\n\t            }\n\t            opts.onChange(c);\n\t          }\n\t          return ret;\n\t        });\n\t      } else if (err) {\n\t        // In case of an error, stop listening for changes and call\n\t        // opts.complete\n\t        opts.aborted = true;\n\t        opts.complete(err);\n\t        return;\n\t      }\n\t\n\t      // The changes feed may have timed out with no results\n\t      // if so reuse last update sequence\n\t      if (res && res.last_seq) {\n\t        lastFetchedSeq = res.last_seq;\n\t      }\n\t\n\t      var finished = (limit && leftToFetch <= 0) ||\n\t        (res && raw_results_length < batchSize) ||\n\t        (opts.descending);\n\t\n\t      if ((opts.continuous && !(limit && leftToFetch <= 0)) || !finished) {\n\t        // Queue a call to fetch again with the newest sequence number\n\t        nextTick(function () { fetch(lastFetchedSeq, fetched); });\n\t      } else {\n\t        // We're done, call the callback\n\t        opts.complete(null, results);\n\t      }\n\t    };\n\t\n\t    fetch(opts.since || 0, fetched);\n\t\n\t    // Return a method to cancel this method from processing any more\n\t    return {\n\t      cancel: function () {\n\t        opts.aborted = true;\n\t        if (xhr) {\n\t          xhr.abort();\n\t        }\n\t      }\n\t    };\n\t  };\n\t\n\t  // Given a set of document/revision IDs (given by req), tets the subset of\n\t  // those that do NOT correspond to revisions stored in the database.\n\t  // See http://wiki.apache.org/couchdb/HttpPostRevsDiff\n\t  api.revsDiff = adapterFun$$1('revsDiff', function (req, opts, callback) {\n\t    // If no options were given, set the callback to be the second parameter\n\t    if (typeof opts === 'function') {\n\t      callback = opts;\n\t      opts = {};\n\t    }\n\t\n\t    // Get the missing document/revision IDs\n\t    ajax$$1(opts, {\n\t      method: 'POST',\n\t      url: genDBUrl(host, '_revs_diff'),\n\t      body: req\n\t    }, callback);\n\t  });\n\t\n\t  api._close = function (callback) {\n\t    callback();\n\t  };\n\t\n\t  api._destroy = function (options, callback) {\n\t    ajax$$1(options, {\n\t      url: genDBUrl(host, ''),\n\t      method: 'DELETE'\n\t    }, function (err, resp) {\n\t      if (err && err.status && err.status !== 404) {\n\t        return callback(err);\n\t      }\n\t      callback(null, resp);\n\t    });\n\t  };\n\t}\n\t\n\t// HttpPouch is a valid adapter.\n\tHttpPouch.valid = function () {\n\t  return true;\n\t};\n\t\n\tvar HttpPouch$1 = function (PouchDB) {\n\t  PouchDB.adapter('http', HttpPouch, false);\n\t  PouchDB.adapter('https', HttpPouch, false);\n\t};\n\t\n\tfunction pad(str, padWith, upToLength) {\n\t  var padding = '';\n\t  var targetLength = upToLength - str.length;\n\t  /* istanbul ignore next */\n\t  while (padding.length < targetLength) {\n\t    padding += padWith;\n\t  }\n\t  return padding;\n\t}\n\t\n\tfunction padLeft(str, padWith, upToLength) {\n\t  var padding = pad(str, padWith, upToLength);\n\t  return padding + str;\n\t}\n\t\n\tvar MIN_MAGNITUDE = -324; // verified by -Number.MIN_VALUE\n\tvar MAGNITUDE_DIGITS = 3; // ditto\n\tvar SEP = ''; // set to '_' for easier debugging \n\t\n\tfunction collate(a, b) {\n\t\n\t  if (a === b) {\n\t    return 0;\n\t  }\n\t\n\t  a = normalizeKey(a);\n\t  b = normalizeKey(b);\n\t\n\t  var ai = collationIndex(a);\n\t  var bi = collationIndex(b);\n\t  if ((ai - bi) !== 0) {\n\t    return ai - bi;\n\t  }\n\t  switch (typeof a) {\n\t    case 'number':\n\t      return a - b;\n\t    case 'boolean':\n\t      return a < b ? -1 : 1;\n\t    case 'string':\n\t      return stringCollate(a, b);\n\t  }\n\t  return Array.isArray(a) ? arrayCollate(a, b) : objectCollate(a, b);\n\t}\n\t\n\t// couch considers null/NaN/Infinity/-Infinity === undefined,\n\t// for the purposes of mapreduce indexes. also, dates get stringified.\n\tfunction normalizeKey(key) {\n\t  switch (typeof key) {\n\t    case 'undefined':\n\t      return null;\n\t    case 'number':\n\t      if (key === Infinity || key === -Infinity || isNaN(key)) {\n\t        return null;\n\t      }\n\t      return key;\n\t    case 'object':\n\t      var origKey = key;\n\t      if (Array.isArray(key)) {\n\t        var len = key.length;\n\t        key = new Array(len);\n\t        for (var i = 0; i < len; i++) {\n\t          key[i] = normalizeKey(origKey[i]);\n\t        }\n\t      /* istanbul ignore next */\n\t      } else if (key instanceof Date) {\n\t        return key.toJSON();\n\t      } else if (key !== null) { // generic object\n\t        key = {};\n\t        for (var k in origKey) {\n\t          if (origKey.hasOwnProperty(k)) {\n\t            var val = origKey[k];\n\t            if (typeof val !== 'undefined') {\n\t              key[k] = normalizeKey(val);\n\t            }\n\t          }\n\t        }\n\t      }\n\t  }\n\t  return key;\n\t}\n\t\n\tfunction indexify(key) {\n\t  if (key !== null) {\n\t    switch (typeof key) {\n\t      case 'boolean':\n\t        return key ? 1 : 0;\n\t      case 'number':\n\t        return numToIndexableString(key);\n\t      case 'string':\n\t        // We've to be sure that key does not contain \\u0000\n\t        // Do order-preserving replacements:\n\t        // 0 -> 1, 1\n\t        // 1 -> 1, 2\n\t        // 2 -> 2, 2\n\t        return key\n\t          .replace(/\\u0002/g, '\\u0002\\u0002')\n\t          .replace(/\\u0001/g, '\\u0001\\u0002')\n\t          .replace(/\\u0000/g, '\\u0001\\u0001');\n\t      case 'object':\n\t        var isArray = Array.isArray(key);\n\t        var arr = isArray ? key : Object.keys(key);\n\t        var i = -1;\n\t        var len = arr.length;\n\t        var result = '';\n\t        if (isArray) {\n\t          while (++i < len) {\n\t            result += toIndexableString(arr[i]);\n\t          }\n\t        } else {\n\t          while (++i < len) {\n\t            var objKey = arr[i];\n\t            result += toIndexableString(objKey) +\n\t                toIndexableString(key[objKey]);\n\t          }\n\t        }\n\t        return result;\n\t    }\n\t  }\n\t  return '';\n\t}\n\t\n\t// convert the given key to a string that would be appropriate\n\t// for lexical sorting, e.g. within a database, where the\n\t// sorting is the same given by the collate() function.\n\tfunction toIndexableString(key) {\n\t  var zero = '\\u0000';\n\t  key = normalizeKey(key);\n\t  return collationIndex(key) + SEP + indexify(key) + zero;\n\t}\n\t\n\tfunction parseNumber(str, i) {\n\t  var originalIdx = i;\n\t  var num;\n\t  var zero = str[i] === '1';\n\t  if (zero) {\n\t    num = 0;\n\t    i++;\n\t  } else {\n\t    var neg = str[i] === '0';\n\t    i++;\n\t    var numAsString = '';\n\t    var magAsString = str.substring(i, i + MAGNITUDE_DIGITS);\n\t    var magnitude = parseInt(magAsString, 10) + MIN_MAGNITUDE;\n\t    /* istanbul ignore next */\n\t    if (neg) {\n\t      magnitude = -magnitude;\n\t    }\n\t    i += MAGNITUDE_DIGITS;\n\t    while (true) {\n\t      var ch = str[i];\n\t      if (ch === '\\u0000') {\n\t        break;\n\t      } else {\n\t        numAsString += ch;\n\t      }\n\t      i++;\n\t    }\n\t    numAsString = numAsString.split('.');\n\t    if (numAsString.length === 1) {\n\t      num = parseInt(numAsString, 10);\n\t    } else {\n\t      /* istanbul ignore next */\n\t      num = parseFloat(numAsString[0] + '.' + numAsString[1]);\n\t    }\n\t    /* istanbul ignore next */\n\t    if (neg) {\n\t      num = num - 10;\n\t    }\n\t    /* istanbul ignore next */\n\t    if (magnitude !== 0) {\n\t      // parseFloat is more reliable than pow due to rounding errors\n\t      // e.g. Number.MAX_VALUE would return Infinity if we did\n\t      // num * Math.pow(10, magnitude);\n\t      num = parseFloat(num + 'e' + magnitude);\n\t    }\n\t  }\n\t  return {num: num, length : i - originalIdx};\n\t}\n\t\n\t// move up the stack while parsing\n\t// this function moved outside of parseIndexableString for performance\n\tfunction pop(stack, metaStack) {\n\t  var obj = stack.pop();\n\t\n\t  if (metaStack.length) {\n\t    var lastMetaElement = metaStack[metaStack.length - 1];\n\t    if (obj === lastMetaElement.element) {\n\t      // popping a meta-element, e.g. an object whose value is another object\n\t      metaStack.pop();\n\t      lastMetaElement = metaStack[metaStack.length - 1];\n\t    }\n\t    var element = lastMetaElement.element;\n\t    var lastElementIndex = lastMetaElement.index;\n\t    if (Array.isArray(element)) {\n\t      element.push(obj);\n\t    } else if (lastElementIndex === stack.length - 2) { // obj with key+value\n\t      var key = stack.pop();\n\t      element[key] = obj;\n\t    } else {\n\t      stack.push(obj); // obj with key only\n\t    }\n\t  }\n\t}\n\t\n\tfunction parseIndexableString(str) {\n\t  var stack = [];\n\t  var metaStack = []; // stack for arrays and objects\n\t  var i = 0;\n\t\n\t  /*eslint no-constant-condition: [\"error\", { \"checkLoops\": false }]*/\n\t  while (true) {\n\t    var collationIndex = str[i++];\n\t    if (collationIndex === '\\u0000') {\n\t      if (stack.length === 1) {\n\t        return stack.pop();\n\t      } else {\n\t        pop(stack, metaStack);\n\t        continue;\n\t      }\n\t    }\n\t    switch (collationIndex) {\n\t      case '1':\n\t        stack.push(null);\n\t        break;\n\t      case '2':\n\t        stack.push(str[i] === '1');\n\t        i++;\n\t        break;\n\t      case '3':\n\t        var parsedNum = parseNumber(str, i);\n\t        stack.push(parsedNum.num);\n\t        i += parsedNum.length;\n\t        break;\n\t      case '4':\n\t        var parsedStr = '';\n\t        /*eslint no-constant-condition: [\"error\", { \"checkLoops\": false }]*/\n\t        while (true) {\n\t          var ch = str[i];\n\t          if (ch === '\\u0000') {\n\t            break;\n\t          }\n\t          parsedStr += ch;\n\t          i++;\n\t        }\n\t        // perform the reverse of the order-preserving replacement\n\t        // algorithm (see above)\n\t        parsedStr = parsedStr.replace(/\\u0001\\u0001/g, '\\u0000')\n\t          .replace(/\\u0001\\u0002/g, '\\u0001')\n\t          .replace(/\\u0002\\u0002/g, '\\u0002');\n\t        stack.push(parsedStr);\n\t        break;\n\t      case '5':\n\t        var arrayElement = { element: [], index: stack.length };\n\t        stack.push(arrayElement.element);\n\t        metaStack.push(arrayElement);\n\t        break;\n\t      case '6':\n\t        var objElement = { element: {}, index: stack.length };\n\t        stack.push(objElement.element);\n\t        metaStack.push(objElement);\n\t        break;\n\t      /* istanbul ignore next */\n\t      default:\n\t        throw new Error(\n\t          'bad collationIndex or unexpectedly reached end of input: ' +\n\t            collationIndex);\n\t    }\n\t  }\n\t}\n\t\n\tfunction arrayCollate(a, b) {\n\t  var len = Math.min(a.length, b.length);\n\t  for (var i = 0; i < len; i++) {\n\t    var sort = collate(a[i], b[i]);\n\t    if (sort !== 0) {\n\t      return sort;\n\t    }\n\t  }\n\t  return (a.length === b.length) ? 0 :\n\t    (a.length > b.length) ? 1 : -1;\n\t}\n\tfunction stringCollate(a, b) {\n\t  // See: https://github.com/daleharvey/pouchdb/issues/40\n\t  // This is incompatible with the CouchDB implementation, but its the\n\t  // best we can do for now\n\t  return (a === b) ? 0 : ((a > b) ? 1 : -1);\n\t}\n\tfunction objectCollate(a, b) {\n\t  var ak = Object.keys(a), bk = Object.keys(b);\n\t  var len = Math.min(ak.length, bk.length);\n\t  for (var i = 0; i < len; i++) {\n\t    // First sort the keys\n\t    var sort = collate(ak[i], bk[i]);\n\t    if (sort !== 0) {\n\t      return sort;\n\t    }\n\t    // if the keys are equal sort the values\n\t    sort = collate(a[ak[i]], b[bk[i]]);\n\t    if (sort !== 0) {\n\t      return sort;\n\t    }\n\t\n\t  }\n\t  return (ak.length === bk.length) ? 0 :\n\t    (ak.length > bk.length) ? 1 : -1;\n\t}\n\t// The collation is defined by erlangs ordered terms\n\t// the atoms null, true, false come first, then numbers, strings,\n\t// arrays, then objects\n\t// null/undefined/NaN/Infinity/-Infinity are all considered null\n\tfunction collationIndex(x) {\n\t  var id = ['boolean', 'number', 'string', 'object'];\n\t  var idx = id.indexOf(typeof x);\n\t  //false if -1 otherwise true, but fast!!!!1\n\t  if (~idx) {\n\t    if (x === null) {\n\t      return 1;\n\t    }\n\t    if (Array.isArray(x)) {\n\t      return 5;\n\t    }\n\t    return idx < 3 ? (idx + 2) : (idx + 3);\n\t  }\n\t  /* istanbul ignore next */\n\t  if (Array.isArray(x)) {\n\t    return 5;\n\t  }\n\t}\n\t\n\t// conversion:\n\t// x yyy zz...zz\n\t// x = 0 for negative, 1 for 0, 2 for positive\n\t// y = exponent (for negative numbers negated) moved so that it's >= 0\n\t// z = mantisse\n\tfunction numToIndexableString(num) {\n\t\n\t  if (num === 0) {\n\t    return '1';\n\t  }\n\t\n\t  // convert number to exponential format for easier and\n\t  // more succinct string sorting\n\t  var expFormat = num.toExponential().split(/e\\+?/);\n\t  var magnitude = parseInt(expFormat[1], 10);\n\t\n\t  var neg = num < 0;\n\t\n\t  var result = neg ? '0' : '2';\n\t\n\t  // first sort by magnitude\n\t  // it's easier if all magnitudes are positive\n\t  var magForComparison = ((neg ? -magnitude : magnitude) - MIN_MAGNITUDE);\n\t  var magString = padLeft((magForComparison).toString(), '0', MAGNITUDE_DIGITS);\n\t\n\t  result += SEP + magString;\n\t\n\t  // then sort by the factor\n\t  var factor = Math.abs(parseFloat(expFormat[0])); // [1..10)\n\t  /* istanbul ignore next */\n\t  if (neg) { // for negative reverse ordering\n\t    factor = 10 - factor;\n\t  }\n\t\n\t  var factorStr = factor.toFixed(20);\n\t\n\t  // strip zeros from the end\n\t  factorStr = factorStr.replace(/\\.?0+$/, '');\n\t\n\t  result += SEP + factorStr;\n\t\n\t  return result;\n\t}\n\t\n\t/*\n\t * Simple task queue to sequentialize actions. Assumes\n\t * callbacks will eventually fire (once).\n\t */\n\t\n\tfunction TaskQueue$2() {\n\t  this.promise = new PouchPromise$1(function (fulfill) {fulfill(); });\n\t}\n\tTaskQueue$2.prototype.add = function (promiseFactory) {\n\t  this.promise = this.promise.catch(function () {\n\t    // just recover\n\t  }).then(function () {\n\t    return promiseFactory();\n\t  });\n\t  return this.promise;\n\t};\n\tTaskQueue$2.prototype.finish = function () {\n\t  return this.promise;\n\t};\n\t\n\tfunction createView(opts) {\n\t  var sourceDB = opts.db;\n\t  var viewName = opts.viewName;\n\t  var mapFun = opts.map;\n\t  var reduceFun = opts.reduce;\n\t  var temporary = opts.temporary;\n\t\n\t  // the \"undefined\" part is for backwards compatibility\n\t  var viewSignature = mapFun.toString() + (reduceFun && reduceFun.toString()) +\n\t    'undefined';\n\t\n\t  var cachedViews;\n\t  if (!temporary) {\n\t    // cache this to ensure we don't try to update the same view twice\n\t    cachedViews = sourceDB._cachedViews = sourceDB._cachedViews || {};\n\t    if (cachedViews[viewSignature]) {\n\t      return cachedViews[viewSignature];\n\t    }\n\t  }\n\t\n\t  var promiseForView = sourceDB.info().then(function (info) {\n\t\n\t    var depDbName = info.db_name + '-mrview-' +\n\t      (temporary ? 'temp' : stringMd5(viewSignature));\n\t\n\t    // save the view name in the source db so it can be cleaned up if necessary\n\t    // (e.g. when the _design doc is deleted, remove all associated view data)\n\t    function diffFunction(doc) {\n\t      doc.views = doc.views || {};\n\t      var fullViewName = viewName;\n\t      if (fullViewName.indexOf('/') === -1) {\n\t        fullViewName = viewName + '/' + viewName;\n\t      }\n\t      var depDbs = doc.views[fullViewName] = doc.views[fullViewName] || {};\n\t      /* istanbul ignore if */\n\t      if (depDbs[depDbName]) {\n\t        return; // no update necessary\n\t      }\n\t      depDbs[depDbName] = true;\n\t      return doc;\n\t    }\n\t    return upsert(sourceDB, '_local/mrviews', diffFunction).then(function () {\n\t      return sourceDB.registerDependentDatabase(depDbName).then(function (res) {\n\t        var db = res.db;\n\t        db.auto_compaction = true;\n\t        var view = {\n\t          name: depDbName,\n\t          db: db,\n\t          sourceDB: sourceDB,\n\t          adapter: sourceDB.adapter,\n\t          mapFun: mapFun,\n\t          reduceFun: reduceFun\n\t        };\n\t        return view.db.get('_local/lastSeq').catch(function (err) {\n\t          /* istanbul ignore if */\n\t          if (err.status !== 404) {\n\t            throw err;\n\t          }\n\t        }).then(function (lastSeqDoc) {\n\t          view.seq = lastSeqDoc ? lastSeqDoc.seq : 0;\n\t          if (cachedViews) {\n\t            view.db.once('destroyed', function () {\n\t              delete cachedViews[viewSignature];\n\t            });\n\t          }\n\t          return view;\n\t        });\n\t      });\n\t    });\n\t  });\n\t\n\t  if (cachedViews) {\n\t    cachedViews[viewSignature] = promiseForView;\n\t  }\n\t  return promiseForView;\n\t}\n\t\n\tfunction QueryParseError(message) {\n\t  this.status = 400;\n\t  this.name = 'query_parse_error';\n\t  this.message = message;\n\t  this.error = true;\n\t  try {\n\t    Error.captureStackTrace(this, QueryParseError);\n\t  } catch (e) {}\n\t}\n\t\n\tinherits(QueryParseError, Error);\n\t\n\tfunction NotFoundError(message) {\n\t  this.status = 404;\n\t  this.name = 'not_found';\n\t  this.message = message;\n\t  this.error = true;\n\t  try {\n\t    Error.captureStackTrace(this, NotFoundError);\n\t  } catch (e) {}\n\t}\n\t\n\tinherits(NotFoundError, Error);\n\t\n\tfunction BuiltInError(message) {\n\t  this.status = 500;\n\t  this.name = 'invalid_value';\n\t  this.message = message;\n\t  this.error = true;\n\t  try {\n\t    Error.captureStackTrace(this, BuiltInError);\n\t  } catch (e) {}\n\t}\n\t\n\tinherits(BuiltInError, Error);\n\t\n\tfunction createBuiltInError(name) {\n\t  var message = 'builtin ' + name +\n\t    ' function requires map values to be numbers' +\n\t    ' or number arrays';\n\t  return new BuiltInError(message);\n\t}\n\t\n\tfunction sum(values) {\n\t  var result = 0;\n\t  for (var i = 0, len = values.length; i < len; i++) {\n\t    var num = values[i];\n\t    if (typeof num !== 'number') {\n\t      if (Array.isArray(num)) {\n\t        // lists of numbers are also allowed, sum them separately\n\t        result = typeof result === 'number' ? [result] : result;\n\t        for (var j = 0, jLen = num.length; j < jLen; j++) {\n\t          var jNum = num[j];\n\t          if (typeof jNum !== 'number') {\n\t            throw createBuiltInError('_sum');\n\t          } else if (typeof result[j] === 'undefined') {\n\t            result.push(jNum);\n\t          } else {\n\t            result[j] += jNum;\n\t          }\n\t        }\n\t      } else { // not array/number\n\t        throw createBuiltInError('_sum');\n\t      }\n\t    } else if (typeof result === 'number') {\n\t      result += num;\n\t    } else { // add number to array\n\t      result[0] += num;\n\t    }\n\t  }\n\t  return result;\n\t}\n\t\n\tvar log$2 = guardedConsole.bind(null, 'log');\n\tvar isArray = Array.isArray;\n\tvar toJSON = JSON.parse;\n\t\n\tfunction evalFunctionWithEval(func, emit) {\n\t  return scopedEval(\n\t    \"return (\" + func.replace(/;\\s*$/, \"\") + \");\",\n\t    {\n\t      emit: emit,\n\t      sum: sum,\n\t      log: log$2,\n\t      isArray: isArray,\n\t      toJSON: toJSON\n\t    }\n\t  );\n\t}\n\t\n\tfunction promisedCallback(promise, callback) {\n\t  if (callback) {\n\t    promise.then(function (res) {\n\t      nextTick(function () {\n\t        callback(null, res);\n\t      });\n\t    }, function (reason) {\n\t      nextTick(function () {\n\t        callback(reason);\n\t      });\n\t    });\n\t  }\n\t  return promise;\n\t}\n\t\n\tfunction callbackify(fun) {\n\t  return getArguments(function (args) {\n\t    var cb = args.pop();\n\t    var promise = fun.apply(this, args);\n\t    if (typeof cb === 'function') {\n\t      promisedCallback(promise, cb);\n\t    }\n\t    return promise;\n\t  });\n\t}\n\t\n\t// Promise finally util similar to Q.finally\n\tfunction fin(promise, finalPromiseFactory) {\n\t  return promise.then(function (res) {\n\t    return finalPromiseFactory().then(function () {\n\t      return res;\n\t    });\n\t  }, function (reason) {\n\t    return finalPromiseFactory().then(function () {\n\t      throw reason;\n\t    });\n\t  });\n\t}\n\t\n\tfunction sequentialize(queue, promiseFactory) {\n\t  return function () {\n\t    var args = arguments;\n\t    var that = this;\n\t    return queue.add(function () {\n\t      return promiseFactory.apply(that, args);\n\t    });\n\t  };\n\t}\n\t\n\t// uniq an array of strings, order not guaranteed\n\t// similar to underscore/lodash _.uniq\n\tfunction uniq(arr) {\n\t  var theSet = new ExportedSet(arr);\n\t  var result = new Array(theSet.size);\n\t  var index = -1;\n\t  theSet.forEach(function (value) {\n\t    result[++index] = value;\n\t  });\n\t  return result;\n\t}\n\t\n\tfunction mapToKeysArray(map) {\n\t  var result = new Array(map.size);\n\t  var index = -1;\n\t  map.forEach(function (value, key) {\n\t    result[++index] = key;\n\t  });\n\t  return result;\n\t}\n\t\n\tvar persistentQueues = {};\n\tvar tempViewQueue = new TaskQueue$2();\n\tvar CHANGES_BATCH_SIZE$1 = 50;\n\t\n\tfunction parseViewName(name) {\n\t  // can be either 'ddocname/viewname' or just 'viewname'\n\t  // (where the ddoc name is the same)\n\t  return name.indexOf('/') === -1 ? [name, name] : name.split('/');\n\t}\n\t\n\tfunction isGenOne(changes) {\n\t  // only return true if the current change is 1-\n\t  // and there are no other leafs\n\t  return changes.length === 1 && /^1-/.test(changes[0].rev);\n\t}\n\t\n\tfunction emitError(db, e) {\n\t  try {\n\t    db.emit('error', e);\n\t  } catch (err) {\n\t    guardedConsole('error',\n\t      'The user\\'s map/reduce function threw an uncaught error.\\n' +\n\t      'You can debug this error by doing:\\n' +\n\t      'myDatabase.on(\\'error\\', function (err) { debugger; });\\n' +\n\t      'Please double-check your map/reduce function.');\n\t    guardedConsole('error', e);\n\t  }\n\t}\n\tfunction tryMap(db, fun, doc) {\n\t  // emit an event if there was an error thrown by a map function.\n\t  // putting try/catches in a single function also avoids deoptimizations.\n\t  try {\n\t    fun(doc);\n\t  } catch (e) {\n\t    emitError(db, e);\n\t  }\n\t}\n\t\n\tfunction tryReduce(db, fun, keys, values, rereduce) {\n\t  // same as above, but returning the result or an error. there are two separate\n\t  // functions to avoid extra memory allocations since the tryCode() case is used\n\t  // for custom map functions (common) vs this function, which is only used for\n\t  // custom reduce functions (rare)\n\t  try {\n\t    return {output : fun(keys, values, rereduce)};\n\t  } catch (e) {\n\t    emitError(db, e);\n\t    return {error: e};\n\t  }\n\t}\n\t\n\tfunction sortByKeyThenValue(x, y) {\n\t  var keyCompare = collate(x.key, y.key);\n\t  return keyCompare !== 0 ? keyCompare : collate(x.value, y.value);\n\t}\n\t\n\tfunction sliceResults(results, limit, skip) {\n\t  skip = skip || 0;\n\t  if (typeof limit === 'number') {\n\t    return results.slice(skip, limit + skip);\n\t  } else if (skip > 0) {\n\t    return results.slice(skip);\n\t  }\n\t  return results;\n\t}\n\t\n\tfunction rowToDocId(row) {\n\t  var val = row.value;\n\t  // Users can explicitly specify a joined doc _id, or it\n\t  // defaults to the doc _id that emitted the key/value.\n\t  var docId = (val && typeof val === 'object' && val._id) || row.id;\n\t  return docId;\n\t}\n\t\n\tfunction readAttachmentsAsBlobOrBuffer$1(res) {\n\t  res.rows.forEach(function (row) {\n\t    var atts = row.doc && row.doc._attachments;\n\t    if (!atts) {\n\t      return;\n\t    }\n\t    Object.keys(atts).forEach(function (filename) {\n\t      var att = atts[filename];\n\t      atts[filename].data = b64ToBluffer(att.data, att.content_type);\n\t    });\n\t  });\n\t}\n\t\n\tfunction postprocessAttachments(opts) {\n\t  return function (res) {\n\t    if (opts.include_docs && opts.attachments && opts.binary) {\n\t      readAttachmentsAsBlobOrBuffer$1(res);\n\t    }\n\t    return res;\n\t  };\n\t}\n\t\n\tvar builtInReduce = {\n\t  _sum: function (keys, values) {\n\t    return sum(values);\n\t  },\n\t\n\t  _count: function (keys, values) {\n\t    return values.length;\n\t  },\n\t\n\t  _stats: function (keys, values) {\n\t    // no need to implement rereduce=true, because Pouch\n\t    // will never call it\n\t    function sumsqr(values) {\n\t      var _sumsqr = 0;\n\t      for (var i = 0, len = values.length; i < len; i++) {\n\t        var num = values[i];\n\t        _sumsqr += (num * num);\n\t      }\n\t      return _sumsqr;\n\t    }\n\t    return {\n\t      sum     : sum(values),\n\t      min     : Math.min.apply(null, values),\n\t      max     : Math.max.apply(null, values),\n\t      count   : values.length,\n\t      sumsqr : sumsqr(values)\n\t    };\n\t  }\n\t};\n\t\n\tfunction addHttpParam(paramName, opts, params, asJson) {\n\t  // add an http param from opts to params, optionally json-encoded\n\t  var val = opts[paramName];\n\t  if (typeof val !== 'undefined') {\n\t    if (asJson) {\n\t      val = encodeURIComponent(JSON.stringify(val));\n\t    }\n\t    params.push(paramName + '=' + val);\n\t  }\n\t}\n\t\n\tfunction coerceInteger(integerCandidate) {\n\t  if (typeof integerCandidate !== 'undefined') {\n\t    var asNumber = Number(integerCandidate);\n\t    // prevents e.g. '1foo' or '1.1' being coerced to 1\n\t    if (!isNaN(asNumber) && asNumber === parseInt(integerCandidate, 10)) {\n\t      return asNumber;\n\t    } else {\n\t      return integerCandidate;\n\t    }\n\t  }\n\t}\n\t\n\tfunction coerceOptions(opts) {\n\t  opts.group_level = coerceInteger(opts.group_level);\n\t  opts.limit = coerceInteger(opts.limit);\n\t  opts.skip = coerceInteger(opts.skip);\n\t  return opts;\n\t}\n\t\n\tfunction checkPositiveInteger(number) {\n\t  if (number) {\n\t    if (typeof number !== 'number') {\n\t      return  new QueryParseError('Invalid value for integer: \"' +\n\t      number + '\"');\n\t    }\n\t    if (number < 0) {\n\t      return new QueryParseError('Invalid value for positive integer: ' +\n\t        '\"' + number + '\"');\n\t    }\n\t  }\n\t}\n\t\n\tfunction checkQueryParseError(options, fun) {\n\t  var startkeyName = options.descending ? 'endkey' : 'startkey';\n\t  var endkeyName = options.descending ? 'startkey' : 'endkey';\n\t\n\t  if (typeof options[startkeyName] !== 'undefined' &&\n\t    typeof options[endkeyName] !== 'undefined' &&\n\t    collate(options[startkeyName], options[endkeyName]) > 0) {\n\t    throw new QueryParseError('No rows can match your key range, ' +\n\t    'reverse your start_key and end_key or set {descending : true}');\n\t  } else if (fun.reduce && options.reduce !== false) {\n\t    if (options.include_docs) {\n\t      throw new QueryParseError('{include_docs:true} is invalid for reduce');\n\t    } else if (options.keys && options.keys.length > 1 &&\n\t        !options.group && !options.group_level) {\n\t      throw new QueryParseError('Multi-key fetches for reduce views must use ' +\n\t      '{group: true}');\n\t    }\n\t  }\n\t  ['group_level', 'limit', 'skip'].forEach(function (optionName) {\n\t    var error = checkPositiveInteger(options[optionName]);\n\t    if (error) {\n\t      throw error;\n\t    }\n\t  });\n\t}\n\t\n\tfunction httpQuery(db, fun, opts) {\n\t  // List of parameters to add to the PUT request\n\t  var params = [];\n\t  var body;\n\t  var method = 'GET';\n\t\n\t  // If opts.reduce exists and is defined, then add it to the list\n\t  // of parameters.\n\t  // If reduce=false then the results are that of only the map function\n\t  // not the final result of map and reduce.\n\t  addHttpParam('reduce', opts, params);\n\t  addHttpParam('include_docs', opts, params);\n\t  addHttpParam('attachments', opts, params);\n\t  addHttpParam('limit', opts, params);\n\t  addHttpParam('descending', opts, params);\n\t  addHttpParam('group', opts, params);\n\t  addHttpParam('group_level', opts, params);\n\t  addHttpParam('skip', opts, params);\n\t  addHttpParam('stale', opts, params);\n\t  addHttpParam('conflicts', opts, params);\n\t  addHttpParam('startkey', opts, params, true);\n\t  addHttpParam('start_key', opts, params, true);\n\t  addHttpParam('endkey', opts, params, true);\n\t  addHttpParam('end_key', opts, params, true);\n\t  addHttpParam('inclusive_end', opts, params);\n\t  addHttpParam('key', opts, params, true);\n\t\n\t  // Format the list of parameters into a valid URI query string\n\t  params = params.join('&');\n\t  params = params === '' ? '' : '?' + params;\n\t\n\t  // If keys are supplied, issue a POST to circumvent GET query string limits\n\t  // see http://wiki.apache.org/couchdb/HTTP_view_API#Querying_Options\n\t  if (typeof opts.keys !== 'undefined') {\n\t    var MAX_URL_LENGTH = 2000;\n\t    // according to http://stackoverflow.com/a/417184/680742,\n\t    // the de facto URL length limit is 2000 characters\n\t\n\t    var keysAsString =\n\t      'keys=' + encodeURIComponent(JSON.stringify(opts.keys));\n\t    if (keysAsString.length + params.length + 1 <= MAX_URL_LENGTH) {\n\t      // If the keys are short enough, do a GET. we do this to work around\n\t      // Safari not understanding 304s on POSTs (see pouchdb/pouchdb#1239)\n\t      params += (params[0] === '?' ? '&' : '?') + keysAsString;\n\t    } else {\n\t      method = 'POST';\n\t      if (typeof fun === 'string') {\n\t        body = {keys: opts.keys};\n\t      } else { // fun is {map : mapfun}, so append to this\n\t        fun.keys = opts.keys;\n\t      }\n\t    }\n\t  }\n\t\n\t  // We are referencing a query defined in the design doc\n\t  if (typeof fun === 'string') {\n\t    var parts = parseViewName(fun);\n\t    return db.request({\n\t      method: method,\n\t      url: '_design/' + parts[0] + '/_view/' + parts[1] + params,\n\t      body: body\n\t    }).then(postprocessAttachments(opts));\n\t  }\n\t\n\t  // We are using a temporary view, terrible for performance, good for testing\n\t  body = body || {};\n\t  Object.keys(fun).forEach(function (key) {\n\t    if (Array.isArray(fun[key])) {\n\t      body[key] = fun[key];\n\t    } else {\n\t      body[key] = fun[key].toString();\n\t    }\n\t  });\n\t  return db.request({\n\t    method: 'POST',\n\t    url: '_temp_view' + params,\n\t    body: body\n\t  }).then(postprocessAttachments(opts));\n\t}\n\t\n\t// custom adapters can define their own api._query\n\t// and override the default behavior\n\t/* istanbul ignore next */\n\tfunction customQuery(db, fun, opts) {\n\t  return new PouchPromise$1(function (resolve, reject) {\n\t    db._query(fun, opts, function (err, res) {\n\t      if (err) {\n\t        return reject(err);\n\t      }\n\t      resolve(res);\n\t    });\n\t  });\n\t}\n\t\n\t// custom adapters can define their own api._viewCleanup\n\t// and override the default behavior\n\t/* istanbul ignore next */\n\tfunction customViewCleanup(db) {\n\t  return new PouchPromise$1(function (resolve, reject) {\n\t    db._viewCleanup(function (err, res) {\n\t      if (err) {\n\t        return reject(err);\n\t      }\n\t      resolve(res);\n\t    });\n\t  });\n\t}\n\t\n\tfunction defaultsTo(value) {\n\t  return function (reason) {\n\t    /* istanbul ignore else */\n\t    if (reason.status === 404) {\n\t      return value;\n\t    } else {\n\t      throw reason;\n\t    }\n\t  };\n\t}\n\t\n\t// returns a promise for a list of docs to update, based on the input docId.\n\t// the order doesn't matter, because post-3.2.0, bulkDocs\n\t// is an atomic operation in all three adapters.\n\tfunction getDocsToPersist(docId, view, docIdsToChangesAndEmits) {\n\t  var metaDocId = '_local/doc_' + docId;\n\t  var defaultMetaDoc = {_id: metaDocId, keys: []};\n\t  var docData = docIdsToChangesAndEmits.get(docId);\n\t  var indexableKeysToKeyValues = docData[0];\n\t  var changes = docData[1];\n\t\n\t  function getMetaDoc() {\n\t    if (isGenOne(changes)) {\n\t      // generation 1, so we can safely assume initial state\n\t      // for performance reasons (avoids unnecessary GETs)\n\t      return PouchPromise$1.resolve(defaultMetaDoc);\n\t    }\n\t    return view.db.get(metaDocId).catch(defaultsTo(defaultMetaDoc));\n\t  }\n\t\n\t  function getKeyValueDocs(metaDoc) {\n\t    if (!metaDoc.keys.length) {\n\t      // no keys, no need for a lookup\n\t      return PouchPromise$1.resolve({rows: []});\n\t    }\n\t    return view.db.allDocs({\n\t      keys: metaDoc.keys,\n\t      include_docs: true\n\t    });\n\t  }\n\t\n\t  function processKeyValueDocs(metaDoc, kvDocsRes) {\n\t    var kvDocs = [];\n\t    var oldKeys = new ExportedSet();\n\t\n\t    for (var i = 0, len = kvDocsRes.rows.length; i < len; i++) {\n\t      var row = kvDocsRes.rows[i];\n\t      var doc = row.doc;\n\t      if (!doc) { // deleted\n\t        continue;\n\t      }\n\t      kvDocs.push(doc);\n\t      oldKeys.add(doc._id);\n\t      doc._deleted = !indexableKeysToKeyValues.has(doc._id);\n\t      if (!doc._deleted) {\n\t        var keyValue = indexableKeysToKeyValues.get(doc._id);\n\t        if ('value' in keyValue) {\n\t          doc.value = keyValue.value;\n\t        }\n\t      }\n\t    }\n\t    var newKeys = mapToKeysArray(indexableKeysToKeyValues);\n\t    newKeys.forEach(function (key) {\n\t      if (!oldKeys.has(key)) {\n\t        // new doc\n\t        var kvDoc = {\n\t          _id: key\n\t        };\n\t        var keyValue = indexableKeysToKeyValues.get(key);\n\t        if ('value' in keyValue) {\n\t          kvDoc.value = keyValue.value;\n\t        }\n\t        kvDocs.push(kvDoc);\n\t      }\n\t    });\n\t    metaDoc.keys = uniq(newKeys.concat(metaDoc.keys));\n\t    kvDocs.push(metaDoc);\n\t\n\t    return kvDocs;\n\t  }\n\t\n\t  return getMetaDoc().then(function (metaDoc) {\n\t    return getKeyValueDocs(metaDoc).then(function (kvDocsRes) {\n\t      return processKeyValueDocs(metaDoc, kvDocsRes);\n\t    });\n\t  });\n\t}\n\t\n\t// updates all emitted key/value docs and metaDocs in the mrview database\n\t// for the given batch of documents from the source database\n\tfunction saveKeyValues(view, docIdsToChangesAndEmits, seq) {\n\t  var seqDocId = '_local/lastSeq';\n\t  return view.db.get(seqDocId)\n\t  .catch(defaultsTo({_id: seqDocId, seq: 0}))\n\t  .then(function (lastSeqDoc) {\n\t    var docIds = mapToKeysArray(docIdsToChangesAndEmits);\n\t    return PouchPromise$1.all(docIds.map(function (docId) {\n\t      return getDocsToPersist(docId, view, docIdsToChangesAndEmits);\n\t    })).then(function (listOfDocsToPersist) {\n\t      var docsToPersist = flatten(listOfDocsToPersist);\n\t      lastSeqDoc.seq = seq;\n\t      docsToPersist.push(lastSeqDoc);\n\t      // write all docs in a single operation, update the seq once\n\t      return view.db.bulkDocs({docs : docsToPersist});\n\t    });\n\t  });\n\t}\n\t\n\tfunction getQueue(view) {\n\t  var viewName = typeof view === 'string' ? view : view.name;\n\t  var queue = persistentQueues[viewName];\n\t  if (!queue) {\n\t    queue = persistentQueues[viewName] = new TaskQueue$2();\n\t  }\n\t  return queue;\n\t}\n\t\n\tfunction updateView(view) {\n\t  return sequentialize(getQueue(view), function () {\n\t    return updateViewInQueue(view);\n\t  })();\n\t}\n\t\n\tfunction updateViewInQueue(view) {\n\t  // bind the emit function once\n\t  var mapResults;\n\t  var doc;\n\t\n\t  function emit(key, value) {\n\t    var output = {id: doc._id, key: normalizeKey(key)};\n\t    // Don't explicitly store the value unless it's defined and non-null.\n\t    // This saves on storage space, because often people don't use it.\n\t    if (typeof value !== 'undefined' && value !== null) {\n\t      output.value = normalizeKey(value);\n\t    }\n\t    mapResults.push(output);\n\t  }\n\t\n\t  var mapFun;\n\t  // for temp_views one can use emit(doc, emit), see #38\n\t  if (typeof view.mapFun === \"function\" && view.mapFun.length === 2) {\n\t    var origMap = view.mapFun;\n\t    mapFun = function (doc) {\n\t      return origMap(doc, emit);\n\t    };\n\t  } else {\n\t    mapFun = evalFunctionWithEval(view.mapFun.toString(), emit);\n\t  }\n\t\n\t  var currentSeq = view.seq || 0;\n\t\n\t  function processChange(docIdsToChangesAndEmits, seq) {\n\t    return function () {\n\t      return saveKeyValues(view, docIdsToChangesAndEmits, seq);\n\t    };\n\t  }\n\t\n\t  var queue = new TaskQueue$2();\n\t\n\t  function processNextBatch() {\n\t    return view.sourceDB.changes({\n\t      conflicts: true,\n\t      include_docs: true,\n\t      style: 'all_docs',\n\t      since: currentSeq,\n\t      limit: CHANGES_BATCH_SIZE$1\n\t    }).then(processBatch);\n\t  }\n\t\n\t  function processBatch(response) {\n\t    var results = response.results;\n\t    if (!results.length) {\n\t      return;\n\t    }\n\t    var docIdsToChangesAndEmits = createDocIdsToChangesAndEmits(results);\n\t    queue.add(processChange(docIdsToChangesAndEmits, currentSeq));\n\t    if (results.length < CHANGES_BATCH_SIZE$1) {\n\t      return;\n\t    }\n\t    return processNextBatch();\n\t  }\n\t\n\t  function createDocIdsToChangesAndEmits(results) {\n\t    var docIdsToChangesAndEmits = new ExportedMap();\n\t    for (var i = 0, len = results.length; i < len; i++) {\n\t      var change = results[i];\n\t      if (change.doc._id[0] !== '_') {\n\t        mapResults = [];\n\t        doc = change.doc;\n\t\n\t        if (!doc._deleted) {\n\t          tryMap(view.sourceDB, mapFun, doc);\n\t        }\n\t        mapResults.sort(sortByKeyThenValue);\n\t\n\t        var indexableKeysToKeyValues = createIndexableKeysToKeyValues(mapResults);\n\t        docIdsToChangesAndEmits.set(change.doc._id, [\n\t          indexableKeysToKeyValues,\n\t          change.changes\n\t        ]);\n\t      }\n\t      currentSeq = change.seq;\n\t    }\n\t    return docIdsToChangesAndEmits;\n\t  }\n\t\n\t  function createIndexableKeysToKeyValues(mapResults) {\n\t    var indexableKeysToKeyValues = new ExportedMap();\n\t    var lastKey;\n\t    for (var i = 0, len = mapResults.length; i < len; i++) {\n\t      var emittedKeyValue = mapResults[i];\n\t      var complexKey = [emittedKeyValue.key, emittedKeyValue.id];\n\t      if (i > 0 && collate(emittedKeyValue.key, lastKey) === 0) {\n\t        complexKey.push(i); // dup key+id, so make it unique\n\t      }\n\t      indexableKeysToKeyValues.set(toIndexableString(complexKey), emittedKeyValue);\n\t      lastKey = emittedKeyValue.key;\n\t    }\n\t    return indexableKeysToKeyValues;\n\t  }\n\t\n\t  return processNextBatch().then(function () {\n\t    return queue.finish();\n\t  }).then(function () {\n\t    view.seq = currentSeq;\n\t  });\n\t}\n\t\n\tfunction reduceView(view, results, options) {\n\t  if (options.group_level === 0) {\n\t    delete options.group_level;\n\t  }\n\t\n\t  var shouldGroup = options.group || options.group_level;\n\t\n\t  var reduceFun;\n\t  if (builtInReduce[view.reduceFun]) {\n\t    reduceFun = builtInReduce[view.reduceFun];\n\t  } else {\n\t    reduceFun = evalFunctionWithEval(view.reduceFun.toString());\n\t  }\n\t\n\t  var groups = [];\n\t  var lvl = isNaN(options.group_level) ? Number.POSITIVE_INFINITY :\n\t    options.group_level;\n\t  results.forEach(function (e) {\n\t    var last = groups[groups.length - 1];\n\t    var groupKey = shouldGroup ? e.key : null;\n\t\n\t    // only set group_level for array keys\n\t    if (shouldGroup && Array.isArray(groupKey)) {\n\t      groupKey = groupKey.slice(0, lvl);\n\t    }\n\t\n\t    if (last && collate(last.groupKey, groupKey) === 0) {\n\t      last.keys.push([e.key, e.id]);\n\t      last.values.push(e.value);\n\t      return;\n\t    }\n\t    groups.push({\n\t      keys: [[e.key, e.id]],\n\t      values: [e.value],\n\t      groupKey: groupKey\n\t    });\n\t  });\n\t  results = [];\n\t  for (var i = 0, len = groups.length; i < len; i++) {\n\t    var e = groups[i];\n\t    var reduceTry = tryReduce(view.sourceDB, reduceFun, e.keys, e.values, false);\n\t    if (reduceTry.error && reduceTry.error instanceof BuiltInError) {\n\t      // CouchDB returns an error if a built-in errors out\n\t      throw reduceTry.error;\n\t    }\n\t    results.push({\n\t      // CouchDB just sets the value to null if a non-built-in errors out\n\t      value: reduceTry.error ? null : reduceTry.output,\n\t      key: e.groupKey\n\t    });\n\t  }\n\t  // no total_rows/offset when reducing\n\t  return {rows: sliceResults(results, options.limit, options.skip)};\n\t}\n\t\n\tfunction queryView(view, opts) {\n\t  return sequentialize(getQueue(view), function () {\n\t    return queryViewInQueue(view, opts);\n\t  })();\n\t}\n\t\n\tfunction queryViewInQueue(view, opts) {\n\t  var totalRows;\n\t  var shouldReduce = view.reduceFun && opts.reduce !== false;\n\t  var skip = opts.skip || 0;\n\t  if (typeof opts.keys !== 'undefined' && !opts.keys.length) {\n\t    // equivalent query\n\t    opts.limit = 0;\n\t    delete opts.keys;\n\t  }\n\t\n\t  function fetchFromView(viewOpts) {\n\t    viewOpts.include_docs = true;\n\t    return view.db.allDocs(viewOpts).then(function (res) {\n\t      totalRows = res.total_rows;\n\t      return res.rows.map(function (result) {\n\t\n\t        // implicit migration - in older versions of PouchDB,\n\t        // we explicitly stored the doc as {id: ..., key: ..., value: ...}\n\t        // this is tested in a migration test\n\t        /* istanbul ignore next */\n\t        if ('value' in result.doc && typeof result.doc.value === 'object' &&\n\t            result.doc.value !== null) {\n\t          var keys = Object.keys(result.doc.value).sort();\n\t          // this detection method is not perfect, but it's unlikely the user\n\t          // emitted a value which was an object with these 3 exact keys\n\t          var expectedKeys = ['id', 'key', 'value'];\n\t          if (!(keys < expectedKeys || keys > expectedKeys)) {\n\t            return result.doc.value;\n\t          }\n\t        }\n\t\n\t        var parsedKeyAndDocId = parseIndexableString(result.doc._id);\n\t        return {\n\t          key: parsedKeyAndDocId[0],\n\t          id: parsedKeyAndDocId[1],\n\t          value: ('value' in result.doc ? result.doc.value : null)\n\t        };\n\t      });\n\t    });\n\t  }\n\t\n\t  function onMapResultsReady(rows) {\n\t    var finalResults;\n\t    if (shouldReduce) {\n\t      finalResults = reduceView(view, rows, opts);\n\t    } else {\n\t      finalResults = {\n\t        total_rows: totalRows,\n\t        offset: skip,\n\t        rows: rows\n\t      };\n\t    }\n\t    if (opts.include_docs) {\n\t      var docIds = uniq(rows.map(rowToDocId));\n\t\n\t      return view.sourceDB.allDocs({\n\t        keys: docIds,\n\t        include_docs: true,\n\t        conflicts: opts.conflicts,\n\t        attachments: opts.attachments,\n\t        binary: opts.binary\n\t      }).then(function (allDocsRes) {\n\t        var docIdsToDocs = new ExportedMap();\n\t        allDocsRes.rows.forEach(function (row) {\n\t          docIdsToDocs.set(row.id, row.doc);\n\t        });\n\t        rows.forEach(function (row) {\n\t          var docId = rowToDocId(row);\n\t          var doc = docIdsToDocs.get(docId);\n\t          if (doc) {\n\t            row.doc = doc;\n\t          }\n\t        });\n\t        return finalResults;\n\t      });\n\t    } else {\n\t      return finalResults;\n\t    }\n\t  }\n\t\n\t  if (typeof opts.keys !== 'undefined') {\n\t    var keys = opts.keys;\n\t    var fetchPromises = keys.map(function (key) {\n\t      var viewOpts = {\n\t        startkey : toIndexableString([key]),\n\t        endkey   : toIndexableString([key, {}])\n\t      };\n\t      return fetchFromView(viewOpts);\n\t    });\n\t    return PouchPromise$1.all(fetchPromises).then(flatten).then(onMapResultsReady);\n\t  } else { // normal query, no 'keys'\n\t    var viewOpts = {\n\t      descending : opts.descending\n\t    };\n\t    if (opts.start_key) {\n\t        opts.startkey = opts.start_key;\n\t    }\n\t    if (opts.end_key) {\n\t        opts.endkey = opts.end_key;\n\t    }\n\t    if (typeof opts.startkey !== 'undefined') {\n\t      viewOpts.startkey = opts.descending ?\n\t        toIndexableString([opts.startkey, {}]) :\n\t        toIndexableString([opts.startkey]);\n\t    }\n\t    if (typeof opts.endkey !== 'undefined') {\n\t      var inclusiveEnd = opts.inclusive_end !== false;\n\t      if (opts.descending) {\n\t        inclusiveEnd = !inclusiveEnd;\n\t      }\n\t\n\t      viewOpts.endkey = toIndexableString(\n\t        inclusiveEnd ? [opts.endkey, {}] : [opts.endkey]);\n\t    }\n\t    if (typeof opts.key !== 'undefined') {\n\t      var keyStart = toIndexableString([opts.key]);\n\t      var keyEnd = toIndexableString([opts.key, {}]);\n\t      if (viewOpts.descending) {\n\t        viewOpts.endkey = keyStart;\n\t        viewOpts.startkey = keyEnd;\n\t      } else {\n\t        viewOpts.startkey = keyStart;\n\t        viewOpts.endkey = keyEnd;\n\t      }\n\t    }\n\t    if (!shouldReduce) {\n\t      if (typeof opts.limit === 'number') {\n\t        viewOpts.limit = opts.limit;\n\t      }\n\t      viewOpts.skip = skip;\n\t    }\n\t    return fetchFromView(viewOpts).then(onMapResultsReady);\n\t  }\n\t}\n\t\n\tfunction httpViewCleanup(db) {\n\t  return db.request({\n\t    method: 'POST',\n\t    url: '_view_cleanup'\n\t  });\n\t}\n\t\n\tfunction localViewCleanup(db) {\n\t  return db.get('_local/mrviews').then(function (metaDoc) {\n\t    var docsToViews = new ExportedMap();\n\t    Object.keys(metaDoc.views).forEach(function (fullViewName) {\n\t      var parts = parseViewName(fullViewName);\n\t      var designDocName = '_design/' + parts[0];\n\t      var viewName = parts[1];\n\t      var views = docsToViews.get(designDocName);\n\t      if (!views) {\n\t        views = new ExportedSet();\n\t        docsToViews.set(designDocName, views);\n\t      }\n\t      views.add(viewName);\n\t    });\n\t    var opts = {\n\t      keys : mapToKeysArray(docsToViews),\n\t      include_docs : true\n\t    };\n\t    return db.allDocs(opts).then(function (res) {\n\t      var viewsToStatus = {};\n\t      res.rows.forEach(function (row) {\n\t        var ddocName = row.key.substring(8); // cuts off '_design/'\n\t        docsToViews.get(row.key).forEach(function (viewName) {\n\t          var fullViewName = ddocName + '/' + viewName;\n\t          /* istanbul ignore if */\n\t          if (!metaDoc.views[fullViewName]) {\n\t            // new format, without slashes, to support PouchDB 2.2.0\n\t            // migration test in pouchdb's browser.migration.js verifies this\n\t            fullViewName = viewName;\n\t          }\n\t          var viewDBNames = Object.keys(metaDoc.views[fullViewName]);\n\t          // design doc deleted, or view function nonexistent\n\t          var statusIsGood = row.doc && row.doc.views &&\n\t            row.doc.views[viewName];\n\t          viewDBNames.forEach(function (viewDBName) {\n\t            viewsToStatus[viewDBName] =\n\t              viewsToStatus[viewDBName] || statusIsGood;\n\t          });\n\t        });\n\t      });\n\t      var dbsToDelete = Object.keys(viewsToStatus).filter(\n\t        function (viewDBName) { return !viewsToStatus[viewDBName]; });\n\t      var destroyPromises = dbsToDelete.map(function (viewDBName) {\n\t        return sequentialize(getQueue(viewDBName), function () {\n\t          return new db.constructor(viewDBName, db.__opts).destroy();\n\t        })();\n\t      });\n\t      return PouchPromise$1.all(destroyPromises).then(function () {\n\t        return {ok: true};\n\t      });\n\t    });\n\t  }, defaultsTo({ok: true}));\n\t}\n\t\n\tvar viewCleanup = callbackify(function () {\n\t  var db = this;\n\t  if (db.type() === 'http') {\n\t    return httpViewCleanup(db);\n\t  }\n\t  /* istanbul ignore next */\n\t  if (typeof db._viewCleanup === 'function') {\n\t    return customViewCleanup(db);\n\t  }\n\t  return localViewCleanup(db);\n\t});\n\t\n\tfunction queryPromised(db, fun, opts) {\n\t  if (db.type() === 'http') {\n\t    return httpQuery(db, fun, opts);\n\t  }\n\t\n\t  /* istanbul ignore next */\n\t  if (typeof db._query === 'function') {\n\t    return customQuery(db, fun, opts);\n\t  }\n\t\n\t  if (typeof fun !== 'string') {\n\t    // temp_view\n\t    checkQueryParseError(opts, fun);\n\t\n\t    var createViewOpts = {\n\t      db : db,\n\t      viewName : 'temp_view/temp_view',\n\t      map : fun.map,\n\t      reduce : fun.reduce,\n\t      temporary : true\n\t    };\n\t    tempViewQueue.add(function () {\n\t      return createView(createViewOpts).then(function (view) {\n\t        function cleanup() {\n\t          return view.db.destroy();\n\t        }\n\t        return fin(updateView(view).then(function () {\n\t          return queryView(view, opts);\n\t        }), cleanup);\n\t      });\n\t    });\n\t    return tempViewQueue.finish();\n\t  } else {\n\t    // persistent view\n\t    var fullViewName = fun;\n\t    var parts = parseViewName(fullViewName);\n\t    var designDocName = parts[0];\n\t    var viewName = parts[1];\n\t    return db.get('_design/' + designDocName).then(function (doc) {\n\t      var fun = doc.views && doc.views[viewName];\n\t\n\t      if (!fun || typeof fun.map !== 'string') {\n\t        throw new NotFoundError('ddoc ' + designDocName +\n\t        ' has no view named ' + viewName);\n\t      }\n\t      checkQueryParseError(opts, fun);\n\t\n\t      var createViewOpts = {\n\t        db : db,\n\t        viewName : fullViewName,\n\t        map : fun.map,\n\t        reduce : fun.reduce\n\t      };\n\t      return createView(createViewOpts).then(function (view) {\n\t        if (opts.stale === 'ok' || opts.stale === 'update_after') {\n\t          if (opts.stale === 'update_after') {\n\t            nextTick(function () {\n\t              updateView(view);\n\t            });\n\t          }\n\t          return queryView(view, opts);\n\t        } else { // stale not ok\n\t          return updateView(view).then(function () {\n\t            return queryView(view, opts);\n\t          });\n\t        }\n\t      });\n\t    });\n\t  }\n\t}\n\t\n\tvar query = function (fun, opts, callback) {\n\t  if (typeof opts === 'function') {\n\t    callback = opts;\n\t    opts = {};\n\t  }\n\t  opts = opts ? coerceOptions(opts) : {};\n\t\n\t  if (typeof fun === 'function') {\n\t    fun = {map : fun};\n\t  }\n\t\n\t  var db = this;\n\t  var promise = PouchPromise$1.resolve().then(function () {\n\t    return queryPromised(db, fun, opts);\n\t  });\n\t  promisedCallback(promise, callback);\n\t  return promise;\n\t};\n\t\n\t\n\tvar mapreduce = {\n\t  query: query,\n\t  viewCleanup: viewCleanup\n\t};\n\t\n\tfunction isGenOne$1(rev) {\n\t  return /^1-/.test(rev);\n\t}\n\t\n\tfunction fileHasChanged(localDoc, remoteDoc, filename) {\n\t  return !localDoc._attachments ||\n\t         !localDoc._attachments[filename] ||\n\t         localDoc._attachments[filename].digest !== remoteDoc._attachments[filename].digest;\n\t}\n\t\n\tfunction getDocAttachments(db, doc) {\n\t  var filenames = Object.keys(doc._attachments);\n\t  return PouchPromise$1.all(filenames.map(function (filename) {\n\t    return db.getAttachment(doc._id, filename, {rev: doc._rev});\n\t  }));\n\t}\n\t\n\tfunction getDocAttachmentsFromTargetOrSource(target, src, doc) {\n\t  var doCheckForLocalAttachments = src.type() === 'http' && target.type() !== 'http';\n\t  var filenames = Object.keys(doc._attachments);\n\t\n\t  if (!doCheckForLocalAttachments) {\n\t    return getDocAttachments(src, doc);\n\t  }\n\t\n\t  return target.get(doc._id).then(function (localDoc) {\n\t    return PouchPromise$1.all(filenames.map(function (filename) {\n\t      if (fileHasChanged(localDoc, doc, filename)) {\n\t        return src.getAttachment(doc._id, filename);\n\t      }\n\t\n\t      return target.getAttachment(localDoc._id, filename);\n\t    }));\n\t  }).catch(function (error) {\n\t    /* istanbul ignore if */\n\t    if (error.status !== 404) {\n\t      throw error;\n\t    }\n\t\n\t    return getDocAttachments(src, doc);\n\t  });\n\t}\n\t\n\tfunction createBulkGetOpts(diffs) {\n\t  var requests = [];\n\t  Object.keys(diffs).forEach(function (id) {\n\t    var missingRevs = diffs[id].missing;\n\t    missingRevs.forEach(function (missingRev) {\n\t      requests.push({\n\t        id: id,\n\t        rev: missingRev\n\t      });\n\t    });\n\t  });\n\t\n\t  return {\n\t    docs: requests,\n\t    revs: true,\n\t    latest: true\n\t  };\n\t}\n\t\n\t//\n\t// Fetch all the documents from the src as described in the \"diffs\",\n\t// which is a mapping of docs IDs to revisions. If the state ever\n\t// changes to \"cancelled\", then the returned promise will be rejected.\n\t// Else it will be resolved with a list of fetched documents.\n\t//\n\tfunction getDocs(src, target, diffs, state) {\n\t  diffs = clone(diffs); // we do not need to modify this\n\t\n\t  var resultDocs = [],\n\t      ok = true;\n\t\n\t  function getAllDocs() {\n\t\n\t    var bulkGetOpts = createBulkGetOpts(diffs);\n\t\n\t    if (!bulkGetOpts.docs.length) { // optimization: skip empty requests\n\t      return;\n\t    }\n\t\n\t    return src.bulkGet(bulkGetOpts).then(function (bulkGetResponse) {\n\t      /* istanbul ignore if */\n\t      if (state.cancelled) {\n\t        throw new Error('cancelled');\n\t      }\n\t      return PouchPromise$1.all(bulkGetResponse.results.map(function (bulkGetInfo) {\n\t        return PouchPromise$1.all(bulkGetInfo.docs.map(function (doc) {\n\t          var remoteDoc = doc.ok;\n\t\n\t          if (doc.error) {\n\t            // when AUTO_COMPACTION is set, docs can be returned which look\n\t            // like this: {\"missing\":\"1-7c3ac256b693c462af8442f992b83696\"}\n\t            ok = false;\n\t          }\n\t\n\t          if (!remoteDoc || !remoteDoc._attachments) {\n\t            return remoteDoc;\n\t          }\n\t\n\t          return getDocAttachmentsFromTargetOrSource(target, src, remoteDoc).then(function (attachments) {\n\t            var filenames = Object.keys(remoteDoc._attachments);\n\t            attachments.forEach(function (attachment, i) {\n\t              var att = remoteDoc._attachments[filenames[i]];\n\t              delete att.stub;\n\t              delete att.length;\n\t              att.data = attachment;\n\t            });\n\t\n\t            return remoteDoc;\n\t          });\n\t        }));\n\t      }))\n\t\n\t      .then(function (results) {\n\t        resultDocs = resultDocs.concat(flatten(results).filter(Boolean));\n\t      });\n\t    });\n\t  }\n\t\n\t  function hasAttachments(doc) {\n\t    return doc._attachments && Object.keys(doc._attachments).length > 0;\n\t  }\n\t\n\t  function hasConflicts(doc) {\n\t    return doc._conflicts && doc._conflicts.length > 0;\n\t  }\n\t\n\t  function fetchRevisionOneDocs(ids) {\n\t    // Optimization: fetch gen-1 docs and attachments in\n\t    // a single request using _all_docs\n\t    return src.allDocs({\n\t      keys: ids,\n\t      include_docs: true,\n\t      conflicts: true\n\t    }).then(function (res) {\n\t      if (state.cancelled) {\n\t        throw new Error('cancelled');\n\t      }\n\t      res.rows.forEach(function (row) {\n\t        if (row.deleted || !row.doc || !isGenOne$1(row.value.rev) ||\n\t            hasAttachments(row.doc) || hasConflicts(row.doc)) {\n\t          // if any of these conditions apply, we need to fetch using get()\n\t          return;\n\t        }\n\t\n\t        // strip _conflicts array to appease CSG (#5793)\n\t        /* istanbul ignore if */\n\t        if (row.doc._conflicts) {\n\t          delete row.doc._conflicts;\n\t        }\n\t\n\t        // the doc we got back from allDocs() is sufficient\n\t        resultDocs.push(row.doc);\n\t        delete diffs[row.id];\n\t      });\n\t    });\n\t  }\n\t\n\t  function getRevisionOneDocs() {\n\t    // filter out the generation 1 docs and get them\n\t    // leaving the non-generation one docs to be got otherwise\n\t    var ids = Object.keys(diffs).filter(function (id) {\n\t      var missing = diffs[id].missing;\n\t      return missing.length === 1 && isGenOne$1(missing[0]);\n\t    });\n\t    if (ids.length > 0) {\n\t      return fetchRevisionOneDocs(ids);\n\t    }\n\t  }\n\t\n\t  function returnResult() {\n\t    return { ok:ok, docs:resultDocs };\n\t  }\n\t\n\t  return PouchPromise$1.resolve()\n\t    .then(getRevisionOneDocs)\n\t    .then(getAllDocs)\n\t    .then(returnResult);\n\t}\n\t\n\tvar CHECKPOINT_VERSION = 1;\n\tvar REPLICATOR = \"pouchdb\";\n\t// This is an arbitrary number to limit the\n\t// amount of replication history we save in the checkpoint.\n\t// If we save too much, the checkpoing docs will become very big,\n\t// if we save fewer, we'll run a greater risk of having to\n\t// read all the changes from 0 when checkpoint PUTs fail\n\t// CouchDB 2.0 has a more involved history pruning,\n\t// but let's go for the simple version for now.\n\tvar CHECKPOINT_HISTORY_SIZE = 5;\n\tvar LOWEST_SEQ = 0;\n\t\n\tfunction updateCheckpoint(db, id, checkpoint, session, returnValue) {\n\t  return db.get(id).catch(function (err) {\n\t    if (err.status === 404) {\n\t      if (db.type() === 'http') {\n\t        explainError(\n\t          404, 'PouchDB is just checking if a remote checkpoint exists.'\n\t        );\n\t      }\n\t      return {\n\t        session_id: session,\n\t        _id: id,\n\t        history: [],\n\t        replicator: REPLICATOR,\n\t        version: CHECKPOINT_VERSION\n\t      };\n\t    }\n\t    throw err;\n\t  }).then(function (doc) {\n\t    if (returnValue.cancelled) {\n\t      return;\n\t    }\n\t\n\t    // if the checkpoint has not changed, do not update\n\t    if (doc.last_seq === checkpoint) {\n\t      return;\n\t    }\n\t\n\t    // Filter out current entry for this replication\n\t    doc.history = (doc.history || []).filter(function (item) {\n\t      return item.session_id !== session;\n\t    });\n\t\n\t    // Add the latest checkpoint to history\n\t    doc.history.unshift({\n\t      last_seq: checkpoint,\n\t      session_id: session\n\t    });\n\t\n\t    // Just take the last pieces in history, to\n\t    // avoid really big checkpoint docs.\n\t    // see comment on history size above\n\t    doc.history = doc.history.slice(0, CHECKPOINT_HISTORY_SIZE);\n\t\n\t    doc.version = CHECKPOINT_VERSION;\n\t    doc.replicator = REPLICATOR;\n\t\n\t    doc.session_id = session;\n\t    doc.last_seq = checkpoint;\n\t\n\t    return db.put(doc).catch(function (err) {\n\t      if (err.status === 409) {\n\t        // retry; someone is trying to write a checkpoint simultaneously\n\t        return updateCheckpoint(db, id, checkpoint, session, returnValue);\n\t      }\n\t      throw err;\n\t    });\n\t  });\n\t}\n\t\n\tfunction Checkpointer(src, target, id, returnValue) {\n\t  this.src = src;\n\t  this.target = target;\n\t  this.id = id;\n\t  this.returnValue = returnValue;\n\t}\n\t\n\tCheckpointer.prototype.writeCheckpoint = function (checkpoint, session) {\n\t  var self = this;\n\t  return this.updateTarget(checkpoint, session).then(function () {\n\t    return self.updateSource(checkpoint, session);\n\t  });\n\t};\n\t\n\tCheckpointer.prototype.updateTarget = function (checkpoint, session) {\n\t  return updateCheckpoint(this.target, this.id, checkpoint,\n\t    session, this.returnValue);\n\t};\n\t\n\tCheckpointer.prototype.updateSource = function (checkpoint, session) {\n\t  var self = this;\n\t  if (this.readOnlySource) {\n\t    return PouchPromise$1.resolve(true);\n\t  }\n\t  return updateCheckpoint(this.src, this.id, checkpoint,\n\t    session, this.returnValue)\n\t    .catch(function (err) {\n\t      if (isForbiddenError(err)) {\n\t        self.readOnlySource = true;\n\t        return true;\n\t      }\n\t      throw err;\n\t    });\n\t};\n\t\n\tvar comparisons = {\n\t  \"undefined\": function (targetDoc, sourceDoc) {\n\t    // This is the previous comparison function\n\t    if (collate(targetDoc.last_seq, sourceDoc.last_seq) === 0) {\n\t      return sourceDoc.last_seq;\n\t    }\n\t    /* istanbul ignore next */\n\t    return 0;\n\t  },\n\t  \"1\": function (targetDoc, sourceDoc) {\n\t    // This is the comparison function ported from CouchDB\n\t    return compareReplicationLogs(sourceDoc, targetDoc).last_seq;\n\t  }\n\t};\n\t\n\tCheckpointer.prototype.getCheckpoint = function () {\n\t  var self = this;\n\t  return self.target.get(self.id).then(function (targetDoc) {\n\t    if (self.readOnlySource) {\n\t      return PouchPromise$1.resolve(targetDoc.last_seq);\n\t    }\n\t\n\t    return self.src.get(self.id).then(function (sourceDoc) {\n\t      // Since we can't migrate an old version doc to a new one\n\t      // (no session id), we just go with the lowest seq in this case\n\t      /* istanbul ignore if */\n\t      if (targetDoc.version !== sourceDoc.version) {\n\t        return LOWEST_SEQ;\n\t      }\n\t\n\t      var version;\n\t      if (targetDoc.version) {\n\t        version = targetDoc.version.toString();\n\t      } else {\n\t        version = \"undefined\";\n\t      }\n\t\n\t      if (version in comparisons) {\n\t        return comparisons[version](targetDoc, sourceDoc);\n\t      }\n\t      /* istanbul ignore next */\n\t      return LOWEST_SEQ;\n\t    }, function (err) {\n\t      if (err.status === 404 && targetDoc.last_seq) {\n\t        return self.src.put({\n\t          _id: self.id,\n\t          last_seq: LOWEST_SEQ\n\t        }).then(function () {\n\t          return LOWEST_SEQ;\n\t        }, function (err) {\n\t          if (isForbiddenError(err)) {\n\t            self.readOnlySource = true;\n\t            return targetDoc.last_seq;\n\t          }\n\t          /* istanbul ignore next */\n\t          return LOWEST_SEQ;\n\t        });\n\t      }\n\t      throw err;\n\t    });\n\t  }).catch(function (err) {\n\t    if (err.status !== 404) {\n\t      throw err;\n\t    }\n\t    return LOWEST_SEQ;\n\t  });\n\t};\n\t// This checkpoint comparison is ported from CouchDBs source\n\t// they come from here:\n\t// https://github.com/apache/couchdb-couch-replicator/blob/master/src/couch_replicator.erl#L863-L906\n\t\n\tfunction compareReplicationLogs(srcDoc, tgtDoc) {\n\t  if (srcDoc.session_id === tgtDoc.session_id) {\n\t    return {\n\t      last_seq: srcDoc.last_seq,\n\t      history: srcDoc.history\n\t    };\n\t  }\n\t\n\t  return compareReplicationHistory(srcDoc.history, tgtDoc.history);\n\t}\n\t\n\tfunction compareReplicationHistory(sourceHistory, targetHistory) {\n\t  // the erlang loop via function arguments is not so easy to repeat in JS\n\t  // therefore, doing this as recursion\n\t  var S = sourceHistory[0];\n\t  var sourceRest = sourceHistory.slice(1);\n\t  var T = targetHistory[0];\n\t  var targetRest = targetHistory.slice(1);\n\t\n\t  if (!S || targetHistory.length === 0) {\n\t    return {\n\t      last_seq: LOWEST_SEQ,\n\t      history: []\n\t    };\n\t  }\n\t\n\t  var sourceId = S.session_id;\n\t  /* istanbul ignore if */\n\t  if (hasSessionId(sourceId, targetHistory)) {\n\t    return {\n\t      last_seq: S.last_seq,\n\t      history: sourceHistory\n\t    };\n\t  }\n\t\n\t  var targetId = T.session_id;\n\t  if (hasSessionId(targetId, sourceRest)) {\n\t    return {\n\t      last_seq: T.last_seq,\n\t      history: targetRest\n\t    };\n\t  }\n\t\n\t  return compareReplicationHistory(sourceRest, targetRest);\n\t}\n\t\n\tfunction hasSessionId(sessionId, history) {\n\t  var props = history[0];\n\t  var rest = history.slice(1);\n\t\n\t  if (!sessionId || history.length === 0) {\n\t    return false;\n\t  }\n\t\n\t  if (sessionId === props.session_id) {\n\t    return true;\n\t  }\n\t\n\t  return hasSessionId(sessionId, rest);\n\t}\n\t\n\tfunction isForbiddenError(err) {\n\t  return typeof err.status === 'number' && Math.floor(err.status / 100) === 4;\n\t}\n\t\n\tvar STARTING_BACK_OFF = 0;\n\t\n\tfunction backOff(opts, returnValue, error, callback) {\n\t  if (opts.retry === false) {\n\t    returnValue.emit('error', error);\n\t    returnValue.removeAllListeners();\n\t    return;\n\t  }\n\t  if (typeof opts.back_off_function !== 'function') {\n\t    opts.back_off_function = defaultBackOff;\n\t  }\n\t  returnValue.emit('requestError', error);\n\t  if (returnValue.state === 'active' || returnValue.state === 'pending') {\n\t    returnValue.emit('paused', error);\n\t    returnValue.state = 'stopped';\n\t    var backOffSet = function backoffTimeSet() {\n\t      opts.current_back_off = STARTING_BACK_OFF;\n\t    };\n\t    var removeBackOffSetter = function removeBackOffTimeSet() {\n\t      returnValue.removeListener('active', backOffSet);\n\t    };\n\t    returnValue.once('paused', removeBackOffSetter);\n\t    returnValue.once('active', backOffSet);\n\t  }\n\t\n\t  opts.current_back_off = opts.current_back_off || STARTING_BACK_OFF;\n\t  opts.current_back_off = opts.back_off_function(opts.current_back_off);\n\t  setTimeout(callback, opts.current_back_off);\n\t}\n\t\n\tfunction sortObjectPropertiesByKey(queryParams) {\n\t  return Object.keys(queryParams).sort(collate).reduce(function (result, key) {\n\t    result[key] = queryParams[key];\n\t    return result;\n\t  }, {});\n\t}\n\t\n\t// Generate a unique id particular to this replication.\n\t// Not guaranteed to align perfectly with CouchDB's rep ids.\n\tfunction generateReplicationId(src, target, opts) {\n\t  var docIds = opts.doc_ids ? opts.doc_ids.sort(collate) : '';\n\t  var filterFun = opts.filter ? opts.filter.toString() : '';\n\t  var queryParams = '';\n\t  var filterViewName =  '';\n\t\n\t  if (opts.filter && opts.query_params) {\n\t    queryParams = JSON.stringify(sortObjectPropertiesByKey(opts.query_params));\n\t  }\n\t\n\t  if (opts.filter && opts.filter === '_view') {\n\t    filterViewName = opts.view.toString();\n\t  }\n\t\n\t  return PouchPromise$1.all([src.id(), target.id()]).then(function (res) {\n\t    var queryData = res[0] + res[1] + filterFun + filterViewName +\n\t      queryParams + docIds;\n\t    return new PouchPromise$1(function (resolve) {\n\t      binaryMd5(queryData, resolve);\n\t    });\n\t  }).then(function (md5sum) {\n\t    // can't use straight-up md5 alphabet, because\n\t    // the char '/' is interpreted as being for attachments,\n\t    // and + is also not url-safe\n\t    md5sum = md5sum.replace(/\\//g, '.').replace(/\\+/g, '_');\n\t    return '_local/' + md5sum;\n\t  });\n\t}\n\t\n\tfunction replicate(src, target, opts, returnValue, result) {\n\t  var batches = [];               // list of batches to be processed\n\t  var currentBatch;               // the batch currently being processed\n\t  var pendingBatch = {\n\t    seq: 0,\n\t    changes: [],\n\t    docs: []\n\t  }; // next batch, not yet ready to be processed\n\t  var writingCheckpoint = false;  // true while checkpoint is being written\n\t  var changesCompleted = false;   // true when all changes received\n\t  var replicationCompleted = false; // true when replication has completed\n\t  var last_seq = 0;\n\t  var continuous = opts.continuous || opts.live || false;\n\t  var batch_size = opts.batch_size || 100;\n\t  var batches_limit = opts.batches_limit || 10;\n\t  var changesPending = false;     // true while src.changes is running\n\t  var doc_ids = opts.doc_ids;\n\t  var repId;\n\t  var checkpointer;\n\t  var changedDocs = [];\n\t  // Like couchdb, every replication gets a unique session id\n\t  var session = uuid();\n\t\n\t  result = result || {\n\t    ok: true,\n\t    start_time: new Date(),\n\t    docs_read: 0,\n\t    docs_written: 0,\n\t    doc_write_failures: 0,\n\t    errors: []\n\t  };\n\t\n\t  var changesOpts = {};\n\t  returnValue.ready(src, target);\n\t\n\t  function initCheckpointer() {\n\t    if (checkpointer) {\n\t      return PouchPromise$1.resolve();\n\t    }\n\t    return generateReplicationId(src, target, opts).then(function (res) {\n\t      repId = res;\n\t      checkpointer = new Checkpointer(src, target, repId, returnValue);\n\t    });\n\t  }\n\t\n\t  function writeDocs() {\n\t    changedDocs = [];\n\t\n\t    if (currentBatch.docs.length === 0) {\n\t      return;\n\t    }\n\t    var docs = currentBatch.docs;\n\t    var bulkOpts = {timeout: opts.timeout};\n\t    return target.bulkDocs({docs: docs, new_edits: false}, bulkOpts).then(function (res) {\n\t      /* istanbul ignore if */\n\t      if (returnValue.cancelled) {\n\t        completeReplication();\n\t        throw new Error('cancelled');\n\t      }\n\t\n\t      // `res` doesn't include full documents (which live in `docs`), so we create a map of \n\t      // (id -> error), and check for errors while iterating over `docs`\n\t      var errorsById = Object.create(null);\n\t      res.forEach(function (res) {\n\t        if (res.error) {\n\t          errorsById[res.id] = res;\n\t        }\n\t      });\n\t\n\t      var errorsNo = Object.keys(errorsById).length;\n\t      result.doc_write_failures += errorsNo;\n\t      result.docs_written += docs.length - errorsNo;\n\t\n\t      docs.forEach(function (doc) {\n\t        var error = errorsById[doc._id];\n\t        if (error) {\n\t          result.errors.push(error);\n\t          if (error.name === 'unauthorized' || error.name === 'forbidden') {\n\t            returnValue.emit('denied', clone(error));\n\t          } else {\n\t            throw error;\n\t          }\n\t        } else {\n\t          changedDocs.push(doc);\n\t        }\n\t      });\n\t\n\t    }, function (err) {\n\t      result.doc_write_failures += docs.length;\n\t      throw err;\n\t    });\n\t  }\n\t\n\t  function finishBatch() {\n\t    if (currentBatch.error) {\n\t      throw new Error('There was a problem getting docs.');\n\t    }\n\t    result.last_seq = last_seq = currentBatch.seq;\n\t    var outResult = clone(result);\n\t    if (changedDocs.length) {\n\t      outResult.docs = changedDocs;\n\t      returnValue.emit('change', outResult);\n\t    }\n\t    writingCheckpoint = true;\n\t    return checkpointer.writeCheckpoint(currentBatch.seq,\n\t        session).then(function () {\n\t      writingCheckpoint = false;\n\t      /* istanbul ignore if */\n\t      if (returnValue.cancelled) {\n\t        completeReplication();\n\t        throw new Error('cancelled');\n\t      }\n\t      currentBatch = undefined;\n\t      getChanges();\n\t    }).catch(function (err) {\n\t      onCheckpointError(err);\n\t      throw err;\n\t    });\n\t  }\n\t\n\t  function getDiffs() {\n\t    var diff = {};\n\t    currentBatch.changes.forEach(function (change) {\n\t      // Couchbase Sync Gateway emits these, but we can ignore them\n\t      /* istanbul ignore if */\n\t      if (change.id === \"_user/\") {\n\t        return;\n\t      }\n\t      diff[change.id] = change.changes.map(function (x) {\n\t        return x.rev;\n\t      });\n\t    });\n\t    return target.revsDiff(diff).then(function (diffs) {\n\t      /* istanbul ignore if */\n\t      if (returnValue.cancelled) {\n\t        completeReplication();\n\t        throw new Error('cancelled');\n\t      }\n\t      // currentBatch.diffs elements are deleted as the documents are written\n\t      currentBatch.diffs = diffs;\n\t    });\n\t  }\n\t\n\t  function getBatchDocs() {\n\t    return getDocs(src, target, currentBatch.diffs, returnValue).then(function (got) {\n\t      currentBatch.error = !got.ok;\n\t      got.docs.forEach(function (doc) {\n\t        delete currentBatch.diffs[doc._id];\n\t        result.docs_read++;\n\t        currentBatch.docs.push(doc);\n\t      });\n\t    });\n\t  }\n\t\n\t  function startNextBatch() {\n\t    if (returnValue.cancelled || currentBatch) {\n\t      return;\n\t    }\n\t    if (batches.length === 0) {\n\t      processPendingBatch(true);\n\t      return;\n\t    }\n\t    currentBatch = batches.shift();\n\t    getDiffs()\n\t      .then(getBatchDocs)\n\t      .then(writeDocs)\n\t      .then(finishBatch)\n\t      .then(startNextBatch)\n\t      .catch(function (err) {\n\t        abortReplication('batch processing terminated with error', err);\n\t      });\n\t  }\n\t\n\t\n\t  function processPendingBatch(immediate) {\n\t    if (pendingBatch.changes.length === 0) {\n\t      if (batches.length === 0 && !currentBatch) {\n\t        if ((continuous && changesOpts.live) || changesCompleted) {\n\t          returnValue.state = 'pending';\n\t          returnValue.emit('paused');\n\t        }\n\t        if (changesCompleted) {\n\t          completeReplication();\n\t        }\n\t      }\n\t      return;\n\t    }\n\t    if (\n\t      immediate ||\n\t      changesCompleted ||\n\t      pendingBatch.changes.length >= batch_size\n\t    ) {\n\t      batches.push(pendingBatch);\n\t      pendingBatch = {\n\t        seq: 0,\n\t        changes: [],\n\t        docs: []\n\t      };\n\t      if (returnValue.state === 'pending' || returnValue.state === 'stopped') {\n\t        returnValue.state = 'active';\n\t        returnValue.emit('active');\n\t      }\n\t      startNextBatch();\n\t    }\n\t  }\n\t\n\t\n\t  function abortReplication(reason, err) {\n\t    if (replicationCompleted) {\n\t      return;\n\t    }\n\t    if (!err.message) {\n\t      err.message = reason;\n\t    }\n\t    result.ok = false;\n\t    result.status = 'aborting';\n\t    batches = [];\n\t    pendingBatch = {\n\t      seq: 0,\n\t      changes: [],\n\t      docs: []\n\t    };\n\t    completeReplication(err);\n\t  }\n\t\n\t\n\t  function completeReplication(fatalError) {\n\t    if (replicationCompleted) {\n\t      return;\n\t    }\n\t    /* istanbul ignore if */\n\t    if (returnValue.cancelled) {\n\t      result.status = 'cancelled';\n\t      if (writingCheckpoint) {\n\t        return;\n\t      }\n\t    }\n\t    result.status = result.status || 'complete';\n\t    result.end_time = new Date();\n\t    result.last_seq = last_seq;\n\t    replicationCompleted = true;\n\t\n\t    if (fatalError) {\n\t      fatalError.result = result;\n\t\n\t      if (fatalError.name === 'unauthorized' || fatalError.name === 'forbidden') {\n\t        returnValue.emit('error', fatalError);\n\t        returnValue.removeAllListeners();\n\t      } else {\n\t        backOff(opts, returnValue, fatalError, function () {\n\t          replicate(src, target, opts, returnValue);\n\t        });\n\t      }\n\t    } else {\n\t      returnValue.emit('complete', result);\n\t      returnValue.removeAllListeners();\n\t    }\n\t  }\n\t\n\t\n\t  function onChange(change) {\n\t    /* istanbul ignore if */\n\t    if (returnValue.cancelled) {\n\t      return completeReplication();\n\t    }\n\t    var filter = filterChange(opts)(change);\n\t    if (!filter) {\n\t      return;\n\t    }\n\t    pendingBatch.seq = change.seq;\n\t    pendingBatch.changes.push(change);\n\t    processPendingBatch(batches.length === 0 && changesOpts.live);\n\t  }\n\t\n\t\n\t  function onChangesComplete(changes) {\n\t    changesPending = false;\n\t    /* istanbul ignore if */\n\t    if (returnValue.cancelled) {\n\t      return completeReplication();\n\t    }\n\t\n\t    // if no results were returned then we're done,\n\t    // else fetch more\n\t    if (changes.results.length > 0) {\n\t      changesOpts.since = changes.last_seq;\n\t      getChanges();\n\t      processPendingBatch(true);\n\t    } else {\n\t\n\t      var complete = function () {\n\t        if (continuous) {\n\t          changesOpts.live = true;\n\t          getChanges();\n\t        } else {\n\t          changesCompleted = true;\n\t        }\n\t        processPendingBatch(true);\n\t      };\n\t\n\t      // update the checkpoint so we start from the right seq next time\n\t      if (!currentBatch && changes.results.length === 0) {\n\t        writingCheckpoint = true;\n\t        checkpointer.writeCheckpoint(changes.last_seq,\n\t            session).then(function () {\n\t          writingCheckpoint = false;\n\t          result.last_seq = last_seq = changes.last_seq;\n\t          complete();\n\t        })\n\t        .catch(onCheckpointError);\n\t      } else {\n\t        complete();\n\t      }\n\t    }\n\t  }\n\t\n\t\n\t  function onChangesError(err) {\n\t    changesPending = false;\n\t    /* istanbul ignore if */\n\t    if (returnValue.cancelled) {\n\t      return completeReplication();\n\t    }\n\t    abortReplication('changes rejected', err);\n\t  }\n\t\n\t\n\t  function getChanges() {\n\t    if (!(\n\t      !changesPending &&\n\t      !changesCompleted &&\n\t      batches.length < batches_limit\n\t      )) {\n\t      return;\n\t    }\n\t    changesPending = true;\n\t    function abortChanges() {\n\t      changes.cancel();\n\t    }\n\t    function removeListener() {\n\t      returnValue.removeListener('cancel', abortChanges);\n\t    }\n\t\n\t    if (returnValue._changes) { // remove old changes() and listeners\n\t      returnValue.removeListener('cancel', returnValue._abortChanges);\n\t      returnValue._changes.cancel();\n\t    }\n\t    returnValue.once('cancel', abortChanges);\n\t\n\t    var changes = src.changes(changesOpts)\n\t      .on('change', onChange);\n\t    changes.then(removeListener, removeListener);\n\t    changes.then(onChangesComplete)\n\t      .catch(onChangesError);\n\t\n\t    if (opts.retry) {\n\t      // save for later so we can cancel if necessary\n\t      returnValue._changes = changes;\n\t      returnValue._abortChanges = abortChanges;\n\t    }\n\t  }\n\t\n\t\n\t  function startChanges() {\n\t    initCheckpointer().then(function () {\n\t      /* istanbul ignore if */\n\t      if (returnValue.cancelled) {\n\t        completeReplication();\n\t        return;\n\t      }\n\t      return checkpointer.getCheckpoint().then(function (checkpoint) {\n\t        last_seq = checkpoint;\n\t        changesOpts = {\n\t          since: last_seq,\n\t          limit: batch_size,\n\t          batch_size: batch_size,\n\t          style: 'all_docs',\n\t          doc_ids: doc_ids,\n\t          return_docs: true // required so we know when we're done\n\t        };\n\t        if (opts.filter) {\n\t          if (typeof opts.filter !== 'string') {\n\t            // required for the client-side filter in onChange\n\t            changesOpts.include_docs = true;\n\t          } else { // ddoc filter\n\t            changesOpts.filter = opts.filter;\n\t          }\n\t        }\n\t        if ('heartbeat' in opts) {\n\t          changesOpts.heartbeat = opts.heartbeat;\n\t        }\n\t        if ('timeout' in opts) {\n\t          changesOpts.timeout = opts.timeout;\n\t        }\n\t        if (opts.query_params) {\n\t          changesOpts.query_params = opts.query_params;\n\t        }\n\t        if (opts.view) {\n\t          changesOpts.view = opts.view;\n\t        }\n\t        getChanges();\n\t      });\n\t    }).catch(function (err) {\n\t      abortReplication('getCheckpoint rejected with ', err);\n\t    });\n\t  }\n\t\n\t  /* istanbul ignore next */\n\t  function onCheckpointError(err) {\n\t    writingCheckpoint = false;\n\t    abortReplication('writeCheckpoint completed with error', err);\n\t  }\n\t\n\t  /* istanbul ignore if */\n\t  if (returnValue.cancelled) { // cancelled immediately\n\t    completeReplication();\n\t    return;\n\t  }\n\t\n\t  if (!returnValue._addedListeners) {\n\t    returnValue.once('cancel', completeReplication);\n\t\n\t    if (typeof opts.complete === 'function') {\n\t      returnValue.once('error', opts.complete);\n\t      returnValue.once('complete', function (result) {\n\t        opts.complete(null, result);\n\t      });\n\t    }\n\t    returnValue._addedListeners = true;\n\t  }\n\t\n\t  if (typeof opts.since === 'undefined') {\n\t    startChanges();\n\t  } else {\n\t    initCheckpointer().then(function () {\n\t      writingCheckpoint = true;\n\t      return checkpointer.writeCheckpoint(opts.since, session);\n\t    }).then(function () {\n\t      writingCheckpoint = false;\n\t      /* istanbul ignore if */\n\t      if (returnValue.cancelled) {\n\t        completeReplication();\n\t        return;\n\t      }\n\t      last_seq = opts.since;\n\t      startChanges();\n\t    }).catch(onCheckpointError);\n\t  }\n\t}\n\t\n\t// We create a basic promise so the caller can cancel the replication possibly\n\t// before we have actually started listening to changes etc\n\tinherits(Replication, events.EventEmitter);\n\tfunction Replication() {\n\t  events.EventEmitter.call(this);\n\t  this.cancelled = false;\n\t  this.state = 'pending';\n\t  var self = this;\n\t  var promise = new PouchPromise$1(function (fulfill, reject) {\n\t    self.once('complete', fulfill);\n\t    self.once('error', reject);\n\t  });\n\t  self.then = function (resolve, reject) {\n\t    return promise.then(resolve, reject);\n\t  };\n\t  self.catch = function (reject) {\n\t    return promise.catch(reject);\n\t  };\n\t  // As we allow error handling via \"error\" event as well,\n\t  // put a stub in here so that rejecting never throws UnhandledError.\n\t  self.catch(function () {});\n\t}\n\t\n\tReplication.prototype.cancel = function () {\n\t  this.cancelled = true;\n\t  this.state = 'cancelled';\n\t  this.emit('cancel');\n\t};\n\t\n\tReplication.prototype.ready = function (src, target) {\n\t  var self = this;\n\t  if (self._readyCalled) {\n\t    return;\n\t  }\n\t  self._readyCalled = true;\n\t\n\t  function onDestroy() {\n\t    self.cancel();\n\t  }\n\t  src.once('destroyed', onDestroy);\n\t  target.once('destroyed', onDestroy);\n\t  function cleanup() {\n\t    src.removeListener('destroyed', onDestroy);\n\t    target.removeListener('destroyed', onDestroy);\n\t  }\n\t  self.once('complete', cleanup);\n\t};\n\t\n\tfunction toPouch(db, opts) {\n\t  var PouchConstructor = opts.PouchConstructor;\n\t  if (typeof db === 'string') {\n\t    return new PouchConstructor(db, opts);\n\t  } else {\n\t    return db;\n\t  }\n\t}\n\t\n\tfunction replicateWrapper(src, target, opts, callback) {\n\t\n\t  if (typeof opts === 'function') {\n\t    callback = opts;\n\t    opts = {};\n\t  }\n\t  if (typeof opts === 'undefined') {\n\t    opts = {};\n\t  }\n\t\n\t  if (opts.doc_ids && !Array.isArray(opts.doc_ids)) {\n\t    throw createError(BAD_REQUEST,\n\t                       \"`doc_ids` filter parameter is not a list.\");\n\t  }\n\t\n\t  opts.complete = callback;\n\t  opts = clone(opts);\n\t  opts.continuous = opts.continuous || opts.live;\n\t  opts.retry = ('retry' in opts) ? opts.retry : false;\n\t  /*jshint validthis:true */\n\t  opts.PouchConstructor = opts.PouchConstructor || this;\n\t  var replicateRet = new Replication(opts);\n\t  var srcPouch = toPouch(src, opts);\n\t  var targetPouch = toPouch(target, opts);\n\t  replicate(srcPouch, targetPouch, opts, replicateRet);\n\t  return replicateRet;\n\t}\n\t\n\tinherits(Sync, events.EventEmitter);\n\tfunction sync$1(src, target, opts, callback) {\n\t  if (typeof opts === 'function') {\n\t    callback = opts;\n\t    opts = {};\n\t  }\n\t  if (typeof opts === 'undefined') {\n\t    opts = {};\n\t  }\n\t  opts = clone(opts);\n\t  /*jshint validthis:true */\n\t  opts.PouchConstructor = opts.PouchConstructor || this;\n\t  src = toPouch(src, opts);\n\t  target = toPouch(target, opts);\n\t  return new Sync(src, target, opts, callback);\n\t}\n\t\n\tfunction Sync(src, target, opts, callback) {\n\t  var self = this;\n\t  this.canceled = false;\n\t\n\t  var optsPush = opts.push ? assign$1({}, opts, opts.push) : opts;\n\t  var optsPull = opts.pull ? assign$1({}, opts, opts.pull) : opts;\n\t\n\t  this.push = replicateWrapper(src, target, optsPush);\n\t  this.pull = replicateWrapper(target, src, optsPull);\n\t\n\t  this.pushPaused = true;\n\t  this.pullPaused = true;\n\t\n\t  function pullChange(change) {\n\t    self.emit('change', {\n\t      direction: 'pull',\n\t      change: change\n\t    });\n\t  }\n\t  function pushChange(change) {\n\t    self.emit('change', {\n\t      direction: 'push',\n\t      change: change\n\t    });\n\t  }\n\t  function pushDenied(doc) {\n\t    self.emit('denied', {\n\t      direction: 'push',\n\t      doc: doc\n\t    });\n\t  }\n\t  function pullDenied(doc) {\n\t    self.emit('denied', {\n\t      direction: 'pull',\n\t      doc: doc\n\t    });\n\t  }\n\t  function pushPaused() {\n\t    self.pushPaused = true;\n\t    /* istanbul ignore if */\n\t    if (self.pullPaused) {\n\t      self.emit('paused');\n\t    }\n\t  }\n\t  function pullPaused() {\n\t    self.pullPaused = true;\n\t    /* istanbul ignore if */\n\t    if (self.pushPaused) {\n\t      self.emit('paused');\n\t    }\n\t  }\n\t  function pushActive() {\n\t    self.pushPaused = false;\n\t    /* istanbul ignore if */\n\t    if (self.pullPaused) {\n\t      self.emit('active', {\n\t        direction: 'push'\n\t      });\n\t    }\n\t  }\n\t  function pullActive() {\n\t    self.pullPaused = false;\n\t    /* istanbul ignore if */\n\t    if (self.pushPaused) {\n\t      self.emit('active', {\n\t        direction: 'pull'\n\t      });\n\t    }\n\t  }\n\t\n\t  var removed = {};\n\t\n\t  function removeAll(type) { // type is 'push' or 'pull'\n\t    return function (event, func) {\n\t      var isChange = event === 'change' &&\n\t        (func === pullChange || func === pushChange);\n\t      var isDenied = event === 'denied' &&\n\t        (func === pullDenied || func === pushDenied);\n\t      var isPaused = event === 'paused' &&\n\t        (func === pullPaused || func === pushPaused);\n\t      var isActive = event === 'active' &&\n\t        (func === pullActive || func === pushActive);\n\t\n\t      if (isChange || isDenied || isPaused || isActive) {\n\t        if (!(event in removed)) {\n\t          removed[event] = {};\n\t        }\n\t        removed[event][type] = true;\n\t        if (Object.keys(removed[event]).length === 2) {\n\t          // both push and pull have asked to be removed\n\t          self.removeAllListeners(event);\n\t        }\n\t      }\n\t    };\n\t  }\n\t\n\t  if (opts.live) {\n\t    this.push.on('complete', self.pull.cancel.bind(self.pull));\n\t    this.pull.on('complete', self.push.cancel.bind(self.push));\n\t  }\n\t\n\t  function addOneListener(ee, event, listener) {\n\t    if (ee.listeners(event).indexOf(listener) == -1) {\n\t      ee.on(event, listener);\n\t    }\n\t  }\n\t\n\t  this.on('newListener', function (event) {\n\t    if (event === 'change') {\n\t      addOneListener(self.pull, 'change', pullChange);\n\t      addOneListener(self.push, 'change', pushChange);\n\t    } else if (event === 'denied') {\n\t      addOneListener(self.pull, 'denied', pullDenied);\n\t      addOneListener(self.push, 'denied', pushDenied);\n\t    } else if (event === 'active') {\n\t      addOneListener(self.pull, 'active', pullActive);\n\t      addOneListener(self.push, 'active', pushActive);\n\t    } else if (event === 'paused') {\n\t      addOneListener(self.pull, 'paused', pullPaused);\n\t      addOneListener(self.push, 'paused', pushPaused);\n\t    }\n\t  });\n\t\n\t  this.on('removeListener', function (event) {\n\t    if (event === 'change') {\n\t      self.pull.removeListener('change', pullChange);\n\t      self.push.removeListener('change', pushChange);\n\t    } else if (event === 'denied') {\n\t      self.pull.removeListener('denied', pullDenied);\n\t      self.push.removeListener('denied', pushDenied);\n\t    } else if (event === 'active') {\n\t      self.pull.removeListener('active', pullActive);\n\t      self.push.removeListener('active', pushActive);\n\t    } else if (event === 'paused') {\n\t      self.pull.removeListener('paused', pullPaused);\n\t      self.push.removeListener('paused', pushPaused);\n\t    }\n\t  });\n\t\n\t  this.pull.on('removeListener', removeAll('pull'));\n\t  this.push.on('removeListener', removeAll('push'));\n\t\n\t  var promise = PouchPromise$1.all([\n\t    this.push,\n\t    this.pull\n\t  ]).then(function (resp) {\n\t    var out = {\n\t      push: resp[0],\n\t      pull: resp[1]\n\t    };\n\t    self.emit('complete', out);\n\t    if (callback) {\n\t      callback(null, out);\n\t    }\n\t    self.removeAllListeners();\n\t    return out;\n\t  }, function (err) {\n\t    self.cancel();\n\t    if (callback) {\n\t      // if there's a callback, then the callback can receive\n\t      // the error event\n\t      callback(err);\n\t    } else {\n\t      // if there's no callback, then we're safe to emit an error\n\t      // event, which would otherwise throw an unhandled error\n\t      // due to 'error' being a special event in EventEmitters\n\t      self.emit('error', err);\n\t    }\n\t    self.removeAllListeners();\n\t    if (callback) {\n\t      // no sense throwing if we're already emitting an 'error' event\n\t      throw err;\n\t    }\n\t  });\n\t\n\t  this.then = function (success, err) {\n\t    return promise.then(success, err);\n\t  };\n\t\n\t  this.catch = function (err) {\n\t    return promise.catch(err);\n\t  };\n\t}\n\t\n\tSync.prototype.cancel = function () {\n\t  if (!this.canceled) {\n\t    this.canceled = true;\n\t    this.push.cancel();\n\t    this.pull.cancel();\n\t  }\n\t};\n\t\n\tfunction replication(PouchDB) {\n\t  PouchDB.replicate = replicateWrapper;\n\t  PouchDB.sync = sync$1;\n\t\n\t  Object.defineProperty(PouchDB.prototype, 'replicate', {\n\t    get: function () {\n\t      var self = this;\n\t      return {\n\t        from: function (other, opts, callback) {\n\t          return self.constructor.replicate(other, self, opts, callback);\n\t        },\n\t        to: function (other, opts, callback) {\n\t          return self.constructor.replicate(self, other, opts, callback);\n\t        }\n\t      };\n\t    }\n\t  });\n\t\n\t  PouchDB.prototype.sync = function (dbName, opts, callback) {\n\t    return this.constructor.sync(this, dbName, opts, callback);\n\t  };\n\t}\n\t\n\tPouchDB$5.plugin(IDBPouch)\n\t  .plugin(WebSqlPouch)\n\t  .plugin(HttpPouch$1)\n\t  .plugin(mapreduce)\n\t  .plugin(replication);\n\t\n\t// Pull from src because pouchdb-node/pouchdb-browser themselves\n\t// are aggressively optimized and jsnext:main would normally give us this\n\t// aggressive bundle.\n\t\n\tmodule.exports = PouchDB$5;\n\t\n\t/* WEBPACK VAR INJECTION */}.call(exports, (function() { return this; }())))\n\n/***/ },\n/* 91 */\n/***/ function(module, exports, __webpack_require__) {\n\n\t'use strict';\n\tvar immediate = __webpack_require__(13);\n\t\n\t/* istanbul ignore next */\n\tfunction INTERNAL() {}\n\t\n\tvar handlers = {};\n\t\n\tvar REJECTED = ['REJECTED'];\n\tvar FULFILLED = ['FULFILLED'];\n\tvar PENDING = ['PENDING'];\n\t\n\tmodule.exports = Promise;\n\t\n\tfunction Promise(resolver) {\n\t  if (typeof resolver !== 'function') {\n\t    throw new TypeError('resolver must be a function');\n\t  }\n\t  this.state = PENDING;\n\t  this.queue = [];\n\t  this.outcome = void 0;\n\t  if (resolver !== INTERNAL) {\n\t    safelyResolveThenable(this, resolver);\n\t  }\n\t}\n\t\n\tPromise.prototype[\"catch\"] = function (onRejected) {\n\t  return this.then(null, onRejected);\n\t};\n\tPromise.prototype.then = function (onFulfilled, onRejected) {\n\t  if (typeof onFulfilled !== 'function' && this.state === FULFILLED ||\n\t    typeof onRejected !== 'function' && this.state === REJECTED) {\n\t    return this;\n\t  }\n\t  var promise = new this.constructor(INTERNAL);\n\t  if (this.state !== PENDING) {\n\t    var resolver = this.state === FULFILLED ? onFulfilled : onRejected;\n\t    unwrap(promise, resolver, this.outcome);\n\t  } else {\n\t    this.queue.push(new QueueItem(promise, onFulfilled, onRejected));\n\t  }\n\t\n\t  return promise;\n\t};\n\tfunction QueueItem(promise, onFulfilled, onRejected) {\n\t  this.promise = promise;\n\t  if (typeof onFulfilled === 'function') {\n\t    this.onFulfilled = onFulfilled;\n\t    this.callFulfilled = this.otherCallFulfilled;\n\t  }\n\t  if (typeof onRejected === 'function') {\n\t    this.onRejected = onRejected;\n\t    this.callRejected = this.otherCallRejected;\n\t  }\n\t}\n\tQueueItem.prototype.callFulfilled = function (value) {\n\t  handlers.resolve(this.promise, value);\n\t};\n\tQueueItem.prototype.otherCallFulfilled = function (value) {\n\t  unwrap(this.promise, this.onFulfilled, value);\n\t};\n\tQueueItem.prototype.callRejected = function (value) {\n\t  handlers.reject(this.promise, value);\n\t};\n\tQueueItem.prototype.otherCallRejected = function (value) {\n\t  unwrap(this.promise, this.onRejected, value);\n\t};\n\t\n\tfunction unwrap(promise, func, value) {\n\t  immediate(function () {\n\t    var returnValue;\n\t    try {\n\t      returnValue = func(value);\n\t    } catch (e) {\n\t      return handlers.reject(promise, e);\n\t    }\n\t    if (returnValue === promise) {\n\t      handlers.reject(promise, new TypeError('Cannot resolve promise with itself'));\n\t    } else {\n\t      handlers.resolve(promise, returnValue);\n\t    }\n\t  });\n\t}\n\t\n\thandlers.resolve = function (self, value) {\n\t  var result = tryCatch(getThen, value);\n\t  if (result.status === 'error') {\n\t    return handlers.reject(self, result.value);\n\t  }\n\t  var thenable = result.value;\n\t\n\t  if (thenable) {\n\t    safelyResolveThenable(self, thenable);\n\t  } else {\n\t    self.state = FULFILLED;\n\t    self.outcome = value;\n\t    var i = -1;\n\t    var len = self.queue.length;\n\t    while (++i < len) {\n\t      self.queue[i].callFulfilled(value);\n\t    }\n\t  }\n\t  return self;\n\t};\n\thandlers.reject = function (self, error) {\n\t  self.state = REJECTED;\n\t  self.outcome = error;\n\t  var i = -1;\n\t  var len = self.queue.length;\n\t  while (++i < len) {\n\t    self.queue[i].callRejected(error);\n\t  }\n\t  return self;\n\t};\n\t\n\tfunction getThen(obj) {\n\t  // Make sure we only access the accessor once as required by the spec\n\t  var then = obj && obj.then;\n\t  if (obj && typeof obj === 'object' && typeof then === 'function') {\n\t    return function appyThen() {\n\t      then.apply(obj, arguments);\n\t    };\n\t  }\n\t}\n\t\n\tfunction safelyResolveThenable(self, thenable) {\n\t  // Either fulfill, reject or reject with error\n\t  var called = false;\n\t  function onError(value) {\n\t    if (called) {\n\t      return;\n\t    }\n\t    called = true;\n\t    handlers.reject(self, value);\n\t  }\n\t\n\t  function onSuccess(value) {\n\t    if (called) {\n\t      return;\n\t    }\n\t    called = true;\n\t    handlers.resolve(self, value);\n\t  }\n\t\n\t  function tryToUnwrap() {\n\t    thenable(onSuccess, onError);\n\t  }\n\t\n\t  var result = tryCatch(tryToUnwrap);\n\t  if (result.status === 'error') {\n\t    onError(result.value);\n\t  }\n\t}\n\t\n\tfunction tryCatch(func, value) {\n\t  var out = {};\n\t  try {\n\t    out.value = func(value);\n\t    out.status = 'success';\n\t  } catch (e) {\n\t    out.status = 'error';\n\t    out.value = e;\n\t  }\n\t  return out;\n\t}\n\t\n\tPromise.resolve = resolve;\n\tfunction resolve(value) {\n\t  if (value instanceof this) {\n\t    return value;\n\t  }\n\t  return handlers.resolve(new this(INTERNAL), value);\n\t}\n\t\n\tPromise.reject = reject;\n\tfunction reject(reason) {\n\t  var promise = new this(INTERNAL);\n\t  return handlers.reject(promise, reason);\n\t}\n\t\n\tPromise.all = all;\n\tfunction all(iterable) {\n\t  var self = this;\n\t  if (Object.prototype.toString.call(iterable) !== '[object Array]') {\n\t    return this.reject(new TypeError('must be an array'));\n\t  }\n\t\n\t  var len = iterable.length;\n\t  var called = false;\n\t  if (!len) {\n\t    return this.resolve([]);\n\t  }\n\t\n\t  var values = new Array(len);\n\t  var resolved = 0;\n\t  var i = -1;\n\t  var promise = new this(INTERNAL);\n\t\n\t  while (++i < len) {\n\t    allResolver(iterable[i], i);\n\t  }\n\t  return promise;\n\t  function allResolver(value, i) {\n\t    self.resolve(value).then(resolveFromAll, function (error) {\n\t      if (!called) {\n\t        called = true;\n\t        handlers.reject(promise, error);\n\t      }\n\t    });\n\t    function resolveFromAll(outValue) {\n\t      values[i] = outValue;\n\t      if (++resolved === len && !called) {\n\t        called = true;\n\t        handlers.resolve(promise, values);\n\t      }\n\t    }\n\t  }\n\t}\n\t\n\tPromise.race = race;\n\tfunction race(iterable) {\n\t  var self = this;\n\t  if (Object.prototype.toString.call(iterable) !== '[object Array]') {\n\t    return this.reject(new TypeError('must be an array'));\n\t  }\n\t\n\t  var len = iterable.length;\n\t  var called = false;\n\t  if (!len) {\n\t    return this.resolve([]);\n\t  }\n\t\n\t  var i = -1;\n\t  var promise = new this(INTERNAL);\n\t\n\t  while (++i < len) {\n\t    resolver(iterable[i]);\n\t  }\n\t  return promise;\n\t  function resolver(value) {\n\t    self.resolve(value).then(function (response) {\n\t      if (!called) {\n\t        called = true;\n\t        handlers.resolve(promise, response);\n\t      }\n\t    }, function (error) {\n\t      if (!called) {\n\t        called = true;\n\t        handlers.reject(promise, error);\n\t      }\n\t    });\n\t  }\n\t}\n\n\n/***/ },\n/* 92 */\n/***/ function(module, exports, __webpack_require__) {\n\n\t/* WEBPACK VAR INJECTION */(function(global) {// This method of obtaining a reference to the global object needs to be\n\t// kept identical to the way it is obtained in runtime.js\n\tvar g =\n\t  typeof global === \"object\" ? global :\n\t  typeof window === \"object\" ? window :\n\t  typeof self === \"object\" ? self : this;\n\t\n\t// Use `getOwnPropertyNames` because not all browsers support calling\n\t// `hasOwnProperty` on the global `self` object in a worker. See #183.\n\tvar hadRuntime = g.regeneratorRuntime &&\n\t  Object.getOwnPropertyNames(g).indexOf(\"regeneratorRuntime\") >= 0;\n\t\n\t// Save the old regeneratorRuntime in case it needs to be restored later.\n\tvar oldRuntime = hadRuntime && g.regeneratorRuntime;\n\t\n\t// Force reevalutation of runtime.js.\n\tg.regeneratorRuntime = undefined;\n\t\n\tmodule.exports = __webpack_require__(93);\n\t\n\tif (hadRuntime) {\n\t  // Restore the original runtime.\n\t  g.regeneratorRuntime = oldRuntime;\n\t} else {\n\t  // Remove the global property added by runtime.js.\n\t  try {\n\t    delete g.regeneratorRuntime;\n\t  } catch(e) {\n\t    g.regeneratorRuntime = undefined;\n\t  }\n\t}\n\t\n\t/* WEBPACK VAR INJECTION */}.call(exports, (function() { return this; }())))\n\n/***/ },\n/* 93 */\n/***/ function(module, exports, __webpack_require__) {\n\n\t/* WEBPACK VAR INJECTION */(function(global, process) {/**\n\t * Copyright (c) 2014, Facebook, Inc.\n\t * All rights reserved.\n\t *\n\t * This source code is licensed under the BSD-style license found in the\n\t * https://raw.github.com/facebook/regenerator/master/LICENSE file. An\n\t * additional grant of patent rights can be found in the PATENTS file in\n\t * the same directory.\n\t */\n\t\n\t!(function(global) {\n\t  \"use strict\";\n\t\n\t  var Op = Object.prototype;\n\t  var hasOwn = Op.hasOwnProperty;\n\t  var undefined; // More compressible than void 0.\n\t  var $Symbol = typeof Symbol === \"function\" ? Symbol : {};\n\t  var iteratorSymbol = $Symbol.iterator || \"@@iterator\";\n\t  var toStringTagSymbol = $Symbol.toStringTag || \"@@toStringTag\";\n\t\n\t  var inModule = typeof module === \"object\";\n\t  var runtime = global.regeneratorRuntime;\n\t  if (runtime) {\n\t    if (inModule) {\n\t      // If regeneratorRuntime is defined globally and we're in a module,\n\t      // make the exports object identical to regeneratorRuntime.\n\t      module.exports = runtime;\n\t    }\n\t    // Don't bother evaluating the rest of this file if the runtime was\n\t    // already defined globally.\n\t    return;\n\t  }\n\t\n\t  // Define the runtime globally (as expected by generated code) as either\n\t  // module.exports (if we're in a module) or a new, empty object.\n\t  runtime = global.regeneratorRuntime = inModule ? module.exports : {};\n\t\n\t  function wrap(innerFn, outerFn, self, tryLocsList) {\n\t    // If outerFn provided and outerFn.prototype is a Generator, then outerFn.prototype instanceof Generator.\n\t    var protoGenerator = outerFn && outerFn.prototype instanceof Generator ? outerFn : Generator;\n\t    var generator = Object.create(protoGenerator.prototype);\n\t    var context = new Context(tryLocsList || []);\n\t\n\t    // The ._invoke method unifies the implementations of the .next,\n\t    // .throw, and .return methods.\n\t    generator._invoke = makeInvokeMethod(innerFn, self, context);\n\t\n\t    return generator;\n\t  }\n\t  runtime.wrap = wrap;\n\t\n\t  // Try/catch helper to minimize deoptimizations. Returns a completion\n\t  // record like context.tryEntries[i].completion. This interface could\n\t  // have been (and was previously) designed to take a closure to be\n\t  // invoked without arguments, but in all the cases we care about we\n\t  // already have an existing method we want to call, so there's no need\n\t  // to create a new function object. We can even get away with assuming\n\t  // the method takes exactly one argument, since that happens to be true\n\t  // in every case, so we don't have to touch the arguments object. The\n\t  // only additional allocation required is the completion record, which\n\t  // has a stable shape and so hopefully should be cheap to allocate.\n\t  function tryCatch(fn, obj, arg) {\n\t    try {\n\t      return { type: \"normal\", arg: fn.call(obj, arg) };\n\t    } catch (err) {\n\t      return { type: \"throw\", arg: err };\n\t    }\n\t  }\n\t\n\t  var GenStateSuspendedStart = \"suspendedStart\";\n\t  var GenStateSuspendedYield = \"suspendedYield\";\n\t  var GenStateExecuting = \"executing\";\n\t  var GenStateCompleted = \"completed\";\n\t\n\t  // Returning this object from the innerFn has the same effect as\n\t  // breaking out of the dispatch switch statement.\n\t  var ContinueSentinel = {};\n\t\n\t  // Dummy constructor functions that we use as the .constructor and\n\t  // .constructor.prototype properties for functions that return Generator\n\t  // objects. For full spec compliance, you may wish to configure your\n\t  // minifier not to mangle the names of these two functions.\n\t  function Generator() {}\n\t  function GeneratorFunction() {}\n\t  function GeneratorFunctionPrototype() {}\n\t\n\t  // This is a polyfill for %IteratorPrototype% for environments that\n\t  // don't natively support it.\n\t  var IteratorPrototype = {};\n\t  IteratorPrototype[iteratorSymbol] = function () {\n\t    return this;\n\t  };\n\t\n\t  var getProto = Object.getPrototypeOf;\n\t  var NativeIteratorPrototype = getProto && getProto(getProto(values([])));\n\t  if (NativeIteratorPrototype &&\n\t      NativeIteratorPrototype !== Op &&\n\t      hasOwn.call(NativeIteratorPrototype, iteratorSymbol)) {\n\t    // This environment has a native %IteratorPrototype%; use it instead\n\t    // of the polyfill.\n\t    IteratorPrototype = NativeIteratorPrototype;\n\t  }\n\t\n\t  var Gp = GeneratorFunctionPrototype.prototype =\n\t    Generator.prototype = Object.create(IteratorPrototype);\n\t  GeneratorFunction.prototype = Gp.constructor = GeneratorFunctionPrototype;\n\t  GeneratorFunctionPrototype.constructor = GeneratorFunction;\n\t  GeneratorFunctionPrototype[toStringTagSymbol] =\n\t    GeneratorFunction.displayName = \"GeneratorFunction\";\n\t\n\t  // Helper for defining the .next, .throw, and .return methods of the\n\t  // Iterator interface in terms of a single ._invoke method.\n\t  function defineIteratorMethods(prototype) {\n\t    [\"next\", \"throw\", \"return\"].forEach(function(method) {\n\t      prototype[method] = function(arg) {\n\t        return this._invoke(method, arg);\n\t      };\n\t    });\n\t  }\n\t\n\t  runtime.isGeneratorFunction = function(genFun) {\n\t    var ctor = typeof genFun === \"function\" && genFun.constructor;\n\t    return ctor\n\t      ? ctor === GeneratorFunction ||\n\t        // For the native GeneratorFunction constructor, the best we can\n\t        // do is to check its .name property.\n\t        (ctor.displayName || ctor.name) === \"GeneratorFunction\"\n\t      : false;\n\t  };\n\t\n\t  runtime.mark = function(genFun) {\n\t    if (Object.setPrototypeOf) {\n\t      Object.setPrototypeOf(genFun, GeneratorFunctionPrototype);\n\t    } else {\n\t      genFun.__proto__ = GeneratorFunctionPrototype;\n\t      if (!(toStringTagSymbol in genFun)) {\n\t        genFun[toStringTagSymbol] = \"GeneratorFunction\";\n\t      }\n\t    }\n\t    genFun.prototype = Object.create(Gp);\n\t    return genFun;\n\t  };\n\t\n\t  // Within the body of any async function, `await x` is transformed to\n\t  // `yield regeneratorRuntime.awrap(x)`, so that the runtime can test\n\t  // `hasOwn.call(value, \"__await\")` to determine if the yielded value is\n\t  // meant to be awaited.\n\t  runtime.awrap = function(arg) {\n\t    return { __await: arg };\n\t  };\n\t\n\t  function AsyncIterator(generator) {\n\t    function invoke(method, arg, resolve, reject) {\n\t      var record = tryCatch(generator[method], generator, arg);\n\t      if (record.type === \"throw\") {\n\t        reject(record.arg);\n\t      } else {\n\t        var result = record.arg;\n\t        var value = result.value;\n\t        if (value &&\n\t            typeof value === \"object\" &&\n\t            hasOwn.call(value, \"__await\")) {\n\t          return Promise.resolve(value.__await).then(function(value) {\n\t            invoke(\"next\", value, resolve, reject);\n\t          }, function(err) {\n\t            invoke(\"throw\", err, resolve, reject);\n\t          });\n\t        }\n\t\n\t        return Promise.resolve(value).then(function(unwrapped) {\n\t          // When a yielded Promise is resolved, its final value becomes\n\t          // the .value of the Promise<{value,done}> result for the\n\t          // current iteration. If the Promise is rejected, however, the\n\t          // result for this iteration will be rejected with the same\n\t          // reason. Note that rejections of yielded Promises are not\n\t          // thrown back into the generator function, as is the case\n\t          // when an awaited Promise is rejected. This difference in\n\t          // behavior between yield and await is important, because it\n\t          // allows the consumer to decide what to do with the yielded\n\t          // rejection (swallow it and continue, manually .throw it back\n\t          // into the generator, abandon iteration, whatever). With\n\t          // await, by contrast, there is no opportunity to examine the\n\t          // rejection reason outside the generator function, so the\n\t          // only option is to throw it from the await expression, and\n\t          // let the generator function handle the exception.\n\t          result.value = unwrapped;\n\t          resolve(result);\n\t        }, reject);\n\t      }\n\t    }\n\t\n\t    if (typeof process === \"object\" && process.domain) {\n\t      invoke = process.domain.bind(invoke);\n\t    }\n\t\n\t    var previousPromise;\n\t\n\t    function enqueue(method, arg) {\n\t      function callInvokeWithMethodAndArg() {\n\t        return new Promise(function(resolve, reject) {\n\t          invoke(method, arg, resolve, reject);\n\t        });\n\t      }\n\t\n\t      return previousPromise =\n\t        // If enqueue has been called before, then we want to wait until\n\t        // all previous Promises have been resolved before calling invoke,\n\t        // so that results are always delivered in the correct order. If\n\t        // enqueue has not been called before, then it is important to\n\t        // call invoke immediately, without waiting on a callback to fire,\n\t        // so that the async generator function has the opportunity to do\n\t        // any necessary setup in a predictable way. This predictability\n\t        // is why the Promise constructor synchronously invokes its\n\t        // executor callback, and why async functions synchronously\n\t        // execute code before the first await. Since we implement simple\n\t        // async functions in terms of async generators, it is especially\n\t        // important to get this right, even though it requires care.\n\t        previousPromise ? previousPromise.then(\n\t          callInvokeWithMethodAndArg,\n\t          // Avoid propagating failures to Promises returned by later\n\t          // invocations of the iterator.\n\t          callInvokeWithMethodAndArg\n\t        ) : callInvokeWithMethodAndArg();\n\t    }\n\t\n\t    // Define the unified helper method that is used to implement .next,\n\t    // .throw, and .return (see defineIteratorMethods).\n\t    this._invoke = enqueue;\n\t  }\n\t\n\t  defineIteratorMethods(AsyncIterator.prototype);\n\t  runtime.AsyncIterator = AsyncIterator;\n\t\n\t  // Note that simple async functions are implemented on top of\n\t  // AsyncIterator objects; they just return a Promise for the value of\n\t  // the final result produced by the iterator.\n\t  runtime.async = function(innerFn, outerFn, self, tryLocsList) {\n\t    var iter = new AsyncIterator(\n\t      wrap(innerFn, outerFn, self, tryLocsList)\n\t    );\n\t\n\t    return runtime.isGeneratorFunction(outerFn)\n\t      ? iter // If outerFn is a generator, return the full iterator.\n\t      : iter.next().then(function(result) {\n\t          return result.done ? result.value : iter.next();\n\t        });\n\t  };\n\t\n\t  function makeInvokeMethod(innerFn, self, context) {\n\t    var state = GenStateSuspendedStart;\n\t\n\t    return function invoke(method, arg) {\n\t      if (state === GenStateExecuting) {\n\t        throw new Error(\"Generator is already running\");\n\t      }\n\t\n\t      if (state === GenStateCompleted) {\n\t        if (method === \"throw\") {\n\t          throw arg;\n\t        }\n\t\n\t        // Be forgiving, per 25.3.3.3.3 of the spec:\n\t        // https://people.mozilla.org/~jorendorff/es6-draft.html#sec-generatorresume\n\t        return doneResult();\n\t      }\n\t\n\t      context.method = method;\n\t      context.arg = arg;\n\t\n\t      while (true) {\n\t        var delegate = context.delegate;\n\t        if (delegate) {\n\t          var delegateResult = maybeInvokeDelegate(delegate, context);\n\t          if (delegateResult) {\n\t            if (delegateResult === ContinueSentinel) continue;\n\t            return delegateResult;\n\t          }\n\t        }\n\t\n\t        if (context.method === \"next\") {\n\t          // Setting context._sent for legacy support of Babel's\n\t          // function.sent implementation.\n\t          context.sent = context._sent = context.arg;\n\t\n\t        } else if (context.method === \"throw\") {\n\t          if (state === GenStateSuspendedStart) {\n\t            state = GenStateCompleted;\n\t            throw context.arg;\n\t          }\n\t\n\t          context.dispatchException(context.arg);\n\t\n\t        } else if (context.method === \"return\") {\n\t          context.abrupt(\"return\", context.arg);\n\t        }\n\t\n\t        state = GenStateExecuting;\n\t\n\t        var record = tryCatch(innerFn, self, context);\n\t        if (record.type === \"normal\") {\n\t          // If an exception is thrown from innerFn, we leave state ===\n\t          // GenStateExecuting and loop back for another invocation.\n\t          state = context.done\n\t            ? GenStateCompleted\n\t            : GenStateSuspendedYield;\n\t\n\t          if (record.arg === ContinueSentinel) {\n\t            continue;\n\t          }\n\t\n\t          return {\n\t            value: record.arg,\n\t            done: context.done\n\t          };\n\t\n\t        } else if (record.type === \"throw\") {\n\t          state = GenStateCompleted;\n\t          // Dispatch the exception by looping back around to the\n\t          // context.dispatchException(context.arg) call above.\n\t          context.method = \"throw\";\n\t          context.arg = record.arg;\n\t        }\n\t      }\n\t    };\n\t  }\n\t\n\t  // Call delegate.iterator[context.method](context.arg) and handle the\n\t  // result, either by returning a { value, done } result from the\n\t  // delegate iterator, or by modifying context.method and context.arg,\n\t  // setting context.delegate to null, and returning the ContinueSentinel.\n\t  function maybeInvokeDelegate(delegate, context) {\n\t    var method = delegate.iterator[context.method];\n\t    if (method === undefined) {\n\t      // A .throw or .return when the delegate iterator has no .throw\n\t      // method always terminates the yield* loop.\n\t      context.delegate = null;\n\t\n\t      if (context.method === \"throw\") {\n\t        if (delegate.iterator.return) {\n\t          // If the delegate iterator has a return method, give it a\n\t          // chance to clean up.\n\t          context.method = \"return\";\n\t          context.arg = undefined;\n\t          maybeInvokeDelegate(delegate, context);\n\t\n\t          if (context.method === \"throw\") {\n\t            // If maybeInvokeDelegate(context) changed context.method from\n\t            // \"return\" to \"throw\", let that override the TypeError below.\n\t            return ContinueSentinel;\n\t          }\n\t        }\n\t\n\t        context.method = \"throw\";\n\t        context.arg = new TypeError(\n\t          \"The iterator does not provide a 'throw' method\");\n\t      }\n\t\n\t      return ContinueSentinel;\n\t    }\n\t\n\t    var record = tryCatch(method, delegate.iterator, context.arg);\n\t\n\t    if (record.type === \"throw\") {\n\t      context.method = \"throw\";\n\t      context.arg = record.arg;\n\t      context.delegate = null;\n\t      return ContinueSentinel;\n\t    }\n\t\n\t    var info = record.arg;\n\t\n\t    if (! info) {\n\t      context.method = \"throw\";\n\t      context.arg = new TypeError(\"iterator result is not an object\");\n\t      context.delegate = null;\n\t      return ContinueSentinel;\n\t    }\n\t\n\t    if (info.done) {\n\t      // Assign the result of the finished delegate to the temporary\n\t      // variable specified by delegate.resultName (see delegateYield).\n\t      context[delegate.resultName] = info.value;\n\t\n\t      // Resume execution at the desired location (see delegateYield).\n\t      context.next = delegate.nextLoc;\n\t\n\t      // If context.method was \"throw\" but the delegate handled the\n\t      // exception, let the outer generator proceed normally. If\n\t      // context.method was \"next\", forget context.arg since it has been\n\t      // \"consumed\" by the delegate iterator. If context.method was\n\t      // \"return\", allow the original .return call to continue in the\n\t      // outer generator.\n\t      if (context.method !== \"return\") {\n\t        context.method = \"next\";\n\t        context.arg = undefined;\n\t      }\n\t\n\t    } else {\n\t      // Re-yield the result returned by the delegate method.\n\t      return info;\n\t    }\n\t\n\t    // The delegate iterator is finished, so forget it and continue with\n\t    // the outer generator.\n\t    context.delegate = null;\n\t    return ContinueSentinel;\n\t  }\n\t\n\t  // Define Generator.prototype.{next,throw,return} in terms of the\n\t  // unified ._invoke helper method.\n\t  defineIteratorMethods(Gp);\n\t\n\t  Gp[toStringTagSymbol] = \"Generator\";\n\t\n\t  Gp.toString = function() {\n\t    return \"[object Generator]\";\n\t  };\n\t\n\t  function pushTryEntry(locs) {\n\t    var entry = { tryLoc: locs[0] };\n\t\n\t    if (1 in locs) {\n\t      entry.catchLoc = locs[1];\n\t    }\n\t\n\t    if (2 in locs) {\n\t      entry.finallyLoc = locs[2];\n\t      entry.afterLoc = locs[3];\n\t    }\n\t\n\t    this.tryEntries.push(entry);\n\t  }\n\t\n\t  function resetTryEntry(entry) {\n\t    var record = entry.completion || {};\n\t    record.type = \"normal\";\n\t    delete record.arg;\n\t    entry.completion = record;\n\t  }\n\t\n\t  function Context(tryLocsList) {\n\t    // The root entry object (effectively a try statement without a catch\n\t    // or a finally block) gives us a place to store values thrown from\n\t    // locations where there is no enclosing try statement.\n\t    this.tryEntries = [{ tryLoc: \"root\" }];\n\t    tryLocsList.forEach(pushTryEntry, this);\n\t    this.reset(true);\n\t  }\n\t\n\t  runtime.keys = function(object) {\n\t    var keys = [];\n\t    for (var key in object) {\n\t      keys.push(key);\n\t    }\n\t    keys.reverse();\n\t\n\t    // Rather than returning an object with a next method, we keep\n\t    // things simple and return the next function itself.\n\t    return function next() {\n\t      while (keys.length) {\n\t        var key = keys.pop();\n\t        if (key in object) {\n\t          next.value = key;\n\t          next.done = false;\n\t          return next;\n\t        }\n\t      }\n\t\n\t      // To avoid creating an additional object, we just hang the .value\n\t      // and .done properties off the next function object itself. This\n\t      // also ensures that the minifier will not anonymize the function.\n\t      next.done = true;\n\t      return next;\n\t    };\n\t  };\n\t\n\t  function values(iterable) {\n\t    if (iterable) {\n\t      var iteratorMethod = iterable[iteratorSymbol];\n\t      if (iteratorMethod) {\n\t        return iteratorMethod.call(iterable);\n\t      }\n\t\n\t      if (typeof iterable.next === \"function\") {\n\t        return iterable;\n\t      }\n\t\n\t      if (!isNaN(iterable.length)) {\n\t        var i = -1, next = function next() {\n\t          while (++i < iterable.length) {\n\t            if (hasOwn.call(iterable, i)) {\n\t              next.value = iterable[i];\n\t              next.done = false;\n\t              return next;\n\t            }\n\t          }\n\t\n\t          next.value = undefined;\n\t          next.done = true;\n\t\n\t          return next;\n\t        };\n\t\n\t        return next.next = next;\n\t      }\n\t    }\n\t\n\t    // Return an iterator with no values.\n\t    return { next: doneResult };\n\t  }\n\t  runtime.values = values;\n\t\n\t  function doneResult() {\n\t    return { value: undefined, done: true };\n\t  }\n\t\n\t  Context.prototype = {\n\t    constructor: Context,\n\t\n\t    reset: function(skipTempReset) {\n\t      this.prev = 0;\n\t      this.next = 0;\n\t      // Resetting context._sent for legacy support of Babel's\n\t      // function.sent implementation.\n\t      this.sent = this._sent = undefined;\n\t      this.done = false;\n\t      this.delegate = null;\n\t\n\t      this.method = \"next\";\n\t      this.arg = undefined;\n\t\n\t      this.tryEntries.forEach(resetTryEntry);\n\t\n\t      if (!skipTempReset) {\n\t        for (var name in this) {\n\t          // Not sure about the optimal order of these conditions:\n\t          if (name.charAt(0) === \"t\" &&\n\t              hasOwn.call(this, name) &&\n\t              !isNaN(+name.slice(1))) {\n\t            this[name] = undefined;\n\t          }\n\t        }\n\t      }\n\t    },\n\t\n\t    stop: function() {\n\t      this.done = true;\n\t\n\t      var rootEntry = this.tryEntries[0];\n\t      var rootRecord = rootEntry.completion;\n\t      if (rootRecord.type === \"throw\") {\n\t        throw rootRecord.arg;\n\t      }\n\t\n\t      return this.rval;\n\t    },\n\t\n\t    dispatchException: function(exception) {\n\t      if (this.done) {\n\t        throw exception;\n\t      }\n\t\n\t      var context = this;\n\t      function handle(loc, caught) {\n\t        record.type = \"throw\";\n\t        record.arg = exception;\n\t        context.next = loc;\n\t\n\t        if (caught) {\n\t          // If the dispatched exception was caught by a catch block,\n\t          // then let that catch block handle the exception normally.\n\t          context.method = \"next\";\n\t          context.arg = undefined;\n\t        }\n\t\n\t        return !! caught;\n\t      }\n\t\n\t      for (var i = this.tryEntries.length - 1; i >= 0; --i) {\n\t        var entry = this.tryEntries[i];\n\t        var record = entry.completion;\n\t\n\t        if (entry.tryLoc === \"root\") {\n\t          // Exception thrown outside of any try block that could handle\n\t          // it, so set the completion value of the entire function to\n\t          // throw the exception.\n\t          return handle(\"end\");\n\t        }\n\t\n\t        if (entry.tryLoc <= this.prev) {\n\t          var hasCatch = hasOwn.call(entry, \"catchLoc\");\n\t          var hasFinally = hasOwn.call(entry, \"finallyLoc\");\n\t\n\t          if (hasCatch && hasFinally) {\n\t            if (this.prev < entry.catchLoc) {\n\t              return handle(entry.catchLoc, true);\n\t            } else if (this.prev < entry.finallyLoc) {\n\t              return handle(entry.finallyLoc);\n\t            }\n\t\n\t          } else if (hasCatch) {\n\t            if (this.prev < entry.catchLoc) {\n\t              return handle(entry.catchLoc, true);\n\t            }\n\t\n\t          } else if (hasFinally) {\n\t            if (this.prev < entry.finallyLoc) {\n\t              return handle(entry.finallyLoc);\n\t            }\n\t\n\t          } else {\n\t            throw new Error(\"try statement without catch or finally\");\n\t          }\n\t        }\n\t      }\n\t    },\n\t\n\t    abrupt: function(type, arg) {\n\t      for (var i = this.tryEntries.length - 1; i >= 0; --i) {\n\t        var entry = this.tryEntries[i];\n\t        if (entry.tryLoc <= this.prev &&\n\t            hasOwn.call(entry, \"finallyLoc\") &&\n\t            this.prev < entry.finallyLoc) {\n\t          var finallyEntry = entry;\n\t          break;\n\t        }\n\t      }\n\t\n\t      if (finallyEntry &&\n\t          (type === \"break\" ||\n\t           type === \"continue\") &&\n\t          finallyEntry.tryLoc <= arg &&\n\t          arg <= finallyEntry.finallyLoc) {\n\t        // Ignore the finally entry if control is not jumping to a\n\t        // location outside the try/catch block.\n\t        finallyEntry = null;\n\t      }\n\t\n\t      var record = finallyEntry ? finallyEntry.completion : {};\n\t      record.type = type;\n\t      record.arg = arg;\n\t\n\t      if (finallyEntry) {\n\t        this.method = \"next\";\n\t        this.next = finallyEntry.finallyLoc;\n\t        return ContinueSentinel;\n\t      }\n\t\n\t      return this.complete(record);\n\t    },\n\t\n\t    complete: function(record, afterLoc) {\n\t      if (record.type === \"throw\") {\n\t        throw record.arg;\n\t      }\n\t\n\t      if (record.type === \"break\" ||\n\t          record.type === \"continue\") {\n\t        this.next = record.arg;\n\t      } else if (record.type === \"return\") {\n\t        this.rval = this.arg = record.arg;\n\t        this.method = \"return\";\n\t        this.next = \"end\";\n\t      } else if (record.type === \"normal\" && afterLoc) {\n\t        this.next = afterLoc;\n\t      }\n\t\n\t      return ContinueSentinel;\n\t    },\n\t\n\t    finish: function(finallyLoc) {\n\t      for (var i = this.tryEntries.length - 1; i >= 0; --i) {\n\t        var entry = this.tryEntries[i];\n\t        if (entry.finallyLoc === finallyLoc) {\n\t          this.complete(entry.completion, entry.afterLoc);\n\t          resetTryEntry(entry);\n\t          return ContinueSentinel;\n\t        }\n\t      }\n\t    },\n\t\n\t    \"catch\": function(tryLoc) {\n\t      for (var i = this.tryEntries.length - 1; i >= 0; --i) {\n\t        var entry = this.tryEntries[i];\n\t        if (entry.tryLoc === tryLoc) {\n\t          var record = entry.completion;\n\t          if (record.type === \"throw\") {\n\t            var thrown = record.arg;\n\t            resetTryEntry(entry);\n\t          }\n\t          return thrown;\n\t        }\n\t      }\n\t\n\t      // The context.catch method must only be called with a location\n\t      // argument that corresponds to a known catch block.\n\t      throw new Error(\"illegal catch attempt\");\n\t    },\n\t\n\t    delegateYield: function(iterable, resultName, nextLoc) {\n\t      this.delegate = {\n\t        iterator: values(iterable),\n\t        resultName: resultName,\n\t        nextLoc: nextLoc\n\t      };\n\t\n\t      if (this.method === \"next\") {\n\t        // Deliberately forget the last sent value so that we don't\n\t        // accidentally pass it on to the delegate.\n\t        this.arg = undefined;\n\t      }\n\t\n\t      return ContinueSentinel;\n\t    }\n\t  };\n\t})(\n\t  // Among the various tricks for obtaining a reference to the global\n\t  // object, this seems to be the most reliable technique that does not\n\t  // use indirect eval (which violates Content Security Policy).\n\t  typeof global === \"object\" ? global :\n\t  typeof window === \"object\" ? window :\n\t  typeof self === \"object\" ? self : this\n\t);\n\t\n\t/* WEBPACK VAR INJECTION */}.call(exports, (function() { return this; }()), __webpack_require__(5)))\n\n/***/ },\n/* 94 */\n/***/ function(module, exports) {\n\n\t// Generated by CoffeeScript 1.9.2\n\t(function() {\n\t  var hasProp = {}.hasOwnProperty,\n\t    slice = [].slice;\n\t\n\t  module.exports = function(source, scope) {\n\t    var key, keys, value, values;\n\t    keys = [];\n\t    values = [];\n\t    for (key in scope) {\n\t      if (!hasProp.call(scope, key)) continue;\n\t      value = scope[key];\n\t      if (key === 'this') {\n\t        continue;\n\t      }\n\t      keys.push(key);\n\t      values.push(value);\n\t    }\n\t    return Function.apply(null, slice.call(keys).concat([source])).apply(scope[\"this\"], values);\n\t  };\n\t\n\t}).call(this);\n\n\n/***/ },\n/* 95 */\n/***/ function(module, exports, __webpack_require__) {\n\n\t(function (factory) {\n\t    if (true) {\n\t        // Node/CommonJS\n\t        module.exports = factory();\n\t    } else if (typeof define === 'function' && define.amd) {\n\t        // AMD\n\t        define(factory);\n\t    } else {\n\t        // Browser globals (with support for web workers)\n\t        var glob;\n\t\n\t        try {\n\t            glob = window;\n\t        } catch (e) {\n\t            glob = self;\n\t        }\n\t\n\t        glob.SparkMD5 = factory();\n\t    }\n\t}(function (undefined) {\n\t\n\t    'use strict';\n\t\n\t    /*\n\t     * Fastest md5 implementation around (JKM md5).\n\t     * Credits: Joseph Myers\n\t     *\n\t     * @see http://www.myersdaily.org/joseph/javascript/md5-text.html\n\t     * @see http://jsperf.com/md5-shootout/7\n\t     */\n\t\n\t    /* this function is much faster,\n\t      so if possible we use it. Some IEs\n\t      are the only ones I know of that\n\t      need the idiotic second function,\n\t      generated by an if clause.  */\n\t    var add32 = function (a, b) {\n\t        return (a + b) & 0xFFFFFFFF;\n\t    },\n\t        hex_chr = ['0', '1', '2', '3', '4', '5', '6', '7', '8', '9', 'a', 'b', 'c', 'd', 'e', 'f'];\n\t\n\t\n\t    function cmn(q, a, b, x, s, t) {\n\t        a = add32(add32(a, q), add32(x, t));\n\t        return add32((a << s) | (a >>> (32 - s)), b);\n\t    }\n\t\n\t    function md5cycle(x, k) {\n\t        var a = x[0],\n\t            b = x[1],\n\t            c = x[2],\n\t            d = x[3];\n\t\n\t        a += (b & c | ~b & d) + k[0] - 680876936 | 0;\n\t        a  = (a << 7 | a >>> 25) + b | 0;\n\t        d += (a & b | ~a & c) + k[1] - 389564586 | 0;\n\t        d  = (d << 12 | d >>> 20) + a | 0;\n\t        c += (d & a | ~d & b) + k[2] + 606105819 | 0;\n\t        c  = (c << 17 | c >>> 15) + d | 0;\n\t        b += (c & d | ~c & a) + k[3] - 1044525330 | 0;\n\t        b  = (b << 22 | b >>> 10) + c | 0;\n\t        a += (b & c | ~b & d) + k[4] - 176418897 | 0;\n\t        a  = (a << 7 | a >>> 25) + b | 0;\n\t        d += (a & b | ~a & c) + k[5] + 1200080426 | 0;\n\t        d  = (d << 12 | d >>> 20) + a | 0;\n\t        c += (d & a | ~d & b) + k[6] - 1473231341 | 0;\n\t        c  = (c << 17 | c >>> 15) + d | 0;\n\t        b += (c & d | ~c & a) + k[7] - 45705983 | 0;\n\t        b  = (b << 22 | b >>> 10) + c | 0;\n\t        a += (b & c | ~b & d) + k[8] + 1770035416 | 0;\n\t        a  = (a << 7 | a >>> 25) + b | 0;\n\t        d += (a & b | ~a & c) + k[9] - 1958414417 | 0;\n\t        d  = (d << 12 | d >>> 20) + a | 0;\n\t        c += (d & a | ~d & b) + k[10] - 42063 | 0;\n\t        c  = (c << 17 | c >>> 15) + d | 0;\n\t        b += (c & d | ~c & a) + k[11] - 1990404162 | 0;\n\t        b  = (b << 22 | b >>> 10) + c | 0;\n\t        a += (b & c | ~b & d) + k[12] + 1804603682 | 0;\n\t        a  = (a << 7 | a >>> 25) + b | 0;\n\t        d += (a & b | ~a & c) + k[13] - 40341101 | 0;\n\t        d  = (d << 12 | d >>> 20) + a | 0;\n\t        c += (d & a | ~d & b) + k[14] - 1502002290 | 0;\n\t        c  = (c << 17 | c >>> 15) + d | 0;\n\t        b += (c & d | ~c & a) + k[15] + 1236535329 | 0;\n\t        b  = (b << 22 | b >>> 10) + c | 0;\n\t\n\t        a += (b & d | c & ~d) + k[1] - 165796510 | 0;\n\t        a  = (a << 5 | a >>> 27) + b | 0;\n\t        d += (a & c | b & ~c) + k[6] - 1069501632 | 0;\n\t        d  = (d << 9 | d >>> 23) + a | 0;\n\t        c += (d & b | a & ~b) + k[11] + 643717713 | 0;\n\t        c  = (c << 14 | c >>> 18) + d | 0;\n\t        b += (c & a | d & ~a) + k[0] - 373897302 | 0;\n\t        b  = (b << 20 | b >>> 12) + c | 0;\n\t        a += (b & d | c & ~d) + k[5] - 701558691 | 0;\n\t        a  = (a << 5 | a >>> 27) + b | 0;\n\t        d += (a & c | b & ~c) + k[10] + 38016083 | 0;\n\t        d  = (d << 9 | d >>> 23) + a | 0;\n\t        c += (d & b | a & ~b) + k[15] - 660478335 | 0;\n\t        c  = (c << 14 | c >>> 18) + d | 0;\n\t        b += (c & a | d & ~a) + k[4] - 405537848 | 0;\n\t        b  = (b << 20 | b >>> 12) + c | 0;\n\t        a += (b & d | c & ~d) + k[9] + 568446438 | 0;\n\t        a  = (a << 5 | a >>> 27) + b | 0;\n\t        d += (a & c | b & ~c) + k[14] - 1019803690 | 0;\n\t        d  = (d << 9 | d >>> 23) + a | 0;\n\t        c += (d & b | a & ~b) + k[3] - 187363961 | 0;\n\t        c  = (c << 14 | c >>> 18) + d | 0;\n\t        b += (c & a | d & ~a) + k[8] + 1163531501 | 0;\n\t        b  = (b << 20 | b >>> 12) + c | 0;\n\t        a += (b & d | c & ~d) + k[13] - 1444681467 | 0;\n\t        a  = (a << 5 | a >>> 27) + b | 0;\n\t        d += (a & c | b & ~c) + k[2] - 51403784 | 0;\n\t        d  = (d << 9 | d >>> 23) + a | 0;\n\t        c += (d & b | a & ~b) + k[7] + 1735328473 | 0;\n\t        c  = (c << 14 | c >>> 18) + d | 0;\n\t        b += (c & a | d & ~a) + k[12] - 1926607734 | 0;\n\t        b  = (b << 20 | b >>> 12) + c | 0;\n\t\n\t        a += (b ^ c ^ d) + k[5] - 378558 | 0;\n\t        a  = (a << 4 | a >>> 28) + b | 0;\n\t        d += (a ^ b ^ c) + k[8] - 2022574463 | 0;\n\t        d  = (d << 11 | d >>> 21) + a | 0;\n\t        c += (d ^ a ^ b) + k[11] + 1839030562 | 0;\n\t        c  = (c << 16 | c >>> 16) + d | 0;\n\t        b += (c ^ d ^ a) + k[14] - 35309556 | 0;\n\t        b  = (b << 23 | b >>> 9) + c | 0;\n\t        a += (b ^ c ^ d) + k[1] - 1530992060 | 0;\n\t        a  = (a << 4 | a >>> 28) + b | 0;\n\t        d += (a ^ b ^ c) + k[4] + 1272893353 | 0;\n\t        d  = (d << 11 | d >>> 21) + a | 0;\n\t        c += (d ^ a ^ b) + k[7] - 155497632 | 0;\n\t        c  = (c << 16 | c >>> 16) + d | 0;\n\t        b += (c ^ d ^ a) + k[10] - 1094730640 | 0;\n\t        b  = (b << 23 | b >>> 9) + c | 0;\n\t        a += (b ^ c ^ d) + k[13] + 681279174 | 0;\n\t        a  = (a << 4 | a >>> 28) + b | 0;\n\t        d += (a ^ b ^ c) + k[0] - 358537222 | 0;\n\t        d  = (d << 11 | d >>> 21) + a | 0;\n\t        c += (d ^ a ^ b) + k[3] - 722521979 | 0;\n\t        c  = (c << 16 | c >>> 16) + d | 0;\n\t        b += (c ^ d ^ a) + k[6] + 76029189 | 0;\n\t        b  = (b << 23 | b >>> 9) + c | 0;\n\t        a += (b ^ c ^ d) + k[9] - 640364487 | 0;\n\t        a  = (a << 4 | a >>> 28) + b | 0;\n\t        d += (a ^ b ^ c) + k[12] - 421815835 | 0;\n\t        d  = (d << 11 | d >>> 21) + a | 0;\n\t        c += (d ^ a ^ b) + k[15] + 530742520 | 0;\n\t        c  = (c << 16 | c >>> 16) + d | 0;\n\t        b += (c ^ d ^ a) + k[2] - 995338651 | 0;\n\t        b  = (b << 23 | b >>> 9) + c | 0;\n\t\n\t        a += (c ^ (b | ~d)) + k[0] - 198630844 | 0;\n\t        a  = (a << 6 | a >>> 26) + b | 0;\n\t        d += (b ^ (a | ~c)) + k[7] + 1126891415 | 0;\n\t        d  = (d << 10 | d >>> 22) + a | 0;\n\t        c += (a ^ (d | ~b)) + k[14] - 1416354905 | 0;\n\t        c  = (c << 15 | c >>> 17) + d | 0;\n\t        b += (d ^ (c | ~a)) + k[5] - 57434055 | 0;\n\t        b  = (b << 21 |b >>> 11) + c | 0;\n\t        a += (c ^ (b | ~d)) + k[12] + 1700485571 | 0;\n\t        a  = (a << 6 | a >>> 26) + b | 0;\n\t        d += (b ^ (a | ~c)) + k[3] - 1894986606 | 0;\n\t        d  = (d << 10 | d >>> 22) + a | 0;\n\t        c += (a ^ (d | ~b)) + k[10] - 1051523 | 0;\n\t        c  = (c << 15 | c >>> 17) + d | 0;\n\t        b += (d ^ (c | ~a)) + k[1] - 2054922799 | 0;\n\t        b  = (b << 21 |b >>> 11) + c | 0;\n\t        a += (c ^ (b | ~d)) + k[8] + 1873313359 | 0;\n\t        a  = (a << 6 | a >>> 26) + b | 0;\n\t        d += (b ^ (a | ~c)) + k[15] - 30611744 | 0;\n\t        d  = (d << 10 | d >>> 22) + a | 0;\n\t        c += (a ^ (d | ~b)) + k[6] - 1560198380 | 0;\n\t        c  = (c << 15 | c >>> 17) + d | 0;\n\t        b += (d ^ (c | ~a)) + k[13] + 1309151649 | 0;\n\t        b  = (b << 21 |b >>> 11) + c | 0;\n\t        a += (c ^ (b | ~d)) + k[4] - 145523070 | 0;\n\t        a  = (a << 6 | a >>> 26) + b | 0;\n\t        d += (b ^ (a | ~c)) + k[11] - 1120210379 | 0;\n\t        d  = (d << 10 | d >>> 22) + a | 0;\n\t        c += (a ^ (d | ~b)) + k[2] + 718787259 | 0;\n\t        c  = (c << 15 | c >>> 17) + d | 0;\n\t        b += (d ^ (c | ~a)) + k[9] - 343485551 | 0;\n\t        b  = (b << 21 | b >>> 11) + c | 0;\n\t\n\t        x[0] = a + x[0] | 0;\n\t        x[1] = b + x[1] | 0;\n\t        x[2] = c + x[2] | 0;\n\t        x[3] = d + x[3] | 0;\n\t    }\n\t\n\t    function md5blk(s) {\n\t        var md5blks = [],\n\t            i; /* Andy King said do it this way. */\n\t\n\t        for (i = 0; i < 64; i += 4) {\n\t            md5blks[i >> 2] = s.charCodeAt(i) + (s.charCodeAt(i + 1) << 8) + (s.charCodeAt(i + 2) << 16) + (s.charCodeAt(i + 3) << 24);\n\t        }\n\t        return md5blks;\n\t    }\n\t\n\t    function md5blk_array(a) {\n\t        var md5blks = [],\n\t            i; /* Andy King said do it this way. */\n\t\n\t        for (i = 0; i < 64; i += 4) {\n\t            md5blks[i >> 2] = a[i] + (a[i + 1] << 8) + (a[i + 2] << 16) + (a[i + 3] << 24);\n\t        }\n\t        return md5blks;\n\t    }\n\t\n\t    function md51(s) {\n\t        var n = s.length,\n\t            state = [1732584193, -271733879, -1732584194, 271733878],\n\t            i,\n\t            length,\n\t            tail,\n\t            tmp,\n\t            lo,\n\t            hi;\n\t\n\t        for (i = 64; i <= n; i += 64) {\n\t            md5cycle(state, md5blk(s.substring(i - 64, i)));\n\t        }\n\t        s = s.substring(i - 64);\n\t        length = s.length;\n\t        tail = [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0];\n\t        for (i = 0; i < length; i += 1) {\n\t            tail[i >> 2] |= s.charCodeAt(i) << ((i % 4) << 3);\n\t        }\n\t        tail[i >> 2] |= 0x80 << ((i % 4) << 3);\n\t        if (i > 55) {\n\t            md5cycle(state, tail);\n\t            for (i = 0; i < 16; i += 1) {\n\t                tail[i] = 0;\n\t            }\n\t        }\n\t\n\t        // Beware that the final length might not fit in 32 bits so we take care of that\n\t        tmp = n * 8;\n\t        tmp = tmp.toString(16).match(/(.*?)(.{0,8})$/);\n\t        lo = parseInt(tmp[2], 16);\n\t        hi = parseInt(tmp[1], 16) || 0;\n\t\n\t        tail[14] = lo;\n\t        tail[15] = hi;\n\t\n\t        md5cycle(state, tail);\n\t        return state;\n\t    }\n\t\n\t    function md51_array(a) {\n\t        var n = a.length,\n\t            state = [1732584193, -271733879, -1732584194, 271733878],\n\t            i,\n\t            length,\n\t            tail,\n\t            tmp,\n\t            lo,\n\t            hi;\n\t\n\t        for (i = 64; i <= n; i += 64) {\n\t            md5cycle(state, md5blk_array(a.subarray(i - 64, i)));\n\t        }\n\t\n\t        // Not sure if it is a bug, however IE10 will always produce a sub array of length 1\n\t        // containing the last element of the parent array if the sub array specified starts\n\t        // beyond the length of the parent array - weird.\n\t        // https://connect.microsoft.com/IE/feedback/details/771452/typed-array-subarray-issue\n\t        a = (i - 64) < n ? a.subarray(i - 64) : new Uint8Array(0);\n\t\n\t        length = a.length;\n\t        tail = [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0];\n\t        for (i = 0; i < length; i += 1) {\n\t            tail[i >> 2] |= a[i] << ((i % 4) << 3);\n\t        }\n\t\n\t        tail[i >> 2] |= 0x80 << ((i % 4) << 3);\n\t        if (i > 55) {\n\t            md5cycle(state, tail);\n\t            for (i = 0; i < 16; i += 1) {\n\t                tail[i] = 0;\n\t            }\n\t        }\n\t\n\t        // Beware that the final length might not fit in 32 bits so we take care of that\n\t        tmp = n * 8;\n\t        tmp = tmp.toString(16).match(/(.*?)(.{0,8})$/);\n\t        lo = parseInt(tmp[2], 16);\n\t        hi = parseInt(tmp[1], 16) || 0;\n\t\n\t        tail[14] = lo;\n\t        tail[15] = hi;\n\t\n\t        md5cycle(state, tail);\n\t\n\t        return state;\n\t    }\n\t\n\t    function rhex(n) {\n\t        var s = '',\n\t            j;\n\t        for (j = 0; j < 4; j += 1) {\n\t            s += hex_chr[(n >> (j * 8 + 4)) & 0x0F] + hex_chr[(n >> (j * 8)) & 0x0F];\n\t        }\n\t        return s;\n\t    }\n\t\n\t    function hex(x) {\n\t        var i;\n\t        for (i = 0; i < x.length; i += 1) {\n\t            x[i] = rhex(x[i]);\n\t        }\n\t        return x.join('');\n\t    }\n\t\n\t    // In some cases the fast add32 function cannot be used..\n\t    if (hex(md51('hello')) !== '5d41402abc4b2a76b9719d911017c592') {\n\t        add32 = function (x, y) {\n\t            var lsw = (x & 0xFFFF) + (y & 0xFFFF),\n\t                msw = (x >> 16) + (y >> 16) + (lsw >> 16);\n\t            return (msw << 16) | (lsw & 0xFFFF);\n\t        };\n\t    }\n\t\n\t    // ---------------------------------------------------\n\t\n\t    /**\n\t     * ArrayBuffer slice polyfill.\n\t     *\n\t     * @see https://github.com/ttaubert/node-arraybuffer-slice\n\t     */\n\t\n\t    if (typeof ArrayBuffer !== 'undefined' && !ArrayBuffer.prototype.slice) {\n\t        (function () {\n\t            function clamp(val, length) {\n\t                val = (val | 0) || 0;\n\t\n\t                if (val < 0) {\n\t                    return Math.max(val + length, 0);\n\t                }\n\t\n\t                return Math.min(val, length);\n\t            }\n\t\n\t            ArrayBuffer.prototype.slice = function (from, to) {\n\t                var length = this.byteLength,\n\t                    begin = clamp(from, length),\n\t                    end = length,\n\t                    num,\n\t                    target,\n\t                    targetArray,\n\t                    sourceArray;\n\t\n\t                if (to !== undefined) {\n\t                    end = clamp(to, length);\n\t                }\n\t\n\t                if (begin > end) {\n\t                    return new ArrayBuffer(0);\n\t                }\n\t\n\t                num = end - begin;\n\t                target = new ArrayBuffer(num);\n\t                targetArray = new Uint8Array(target);\n\t\n\t                sourceArray = new Uint8Array(this, begin, num);\n\t                targetArray.set(sourceArray);\n\t\n\t                return target;\n\t            };\n\t        })();\n\t    }\n\t\n\t    // ---------------------------------------------------\n\t\n\t    /**\n\t     * Helpers.\n\t     */\n\t\n\t    function toUtf8(str) {\n\t        if (/[\\u0080-\\uFFFF]/.test(str)) {\n\t            str = unescape(encodeURIComponent(str));\n\t        }\n\t\n\t        return str;\n\t    }\n\t\n\t    function utf8Str2ArrayBuffer(str, returnUInt8Array) {\n\t        var length = str.length,\n\t           buff = new ArrayBuffer(length),\n\t           arr = new Uint8Array(buff),\n\t           i;\n\t\n\t        for (i = 0; i < length; i += 1) {\n\t            arr[i] = str.charCodeAt(i);\n\t        }\n\t\n\t        return returnUInt8Array ? arr : buff;\n\t    }\n\t\n\t    function arrayBuffer2Utf8Str(buff) {\n\t        return String.fromCharCode.apply(null, new Uint8Array(buff));\n\t    }\n\t\n\t    function concatenateArrayBuffers(first, second, returnUInt8Array) {\n\t        var result = new Uint8Array(first.byteLength + second.byteLength);\n\t\n\t        result.set(new Uint8Array(first));\n\t        result.set(new Uint8Array(second), first.byteLength);\n\t\n\t        return returnUInt8Array ? result : result.buffer;\n\t    }\n\t\n\t    function hexToBinaryString(hex) {\n\t        var bytes = [],\n\t            length = hex.length,\n\t            x;\n\t\n\t        for (x = 0; x < length - 1; x += 2) {\n\t            bytes.push(parseInt(hex.substr(x, 2), 16));\n\t        }\n\t\n\t        return String.fromCharCode.apply(String, bytes);\n\t    }\n\t\n\t    // ---------------------------------------------------\n\t\n\t    /**\n\t     * SparkMD5 OOP implementation.\n\t     *\n\t     * Use this class to perform an incremental md5, otherwise use the\n\t     * static methods instead.\n\t     */\n\t\n\t    function SparkMD5() {\n\t        // call reset to init the instance\n\t        this.reset();\n\t    }\n\t\n\t    /**\n\t     * Appends a string.\n\t     * A conversion will be applied if an utf8 string is detected.\n\t     *\n\t     * @param {String} str The string to be appended\n\t     *\n\t     * @return {SparkMD5} The instance itself\n\t     */\n\t    SparkMD5.prototype.append = function (str) {\n\t        // Converts the string to utf8 bytes if necessary\n\t        // Then append as binary\n\t        this.appendBinary(toUtf8(str));\n\t\n\t        return this;\n\t    };\n\t\n\t    /**\n\t     * Appends a binary string.\n\t     *\n\t     * @param {String} contents The binary string to be appended\n\t     *\n\t     * @return {SparkMD5} The instance itself\n\t     */\n\t    SparkMD5.prototype.appendBinary = function (contents) {\n\t        this._buff += contents;\n\t        this._length += contents.length;\n\t\n\t        var length = this._buff.length,\n\t            i;\n\t\n\t        for (i = 64; i <= length; i += 64) {\n\t            md5cycle(this._hash, md5blk(this._buff.substring(i - 64, i)));\n\t        }\n\t\n\t        this._buff = this._buff.substring(i - 64);\n\t\n\t        return this;\n\t    };\n\t\n\t    /**\n\t     * Finishes the incremental computation, reseting the internal state and\n\t     * returning the result.\n\t     *\n\t     * @param {Boolean} raw True to get the raw string, false to get the hex string\n\t     *\n\t     * @return {String} The result\n\t     */\n\t    SparkMD5.prototype.end = function (raw) {\n\t        var buff = this._buff,\n\t            length = buff.length,\n\t            i,\n\t            tail = [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0],\n\t            ret;\n\t\n\t        for (i = 0; i < length; i += 1) {\n\t            tail[i >> 2] |= buff.charCodeAt(i) << ((i % 4) << 3);\n\t        }\n\t\n\t        this._finish(tail, length);\n\t        ret = hex(this._hash);\n\t\n\t        if (raw) {\n\t            ret = hexToBinaryString(ret);\n\t        }\n\t\n\t        this.reset();\n\t\n\t        return ret;\n\t    };\n\t\n\t    /**\n\t     * Resets the internal state of the computation.\n\t     *\n\t     * @return {SparkMD5} The instance itself\n\t     */\n\t    SparkMD5.prototype.reset = function () {\n\t        this._buff = '';\n\t        this._length = 0;\n\t        this._hash = [1732584193, -271733879, -1732584194, 271733878];\n\t\n\t        return this;\n\t    };\n\t\n\t    /**\n\t     * Gets the internal state of the computation.\n\t     *\n\t     * @return {Object} The state\n\t     */\n\t    SparkMD5.prototype.getState = function () {\n\t        return {\n\t            buff: this._buff,\n\t            length: this._length,\n\t            hash: this._hash\n\t        };\n\t    };\n\t\n\t    /**\n\t     * Gets the internal state of the computation.\n\t     *\n\t     * @param {Object} state The state\n\t     *\n\t     * @return {SparkMD5} The instance itself\n\t     */\n\t    SparkMD5.prototype.setState = function (state) {\n\t        this._buff = state.buff;\n\t        this._length = state.length;\n\t        this._hash = state.hash;\n\t\n\t        return this;\n\t    };\n\t\n\t    /**\n\t     * Releases memory used by the incremental buffer and other additional\n\t     * resources. If you plan to use the instance again, use reset instead.\n\t     */\n\t    SparkMD5.prototype.destroy = function () {\n\t        delete this._hash;\n\t        delete this._buff;\n\t        delete this._length;\n\t    };\n\t\n\t    /**\n\t     * Finish the final calculation based on the tail.\n\t     *\n\t     * @param {Array}  tail   The tail (will be modified)\n\t     * @param {Number} length The length of the remaining buffer\n\t     */\n\t    SparkMD5.prototype._finish = function (tail, length) {\n\t        var i = length,\n\t            tmp,\n\t            lo,\n\t            hi;\n\t\n\t        tail[i >> 2] |= 0x80 << ((i % 4) << 3);\n\t        if (i > 55) {\n\t            md5cycle(this._hash, tail);\n\t            for (i = 0; i < 16; i += 1) {\n\t                tail[i] = 0;\n\t            }\n\t        }\n\t\n\t        // Do the final computation based on the tail and length\n\t        // Beware that the final length may not fit in 32 bits so we take care of that\n\t        tmp = this._length * 8;\n\t        tmp = tmp.toString(16).match(/(.*?)(.{0,8})$/);\n\t        lo = parseInt(tmp[2], 16);\n\t        hi = parseInt(tmp[1], 16) || 0;\n\t\n\t        tail[14] = lo;\n\t        tail[15] = hi;\n\t        md5cycle(this._hash, tail);\n\t    };\n\t\n\t    /**\n\t     * Performs the md5 hash on a string.\n\t     * A conversion will be applied if utf8 string is detected.\n\t     *\n\t     * @param {String}  str The string\n\t     * @param {Boolean} raw True to get the raw string, false to get the hex string\n\t     *\n\t     * @return {String} The result\n\t     */\n\t    SparkMD5.hash = function (str, raw) {\n\t        // Converts the string to utf8 bytes if necessary\n\t        // Then compute it using the binary function\n\t        return SparkMD5.hashBinary(toUtf8(str), raw);\n\t    };\n\t\n\t    /**\n\t     * Performs the md5 hash on a binary string.\n\t     *\n\t     * @param {String}  content The binary string\n\t     * @param {Boolean} raw     True to get the raw string, false to get the hex string\n\t     *\n\t     * @return {String} The result\n\t     */\n\t    SparkMD5.hashBinary = function (content, raw) {\n\t        var hash = md51(content),\n\t            ret = hex(hash);\n\t\n\t        return raw ? hexToBinaryString(ret) : ret;\n\t    };\n\t\n\t    // ---------------------------------------------------\n\t\n\t    /**\n\t     * SparkMD5 OOP implementation for array buffers.\n\t     *\n\t     * Use this class to perform an incremental md5 ONLY for array buffers.\n\t     */\n\t    SparkMD5.ArrayBuffer = function () {\n\t        // call reset to init the instance\n\t        this.reset();\n\t    };\n\t\n\t    /**\n\t     * Appends an array buffer.\n\t     *\n\t     * @param {ArrayBuffer} arr The array to be appended\n\t     *\n\t     * @return {SparkMD5.ArrayBuffer} The instance itself\n\t     */\n\t    SparkMD5.ArrayBuffer.prototype.append = function (arr) {\n\t        var buff = concatenateArrayBuffers(this._buff.buffer, arr, true),\n\t            length = buff.length,\n\t            i;\n\t\n\t        this._length += arr.byteLength;\n\t\n\t        for (i = 64; i <= length; i += 64) {\n\t            md5cycle(this._hash, md5blk_array(buff.subarray(i - 64, i)));\n\t        }\n\t\n\t        this._buff = (i - 64) < length ? new Uint8Array(buff.buffer.slice(i - 64)) : new Uint8Array(0);\n\t\n\t        return this;\n\t    };\n\t\n\t    /**\n\t     * Finishes the incremental computation, reseting the internal state and\n\t     * returning the result.\n\t     *\n\t     * @param {Boolean} raw True to get the raw string, false to get the hex string\n\t     *\n\t     * @return {String} The result\n\t     */\n\t    SparkMD5.ArrayBuffer.prototype.end = function (raw) {\n\t        var buff = this._buff,\n\t            length = buff.length,\n\t            tail = [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0],\n\t            i,\n\t            ret;\n\t\n\t        for (i = 0; i < length; i += 1) {\n\t            tail[i >> 2] |= buff[i] << ((i % 4) << 3);\n\t        }\n\t\n\t        this._finish(tail, length);\n\t        ret = hex(this._hash);\n\t\n\t        if (raw) {\n\t            ret = hexToBinaryString(ret);\n\t        }\n\t\n\t        this.reset();\n\t\n\t        return ret;\n\t    };\n\t\n\t    /**\n\t     * Resets the internal state of the computation.\n\t     *\n\t     * @return {SparkMD5.ArrayBuffer} The instance itself\n\t     */\n\t    SparkMD5.ArrayBuffer.prototype.reset = function () {\n\t        this._buff = new Uint8Array(0);\n\t        this._length = 0;\n\t        this._hash = [1732584193, -271733879, -1732584194, 271733878];\n\t\n\t        return this;\n\t    };\n\t\n\t    /**\n\t     * Gets the internal state of the computation.\n\t     *\n\t     * @return {Object} The state\n\t     */\n\t    SparkMD5.ArrayBuffer.prototype.getState = function () {\n\t        var state = SparkMD5.prototype.getState.call(this);\n\t\n\t        // Convert buffer to a string\n\t        state.buff = arrayBuffer2Utf8Str(state.buff);\n\t\n\t        return state;\n\t    };\n\t\n\t    /**\n\t     * Gets the internal state of the computation.\n\t     *\n\t     * @param {Object} state The state\n\t     *\n\t     * @return {SparkMD5.ArrayBuffer} The instance itself\n\t     */\n\t    SparkMD5.ArrayBuffer.prototype.setState = function (state) {\n\t        // Convert string to buffer\n\t        state.buff = utf8Str2ArrayBuffer(state.buff, true);\n\t\n\t        return SparkMD5.prototype.setState.call(this, state);\n\t    };\n\t\n\t    SparkMD5.ArrayBuffer.prototype.destroy = SparkMD5.prototype.destroy;\n\t\n\t    SparkMD5.ArrayBuffer.prototype._finish = SparkMD5.prototype._finish;\n\t\n\t    /**\n\t     * Performs the md5 hash on an array buffer.\n\t     *\n\t     * @param {ArrayBuffer} arr The array buffer\n\t     * @param {Boolean}     raw True to get the raw string, false to get the hex one\n\t     *\n\t     * @return {String} The result\n\t     */\n\t    SparkMD5.ArrayBuffer.hash = function (arr, raw) {\n\t        var hash = md51_array(new Uint8Array(arr)),\n\t            ret = hex(hash);\n\t\n\t        return raw ? hexToBinaryString(ret) : ret;\n\t    };\n\t\n\t    return SparkMD5;\n\t}));\n\n\n/***/ },\n/* 96 */\n/***/ function(module, exports) {\n\n\t'use strict';\n\t\n\t/**\n\t * Stringify/parse functions that don't operate\n\t * recursively, so they avoid call stack exceeded\n\t * errors.\n\t */\n\texports.stringify = function stringify(input) {\n\t  var queue = [];\n\t  queue.push({obj: input});\n\t\n\t  var res = '';\n\t  var next, obj, prefix, val, i, arrayPrefix, keys, k, key, value, objPrefix;\n\t  while ((next = queue.pop())) {\n\t    obj = next.obj;\n\t    prefix = next.prefix || '';\n\t    val = next.val || '';\n\t    res += prefix;\n\t    if (val) {\n\t      res += val;\n\t    } else if (typeof obj !== 'object') {\n\t      res += typeof obj === 'undefined' ? null : JSON.stringify(obj);\n\t    } else if (obj === null) {\n\t      res += 'null';\n\t    } else if (Array.isArray(obj)) {\n\t      queue.push({val: ']'});\n\t      for (i = obj.length - 1; i >= 0; i--) {\n\t        arrayPrefix = i === 0 ? '' : ',';\n\t        queue.push({obj: obj[i], prefix: arrayPrefix});\n\t      }\n\t      queue.push({val: '['});\n\t    } else { // object\n\t      keys = [];\n\t      for (k in obj) {\n\t        if (obj.hasOwnProperty(k)) {\n\t          keys.push(k);\n\t        }\n\t      }\n\t      queue.push({val: '}'});\n\t      for (i = keys.length - 1; i >= 0; i--) {\n\t        key = keys[i];\n\t        value = obj[key];\n\t        objPrefix = (i > 0 ? ',' : '');\n\t        objPrefix += JSON.stringify(key) + ':';\n\t        queue.push({obj: value, prefix: objPrefix});\n\t      }\n\t      queue.push({val: '{'});\n\t    }\n\t  }\n\t  return res;\n\t};\n\t\n\t// Convenience function for the parse function.\n\t// This pop function is basically copied from\n\t// pouchCollate.parseIndexableString\n\tfunction pop(obj, stack, metaStack) {\n\t  var lastMetaElement = metaStack[metaStack.length - 1];\n\t  if (obj === lastMetaElement.element) {\n\t    // popping a meta-element, e.g. an object whose value is another object\n\t    metaStack.pop();\n\t    lastMetaElement = metaStack[metaStack.length - 1];\n\t  }\n\t  var element = lastMetaElement.element;\n\t  var lastElementIndex = lastMetaElement.index;\n\t  if (Array.isArray(element)) {\n\t    element.push(obj);\n\t  } else if (lastElementIndex === stack.length - 2) { // obj with key+value\n\t    var key = stack.pop();\n\t    element[key] = obj;\n\t  } else {\n\t    stack.push(obj); // obj with key only\n\t  }\n\t}\n\t\n\texports.parse = function (str) {\n\t  var stack = [];\n\t  var metaStack = []; // stack for arrays and objects\n\t  var i = 0;\n\t  var collationIndex,parsedNum,numChar;\n\t  var parsedString,lastCh,numConsecutiveSlashes,ch;\n\t  var arrayElement, objElement;\n\t  while (true) {\n\t    collationIndex = str[i++];\n\t    if (collationIndex === '}' ||\n\t        collationIndex === ']' ||\n\t        typeof collationIndex === 'undefined') {\n\t      if (stack.length === 1) {\n\t        return stack.pop();\n\t      } else {\n\t        pop(stack.pop(), stack, metaStack);\n\t        continue;\n\t      }\n\t    }\n\t    switch (collationIndex) {\n\t      case ' ':\n\t      case '\\t':\n\t      case '\\n':\n\t      case ':':\n\t      case ',':\n\t        break;\n\t      case 'n':\n\t        i += 3; // 'ull'\n\t        pop(null, stack, metaStack);\n\t        break;\n\t      case 't':\n\t        i += 3; // 'rue'\n\t        pop(true, stack, metaStack);\n\t        break;\n\t      case 'f':\n\t        i += 4; // 'alse'\n\t        pop(false, stack, metaStack);\n\t        break;\n\t      case '0':\n\t      case '1':\n\t      case '2':\n\t      case '3':\n\t      case '4':\n\t      case '5':\n\t      case '6':\n\t      case '7':\n\t      case '8':\n\t      case '9':\n\t      case '-':\n\t        parsedNum = '';\n\t        i--;\n\t        while (true) {\n\t          numChar = str[i++];\n\t          if (/[\\d\\.\\-e\\+]/.test(numChar)) {\n\t            parsedNum += numChar;\n\t          } else {\n\t            i--;\n\t            break;\n\t          }\n\t        }\n\t        pop(parseFloat(parsedNum), stack, metaStack);\n\t        break;\n\t      case '\"':\n\t        parsedString = '';\n\t        lastCh = void 0;\n\t        numConsecutiveSlashes = 0;\n\t        while (true) {\n\t          ch = str[i++];\n\t          if (ch !== '\"' || (lastCh === '\\\\' &&\n\t              numConsecutiveSlashes % 2 === 1)) {\n\t            parsedString += ch;\n\t            lastCh = ch;\n\t            if (lastCh === '\\\\') {\n\t              numConsecutiveSlashes++;\n\t            } else {\n\t              numConsecutiveSlashes = 0;\n\t            }\n\t          } else {\n\t            break;\n\t          }\n\t        }\n\t        pop(JSON.parse('\"' + parsedString + '\"'), stack, metaStack);\n\t        break;\n\t      case '[':\n\t        arrayElement = { element: [], index: stack.length };\n\t        stack.push(arrayElement.element);\n\t        metaStack.push(arrayElement);\n\t        break;\n\t      case '{':\n\t        objElement = { element: {}, index: stack.length };\n\t        stack.push(objElement.element);\n\t        metaStack.push(objElement);\n\t        break;\n\t      default:\n\t        throw new Error(\n\t          'unexpectedly reached end of input: ' + collationIndex);\n\t    }\n\t  }\n\t};\n\n\n/***/ },\n/* 97 */\n/***/ function(module, exports) {\n\n\t(function(self) {\n\t  'use strict';\n\t\n\t  if (self.fetch) {\n\t    return\n\t  }\n\t\n\t  var support = {\n\t    searchParams: 'URLSearchParams' in self,\n\t    iterable: 'Symbol' in self && 'iterator' in Symbol,\n\t    blob: 'FileReader' in self && 'Blob' in self && (function() {\n\t      try {\n\t        new Blob()\n\t        return true\n\t      } catch(e) {\n\t        return false\n\t      }\n\t    })(),\n\t    formData: 'FormData' in self,\n\t    arrayBuffer: 'ArrayBuffer' in self\n\t  }\n\t\n\t  if (support.arrayBuffer) {\n\t    var viewClasses = [\n\t      '[object Int8Array]',\n\t      '[object Uint8Array]',\n\t      '[object Uint8ClampedArray]',\n\t      '[object Int16Array]',\n\t      '[object Uint16Array]',\n\t      '[object Int32Array]',\n\t      '[object Uint32Array]',\n\t      '[object Float32Array]',\n\t      '[object Float64Array]'\n\t    ]\n\t\n\t    var isDataView = function(obj) {\n\t      return obj && DataView.prototype.isPrototypeOf(obj)\n\t    }\n\t\n\t    var isArrayBufferView = ArrayBuffer.isView || function(obj) {\n\t      return obj && viewClasses.indexOf(Object.prototype.toString.call(obj)) > -1\n\t    }\n\t  }\n\t\n\t  function normalizeName(name) {\n\t    if (typeof name !== 'string') {\n\t      name = String(name)\n\t    }\n\t    if (/[^a-z0-9\\-#$%&'*+.\\^_`|~]/i.test(name)) {\n\t      throw new TypeError('Invalid character in header field name')\n\t    }\n\t    return name.toLowerCase()\n\t  }\n\t\n\t  function normalizeValue(value) {\n\t    if (typeof value !== 'string') {\n\t      value = String(value)\n\t    }\n\t    return value\n\t  }\n\t\n\t  // Build a destructive iterator for the value list\n\t  function iteratorFor(items) {\n\t    var iterator = {\n\t      next: function() {\n\t        var value = items.shift()\n\t        return {done: value === undefined, value: value}\n\t      }\n\t    }\n\t\n\t    if (support.iterable) {\n\t      iterator[Symbol.iterator] = function() {\n\t        return iterator\n\t      }\n\t    }\n\t\n\t    return iterator\n\t  }\n\t\n\t  function Headers(headers) {\n\t    this.map = {}\n\t\n\t    if (headers instanceof Headers) {\n\t      headers.forEach(function(value, name) {\n\t        this.append(name, value)\n\t      }, this)\n\t    } else if (Array.isArray(headers)) {\n\t      headers.forEach(function(header) {\n\t        this.append(header[0], header[1])\n\t      }, this)\n\t    } else if (headers) {\n\t      Object.getOwnPropertyNames(headers).forEach(function(name) {\n\t        this.append(name, headers[name])\n\t      }, this)\n\t    }\n\t  }\n\t\n\t  Headers.prototype.append = function(name, value) {\n\t    name = normalizeName(name)\n\t    value = normalizeValue(value)\n\t    var oldValue = this.map[name]\n\t    this.map[name] = oldValue ? oldValue+','+value : value\n\t  }\n\t\n\t  Headers.prototype['delete'] = function(name) {\n\t    delete this.map[normalizeName(name)]\n\t  }\n\t\n\t  Headers.prototype.get = function(name) {\n\t    name = normalizeName(name)\n\t    return this.has(name) ? this.map[name] : null\n\t  }\n\t\n\t  Headers.prototype.has = function(name) {\n\t    return this.map.hasOwnProperty(normalizeName(name))\n\t  }\n\t\n\t  Headers.prototype.set = function(name, value) {\n\t    this.map[normalizeName(name)] = normalizeValue(value)\n\t  }\n\t\n\t  Headers.prototype.forEach = function(callback, thisArg) {\n\t    for (var name in this.map) {\n\t      if (this.map.hasOwnProperty(name)) {\n\t        callback.call(thisArg, this.map[name], name, this)\n\t      }\n\t    }\n\t  }\n\t\n\t  Headers.prototype.keys = function() {\n\t    var items = []\n\t    this.forEach(function(value, name) { items.push(name) })\n\t    return iteratorFor(items)\n\t  }\n\t\n\t  Headers.prototype.values = function() {\n\t    var items = []\n\t    this.forEach(function(value) { items.push(value) })\n\t    return iteratorFor(items)\n\t  }\n\t\n\t  Headers.prototype.entries = function() {\n\t    var items = []\n\t    this.forEach(function(value, name) { items.push([name, value]) })\n\t    return iteratorFor(items)\n\t  }\n\t\n\t  if (support.iterable) {\n\t    Headers.prototype[Symbol.iterator] = Headers.prototype.entries\n\t  }\n\t\n\t  function consumed(body) {\n\t    if (body.bodyUsed) {\n\t      return Promise.reject(new TypeError('Already read'))\n\t    }\n\t    body.bodyUsed = true\n\t  }\n\t\n\t  function fileReaderReady(reader) {\n\t    return new Promise(function(resolve, reject) {\n\t      reader.onload = function() {\n\t        resolve(reader.result)\n\t      }\n\t      reader.onerror = function() {\n\t        reject(reader.error)\n\t      }\n\t    })\n\t  }\n\t\n\t  function readBlobAsArrayBuffer(blob) {\n\t    var reader = new FileReader()\n\t    var promise = fileReaderReady(reader)\n\t    reader.readAsArrayBuffer(blob)\n\t    return promise\n\t  }\n\t\n\t  function readBlobAsText(blob) {\n\t    var reader = new FileReader()\n\t    var promise = fileReaderReady(reader)\n\t    reader.readAsText(blob)\n\t    return promise\n\t  }\n\t\n\t  function readArrayBufferAsText(buf) {\n\t    var view = new Uint8Array(buf)\n\t    var chars = new Array(view.length)\n\t\n\t    for (var i = 0; i < view.length; i++) {\n\t      chars[i] = String.fromCharCode(view[i])\n\t    }\n\t    return chars.join('')\n\t  }\n\t\n\t  function bufferClone(buf) {\n\t    if (buf.slice) {\n\t      return buf.slice(0)\n\t    } else {\n\t      var view = new Uint8Array(buf.byteLength)\n\t      view.set(new Uint8Array(buf))\n\t      return view.buffer\n\t    }\n\t  }\n\t\n\t  function Body() {\n\t    this.bodyUsed = false\n\t\n\t    this._initBody = function(body) {\n\t      this._bodyInit = body\n\t      if (!body) {\n\t        this._bodyText = ''\n\t      } else if (typeof body === 'string') {\n\t        this._bodyText = body\n\t      } else if (support.blob && Blob.prototype.isPrototypeOf(body)) {\n\t        this._bodyBlob = body\n\t      } else if (support.formData && FormData.prototype.isPrototypeOf(body)) {\n\t        this._bodyFormData = body\n\t      } else if (support.searchParams && URLSearchParams.prototype.isPrototypeOf(body)) {\n\t        this._bodyText = body.toString()\n\t      } else if (support.arrayBuffer && support.blob && isDataView(body)) {\n\t        this._bodyArrayBuffer = bufferClone(body.buffer)\n\t        // IE 10-11 can't handle a DataView body.\n\t        this._bodyInit = new Blob([this._bodyArrayBuffer])\n\t      } else if (support.arrayBuffer && (ArrayBuffer.prototype.isPrototypeOf(body) || isArrayBufferView(body))) {\n\t        this._bodyArrayBuffer = bufferClone(body)\n\t      } else {\n\t        throw new Error('unsupported BodyInit type')\n\t      }\n\t\n\t      if (!this.headers.get('content-type')) {\n\t        if (typeof body === 'string') {\n\t          this.headers.set('content-type', 'text/plain;charset=UTF-8')\n\t        } else if (this._bodyBlob && this._bodyBlob.type) {\n\t          this.headers.set('content-type', this._bodyBlob.type)\n\t        } else if (support.searchParams && URLSearchParams.prototype.isPrototypeOf(body)) {\n\t          this.headers.set('content-type', 'application/x-www-form-urlencoded;charset=UTF-8')\n\t        }\n\t      }\n\t    }\n\t\n\t    if (support.blob) {\n\t      this.blob = function() {\n\t        var rejected = consumed(this)\n\t        if (rejected) {\n\t          return rejected\n\t        }\n\t\n\t        if (this._bodyBlob) {\n\t          return Promise.resolve(this._bodyBlob)\n\t        } else if (this._bodyArrayBuffer) {\n\t          return Promise.resolve(new Blob([this._bodyArrayBuffer]))\n\t        } else if (this._bodyFormData) {\n\t          throw new Error('could not read FormData body as blob')\n\t        } else {\n\t          return Promise.resolve(new Blob([this._bodyText]))\n\t        }\n\t      }\n\t\n\t      this.arrayBuffer = function() {\n\t        if (this._bodyArrayBuffer) {\n\t          return consumed(this) || Promise.resolve(this._bodyArrayBuffer)\n\t        } else {\n\t          return this.blob().then(readBlobAsArrayBuffer)\n\t        }\n\t      }\n\t    }\n\t\n\t    this.text = function() {\n\t      var rejected = consumed(this)\n\t      if (rejected) {\n\t        return rejected\n\t      }\n\t\n\t      if (this._bodyBlob) {\n\t        return readBlobAsText(this._bodyBlob)\n\t      } else if (this._bodyArrayBuffer) {\n\t        return Promise.resolve(readArrayBufferAsText(this._bodyArrayBuffer))\n\t      } else if (this._bodyFormData) {\n\t        throw new Error('could not read FormData body as text')\n\t      } else {\n\t        return Promise.resolve(this._bodyText)\n\t      }\n\t    }\n\t\n\t    if (support.formData) {\n\t      this.formData = function() {\n\t        return this.text().then(decode)\n\t      }\n\t    }\n\t\n\t    this.json = function() {\n\t      return this.text().then(JSON.parse)\n\t    }\n\t\n\t    return this\n\t  }\n\t\n\t  // HTTP methods whose capitalization should be normalized\n\t  var methods = ['DELETE', 'GET', 'HEAD', 'OPTIONS', 'POST', 'PUT']\n\t\n\t  function normalizeMethod(method) {\n\t    var upcased = method.toUpperCase()\n\t    return (methods.indexOf(upcased) > -1) ? upcased : method\n\t  }\n\t\n\t  function Request(input, options) {\n\t    options = options || {}\n\t    var body = options.body\n\t\n\t    if (input instanceof Request) {\n\t      if (input.bodyUsed) {\n\t        throw new TypeError('Already read')\n\t      }\n\t      this.url = input.url\n\t      this.credentials = input.credentials\n\t      if (!options.headers) {\n\t        this.headers = new Headers(input.headers)\n\t      }\n\t      this.method = input.method\n\t      this.mode = input.mode\n\t      if (!body && input._bodyInit != null) {\n\t        body = input._bodyInit\n\t        input.bodyUsed = true\n\t      }\n\t    } else {\n\t      this.url = String(input)\n\t    }\n\t\n\t    this.credentials = options.credentials || this.credentials || 'omit'\n\t    if (options.headers || !this.headers) {\n\t      this.headers = new Headers(options.headers)\n\t    }\n\t    this.method = normalizeMethod(options.method || this.method || 'GET')\n\t    this.mode = options.mode || this.mode || null\n\t    this.referrer = null\n\t\n\t    if ((this.method === 'GET' || this.method === 'HEAD') && body) {\n\t      throw new TypeError('Body not allowed for GET or HEAD requests')\n\t    }\n\t    this._initBody(body)\n\t  }\n\t\n\t  Request.prototype.clone = function() {\n\t    return new Request(this, { body: this._bodyInit })\n\t  }\n\t\n\t  function decode(body) {\n\t    var form = new FormData()\n\t    body.trim().split('&').forEach(function(bytes) {\n\t      if (bytes) {\n\t        var split = bytes.split('=')\n\t        var name = split.shift().replace(/\\+/g, ' ')\n\t        var value = split.join('=').replace(/\\+/g, ' ')\n\t        form.append(decodeURIComponent(name), decodeURIComponent(value))\n\t      }\n\t    })\n\t    return form\n\t  }\n\t\n\t  function parseHeaders(rawHeaders) {\n\t    var headers = new Headers()\n\t    rawHeaders.split(/\\r?\\n/).forEach(function(line) {\n\t      var parts = line.split(':')\n\t      var key = parts.shift().trim()\n\t      if (key) {\n\t        var value = parts.join(':').trim()\n\t        headers.append(key, value)\n\t      }\n\t    })\n\t    return headers\n\t  }\n\t\n\t  Body.call(Request.prototype)\n\t\n\t  function Response(bodyInit, options) {\n\t    if (!options) {\n\t      options = {}\n\t    }\n\t\n\t    this.type = 'default'\n\t    this.status = 'status' in options ? options.status : 200\n\t    this.ok = this.status >= 200 && this.status < 300\n\t    this.statusText = 'statusText' in options ? options.statusText : 'OK'\n\t    this.headers = new Headers(options.headers)\n\t    this.url = options.url || ''\n\t    this._initBody(bodyInit)\n\t  }\n\t\n\t  Body.call(Response.prototype)\n\t\n\t  Response.prototype.clone = function() {\n\t    return new Response(this._bodyInit, {\n\t      status: this.status,\n\t      statusText: this.statusText,\n\t      headers: new Headers(this.headers),\n\t      url: this.url\n\t    })\n\t  }\n\t\n\t  Response.error = function() {\n\t    var response = new Response(null, {status: 0, statusText: ''})\n\t    response.type = 'error'\n\t    return response\n\t  }\n\t\n\t  var redirectStatuses = [301, 302, 303, 307, 308]\n\t\n\t  Response.redirect = function(url, status) {\n\t    if (redirectStatuses.indexOf(status) === -1) {\n\t      throw new RangeError('Invalid status code')\n\t    }\n\t\n\t    return new Response(null, {status: status, headers: {location: url}})\n\t  }\n\t\n\t  self.Headers = Headers\n\t  self.Request = Request\n\t  self.Response = Response\n\t\n\t  self.fetch = function(input, init) {\n\t    return new Promise(function(resolve, reject) {\n\t      var request = new Request(input, init)\n\t      var xhr = new XMLHttpRequest()\n\t\n\t      xhr.onload = function() {\n\t        var options = {\n\t          status: xhr.status,\n\t          statusText: xhr.statusText,\n\t          headers: parseHeaders(xhr.getAllResponseHeaders() || '')\n\t        }\n\t        options.url = 'responseURL' in xhr ? xhr.responseURL : options.headers.get('X-Request-URL')\n\t        var body = 'response' in xhr ? xhr.response : xhr.responseText\n\t        resolve(new Response(body, options))\n\t      }\n\t\n\t      xhr.onerror = function() {\n\t        reject(new TypeError('Network request failed'))\n\t      }\n\t\n\t      xhr.ontimeout = function() {\n\t        reject(new TypeError('Network request failed'))\n\t      }\n\t\n\t      xhr.open(request.method, request.url, true)\n\t\n\t      if (request.credentials === 'include') {\n\t        xhr.withCredentials = true\n\t      }\n\t\n\t      if ('responseType' in xhr && support.blob) {\n\t        xhr.responseType = 'blob'\n\t      }\n\t\n\t      request.headers.forEach(function(value, name) {\n\t        xhr.setRequestHeader(name, value)\n\t      })\n\t\n\t      xhr.send(typeof request._bodyInit === 'undefined' ? null : request._bodyInit)\n\t    })\n\t  }\n\t  self.fetch.polyfill = true\n\t})(typeof self !== 'undefined' ? self : this);\n\n\n/***/ },\n/* 98 */\n/***/ function(module, exports) {\n\n\t/* (ignored) */\n\n/***/ },\n/* 99 */\n98\n/******/ ])))\n});\n;\n\n\n// WEBPACK FOOTER //\n// cozy-client.min.js"," \t// The module cache\n \tvar installedModules = {};\n\n \t// The require function\n \tfunction __webpack_require__(moduleId) {\n\n \t\t// Check if module is in cache\n \t\tif(installedModules[moduleId])\n \t\t\treturn installedModules[moduleId].exports;\n\n \t\t// Create a new module (and put it into the cache)\n \t\tvar module = installedModules[moduleId] = {\n \t\t\texports: {},\n \t\t\tid: moduleId,\n \t\t\tloaded: false\n \t\t};\n\n \t\t// Execute the module function\n \t\tmodules[moduleId].call(module.exports, module, module.exports, __webpack_require__);\n\n \t\t// Flag the module as loaded\n \t\tmodule.loaded = true;\n\n \t\t// Return the exports of the module\n \t\treturn module.exports;\n \t}\n\n\n \t// expose the modules object (__webpack_modules__)\n \t__webpack_require__.m = modules;\n\n \t// expose the module cache\n \t__webpack_require__.c = installedModules;\n\n \t// __webpack_public_path__\n \t__webpack_require__.p = \"\";\n\n \t// Load entry module and return exports\n \treturn __webpack_require__(0);\n\n\n\n// WEBPACK FOOTER //\n// webpack/bootstrap 55c3d57ab06a4462218d","/* global fetch */\nimport {refreshToken, AccessToken} from './auth_v3'\nimport {retry, encodeQuery} from './utils'\nimport jsonapi from './jsonapi'\n\nexport function cozyFetch (cozy, path, options = {}) {\n  return cozy.fullpath(path).then((fullpath) => {\n    let resp\n    if (options.disableAuth) {\n      resp = fetch(fullpath, options)\n    } else if (options.manualAuthCredentials) {\n      resp = cozyFetchWithAuth(cozy, fullpath, options, options.manualAuthCredentials)\n    } else {\n      resp = cozy.authorize().then((credentials) =>\n        cozyFetchWithAuth(cozy, fullpath, options, credentials))\n    }\n    return resp.then(res => handleResponse(res, cozy._invalidTokenErrorHandler))\n  })\n}\n\nfunction cozyFetchWithAuth (cozy, fullpath, options, credentials) {\n  if (credentials) {\n    options.headers = options.headers || {}\n    options.headers['Authorization'] = credentials.token.toAuthHeader()\n  }\n\n  // the option credentials:include tells fetch to include the cookies in the\n  // request even for cross-origin requests\n  options.credentials = 'include'\n\n  return Promise.all([\n    cozy.isV2(),\n    fetch(fullpath, options)\n  ]).then(([isV2, res]) => {\n    if ((res.status !== 400 && res.status !== 401) || isV2 || !credentials || options.dontRetry) {\n      return res\n    }\n    // we try to refresh the token only for OAuth, ie, the client defined\n    // and the token is an instance of AccessToken.\n    const { client, token } = credentials\n    if (!client || !(token instanceof AccessToken)) {\n      return res\n    }\n    options.dontRetry = true\n    return retry(() => refreshToken(cozy, client, token), 3)()\n      .then((newToken) => cozy.saveCredentials(client, newToken))\n      .then((credentials) => cozyFetchWithAuth(cozy, fullpath, options, credentials))\n  })\n}\n\nexport function cozyFetchJSON (cozy, method, path, body, options = {}) {\n  const processJSONAPI = typeof options.processJSONAPI === 'undefined' || options.processJSONAPI\n  return fetchJSON(cozy, method, path, body, options)\n    .then(response => handleJSONResponse(response, processJSONAPI))\n}\n\nexport function cozyFetchRawJSON (cozy, method, path, body, options = {}) {\n  return fetchJSON(cozy, method, path, body, options)\n    .then(response => handleJSONResponse(response, false))\n}\n\nfunction fetchJSON (cozy, method, path, body, options = {}) {\n  options.method = method\n\n  const headers = options.headers = options.headers || {}\n\n  headers['Accept'] = 'application/json'\n\n  if (method !== 'GET' && method !== 'HEAD' && body !== undefined) {\n    if (headers['Content-Type']) {\n      options.body = body\n    } else {\n      headers['Content-Type'] = 'application/json'\n      options.body = JSON.stringify(body)\n    }\n  }\n\n  return cozyFetch(cozy, path, options)\n}\n\nfunction handleResponse (res, invalidTokenErrorHandler) {\n  if (res.ok) {\n    return res\n  }\n  let data\n  const contentType = res.headers.get('content-type')\n  if (contentType && contentType.indexOf('json') >= 0) {\n    data = res.json()\n  } else {\n    data = res.text()\n  }\n  return data.then(err => {\n    const error = new FetchError(res, err)\n    if (FetchError.isInvalidToken(error) && invalidTokenErrorHandler) {\n      invalidTokenErrorHandler(error)\n    }\n    throw error\n  })\n}\n\nfunction handleJSONResponse (res, processJSONAPI = true) {\n  const contentType = res.headers.get('content-type')\n  if (!contentType || contentType.indexOf('json') < 0) {\n    return res.text((data) => {\n      throw new FetchError(res, new Error('Response is not JSON: ' + data))\n    })\n  }\n\n  const json = res.json()\n  if (contentType.indexOf('application/vnd.api+json') === 0 && processJSONAPI) {\n    return json.then(jsonapi)\n  } else {\n    return json\n  }\n}\n\nexport function handleInvalidTokenError (error) {\n  try {\n    const currentOrigin = window.location.origin\n    const requestUrl = error.url\n\n    if (requestUrl.indexOf(currentOrigin.replace(/^(https?:\\/\\/\\w+)-\\w+\\./, '$1.')) === 0) {\n      const redirectURL = `${currentOrigin}?${encodeQuery({ 'disconnect': 1 })}`\n      window.location = redirectURL\n    }\n  } catch (e) {\n    console.warn('Unable to handle invalid token error', e, error)\n  }\n}\n\nexport class FetchError extends Error {\n  constructor (res, reason) {\n    super()\n    if (Error.captureStackTrace) {\n      Error.captureStackTrace(this, this.constructor)\n    }\n    // XXX We have to hardcode this because babel doesn't play nice when extending Error\n    this.name = 'FetchError'\n    this.response = res\n    this.url = res.url\n    this.status = res.status\n    this.reason = reason\n\n    Object.defineProperty(this, 'message', {\n      value: reason.message ||\n        (typeof reason === 'string' ? reason : JSON.stringify(reason))\n    })\n  }\n}\n\nFetchError.isUnauthorized = function (err) {\n  // XXX We can't use err instanceof FetchError because of the caveats of babel\n  return err.name === 'FetchError' && err.status === 401\n}\n\nFetchError.isNotFound = function (err) {\n  // XXX We can't use err instanceof FetchError because of the caveats of babel\n  return err.name === 'FetchError' && err.status === 404\n}\n\nFetchError.isInvalidToken = function (err) {\n  // XXX We can't use err instanceof FetchError because of the caveats of babel\n  return err.name === 'FetchError' && err.status === 400 && err.reason && (err.reason.error === 'Invalid JWT token' || err.reason.error === 'Expired token')\n}\n\n\n\n// WEBPACK FOOTER //\n// ./src/fetch.js","'use strict';\n\nvar Promise = require('pouchdb-promise');\n\n/* istanbul ignore next */\nexports.once = function (fun) {\n  var called = false;\n  return exports.getArguments(function (args) {\n    if (called) {\n      console.trace();\n      throw new Error('once called  more than once');\n    } else {\n      called = true;\n      fun.apply(this, args);\n    }\n  });\n};\n/* istanbul ignore next */\nexports.getArguments = function (fun) {\n  return function () {\n    var len = arguments.length;\n    var args = new Array(len);\n    var i = -1;\n    while (++i < len) {\n      args[i] = arguments[i];\n    }\n    return fun.call(this, args);\n  };\n};\n/* istanbul ignore next */\nexports.toPromise = function (func) {\n  //create the function we will be returning\n  return exports.getArguments(function (args) {\n    var self = this;\n    var tempCB = (typeof args[args.length - 1] === 'function') ? args.pop() : false;\n    // if the last argument is a function, assume its a callback\n    var usedCB;\n    if (tempCB) {\n      // if it was a callback, create a new callback which calls it,\n      // but do so async so we don't trap any errors\n      usedCB = function (err, resp) {\n        process.nextTick(function () {\n          tempCB(err, resp);\n        });\n      };\n    }\n    var promise = new Promise(function (fulfill, reject) {\n      try {\n        var callback = exports.once(function (err, mesg) {\n          if (err) {\n            reject(err);\n          } else {\n            fulfill(mesg);\n          }\n        });\n        // create a callback for this invocation\n        // apply the function in the orig context\n        args.push(callback);\n        func.apply(self, args);\n      } catch (e) {\n        reject(e);\n      }\n    });\n    // if there is a callback, call it back\n    if (usedCB) {\n      promise.then(function (result) {\n        usedCB(null, result);\n      }, usedCB);\n    }\n    promise.cancel = function () {\n      return this;\n    };\n    return promise;\n  });\n};\n\nexports.inherits = require('inherits');\nexports.Promise = Promise;\n\nexports.clone = function (obj) {\n  return exports.extend(true, {}, obj);\n};\n\nexports.extend = require('pouchdb-extend');\n\nexports.callbackify = function (fun) {\n  return exports.getArguments(function (args) {\n    var cb = args.pop();\n    var promise = fun.apply(this, args);\n    exports.promisedCallback(promise, cb);\n    return promise;\n  });\n};\n\nexports.promisedCallback = function (promise, callback) {\n  promise.then(function (res) {\n    process.nextTick(function () {\n      callback(null, res);\n    });\n  }, function (reason) {\n    process.nextTick(function () {\n      callback(reason);\n    });\n  });\n  return promise;\n};\n\nvar crypto = require('crypto');\nvar Md5 = require('spark-md5');\n\nexports.MD5 = function (string) {\n  /* istanbul ignore else */\n  if (!process.browser) {\n    return crypto.createHash('md5').update(string).digest('hex');\n  } else {\n    return Md5.hash(string);\n  }\n};\n\nexports.flatten = exports.getArguments(function (args) {\n  var res = [];\n  for (var i = 0, len = args.length; i < len; i++) {\n    var subArr = args[i];\n    if (Array.isArray(subArr)) {\n      res = res.concat(exports.flatten.apply(null, subArr));\n    } else {\n      res.push(subArr);\n    }\n  }\n  return res;\n});\n\nexports.mergeObjects = function (arr) {\n  var res = {};\n  for (var i = 0, len = arr.length; i < len; i++) {\n    res = exports.extend(true, res, arr[i]);\n  }\n  return res;\n};\n\n// this would just be \"return doc[field]\", but fields\n// can be \"deep\" due to dot notation\nexports.getFieldFromDoc = function (doc, parsedField) {\n  var value = doc;\n  for (var i = 0, len = parsedField.length; i < len; i++) {\n    var key = parsedField[i];\n    value = value[key];\n    if (!value) {\n      break;\n    }\n  }\n  return value;\n};\n\nexports.setFieldInDoc = function (doc, parsedField, value) {\n  for (var i = 0, len = parsedField.length; i < len-1; i++) {\n    var elem = parsedField[i];\n    doc = doc[elem] = {};\n  }\n  doc[parsedField[len-1]] = value;\n};\n\n// Converts a string in dot notation to an array of its components, with backslash escaping\nexports.parseField = function (fieldName) {\n  // fields may be deep (e.g. \"foo.bar.baz\"), so parse\n  var fields = [];\n  var current = '';\n  for (var i = 0, len = fieldName.length; i < len; i++) {\n    var ch = fieldName[i];\n    if (ch === '.') {\n      if (i > 0 && fieldName[i - 1] === '\\\\') { // escaped delimiter\n        current = current.substring(0, current.length - 1) + '.';\n      } else { // not escaped, so delimiter\n        fields.push(current);\n        current = '';\n      }\n    } else { // normal character\n      current += ch;\n    }\n  }\n  fields.push(current);\n  return fields;\n};\n\n// Selects a list of fields defined in dot notation from one doc\n// and copies them to a new doc. Like underscore _.pick but supports nesting.\nexports.pick = function (obj, arr) {\n  var res = {};\n  for (var i = 0, len = arr.length; i < len; i++) {\n    var parsedField = exports.parseField(arr[i]);\n    var value = exports.getFieldFromDoc(obj, parsedField);\n    if(typeof value !== 'undefined') {\n      exports.setFieldInDoc(res, parsedField, value);\n    }\n  }\n  return res;\n};\n\n// e.g. ['a'], ['a', 'b'] is true, but ['b'], ['a', 'b'] is false\nexports.oneArrayIsSubArrayOfOther = function (left, right) {\n\n  for (var i = 0, len = Math.min(left.length, right.length); i < len; i++) {\n    if (left[i] !== right[i]) {\n      return false;\n    }\n  }\n  return true;\n};\n\n// e.g.['a', 'b', 'c'], ['a', 'b'] is false\nexports.oneArrayIsStrictSubArrayOfOther = function (left, right) {\n\n  if (left.length > right.length) {\n    return false;\n  }\n\n  return exports.oneArrayIsSubArrayOfOther(left, right);\n};\n\n// same as above, but treat the left array as an unordered set\n// e.g. ['b', 'a'], ['a', 'b', 'c'] is true, but ['c'], ['a', 'b', 'c'] is false\nexports.oneSetIsSubArrayOfOther = function (left, right) {\n  left = left.slice();\n  for (var i = 0, len = right.length; i < len; i++) {\n    var field = right[i];\n    if (!left.length) {\n      break;\n    }\n    var leftIdx = left.indexOf(field);\n    if (leftIdx === -1) {\n      return false;\n    } else {\n      left.splice(leftIdx, 1);\n    }\n  }\n  return true;\n};\n\nexports.compare = function (left, right) {\n  return left < right ? -1 : left > right ? 1 : 0;\n};\n\nexports.arrayToObject = function (arr) {\n  var res = {};\n  for (var i = 0, len = arr.length; i < len; i++) {\n    res[arr[i]] = true;\n  }\n  return res;\n};\n\nexports.max = function (arr, fun) {\n  var max = null;\n  var maxScore = -1;\n  for (var i = 0, len = arr.length; i < len; i++) {\n    var element = arr[i];\n    var score = fun(element);\n    if (score > maxScore) {\n      maxScore = score;\n      max = element;\n    }\n  }\n  return max;\n};\n\nexports.arrayEquals = function (arr1, arr2) {\n  if (arr1.length !== arr2.length) {\n    return false;\n  }\n  for (var i = 0, len = arr1.length; i < len; i++) {\n    if (arr1[i] !== arr2[i]) {\n      return false;\n    }\n  }\n  return true;\n};\n\nexports.uniq = function(arr) {\n  var obj = {};\n  for (var i = 0; i < arr.length; i++) {\n    obj['$' + arr[i]] = true;\n  }\n  return Object.keys(obj).map(function (key) {\n    return key.substring(1);\n  });\n};\n\nexports.log = require('debug')('pouchdb:find');\n\n\n\n//////////////////\n// WEBPACK FOOTER\n// ./~/pouchdb-find/lib/utils.js\n// module id = 2\n// module chunks = 0","/* global navigator */\nconst FuzzFactor = 0.3\n\nexport function unpromiser (fn) {\n  return function (...args) {\n    const value = fn.apply(this, args)\n    if (!isPromise(value)) {\n      return value\n    }\n    const l = args.length\n    if (l === 0 || typeof args[l - 1] !== 'function') {\n      return\n    }\n    const cb = args[l - 1]\n    value.then(\n      (res) => cb(null, res),\n      (err) => cb(err, null)\n    )\n  }\n}\n\nexport function isPromise (value) {\n  return !!value && typeof value.then === 'function'\n}\n\nexport function isOnline () {\n  return typeof navigator !== 'undefined' ? navigator.onLine : true\n}\n\nexport function isOffline () {\n  return !isOnline()\n}\n\nexport function sleep (time, args) {\n  return new Promise((resolve) => {\n    setTimeout(resolve, time, args)\n  })\n}\n\nexport function retry (fn, count, delay = 300) {\n  return function doTry (...args) {\n    return fn(...args).catch((err) => {\n      if (--count < 0) {\n        throw err\n      }\n      return sleep(getBackedoffDelay(delay, count))\n        .then(() => doTry(...args))\n    })\n  }\n}\n\nexport function getFuzzedDelay (retryDelay) {\n  const fuzzingFactor = ((Math.random() * 2) - 1) * FuzzFactor\n  return retryDelay * (1.0 + fuzzingFactor)\n}\n\nexport function getBackedoffDelay (retryDelay, retryCount = 1) {\n  return getFuzzedDelay(retryDelay * Math.pow(2, retryCount - 1))\n}\n\nexport function createPath (cozy, isV2, doctype, id = '', query = null) {\n  let route = '/data/'\n  if (!isV2) {\n    route += `${encodeURIComponent(doctype)}/`\n  }\n  if (id !== '') {\n    route += encodeURIComponent(id)\n  }\n  const q = encodeQuery(query)\n  if (q !== '') {\n    route += '?' + q\n  }\n  return route\n}\n\nexport function encodeQuery (query) {\n  if (!query) {\n    return ''\n  }\n  let q = ''\n  for (const qname in query) {\n    if (q !== '') {\n      q += '&'\n    }\n    q += `${encodeURIComponent(qname)}=${encodeURIComponent(query[qname])}`\n  }\n  return q\n}\n\nexport function decodeQuery (url) {\n  let queryIndex = url.indexOf('?')\n  if (queryIndex < 0) {\n    queryIndex = url.length\n  }\n  const queries = {}\n  let fragIndex = url.indexOf('#')\n  if (fragIndex < 0) {\n    fragIndex = url.length\n  }\n  if (fragIndex < queryIndex) {\n    return queries\n  }\n  const queryStr = url.slice(queryIndex + 1, fragIndex)\n  if (queryStr === '') {\n    return queries\n  }\n  const parts = queryStr.split('&')\n  for (let i = 0; i < parts.length; i++) {\n    let pair = parts[i].split('=')\n    if (pair.length === 0 || pair[0] === '') {\n      continue\n    }\n    const qname = decodeURIComponent(pair[0])\n    if (queries.hasOwnProperty(qname)) {\n      continue\n    }\n    if (pair.length === 1) {\n      queries[qname] = true\n    } else if (pair.length === 2) {\n      queries[qname] = decodeURIComponent(pair[1])\n    } else {\n      throw new Error('Malformed URL')\n    }\n  }\n  return queries\n}\n\nconst warned = []\nexport function warn (text) {\n  if (warned.indexOf(text) === -1) {\n    warned.push(text)\n    console.warn('cozy-client-js', text)\n  }\n}\n\n\n\n// WEBPACK FOOTER //\n// ./src/utils.js","'use strict';\n\nvar utils = require('../../utils');\nvar collate = require('pouchdb-collate');\n\nfunction getKey(obj) {\n  return Object.keys(obj)[0];\n}\n\nfunction getValue(obj) {\n  return obj[getKey(obj)];\n}\n\n// normalize the \"sort\" value\nfunction massageSort(sort) {\n  if (!Array.isArray(sort)) {\n    throw new Error('invalid sort json - should be an array');\n  }\n  return sort.map(function (sorting) {\n    if (typeof sorting === 'string') {\n      var obj = {};\n      obj[sorting] = 'asc';\n      return obj;\n    } else {\n      return sorting;\n    }\n  });\n}\n\nvar combinationFields = ['$or', '$nor', '$not'];\nfunction isCombinationalField (field) {\n  return combinationFields.indexOf(field) > -1;\n}\n\n// collapse logically equivalent gt/gte values\nfunction mergeGtGte(operator, value, fieldMatchers) {\n  if (typeof fieldMatchers.$eq !== 'undefined') {\n    return; // do nothing\n  }\n  if (typeof fieldMatchers.$gte !== 'undefined') {\n    if (operator === '$gte') {\n      if (value > fieldMatchers.$gte) { // more specificity\n        fieldMatchers.$gte = value;\n      }\n    } else { // operator === '$gt'\n      if (value >= fieldMatchers.$gte) { // more specificity\n        delete fieldMatchers.$gte;\n        fieldMatchers.$gt = value;\n      }\n    }\n  } else if (typeof fieldMatchers.$gt !== 'undefined') {\n    if (operator === '$gte') {\n      if (value > fieldMatchers.$gt) { // more specificity\n        delete fieldMatchers.$gt;\n        fieldMatchers.$gte = value;\n      }\n    } else { // operator === '$gt'\n      if (value > fieldMatchers.$gt) { // more specificity\n        fieldMatchers.$gt = value;\n      }\n    }\n  } else {\n    fieldMatchers[operator] = value;\n  }\n}\n\n// collapse logically equivalent lt/lte values\nfunction mergeLtLte(operator, value, fieldMatchers) {\n  if (typeof fieldMatchers.$eq !== 'undefined') {\n    return; // do nothing\n  }\n  if (typeof fieldMatchers.$lte !== 'undefined') {\n    if (operator === '$lte') {\n      if (value < fieldMatchers.$lte) { // more specificity\n        fieldMatchers.$lte = value;\n      }\n    } else { // operator === '$gt'\n      if (value <= fieldMatchers.$lte) { // more specificity\n        delete fieldMatchers.$lte;\n        fieldMatchers.$lt = value;\n      }\n    }\n  } else if (typeof fieldMatchers.$lt !== 'undefined') {\n    if (operator === '$lte') {\n      if (value < fieldMatchers.$lt) { // more specificity\n        delete fieldMatchers.$lt;\n        fieldMatchers.$lte = value;\n      }\n    } else { // operator === '$gt'\n      if (value < fieldMatchers.$lt) { // more specificity\n        fieldMatchers.$lt = value;\n      }\n    }\n  } else {\n    fieldMatchers[operator] = value;\n  }\n}\n\n// combine $ne values into one array\nfunction mergeNe(value, fieldMatchers) {\n  if ('$ne' in fieldMatchers) {\n    // there are many things this could \"not\" be\n    fieldMatchers.$ne.push(value);\n  } else { // doesn't exist yet\n    fieldMatchers.$ne = [value];\n  }\n}\n\n// add $eq into the mix\nfunction mergeEq(value, fieldMatchers) {\n  // these all have less specificity than the $eq\n  // TODO: check for user errors here\n  delete fieldMatchers.$gt;\n  delete fieldMatchers.$gte;\n  delete fieldMatchers.$lt;\n  delete fieldMatchers.$lte;\n  delete fieldMatchers.$ne;\n  fieldMatchers.$eq = value;\n}\n\n// flatten an array of selectors joined by an $and operator\nfunction mergeAndedSelectors(selectors) {\n\n  // sort to ensure that e.g. if the user specified\n  // $and: [{$gt: 'a'}, {$gt: 'b'}], then it's collapsed into\n  // just {$gt: 'b'}\n  var res = {};\n\n  selectors.forEach(function (selector) {\n    Object.keys(selector).forEach(function (field) {\n      var matcher = selector[field];\n      if (typeof matcher !== 'object') {\n        matcher = {$eq: matcher};\n      }\n\n      if (isCombinationalField(field)) {\n        if (matcher instanceof Array) {\n          res[field] = matcher.map(function (m) {\n            return mergeAndedSelectors([m]);\n          });\n        } else {\n          res[field] = mergeAndedSelectors([matcher]);\n        }\n      } else {\n        var fieldMatchers = res[field] = res[field] || {};\n        Object.keys(matcher).forEach(function (operator) {\n          var value = matcher[operator];\n\n          if (operator === '$gt' || operator === '$gte') {\n            return mergeGtGte(operator, value, fieldMatchers);\n          } else if (operator === '$lt' || operator === '$lte') {\n            return mergeLtLte(operator, value, fieldMatchers);\n          } else if (operator === '$ne') {\n            return mergeNe(value, fieldMatchers);\n          } else if (operator === '$eq') {\n            return mergeEq(value, fieldMatchers);\n          }\n          fieldMatchers[operator] = value;\n        });\n      }\n    });\n  });\n\n  return res;\n}\n\n//\n// normalize the selector\n//\nfunction massageSelector(input) {\n  var result = utils.clone(input);\n  var wasAnded = false;\n  if ('$and' in result) {\n    result = mergeAndedSelectors(result['$and']);\n    wasAnded = true;\n  }\n\n  if ('$not' in result) {\n    //This feels a little like forcing, but it will work for now,\n    //I would like to come back to this and make the merging of selectors a little more generic\n    result['$not'] = mergeAndedSelectors([result['$not']]);\n  }\n\n  var fields = Object.keys(result);\n\n  for (var i = 0; i < fields.length; i++) {\n    var field = fields[i];\n    var matcher = result[field];\n\n    if (typeof matcher !== 'object' || matcher === null) {\n      matcher = {$eq: matcher};\n    } else if ('$ne' in matcher && !wasAnded) {\n      // I put these in an array, since there may be more than one\n      // but in the \"mergeAnded\" operation, I already take care of that\n      matcher.$ne = [matcher.$ne];\n    }\n    result[field] = matcher;\n  }\n\n  return result;\n}\n\n\nfunction massageIndexDef(indexDef) {\n  indexDef.fields = indexDef.fields.map(function (field) {\n    if (typeof field === 'string') {\n      var obj = {};\n      obj[field] = 'asc';\n      return obj;\n    }\n    return field;\n  });\n  return indexDef;\n}\n\nfunction getKeyFromDoc(doc, index) {\n  var res = [];\n  for (var i = 0; i < index.def.fields.length; i++) {\n    var field = getKey(index.def.fields[i]);\n    res.push(doc[field]);\n  }\n  return res;\n}\n\n// have to do this manually because REASONS. I don't know why\n// CouchDB didn't implement inclusive_start\nfunction filterInclusiveStart(rows, targetValue, index) {\n  var indexFields = index.def.fields;\n  for (var i = 0, len = rows.length; i < len; i++) {\n    var row = rows[i];\n\n    // shave off any docs at the beginning that are <= the\n    // target value\n\n    var docKey = getKeyFromDoc(row.doc, index);\n    if (indexFields.length === 1) {\n      docKey = docKey[0]; // only one field, not multi-field\n    } else { // more than one field in index\n      // in the case where e.g. the user is searching {$gt: {a: 1}}\n      // but the index is [a, b], then we need to shorten the doc key\n      while (docKey.length > targetValue.length) {\n        docKey.pop();\n      }\n    }\n    //ABS as we just looking for values that don't match\n    if (Math.abs(collate.collate(docKey, targetValue)) > 0) {\n      // no need to filter any further; we're past the key\n      break;\n    }\n  }\n  return i > 0 ? rows.slice(i) : rows;\n}\n\nfunction reverseOptions(opts) {\n  var newOpts = utils.clone(opts);\n  delete newOpts.startkey;\n  delete newOpts.endkey;\n  delete newOpts.inclusive_start;\n  delete newOpts.inclusive_end;\n\n  if ('endkey' in opts) {\n    newOpts.startkey = opts.endkey;\n  }\n  if ('startkey' in opts) {\n    newOpts.endkey = opts.startkey;\n  }\n  if ('inclusive_start' in opts) {\n    newOpts.inclusive_end = opts.inclusive_start;\n  }\n  if ('inclusive_end' in opts) {\n    newOpts.inclusive_start = opts.inclusive_end;\n  }\n  return newOpts;\n}\n\nfunction validateIndex(index) {\n  var ascFields = index.fields.filter(function (field) {\n    return getValue(field) === 'asc';\n  });\n  if (ascFields.length !== 0 && ascFields.length !== index.fields.length) {\n    throw new Error('unsupported mixed sorting');\n  }\n}\n\nfunction validateSort (requestDef, index) {\n  if (index.defaultUsed && requestDef.sort) {\n    var noneIdSorts = requestDef.sort.filter(function (sortItem) {\n      return Object.keys(sortItem)[0] !== '_id';\n    }).map(function (sortItem) {\n      return Object.keys(sortItem)[0];\n    });\n\n    if (noneIdSorts.length > 0) {\n      throw new Error('Cannot sort on field(s) \"' + noneIdSorts.join(',') +\n      '\" when using the default index');\n    }\n  }\n\n  if (index.defaultUsed) {\n    return;\n  }\n}\n\nfunction validateFindRequest(requestDef) {\n  if (typeof requestDef.selector !== 'object') {\n    throw new Error('you must provide a selector when you find()');\n  }\n\n  /*var selectors = requestDef.selector['$and'] || [requestDef.selector];\n  for (var i = 0; i < selectors.length; i++) {\n    var selector = selectors[i];\n    var keys = Object.keys(selector);\n    if (keys.length === 0) {\n      throw new Error('invalid empty selector');\n    }\n    //var selection = selector[keys[0]];\n    /*if (Object.keys(selection).length !== 1) {\n      throw new Error('invalid selector: ' + JSON.stringify(selection) +\n        ' - it must have exactly one key/value');\n    }\n  }*/\n}\n\n// determine the maximum number of fields\n// we're going to need to query, e.g. if the user\n// has selection ['a'] and sorting ['a', 'b'], then we\n// need to use the longer of the two: ['a', 'b']\nfunction getUserFields(selector, sort) {\n  var selectorFields = Object.keys(selector);\n  var sortFields = sort? sort.map(getKey) : [];\n  var userFields;\n  if (selectorFields.length >= sortFields.length) {\n    userFields = selectorFields;\n  } else {\n    userFields = sortFields;\n  }\n\n  if (sortFields.length === 0) {\n    return {\n      fields: userFields\n    };\n  }\n\n  // sort according to the user's preferred sorting\n  userFields = userFields.sort(function (left, right) {\n    var leftIdx = sortFields.indexOf(left);\n    if (leftIdx === -1) {\n      leftIdx = Number.MAX_VALUE;\n    }\n    var rightIdx = sortFields.indexOf(right);\n    if (rightIdx === -1) {\n      rightIdx = Number.MAX_VALUE;\n    }\n    return leftIdx < rightIdx ? -1 : leftIdx > rightIdx ? 1 : 0;\n  });\n\n  return {\n    fields: userFields,\n    sortOrder: sort.map(getKey)\n  };\n}\n\nmodule.exports = {\n  getKey: getKey,\n  getValue: getValue,\n  massageSort: massageSort,\n  massageSelector: massageSelector,\n  validateIndex: validateIndex,\n  validateFindRequest: validateFindRequest,\n  validateSort: validateSort,\n  reverseOptions: reverseOptions,\n  filterInclusiveStart: filterInclusiveStart,\n  massageIndexDef: massageIndexDef,\n  parseField: utils.parseField,\n  getUserFields: getUserFields,\n  isCombinationalField: isCombinationalField\n};\n\n\n\n//////////////////\n// WEBPACK FOOTER\n// ./~/pouchdb-find/lib/adapters/local/utils.js\n// module id = 4\n// module chunks = 0","// shim for using process in browser\nvar process = module.exports = {};\n\n// cached from whatever global is present so that test runners that stub it\n// don't break things.  But we need to wrap it in a try catch in case it is\n// wrapped in strict mode code which doesn't define any globals.  It's inside a\n// function because try/catches deoptimize in certain engines.\n\nvar cachedSetTimeout;\nvar cachedClearTimeout;\n\nfunction defaultSetTimout() {\n    throw new Error('setTimeout has not been defined');\n}\nfunction defaultClearTimeout () {\n    throw new Error('clearTimeout has not been defined');\n}\n(function () {\n    try {\n        if (typeof setTimeout === 'function') {\n            cachedSetTimeout = setTimeout;\n        } else {\n            cachedSetTimeout = defaultSetTimout;\n        }\n    } catch (e) {\n        cachedSetTimeout = defaultSetTimout;\n    }\n    try {\n        if (typeof clearTimeout === 'function') {\n            cachedClearTimeout = clearTimeout;\n        } else {\n            cachedClearTimeout = defaultClearTimeout;\n        }\n    } catch (e) {\n        cachedClearTimeout = defaultClearTimeout;\n    }\n} ())\nfunction runTimeout(fun) {\n    if (cachedSetTimeout === setTimeout) {\n        //normal enviroments in sane situations\n        return setTimeout(fun, 0);\n    }\n    // if setTimeout wasn't available but was latter defined\n    if ((cachedSetTimeout === defaultSetTimout || !cachedSetTimeout) && setTimeout) {\n        cachedSetTimeout = setTimeout;\n        return setTimeout(fun, 0);\n    }\n    try {\n        // when when somebody has screwed with setTimeout but no I.E. maddness\n        return cachedSetTimeout(fun, 0);\n    } catch(e){\n        try {\n            // When we are in I.E. but the script has been evaled so I.E. doesn't trust the global object when called normally\n            return cachedSetTimeout.call(null, fun, 0);\n        } catch(e){\n            // same as above but when it's a version of I.E. that must have the global object for 'this', hopfully our context correct otherwise it will throw a global error\n            return cachedSetTimeout.call(this, fun, 0);\n        }\n    }\n\n\n}\nfunction runClearTimeout(marker) {\n    if (cachedClearTimeout === clearTimeout) {\n        //normal enviroments in sane situations\n        return clearTimeout(marker);\n    }\n    // if clearTimeout wasn't available but was latter defined\n    if ((cachedClearTimeout === defaultClearTimeout || !cachedClearTimeout) && clearTimeout) {\n        cachedClearTimeout = clearTimeout;\n        return clearTimeout(marker);\n    }\n    try {\n        // when when somebody has screwed with setTimeout but no I.E. maddness\n        return cachedClearTimeout(marker);\n    } catch (e){\n        try {\n            // When we are in I.E. but the script has been evaled so I.E. doesn't  trust the global object when called normally\n            return cachedClearTimeout.call(null, marker);\n        } catch (e){\n            // same as above but when it's a version of I.E. that must have the global object for 'this', hopfully our context correct otherwise it will throw a global error.\n            // Some versions of I.E. have different rules for clearTimeout vs setTimeout\n            return cachedClearTimeout.call(this, marker);\n        }\n    }\n\n\n\n}\nvar queue = [];\nvar draining = false;\nvar currentQueue;\nvar queueIndex = -1;\n\nfunction cleanUpNextTick() {\n    if (!draining || !currentQueue) {\n        return;\n    }\n    draining = false;\n    if (currentQueue.length) {\n        queue = currentQueue.concat(queue);\n    } else {\n        queueIndex = -1;\n    }\n    if (queue.length) {\n        drainQueue();\n    }\n}\n\nfunction drainQueue() {\n    if (draining) {\n        return;\n    }\n    var timeout = runTimeout(cleanUpNextTick);\n    draining = true;\n\n    var len = queue.length;\n    while(len) {\n        currentQueue = queue;\n        queue = [];\n        while (++queueIndex < len) {\n            if (currentQueue) {\n                currentQueue[queueIndex].run();\n            }\n        }\n        queueIndex = -1;\n        len = queue.length;\n    }\n    currentQueue = null;\n    draining = false;\n    runClearTimeout(timeout);\n}\n\nprocess.nextTick = function (fun) {\n    var args = new Array(arguments.length - 1);\n    if (arguments.length > 1) {\n        for (var i = 1; i < arguments.length; i++) {\n            args[i - 1] = arguments[i];\n        }\n    }\n    queue.push(new Item(fun, args));\n    if (queue.length === 1 && !draining) {\n        runTimeout(drainQueue);\n    }\n};\n\n// v8 likes predictible objects\nfunction Item(fun, array) {\n    this.fun = fun;\n    this.array = array;\n}\nItem.prototype.run = function () {\n    this.fun.apply(null, this.array);\n};\nprocess.title = 'browser';\nprocess.browser = true;\nprocess.env = {};\nprocess.argv = [];\nprocess.version = ''; // empty string to avoid regexp issues\nprocess.versions = {};\n\nfunction noop() {}\n\nprocess.on = noop;\nprocess.addListener = noop;\nprocess.once = noop;\nprocess.off = noop;\nprocess.removeListener = noop;\nprocess.removeAllListeners = noop;\nprocess.emit = noop;\n\nprocess.binding = function (name) {\n    throw new Error('process.binding is not supported');\n};\n\nprocess.cwd = function () { return '/' };\nprocess.chdir = function (dir) {\n    throw new Error('process.chdir is not supported');\n};\nprocess.umask = function() { return 0; };\n\n\n\n//////////////////\n// WEBPACK FOOTER\n// ./~/process/browser.js\n// module id = 5\n// module chunks = 0","import {warn} from './utils'\n\nexport const DOCTYPE_FILES = 'io.cozy.files'\n\nconst KNOWN_DOCTYPES = {\n  'files': DOCTYPE_FILES,\n  'folder': DOCTYPE_FILES,\n  'contact': 'io.cozy.contacts',\n  'event': 'io.cozy.events',\n  'track': 'io.cozy.labs.music.track',\n  'playlist': 'io.cozy.labs.music.playlist'\n}\n\nconst REVERSE_KNOWN = {}\nObject.keys(KNOWN_DOCTYPES).forEach(k => {\n  REVERSE_KNOWN[KNOWN_DOCTYPES[k]] = k\n})\n\nexport function normalizeDoctype (cozy, isV2, doctype) {\n  let isQualified = doctype.indexOf('.') !== -1\n  if (isV2 && isQualified) {\n    let known = REVERSE_KNOWN[doctype]\n    if (known) return known\n    return doctype.replace(/\\./g, '-')\n  }\n  if (!isV2 && !isQualified) {\n    let known = KNOWN_DOCTYPES[doctype]\n    if (known) {\n      warn('you are using a non-qualified doctype ' + doctype + ' assumed to be ' + known)\n      return known\n    }\n    throw new Error('Doctype ' + doctype + ' should be qualified.')\n  }\n  return doctype\n}\n\n\n\n// WEBPACK FOOTER //\n// ./src/doctypes.js","// https://github.com/zloirock/core-js/issues/86#issuecomment-115759028\nvar global = module.exports = typeof window != 'undefined' && window.Math == Math\n  ? window : typeof self != 'undefined' && self.Math == Math ? self\n  // eslint-disable-next-line no-new-func\n  : Function('return this')();\nif (typeof __g == 'number') __g = global; // eslint-disable-line no-undef\n\n\n\n//////////////////\n// WEBPACK FOOTER\n// ./~/core-js/modules/_global.js\n// module id = 7\n// module chunks = 0","'use strict';\n\nvar MIN_MAGNITUDE = -324; // verified by -Number.MIN_VALUE\nvar MAGNITUDE_DIGITS = 3; // ditto\nvar SEP = ''; // set to '_' for easier debugging \n\nvar utils = require('./utils');\n\nexports.collate = function (a, b) {\n\n  if (a === b) {\n    return 0;\n  }\n\n  a = exports.normalizeKey(a);\n  b = exports.normalizeKey(b);\n\n  var ai = collationIndex(a);\n  var bi = collationIndex(b);\n  if ((ai - bi) !== 0) {\n    return ai - bi;\n  }\n  if (a === null) {\n    return 0;\n  }\n  switch (typeof a) {\n    case 'number':\n      return a - b;\n    case 'boolean':\n      return a === b ? 0 : (a < b ? -1 : 1);\n    case 'string':\n      return stringCollate(a, b);\n  }\n  return Array.isArray(a) ? arrayCollate(a, b) : objectCollate(a, b);\n};\n\n// couch considers null/NaN/Infinity/-Infinity === undefined,\n// for the purposes of mapreduce indexes. also, dates get stringified.\nexports.normalizeKey = function (key) {\n  switch (typeof key) {\n    case 'undefined':\n      return null;\n    case 'number':\n      if (key === Infinity || key === -Infinity || isNaN(key)) {\n        return null;\n      }\n      return key;\n    case 'object':\n      var origKey = key;\n      if (Array.isArray(key)) {\n        var len = key.length;\n        key = new Array(len);\n        for (var i = 0; i < len; i++) {\n          key[i] = exports.normalizeKey(origKey[i]);\n        }\n      } else if (key instanceof Date) {\n        return key.toJSON();\n      } else if (key !== null) { // generic object\n        key = {};\n        for (var k in origKey) {\n          if (origKey.hasOwnProperty(k)) {\n            var val = origKey[k];\n            if (typeof val !== 'undefined') {\n              key[k] = exports.normalizeKey(val);\n            }\n          }\n        }\n      }\n  }\n  return key;\n};\n\nfunction indexify(key) {\n  if (key !== null) {\n    switch (typeof key) {\n      case 'boolean':\n        return key ? 1 : 0;\n      case 'number':\n        return numToIndexableString(key);\n      case 'string':\n        // We've to be sure that key does not contain \\u0000\n        // Do order-preserving replacements:\n        // 0 -> 1, 1\n        // 1 -> 1, 2\n        // 2 -> 2, 2\n        return key\n          .replace(/\\u0002/g, '\\u0002\\u0002')\n          .replace(/\\u0001/g, '\\u0001\\u0002')\n          .replace(/\\u0000/g, '\\u0001\\u0001');\n      case 'object':\n        var isArray = Array.isArray(key);\n        var arr = isArray ? key : Object.keys(key);\n        var i = -1;\n        var len = arr.length;\n        var result = '';\n        if (isArray) {\n          while (++i < len) {\n            result += exports.toIndexableString(arr[i]);\n          }\n        } else {\n          while (++i < len) {\n            var objKey = arr[i];\n            result += exports.toIndexableString(objKey) +\n                exports.toIndexableString(key[objKey]);\n          }\n        }\n        return result;\n    }\n  }\n  return '';\n}\n\n// convert the given key to a string that would be appropriate\n// for lexical sorting, e.g. within a database, where the\n// sorting is the same given by the collate() function.\nexports.toIndexableString = function (key) {\n  var zero = '\\u0000';\n  key = exports.normalizeKey(key);\n  return collationIndex(key) + SEP + indexify(key) + zero;\n};\n\nfunction parseNumber(str, i) {\n  var originalIdx = i;\n  var num;\n  var zero = str[i] === '1';\n  if (zero) {\n    num = 0;\n    i++;\n  } else {\n    var neg = str[i] === '0';\n    i++;\n    var numAsString = '';\n    var magAsString = str.substring(i, i + MAGNITUDE_DIGITS);\n    var magnitude = parseInt(magAsString, 10) + MIN_MAGNITUDE;\n    if (neg) {\n      magnitude = -magnitude;\n    }\n    i += MAGNITUDE_DIGITS;\n    while (true) {\n      var ch = str[i];\n      if (ch === '\\u0000') {\n        break;\n      } else {\n        numAsString += ch;\n      }\n      i++;\n    }\n    numAsString = numAsString.split('.');\n    if (numAsString.length === 1) {\n      num = parseInt(numAsString, 10);\n    } else {\n      num = parseFloat(numAsString[0] + '.' + numAsString[1]);\n    }\n    if (neg) {\n      num = num - 10;\n    }\n    if (magnitude !== 0) {\n      // parseFloat is more reliable than pow due to rounding errors\n      // e.g. Number.MAX_VALUE would return Infinity if we did\n      // num * Math.pow(10, magnitude);\n      num = parseFloat(num + 'e' + magnitude);\n    }\n  }\n  return {num: num, length : i - originalIdx};\n}\n\n// move up the stack while parsing\n// this function moved outside of parseIndexableString for performance\nfunction pop(stack, metaStack) {\n  var obj = stack.pop();\n\n  if (metaStack.length) {\n    var lastMetaElement = metaStack[metaStack.length - 1];\n    if (obj === lastMetaElement.element) {\n      // popping a meta-element, e.g. an object whose value is another object\n      metaStack.pop();\n      lastMetaElement = metaStack[metaStack.length - 1];\n    }\n    var element = lastMetaElement.element;\n    var lastElementIndex = lastMetaElement.index;\n    if (Array.isArray(element)) {\n      element.push(obj);\n    } else if (lastElementIndex === stack.length - 2) { // obj with key+value\n      var key = stack.pop();\n      element[key] = obj;\n    } else {\n      stack.push(obj); // obj with key only\n    }\n  }\n}\n\nexports.parseIndexableString = function (str) {\n  var stack = [];\n  var metaStack = []; // stack for arrays and objects\n  var i = 0;\n\n  while (true) {\n    var collationIndex = str[i++];\n    if (collationIndex === '\\u0000') {\n      if (stack.length === 1) {\n        return stack.pop();\n      } else {\n        pop(stack, metaStack);\n        continue;\n      }\n    }\n    switch (collationIndex) {\n      case '1':\n        stack.push(null);\n        break;\n      case '2':\n        stack.push(str[i] === '1');\n        i++;\n        break;\n      case '3':\n        var parsedNum = parseNumber(str, i);\n        stack.push(parsedNum.num);\n        i += parsedNum.length;\n        break;\n      case '4':\n        var parsedStr = '';\n        while (true) {\n          var ch = str[i];\n          if (ch === '\\u0000') {\n            break;\n          }\n          parsedStr += ch;\n          i++;\n        }\n        // perform the reverse of the order-preserving replacement\n        // algorithm (see above)\n        parsedStr = parsedStr.replace(/\\u0001\\u0001/g, '\\u0000')\n          .replace(/\\u0001\\u0002/g, '\\u0001')\n          .replace(/\\u0002\\u0002/g, '\\u0002');\n        stack.push(parsedStr);\n        break;\n      case '5':\n        var arrayElement = { element: [], index: stack.length };\n        stack.push(arrayElement.element);\n        metaStack.push(arrayElement);\n        break;\n      case '6':\n        var objElement = { element: {}, index: stack.length };\n        stack.push(objElement.element);\n        metaStack.push(objElement);\n        break;\n      default:\n        throw new Error(\n          'bad collationIndex or unexpectedly reached end of input: ' + collationIndex);\n    }\n  }\n};\n\nfunction arrayCollate(a, b) {\n  var len = Math.min(a.length, b.length);\n  for (var i = 0; i < len; i++) {\n    var sort = exports.collate(a[i], b[i]);\n    if (sort !== 0) {\n      return sort;\n    }\n  }\n  return (a.length === b.length) ? 0 :\n    (a.length > b.length) ? 1 : -1;\n}\nfunction stringCollate(a, b) {\n  // See: https://github.com/daleharvey/pouchdb/issues/40\n  // This is incompatible with the CouchDB implementation, but its the\n  // best we can do for now\n  return (a === b) ? 0 : ((a > b) ? 1 : -1);\n}\nfunction objectCollate(a, b) {\n  var ak = Object.keys(a), bk = Object.keys(b);\n  var len = Math.min(ak.length, bk.length);\n  for (var i = 0; i < len; i++) {\n    // First sort the keys\n    var sort = exports.collate(ak[i], bk[i]);\n    if (sort !== 0) {\n      return sort;\n    }\n    // if the keys are equal sort the values\n    sort = exports.collate(a[ak[i]], b[bk[i]]);\n    if (sort !== 0) {\n      return sort;\n    }\n\n  }\n  return (ak.length === bk.length) ? 0 :\n    (ak.length > bk.length) ? 1 : -1;\n}\n// The collation is defined by erlangs ordered terms\n// the atoms null, true, false come first, then numbers, strings,\n// arrays, then objects\n// null/undefined/NaN/Infinity/-Infinity are all considered null\nfunction collationIndex(x) {\n  var id = ['boolean', 'number', 'string', 'object'];\n  var idx = id.indexOf(typeof x);\n  //false if -1 otherwise true, but fast!!!!1\n  if (~idx) {\n    if (x === null) {\n      return 1;\n    }\n    if (Array.isArray(x)) {\n      return 5;\n    }\n    return idx < 3 ? (idx + 2) : (idx + 3);\n  }\n  if (Array.isArray(x)) {\n    return 5;\n  }\n}\n\n// conversion:\n// x yyy zz...zz\n// x = 0 for negative, 1 for 0, 2 for positive\n// y = exponent (for negative numbers negated) moved so that it's >= 0\n// z = mantisse\nfunction numToIndexableString(num) {\n\n  if (num === 0) {\n    return '1';\n  }\n\n  // convert number to exponential format for easier and\n  // more succinct string sorting\n  var expFormat = num.toExponential().split(/e\\+?/);\n  var magnitude = parseInt(expFormat[1], 10);\n\n  var neg = num < 0;\n\n  var result = neg ? '0' : '2';\n\n  // first sort by magnitude\n  // it's easier if all magnitudes are positive\n  var magForComparison = ((neg ? -magnitude : magnitude) - MIN_MAGNITUDE);\n  var magString = utils.padLeft((magForComparison).toString(), '0', MAGNITUDE_DIGITS);\n\n  result += SEP + magString;\n\n  // then sort by the factor\n  var factor = Math.abs(parseFloat(expFormat[0])); // [1..10)\n  if (neg) { // for negative reverse ordering\n    factor = 10 - factor;\n  }\n\n  var factorStr = factor.toFixed(20);\n\n  // strip zeros from the end\n  factorStr = factorStr.replace(/\\.?0+$/, '');\n\n  result += SEP + factorStr;\n\n  return result;\n}\n\n\n\n//////////////////\n// WEBPACK FOOTER\n// ./~/pouchdb-collate/lib/index.js\n// module id = 8\n// module chunks = 0","/* global btoa */\nimport {encodeQuery, decodeQuery, isOffline} from './utils'\nimport {cozyFetchJSON, FetchError} from './fetch'\n\nconst StateSize = 16\n\nexport const CredsKey = 'creds'\nexport const StateKey = 'state'\n\nexport class Client {\n  constructor (opts) {\n    this.clientID = opts.clientID || opts.client_id || ''\n    this.clientSecret = opts.clientSecret || opts.client_secret || ''\n    this.registrationAccessToken = opts.registrationAccessToken || opts.registration_access_token || ''\n\n    if (opts.redirect_uris) {\n      this.redirectURI = opts.redirect_uris[0] || ''\n    } else {\n      this.redirectURI = opts.redirectURI || ''\n    }\n\n    this.softwareID = opts.softwareID || opts.software_id || ''\n    this.softwareVersion = opts.softwareVersion || opts.software_version || ''\n    this.clientName = opts.clientName || opts.client_name || ''\n    this.clientKind = opts.clientKind || opts.client_kind || ''\n    this.clientURI = opts.clientURI || opts.client_uri || ''\n\n    this.logoURI = opts.logoURI || opts.logo_uri || ''\n    this.policyURI = opts.policyURI || opts.policy_uri || ''\n\n    this.notificationPlatform = opts.notificationPlatform || opts.notification_platform || ''\n    this.notificationDeviceToken = opts.notificationDeviceToken || opts.notification_device_token || ''\n\n    if (!this.registrationAccessToken) {\n      if (this.redirectURI === '') {\n        throw new Error('Missing redirectURI field')\n      }\n      if (this.softwareID === '') {\n        throw new Error('Missing softwareID field')\n      }\n      if (this.clientName === '') {\n        throw new Error('Missing clientName field')\n      }\n    }\n  }\n\n  isRegistered () {\n    return this.clientID !== ''\n  }\n\n  toRegisterJSON () {\n    return {\n      redirect_uris: [this.redirectURI],\n      software_id: this.softwareID,\n      software_version: this.softwareVersion,\n      client_name: this.clientName,\n      client_kind: this.clientKind,\n      client_uri: this.clientURI,\n      logo_uri: this.logoURI,\n      policy_uri: this.policyURI,\n      notification_platform: this.notificationPlatform,\n      notification_device_token: this.notificationDeviceToken\n    }\n  }\n\n  toAuthHeader () {\n    return 'Bearer ' + this.registrationAccessToken\n  }\n}\n\nexport class AccessToken {\n  constructor (opts) {\n    this.tokenType = opts.tokenType || opts.token_type\n    this.accessToken = opts.accessToken || opts.access_token\n    this.refreshToken = opts.refreshToken || opts.refresh_token\n    this.scope = opts.scope\n  }\n\n  toAuthHeader () {\n    return 'Bearer ' + this.accessToken\n  }\n\n  toBasicAuth () {\n    return `user:${this.accessToken}@`\n  }\n}\n\nexport class AppToken {\n  constructor (opts) {\n    this.token = opts.token || ''\n  }\n\n  toAuthHeader () {\n    return 'Bearer ' + this.token\n  }\n\n  toBasicAuth () {\n    return `user:${this.token}@`\n  }\n}\n\nexport function client (cozy, clientParams) {\n  if (!clientParams) {\n    clientParams = cozy._clientParams\n  }\n  if (clientParams instanceof Client) {\n    return clientParams\n  }\n  return new Client(clientParams)\n}\n\nexport function registerClient (cozy, clientParams) {\n  const cli = client(cozy, clientParams)\n  if (cli.isRegistered()) {\n    return Promise.reject(new Error('Client already registered'))\n  }\n  return cozyFetchJSON(cozy, 'POST', '/auth/register', cli.toRegisterJSON(), {\n    disableAuth: true\n  })\n    .then((data) => new Client(data))\n}\n\nexport function updateClient (cozy, clientParams, resetSecret = false) {\n  const cli = client(cozy, clientParams)\n  if (!cli.isRegistered()) {\n    return Promise.reject(new Error('Client not registered'))\n  }\n  let data = cli.toRegisterJSON()\n  data.client_id = cli.clientID\n  if (resetSecret) data.client_secret = cli.clientSecret\n\n  return cozyFetchJSON(cozy, 'PUT', `/auth/register/${cli.clientID}`, data, {\n    manualAuthCredentials: {\n      token: cli\n    }\n  }).then((data) => createClient(data, cli))\n}\n\nexport function unregisterClient (cozy, clientParams) {\n  const cli = client(cozy, clientParams)\n  if (!cli.isRegistered()) {\n    return Promise.reject(new Error('Client not registered'))\n  }\n  return cozyFetchJSON(cozy, 'DELETE', `/auth/register/${cli.clientID}`, null, {\n    manualAuthCredentials: {\n      token: cli\n    }\n  })\n}\n\n// getClient will retrive the registered client informations from the server.\nexport function getClient (cozy, clientParams) {\n  const cli = client(cozy, clientParams)\n  if (!cli.isRegistered()) {\n    return Promise.reject(new Error('Client not registered'))\n  }\n  if (isOffline()) {\n    return Promise.resolve(cli)\n  }\n  return cozyFetchJSON(cozy, 'GET', `/auth/register/${cli.clientID}`, null,\n    {\n      manualAuthCredentials: {\n        token: cli\n      }\n    })\n    .then((data) => createClient(data, cli))\n    .catch((err) => {\n      // If we fall into an error while fetching the client (because of a\n      // bad connectivity for instance), we do not bail the whole process\n      // since the client should be able to continue with the persisted\n      // client and token.\n      //\n      // If it is an explicit Unauthorized error though, we bail, clear th\n      // cache and retry.\n      if (FetchError.isUnauthorized(err) || FetchError.isNotFound(err)) {\n        throw new Error('Client has been revoked')\n      }\n      throw err\n    })\n}\n\n// createClient returns a new Client instance given on object containing the\n// data of the client, from the API, and an old instance of the client.\nfunction createClient (data, oldClient) {\n  const newClient = new Client(data)\n  // we need to keep track of the registrationAccessToken since it is send\n  // only on registration. The GET /auth/register/:client-id endpoint does\n  // not return this token.\n  const shouldPassRegistration = (\n    !!oldClient &&\n    oldClient.registrationAccessToken !== '' &&\n    newClient.registrationAccessToken === ''\n  )\n  if (shouldPassRegistration) {\n    newClient.registrationAccessToken = oldClient.registrationAccessToken\n  }\n  return newClient\n}\n\n// getAuthCodeURL returns a pair {authURL,state} given a registered client. The\n// state should be stored in order to be checked against on the user validation\n// phase.\nexport function getAuthCodeURL (cozy, client, scopes = []) {\n  if (!(client instanceof Client)) {\n    client = new Client(client)\n  }\n  if (!client.isRegistered()) {\n    throw new Error('Client not registered')\n  }\n  const state = generateRandomState()\n  const query = {\n    'client_id': client.clientID,\n    'redirect_uri': client.redirectURI,\n    'state': state,\n    'response_type': 'code',\n    'scope': scopes.join(' ')\n  }\n  return {\n    url: cozy._url + `/auth/authorize?${encodeQuery(query)}`,\n    state: state\n  }\n}\n\n// getAccessToken perform a request on the access_token entrypoint with the\n// authorization_code grant type in order to generate a new access token for a\n// newly registered client.\n//\n// This method extracts the access code and state from the given URL. By\n// default it uses window.location.href. Also, it checks the given state with\n// the one specified in the URL query parameter to prevent CSRF attacks.\nexport function getAccessToken (cozy, client, state, pageURL = '') {\n  if (!state) {\n    return Promise.reject(new Error('Missing state value'))\n  }\n  const grantQueries = getGrantCodeFromPageURL(pageURL)\n  if (grantQueries === null) {\n    return Promise.reject(new Error('Missing states from current URL'))\n  }\n  if (state !== grantQueries.state) {\n    return Promise.reject(new Error('Given state does not match url query state'))\n  }\n  return retrieveToken(cozy, client, null, {\n    'grant_type': 'authorization_code',\n    'code': grantQueries.code\n  })\n}\n\n// refreshToken perform a request on the access_token entrypoint with the\n// refresh_token grant type in order to refresh the given token.\nexport function refreshToken (cozy, client, token) {\n  return retrieveToken(cozy, client, token, {\n    'grant_type': 'refresh_token',\n    'refresh_token': token.refreshToken\n  })\n}\n\n// oauthFlow performs the stateful registration and access granting of an OAuth\n// client.\nexport function oauthFlow (cozy, storage, clientParams, onRegistered, ignoreCachedCredentials = false) {\n  if (ignoreCachedCredentials) {\n    return storage.clear().then(() => oauthFlow(cozy, storage, clientParams, onRegistered, false))\n  }\n\n  let tryCount = 0\n\n  function clearAndRetry (err) {\n    if (tryCount++ > 0) {\n      throw err\n    }\n    return storage.clear().then(() =>\n      oauthFlow(cozy, storage, clientParams, onRegistered))\n  }\n\n  function registerNewClient () {\n    return storage.clear()\n      .then(() => registerClient(cozy, clientParams))\n      .then((client) => {\n        const {url, state} = getAuthCodeURL(cozy, client, clientParams.scopes)\n        return storage.save(StateKey, {client, url, state})\n      })\n  }\n\n  return Promise.all([\n    storage.load(CredsKey),\n    storage.load(StateKey)\n  ]).then(([credentials, storedState]) => {\n    // If credentials are cached we re-fetch the registered client with the\n    // said token. Fetching the client, if the token is outdated we should try\n    // the token is refreshed.\n    if (credentials) {\n      let oldClient, token\n      try {\n        oldClient = new Client(credentials.client)\n        token = new AccessToken(credentials.token)\n      } catch (err) {\n        // bad cache, we should clear and retry the process\n        return clearAndRetry(err)\n      }\n      return getClient(cozy, oldClient)\n        .then((client) => ({client, token}))\n        .catch((err) => {\n          // If we fall into an error while fetching the client (because of a\n          // bad connectivity for instance), we do not bail the whole process\n          // since the client should be able to continue with the persisted\n          // client and token.\n          //\n          // If it is an explicit Unauthorized error though, we bail, clear th\n          // cache and retry.\n          if (FetchError.isUnauthorized(err) || FetchError.isNotFound(err)) {\n            throw new Error('Client has been revoked')\n          }\n          return { client: oldClient, token }\n        })\n    }\n\n    // Otherwise register a new client if necessary (ie. no client is stored)\n    // and call the onRegistered callback to wait for the user to grant the\n    // access. Finally fetches to access token on success.\n    let statePromise\n    if (!storedState) {\n      statePromise = registerNewClient()\n    } else {\n      statePromise = Promise.resolve(storedState)\n    }\n\n    let client, state, token\n    return statePromise\n      .then((data) => {\n        client = data.client\n        state = data.state\n        return Promise.resolve(onRegistered(client, data.url))\n      })\n      .then((pageURL) => getAccessToken(cozy, client, state, pageURL))\n      .then((t) => { token = t })\n      .then(() => storage.delete(StateKey))\n      .then(() => ({client, token}))\n  })\n  .then(\n    (creds) => storage.save(CredsKey, creds),\n    (err) => {\n      if (FetchError.isUnauthorized(err)) {\n        return clearAndRetry(err)\n      } else {\n        throw err\n      }\n    })\n}\n\n// retrieveToken perform a request on the access_token entrypoint in order to\n// fetch a token.\nfunction retrieveToken (cozy, client, token, query) {\n  if (!(client instanceof Client)) {\n    client = new Client(client)\n  }\n  if (!client.isRegistered()) {\n    return Promise.reject(new Error('Client not registered'))\n  }\n  const body = encodeQuery(Object.assign({}, query, {\n    'client_id': client.clientID,\n    'client_secret': client.clientSecret\n  }))\n  return cozyFetchJSON(cozy, 'POST', '/auth/access_token', body, {\n    disableAuth: (token === null),\n    dontRetry: true,\n    manualAuthCredentials: { client, token },\n    headers: { 'Content-Type': 'application/x-www-form-urlencoded' }\n  })\n    .then((data) => {\n      data.refreshToken = data.refreshToken || query.refresh_token\n      return new AccessToken(data)\n    })\n}\n\n// getGrantCodeFromPageURL extract the state and access_code query parameters\n// from the given url\nfunction getGrantCodeFromPageURL (pageURL = '') {\n  if (pageURL === '' && typeof window !== 'undefined') {\n    pageURL = window.location.href\n  }\n  const queries = decodeQuery(pageURL)\n  if (!queries.hasOwnProperty('state')) {\n    return null\n  }\n  return {\n    state: queries['state'],\n    code: queries['access_code']\n  }\n}\n\n// generateRandomState will try to generate a 128bits random value from a secure\n// pseudo random generator. It will fallback on Math.random if it cannot find\n// such generator.\nfunction generateRandomState () {\n  let buffer\n  if (typeof window !== 'undefined' &&\n      typeof window.crypto !== 'undefined' &&\n      typeof window.crypto.getRandomValues === 'function') {\n    buffer = new Uint8Array(StateSize)\n    window.crypto.getRandomValues(buffer)\n  } else {\n    try {\n      buffer = require('crypto').randomBytes(StateSize)\n    } catch (e) {}\n  }\n  if (!buffer) {\n    buffer = new Array(StateSize)\n    for (let i = 0; i < buffer.length; i++) {\n      buffer[i] = Math.floor((Math.random() * 255))\n    }\n  }\n  return btoa(String.fromCharCode.apply(null, buffer))\n    .replace(/=+$/, '')\n    .replace(/\\//g, '_')\n    .replace(/\\+/g, '-')\n}\n\n\n\n// WEBPACK FOOTER //\n// ./src/auth_v3.js","// Thank's IE8 for his funny defineProperty\nmodule.exports = !require('./_fails')(function () {\n  return Object.defineProperty({}, 'a', { get: function () { return 7; } }).a != 7;\n});\n\n\n\n//////////////////\n// WEBPACK FOOTER\n// ./~/core-js/modules/_descriptors.js\n// module id = 10\n// module chunks = 0","module.exports = function (exec) {\n  try {\n    return !!exec();\n  } catch (e) {\n    return true;\n  }\n};\n\n\n\n//////////////////\n// WEBPACK FOOTER\n// ./~/core-js/modules/_fails.js\n// module id = 11\n// module chunks = 0","module.exports = function (it) {\n  return typeof it === 'object' ? it !== null : typeof it === 'function';\n};\n\n\n\n//////////////////\n// WEBPACK FOOTER\n// ./~/core-js/modules/_is-object.js\n// module id = 12\n// module chunks = 0","'use strict';\nvar Mutation = global.MutationObserver || global.WebKitMutationObserver;\n\nvar scheduleDrain;\n\n{\n  if (Mutation) {\n    var called = 0;\n    var observer = new Mutation(nextTick);\n    var element = global.document.createTextNode('');\n    observer.observe(element, {\n      characterData: true\n    });\n    scheduleDrain = function () {\n      element.data = (called = ++called % 2);\n    };\n  } else if (!global.setImmediate && typeof global.MessageChannel !== 'undefined') {\n    var channel = new global.MessageChannel();\n    channel.port1.onmessage = nextTick;\n    scheduleDrain = function () {\n      channel.port2.postMessage(0);\n    };\n  } else if ('document' in global && 'onreadystatechange' in global.document.createElement('script')) {\n    scheduleDrain = function () {\n\n      // Create a <script> element; its readystatechange event will be fired asynchronously once it is inserted\n      // into the document. Do so, thus queuing up the task. Remember to clean up once it's been called.\n      var scriptEl = global.document.createElement('script');\n      scriptEl.onreadystatechange = function () {\n        nextTick();\n\n        scriptEl.onreadystatechange = null;\n        scriptEl.parentNode.removeChild(scriptEl);\n        scriptEl = null;\n      };\n      global.document.documentElement.appendChild(scriptEl);\n    };\n  } else {\n    scheduleDrain = function () {\n      setTimeout(nextTick, 0);\n    };\n  }\n}\n\nvar draining;\nvar queue = [];\n//named nextTick for less confusing stack traces\nfunction nextTick() {\n  draining = true;\n  var i, oldQueue;\n  var len = queue.length;\n  while (len) {\n    oldQueue = queue;\n    queue = [];\n    i = -1;\n    while (++i < len) {\n      oldQueue[i]();\n    }\n    len = queue.length;\n  }\n  draining = false;\n}\n\nmodule.exports = immediate;\nfunction immediate(task) {\n  if (queue.push(task) === 1 && !draining) {\n    scheduleDrain();\n  }\n}\n\n\n\n//////////////////\n// WEBPACK FOOTER\n// ./~/immediate/lib/browser.js\n// module id = 13\n// module chunks = 0","if (typeof Object.create === 'function') {\n  // implementation from standard node.js 'util' module\n  module.exports = function inherits(ctor, superCtor) {\n    ctor.super_ = superCtor\n    ctor.prototype = Object.create(superCtor.prototype, {\n      constructor: {\n        value: ctor,\n        enumerable: false,\n        writable: true,\n        configurable: true\n      }\n    });\n  };\n} else {\n  // old school shim for old browsers\n  module.exports = function inherits(ctor, superCtor) {\n    ctor.super_ = superCtor\n    var TempCtor = function () {}\n    TempCtor.prototype = superCtor.prototype\n    ctor.prototype = new TempCtor()\n    ctor.prototype.constructor = ctor\n  }\n}\n\n\n\n//////////////////\n// WEBPACK FOOTER\n// ./~/inherits/inherits_browser.js\n// module id = 14\n// module chunks = 0","'use strict';\n/* istanbul ignore if */\nexports.Promise = require('pouchdb-promise');\n\nexports.inherits = require('inherits');\nexports.extend = require('pouchdb-extend');\nvar argsarray = require('argsarray');\n\n/* istanbul ignore next */\nexports.promisedCallback = function (promise, callback) {\n  if (callback) {\n    promise.then(function (res) {\n      process.nextTick(function () {\n        callback(null, res);\n      });\n    }, function (reason) {\n      process.nextTick(function () {\n        callback(reason);\n      });\n    });\n  }\n  return promise;\n};\n\n/* istanbul ignore next */\nexports.callbackify = function (fun) {\n  return argsarray(function (args) {\n    var cb = args.pop();\n    var promise = fun.apply(this, args);\n    if (typeof cb === 'function') {\n      exports.promisedCallback(promise, cb);\n    }\n    return promise;\n  });\n};\n\n// Promise finally util similar to Q.finally\n/* istanbul ignore next */\nexports.fin = function (promise, cb) {\n  return promise.then(function (res) {\n    var promise2 = cb();\n    if (typeof promise2.then === 'function') {\n      return promise2.then(function () {\n        return res;\n      });\n    }\n    return res;\n  }, function (reason) {\n    var promise2 = cb();\n    if (typeof promise2.then === 'function') {\n      return promise2.then(function () {\n        throw reason;\n      });\n    }\n    throw reason;\n  });\n};\n\nexports.sequentialize = function (queue, promiseFactory) {\n  return function () {\n    var args = arguments;\n    var that = this;\n    return queue.add(function () {\n      return promiseFactory.apply(that, args);\n    });\n  };\n};\n\nexports.flatten = function (arrs) {\n  var res = [];\n  for (var i = 0, len = arrs.length; i < len; i++) {\n    res = res.concat(arrs[i]);\n  }\n  return res;\n};\n\n// uniq an array of strings, order not guaranteed\n// similar to underscore/lodash _.uniq\nexports.uniq = function (arr) {\n  var map = {};\n\n  for (var i = 0, len = arr.length; i < len; i++) {\n    map['$' + arr[i]] = true;\n  }\n\n  var keys = Object.keys(map);\n  var output = new Array(keys.length);\n\n  for (i = 0, len = keys.length; i < len; i++) {\n    output[i] = keys[i].substring(1);\n  }\n  return output;\n};\n\nvar crypto = require('crypto');\nvar Md5 = require('spark-md5');\n\nexports.MD5 = function (string) {\n  /* istanbul ignore else */\n  if (!process.browser) {\n    return crypto.createHash('md5').update(string).digest('hex');\n  } else {\n    return Md5.hash(string);\n  }\n};\n\n\n//////////////////\n// WEBPACK FOOTER\n// ./~/pouchdb-find/lib/abstract-mapreduce/utils.js\n// module id = 15\n// module chunks = 0","'use strict';\n\nvar localUtils = require('./utils');\nvar abstractMapReduce = require('../../abstract-mapreduce');\nvar parseField = localUtils.parseField;\n\n//\n// One thing about these mappers:\n//\n// Per the advice of John-David Dalton (http://youtu.be/NthmeLEhDDM),\n// what you want to do in this case is optimize for the smallest possible\n// function, since that's the thing that gets run over and over again.\n//\n// This code would be a lot simpler if all the if/elses were inside\n// the function, but it would also be a lot less performant.\n//\n\n\nfunction createDeepMultiMapper(fields, emit) {\n  return function (doc) {\n    var toEmit = [];\n    for (var i = 0, iLen = fields.length; i < iLen; i++) {\n      var parsedField = parseField(fields[i]);\n      var value = doc;\n      for (var j = 0, jLen = parsedField.length; j < jLen; j++) {\n        var key = parsedField[j];\n        value = value[key];\n        if (!value) {\n          break;\n        }\n      }\n      toEmit.push(value);\n    }\n    emit(toEmit);\n  };\n}\n\nfunction createDeepSingleMapper(field, emit) {\n  var parsedField = parseField(field);\n  return function (doc) {\n    var value = doc;\n    for (var i = 0, len = parsedField.length; i < len; i++) {\n      var key = parsedField[i];\n      value = value[key];\n      if (!value) {\n        return; // do nothing\n      }\n    }\n    emit(value);\n  };\n}\n\nfunction createShallowSingleMapper(field, emit) {\n  return function (doc) {\n    emit(doc[field]);\n  };\n}\n\nfunction createShallowMultiMapper(fields, emit) {\n  return function (doc) {\n    var toEmit = [];\n    for (var i = 0, len = fields.length; i < len; i++) {\n      toEmit.push(doc[fields[i]]);\n    }\n    emit(toEmit);\n  };\n}\n\nfunction checkShallow(fields) {\n  for (var i = 0, len = fields.length; i < len; i++) {\n    var field = fields[i];\n    if (field.indexOf('.') !== -1) {\n      return false;\n    }\n  }\n  return true;\n}\n\nfunction createMapper(fields, emit) {\n  var isShallow = checkShallow(fields);\n  var isSingle = fields.length === 1;\n\n  // notice we try to optimize for the most common case,\n  // i.e. single shallow indexes\n  if (isShallow) {\n    if (isSingle) {\n      return createShallowSingleMapper(fields[0], emit);\n    } else { // multi\n      return createShallowMultiMapper(fields, emit);\n    }\n  } else { // deep\n    if (isSingle) {\n      return createDeepSingleMapper(fields[0], emit);\n    } else { // multi\n      return createDeepMultiMapper(fields, emit);\n    }\n  }\n}\n\nfunction mapper(mapFunDef, emit) {\n  // mapFunDef is a list of fields\n\n  var fields = Object.keys(mapFunDef.fields);\n\n  return createMapper(fields, emit);\n}\n\n/* istanbul ignore next */\nfunction reducer(/*reduceFunDef*/) {\n  throw new Error('reduce not supported');\n}\n\nfunction ddocValidator(ddoc, viewName) {\n  var view = ddoc.views[viewName];\n  // This doesn't actually need to be here apparently, but\n  // I feel safer keeping it.\n  /* istanbul ignore if */\n  if (!view.map || !view.map.fields) {\n    throw new Error('ddoc ' + ddoc._id +' with view ' + viewName +\n      ' doesn\\'t have map.fields defined. ' +\n      'maybe it wasn\\'t created by this plugin?');\n  }\n}\n\nvar abstractMapper = abstractMapReduce({\n  name: 'indexes',\n  mapper: mapper,\n  reducer: reducer,\n  ddocValidator: ddocValidator\n});\n\nmodule.exports = abstractMapper;\n\n\n//////////////////\n// WEBPACK FOOTER\n// ./~/pouchdb-find/lib/adapters/local/abstract-mapper.js\n// module id = 16\n// module chunks = 0","'use strict';\n\nmodule.exports = argsArray;\n\nfunction argsArray(fun) {\n  return function () {\n    var len = arguments.length;\n    if (len) {\n      var args = [];\n      var i = -1;\n      while (++i < len) {\n        args[i] = arguments[i];\n      }\n      return fun.call(this, args);\n    } else {\n      return fun.call(this, []);\n    }\n  };\n}\n\n\n//////////////////\n// WEBPACK FOOTER\n// ./~/argsarray/index.js\n// module id = 17\n// module chunks = 0","function indexKey (doc) {\n  return doc.type + '/' + doc.id\n}\n\nfunction findByRef (resources, ref) {\n  return resources[indexKey(ref)]\n}\n\nfunction handleResource (rawResource, resources, links) {\n  let resource = {\n    _id: rawResource.id,\n    _type: rawResource.type,\n    _rev: (rawResource.meta && rawResource.meta.rev),\n    links: Object.assign({}, rawResource.links, links),\n    attributes: rawResource.attributes,\n    relations: (name) => {\n      let rels = rawResource.relationships[name]\n      if (rels === undefined || rels.data === undefined) return undefined\n      if (rels.data === null) return null\n      if (!Array.isArray(rels.data)) return findByRef(resources, rels.data)\n      return rels.data.map(ref => findByRef(resources, ref))\n    }\n  }\n  if (rawResource.relationships) {\n    resource.relationships = rawResource.relationships\n  }\n\n  resources[indexKey(rawResource)] = resource\n\n  return resource\n}\n\nfunction handleTopLevel (doc, resources = {}) {\n  // build an index of included resource by Type & ID\n  const included = doc.included\n\n  if (Array.isArray(included)) {\n    included.forEach((r) => handleResource(r, resources, doc.links))\n  }\n\n  if (Array.isArray(doc.data)) {\n    return doc.data.map((r) => handleResource(r, resources, doc.links))\n  } else {\n    return handleResource(doc.data, resources, doc.links)\n  }\n}\n\nexport default handleTopLevel\n\n\n\n// WEBPACK FOOTER //\n// ./src/jsonapi.js","var core = module.exports = { version: '2.5.3' };\nif (typeof __e == 'number') __e = core; // eslint-disable-line no-undef\n\n\n\n//////////////////\n// WEBPACK FOOTER\n// ./~/core-js/modules/_core.js\n// module id = 19\n// module chunks = 0","// 7.2.1 RequireObjectCoercible(argument)\nmodule.exports = function (it) {\n  if (it == undefined) throw TypeError(\"Can't call method on  \" + it);\n  return it;\n};\n\n\n\n//////////////////\n// WEBPACK FOOTER\n// ./~/core-js/modules/_defined.js\n// module id = 20\n// module chunks = 0","var hasOwnProperty = {}.hasOwnProperty;\nmodule.exports = function (it, key) {\n  return hasOwnProperty.call(it, key);\n};\n\n\n\n//////////////////\n// WEBPACK FOOTER\n// ./~/core-js/modules/_has.js\n// module id = 21\n// module chunks = 0","var dP = require('./_object-dp');\nvar createDesc = require('./_property-desc');\nmodule.exports = require('./_descriptors') ? function (object, key, value) {\n  return dP.f(object, key, createDesc(1, value));\n} : function (object, key, value) {\n  object[key] = value;\n  return object;\n};\n\n\n\n//////////////////\n// WEBPACK FOOTER\n// ./~/core-js/modules/_hide.js\n// module id = 22\n// module chunks = 0","// fallback for non-array-like ES3 and non-enumerable old V8 strings\nvar cof = require('./_cof');\n// eslint-disable-next-line no-prototype-builtins\nmodule.exports = Object('z').propertyIsEnumerable(0) ? Object : function (it) {\n  return cof(it) == 'String' ? it.split('') : Object(it);\n};\n\n\n\n//////////////////\n// WEBPACK FOOTER\n// ./~/core-js/modules/_iobject.js\n// module id = 23\n// module chunks = 0","// 7.1.4 ToInteger\nvar ceil = Math.ceil;\nvar floor = Math.floor;\nmodule.exports = function (it) {\n  return isNaN(it = +it) ? 0 : (it > 0 ? floor : ceil)(it);\n};\n\n\n\n//////////////////\n// WEBPACK FOOTER\n// ./~/core-js/modules/_to-integer.js\n// module id = 24\n// module chunks = 0","// to indexed object, toObject with fallback for non-array-like ES3 strings\nvar IObject = require('./_iobject');\nvar defined = require('./_defined');\nmodule.exports = function (it) {\n  return IObject(defined(it));\n};\n\n\n\n//////////////////\n// WEBPACK FOOTER\n// ./~/core-js/modules/_to-iobject.js\n// module id = 25\n// module chunks = 0","var id = 0;\nvar px = Math.random();\nmodule.exports = function (key) {\n  return 'Symbol('.concat(key === undefined ? '' : key, ')_', (++id + px).toString(36));\n};\n\n\n\n//////////////////\n// WEBPACK FOOTER\n// ./~/core-js/modules/_uid.js\n// module id = 26\n// module chunks = 0","/**\n * This is the web browser implementation of `debug()`.\n *\n * Expose `debug()` as the module.\n */\n\nexports = module.exports = require('./debug');\nexports.log = log;\nexports.formatArgs = formatArgs;\nexports.save = save;\nexports.load = load;\nexports.useColors = useColors;\nexports.storage = 'undefined' != typeof chrome\n               && 'undefined' != typeof chrome.storage\n                  ? chrome.storage.local\n                  : localstorage();\n\n/**\n * Colors.\n */\n\nexports.colors = [\n  'lightseagreen',\n  'forestgreen',\n  'goldenrod',\n  'dodgerblue',\n  'darkorchid',\n  'crimson'\n];\n\n/**\n * Currently only WebKit-based Web Inspectors, Firefox >= v31,\n * and the Firebug extension (any Firefox version) are known\n * to support \"%c\" CSS customizations.\n *\n * TODO: add a `localStorage` variable to explicitly enable/disable colors\n */\n\nfunction useColors() {\n  // NB: In an Electron preload script, document will be defined but not fully\n  // initialized. Since we know we're in Chrome, we'll just detect this case\n  // explicitly\n  if (typeof window !== 'undefined' && window && typeof window.process !== 'undefined' && window.process.type === 'renderer') {\n    return true;\n  }\n\n  // is webkit? http://stackoverflow.com/a/16459606/376773\n  // document is undefined in react-native: https://github.com/facebook/react-native/pull/1632\n  return (typeof document !== 'undefined' && document && 'WebkitAppearance' in document.documentElement.style) ||\n    // is firebug? http://stackoverflow.com/a/398120/376773\n    (typeof window !== 'undefined' && window && window.console && (console.firebug || (console.exception && console.table))) ||\n    // is firefox >= v31?\n    // https://developer.mozilla.org/en-US/docs/Tools/Web_Console#Styling_messages\n    (typeof navigator !== 'undefined' && navigator && navigator.userAgent && navigator.userAgent.toLowerCase().match(/firefox\\/(\\d+)/) && parseInt(RegExp.$1, 10) >= 31) ||\n    // double check webkit in userAgent just in case we are in a worker\n    (typeof navigator !== 'undefined' && navigator && navigator.userAgent && navigator.userAgent.toLowerCase().match(/applewebkit\\/(\\d+)/));\n}\n\n/**\n * Map %j to `JSON.stringify()`, since no Web Inspectors do that by default.\n */\n\nexports.formatters.j = function(v) {\n  try {\n    return JSON.stringify(v);\n  } catch (err) {\n    return '[UnexpectedJSONParseError]: ' + err.message;\n  }\n};\n\n\n/**\n * Colorize log arguments if enabled.\n *\n * @api public\n */\n\nfunction formatArgs(args) {\n  var useColors = this.useColors;\n\n  args[0] = (useColors ? '%c' : '')\n    + this.namespace\n    + (useColors ? ' %c' : ' ')\n    + args[0]\n    + (useColors ? '%c ' : ' ')\n    + '+' + exports.humanize(this.diff);\n\n  if (!useColors) return;\n\n  var c = 'color: ' + this.color;\n  args.splice(1, 0, c, 'color: inherit')\n\n  // the final \"%c\" is somewhat tricky, because there could be other\n  // arguments passed either before or after the %c, so we need to\n  // figure out the correct index to insert the CSS into\n  var index = 0;\n  var lastC = 0;\n  args[0].replace(/%[a-zA-Z%]/g, function(match) {\n    if ('%%' === match) return;\n    index++;\n    if ('%c' === match) {\n      // we only are interested in the *last* %c\n      // (the user may have provided their own)\n      lastC = index;\n    }\n  });\n\n  args.splice(lastC, 0, c);\n}\n\n/**\n * Invokes `console.log()` when available.\n * No-op when `console.log` is not a \"function\".\n *\n * @api public\n */\n\nfunction log() {\n  // this hackery is required for IE8/9, where\n  // the `console.log` function doesn't have 'apply'\n  return 'object' === typeof console\n    && console.log\n    && Function.prototype.apply.call(console.log, console, arguments);\n}\n\n/**\n * Save `namespaces`.\n *\n * @param {String} namespaces\n * @api private\n */\n\nfunction save(namespaces) {\n  try {\n    if (null == namespaces) {\n      exports.storage.removeItem('debug');\n    } else {\n      exports.storage.debug = namespaces;\n    }\n  } catch(e) {}\n}\n\n/**\n * Load `namespaces`.\n *\n * @return {String} returns the previously persisted debug modes\n * @api private\n */\n\nfunction load() {\n  try {\n    return exports.storage.debug;\n  } catch(e) {}\n\n  // If debug isn't set in LS, and we're in Electron, try to load $DEBUG\n  if (typeof process !== 'undefined' && 'env' in process) {\n    return process.env.DEBUG;\n  }\n}\n\n/**\n * Enable namespaces listed in `localStorage.debug` initially.\n */\n\nexports.enable(load());\n\n/**\n * Localstorage attempts to return the localstorage.\n *\n * This is necessary because safari throws\n * when a user disables cookies/localstorage\n * and you attempt to access it.\n *\n * @return {LocalStorage}\n * @api private\n */\n\nfunction localstorage() {\n  try {\n    return window.localStorage;\n  } catch (e) {}\n}\n\n\n\n//////////////////\n// WEBPACK FOOTER\n// ./~/debug/src/browser.js\n// module id = 27\n// module chunks = 0","'use strict';\nvar immediate = require('immediate');\n\n/* istanbul ignore next */\nfunction INTERNAL() {}\n\nvar handlers = {};\n\nvar REJECTED = ['REJECTED'];\nvar FULFILLED = ['FULFILLED'];\nvar PENDING = ['PENDING'];\n/* istanbul ignore else */\nif (!process.browser) {\n  // in which we actually take advantage of JS scoping\n  var UNHANDLED = ['UNHANDLED'];\n}\n\nmodule.exports = Promise;\n\nfunction Promise(resolver) {\n  if (typeof resolver !== 'function') {\n    throw new TypeError('resolver must be a function');\n  }\n  this.state = PENDING;\n  this.queue = [];\n  this.outcome = void 0;\n  /* istanbul ignore else */\n  if (!process.browser) {\n    this.handled = UNHANDLED;\n  }\n  if (resolver !== INTERNAL) {\n    safelyResolveThenable(this, resolver);\n  }\n}\n\nPromise.prototype.catch = function (onRejected) {\n  return this.then(null, onRejected);\n};\nPromise.prototype.then = function (onFulfilled, onRejected) {\n  if (typeof onFulfilled !== 'function' && this.state === FULFILLED ||\n    typeof onRejected !== 'function' && this.state === REJECTED) {\n    return this;\n  }\n  var promise = new this.constructor(INTERNAL);\n  /* istanbul ignore else */\n  if (!process.browser) {\n    if (this.handled === UNHANDLED) {\n      this.handled = null;\n    }\n  }\n  if (this.state !== PENDING) {\n    var resolver = this.state === FULFILLED ? onFulfilled : onRejected;\n    unwrap(promise, resolver, this.outcome);\n  } else {\n    this.queue.push(new QueueItem(promise, onFulfilled, onRejected));\n  }\n\n  return promise;\n};\nfunction QueueItem(promise, onFulfilled, onRejected) {\n  this.promise = promise;\n  if (typeof onFulfilled === 'function') {\n    this.onFulfilled = onFulfilled;\n    this.callFulfilled = this.otherCallFulfilled;\n  }\n  if (typeof onRejected === 'function') {\n    this.onRejected = onRejected;\n    this.callRejected = this.otherCallRejected;\n  }\n}\nQueueItem.prototype.callFulfilled = function (value) {\n  handlers.resolve(this.promise, value);\n};\nQueueItem.prototype.otherCallFulfilled = function (value) {\n  unwrap(this.promise, this.onFulfilled, value);\n};\nQueueItem.prototype.callRejected = function (value) {\n  handlers.reject(this.promise, value);\n};\nQueueItem.prototype.otherCallRejected = function (value) {\n  unwrap(this.promise, this.onRejected, value);\n};\n\nfunction unwrap(promise, func, value) {\n  immediate(function () {\n    var returnValue;\n    try {\n      returnValue = func(value);\n    } catch (e) {\n      return handlers.reject(promise, e);\n    }\n    if (returnValue === promise) {\n      handlers.reject(promise, new TypeError('Cannot resolve promise with itself'));\n    } else {\n      handlers.resolve(promise, returnValue);\n    }\n  });\n}\n\nhandlers.resolve = function (self, value) {\n  var result = tryCatch(getThen, value);\n  if (result.status === 'error') {\n    return handlers.reject(self, result.value);\n  }\n  var thenable = result.value;\n\n  if (thenable) {\n    safelyResolveThenable(self, thenable);\n  } else {\n    self.state = FULFILLED;\n    self.outcome = value;\n    var i = -1;\n    var len = self.queue.length;\n    while (++i < len) {\n      self.queue[i].callFulfilled(value);\n    }\n  }\n  return self;\n};\nhandlers.reject = function (self, error) {\n  self.state = REJECTED;\n  self.outcome = error;\n  /* istanbul ignore else */\n  if (!process.browser) {\n    if (self.handled === UNHANDLED) {\n      immediate(function () {\n        if (self.handled === UNHANDLED) {\n          process.emit('unhandledRejection', error, self);\n        }\n      });\n    }\n  }\n  var i = -1;\n  var len = self.queue.length;\n  while (++i < len) {\n    self.queue[i].callRejected(error);\n  }\n  return self;\n};\n\nfunction getThen(obj) {\n  // Make sure we only access the accessor once as required by the spec\n  var then = obj && obj.then;\n  if (obj && typeof obj === 'object' && typeof then === 'function') {\n    return function appyThen() {\n      then.apply(obj, arguments);\n    };\n  }\n}\n\nfunction safelyResolveThenable(self, thenable) {\n  // Either fulfill, reject or reject with error\n  var called = false;\n  function onError(value) {\n    if (called) {\n      return;\n    }\n    called = true;\n    handlers.reject(self, value);\n  }\n\n  function onSuccess(value) {\n    if (called) {\n      return;\n    }\n    called = true;\n    handlers.resolve(self, value);\n  }\n\n  function tryToUnwrap() {\n    thenable(onSuccess, onError);\n  }\n\n  var result = tryCatch(tryToUnwrap);\n  if (result.status === 'error') {\n    onError(result.value);\n  }\n}\n\nfunction tryCatch(func, value) {\n  var out = {};\n  try {\n    out.value = func(value);\n    out.status = 'success';\n  } catch (e) {\n    out.status = 'error';\n    out.value = e;\n  }\n  return out;\n}\n\nPromise.resolve = resolve;\nfunction resolve(value) {\n  if (value instanceof this) {\n    return value;\n  }\n  return handlers.resolve(new this(INTERNAL), value);\n}\n\nPromise.reject = reject;\nfunction reject(reason) {\n  var promise = new this(INTERNAL);\n  return handlers.reject(promise, reason);\n}\n\nPromise.all = all;\nfunction all(iterable) {\n  var self = this;\n  if (Object.prototype.toString.call(iterable) !== '[object Array]') {\n    return this.reject(new TypeError('must be an array'));\n  }\n\n  var len = iterable.length;\n  var called = false;\n  if (!len) {\n    return this.resolve([]);\n  }\n\n  var values = new Array(len);\n  var resolved = 0;\n  var i = -1;\n  var promise = new this(INTERNAL);\n\n  while (++i < len) {\n    allResolver(iterable[i], i);\n  }\n  return promise;\n  function allResolver(value, i) {\n    self.resolve(value).then(resolveFromAll, function (error) {\n      if (!called) {\n        called = true;\n        handlers.reject(promise, error);\n      }\n    });\n    function resolveFromAll(outValue) {\n      values[i] = outValue;\n      if (++resolved === len && !called) {\n        called = true;\n        handlers.resolve(promise, values);\n      }\n    }\n  }\n}\n\nPromise.race = race;\nfunction race(iterable) {\n  var self = this;\n  if (Object.prototype.toString.call(iterable) !== '[object Array]') {\n    return this.reject(new TypeError('must be an array'));\n  }\n\n  var len = iterable.length;\n  var called = false;\n  if (!len) {\n    return this.resolve([]);\n  }\n\n  var i = -1;\n  var promise = new this(INTERNAL);\n\n  while (++i < len) {\n    resolver(iterable[i]);\n  }\n  return promise;\n  function resolver(value) {\n    self.resolve(value).then(function (response) {\n      if (!called) {\n        called = true;\n        handlers.resolve(promise, response);\n      }\n    }, function (error) {\n      if (!called) {\n        called = true;\n        handlers.reject(promise, error);\n      }\n    });\n  }\n}\n\n\n\n//////////////////\n// WEBPACK FOOTER\n// ./~/lie/lib/index.js\n// module id = 28\n// module chunks = 0","\"use strict\";\n\n// Extends method\n// (taken from http://code.jquery.com/jquery-1.9.0.js)\n// Populate the class2type map\nvar class2type = {};\n\nvar types = [\n  \"Boolean\", \"Number\", \"String\", \"Function\", \"Array\",\n  \"Date\", \"RegExp\", \"Object\", \"Error\"\n];\nfor (var i = 0; i < types.length; i++) {\n  var typename = types[i];\n  class2type[\"[object \" + typename + \"]\"] = typename.toLowerCase();\n}\n\nvar core_toString = class2type.toString;\nvar core_hasOwn = class2type.hasOwnProperty;\n\nfunction type(obj) {\n  if (obj === null) {\n    return String(obj);\n  }\n  return typeof obj === \"object\" || typeof obj === \"function\" ?\n    class2type[core_toString.call(obj)] || \"object\" :\n    typeof obj;\n}\n\nfunction isWindow(obj) {\n  return obj !== null && obj === obj.window;\n}\n\nfunction isPlainObject(obj) {\n  // Must be an Object.\n  // Because of IE, we also have to check the presence of\n  // the constructor property.\n  // Make sure that DOM nodes and window objects don't pass through, as well\n  if (!obj || type(obj) !== \"object\" || obj.nodeType || isWindow(obj)) {\n    return false;\n  }\n\n  try {\n    // Not own constructor property must be Object\n    if (obj.constructor &&\n      !core_hasOwn.call(obj, \"constructor\") &&\n      !core_hasOwn.call(obj.constructor.prototype, \"isPrototypeOf\")) {\n      return false;\n    }\n  } catch ( e ) {\n    // IE8,9 Will throw exceptions on certain host objects #9897\n    return false;\n  }\n\n  // Own properties are enumerated firstly, so to speed up,\n  // if last one is own, then all properties are own.\n  var key;\n  for (key in obj) {}\n\n  return key === undefined || core_hasOwn.call(obj, key);\n}\n\n\nfunction isFunction(obj) {\n  return type(obj) === \"function\";\n}\n\nvar isArray = Array.isArray || function (obj) {\n  return type(obj) === \"array\";\n};\n\nfunction extend() {\n  // originally extend() was recursive, but this ended up giving us\n  // \"call stack exceeded\", so it's been unrolled to use a literal stack\n  // (see https://github.com/pouchdb/pouchdb/issues/2543)\n  var stack = [];\n  var i = -1;\n  var len = arguments.length;\n  var args = new Array(len);\n  while (++i < len) {\n    args[i] = arguments[i];\n  }\n  var container = {};\n  stack.push({args: args, result: {container: container, key: 'key'}});\n  var next;\n  while ((next = stack.pop())) {\n    extendInner(stack, next.args, next.result);\n  }\n  return container.key;\n}\n\nfunction extendInner(stack, args, result) {\n  var options, name, src, copy, copyIsArray, clone,\n    target = args[0] || {},\n    i = 1,\n    length = args.length,\n    deep = false,\n    numericStringRegex = /\\d+/,\n    optionsIsArray;\n\n  // Handle a deep copy situation\n  if (typeof target === \"boolean\") {\n    deep = target;\n    target = args[1] || {};\n    // skip the boolean and the target\n    i = 2;\n  }\n\n  // Handle case when target is a string or something (possible in deep copy)\n  if (typeof target !== \"object\" && !isFunction(target)) {\n    target = {};\n  }\n\n  // extend jQuery itself if only one argument is passed\n  if (length === i) {\n    /* jshint validthis: true */\n    target = this;\n    --i;\n  }\n\n  for (; i < length; i++) {\n    // Only deal with non-null/undefined values\n    if ((options = args[i]) != null) {\n      optionsIsArray = isArray(options);\n      // Extend the base object\n      for (name in options) {\n        //if (options.hasOwnProperty(name)) {\n        if (!(name in Object.prototype)) {\n          if (optionsIsArray && !numericStringRegex.test(name)) {\n            continue;\n          }\n\n          src = target[name];\n          copy = options[name];\n\n          // Prevent never-ending loop\n          if (target === copy) {\n            continue;\n          }\n\n          // Recurse if we're merging plain objects or arrays\n          if (deep && copy && (isPlainObject(copy) ||\n              (copyIsArray = isArray(copy)))) {\n            if (copyIsArray) {\n              copyIsArray = false;\n              clone = src && isArray(src) ? src : [];\n\n            } else {\n              clone = src && isPlainObject(src) ? src : {};\n            }\n\n            // Never move original objects, clone them\n            stack.push({\n              args: [deep, clone, copy],\n              result: {\n                container: target,\n                key: name\n              }\n            });\n\n          // Don't bring in undefined values\n          } else if (copy !== undefined) {\n            if (!(isArray(options) && isFunction(copy))) {\n              target[name] = copy;\n            }\n          }\n        }\n      }\n    }\n  }\n\n  // \"Return\" the modified object by setting the key\n  // on the given container\n  result.container[result.key] = target;\n}\n\n\nmodule.exports = extend;\n\n\n\n\n\n//////////////////\n// WEBPACK FOOTER\n// ./~/pouchdb-extend/index.js\n// module id = 29\n// module chunks = 0","'use strict';\n\nvar upsert = require('pouchdb-upsert').upsert;\n\nmodule.exports = function (db, doc, diffFun) {\n  return upsert.apply(db, [doc, diffFun]);\n};\n\n\n//////////////////\n// WEBPACK FOOTER\n// ./~/pouchdb-find/lib/abstract-mapreduce/upsert.js\n// module id = 30\n// module chunks = 0","'use strict';\n\nvar utils = require('../../../utils');\n\nvar localUtils = require('../utils');\nvar massageIndexDef = localUtils.massageIndexDef;\n\nfunction getIndexes(db) {\n  // just search through all the design docs and filter in-memory.\n  // hopefully there aren't that many ddocs.\n  return db.allDocs({\n    startkey: '_design/',\n    endkey: '_design/\\uffff',\n    include_docs: true\n  }).then(function (allDocsRes) {\n    var res = {\n      indexes: [{\n        ddoc: null,\n        name: '_all_docs',\n        type: 'special',\n        def: {\n          fields: [{_id: 'asc'}]\n        }\n      }]\n    };\n\n    res.indexes = utils.flatten(res.indexes, allDocsRes.rows.filter(function (row) {\n      return row.doc.language === 'query';\n    }).map(function (row) {\n      var viewNames = row.doc.views !== undefined ? Object.keys(row.doc.views) : [];\n\n      return viewNames.map(function (viewName) {\n        var view = row.doc.views[viewName];\n        return {\n          ddoc: row.id,\n          name: viewName,\n          type: 'json',\n          def: massageIndexDef(view.options.def)\n        };\n      });\n    }));\n\n    // these are sorted by view name for some reason\n    res.indexes.sort(function (left, right) {\n      return utils.compare(left.name, right.name);\n    });\n    res.total_rows = res.indexes.length;\n    return res;\n  });\n}\n\nmodule.exports = getIndexes;\n\n\n\n//////////////////\n// WEBPACK FOOTER\n// ./~/pouchdb-find/lib/adapters/local/get-indexes/index.js\n// module id = 31\n// module chunks = 0","'use strict';\n\nvar utils = require('./utils');\nvar clone = utils.clone;\n\n// we restucture the supplied JSON considerably, because the official\n// Mango API is very particular about a lot of this stuff, but we like\n// to be liberal with what we accept in order to prevent mental\n// breakdowns in our users\nmodule.exports = function (requestDef) {\n  requestDef = clone(requestDef);\n\n  if (!requestDef.index) {\n    requestDef.index = {};\n  }\n\n  ['type', 'name', 'ddoc'].forEach(function (key) {\n    if (requestDef.index[key]) {\n      requestDef[key] = requestDef.index[key];\n      delete requestDef.index[key];\n    }\n  });\n\n  if (requestDef.fields) {\n    requestDef.index.fields = requestDef.fields;\n    delete requestDef.fields;\n  }\n\n  if (!requestDef.type) {\n    requestDef.type = 'json';\n  }\n  return requestDef;\n};\n\n\n//////////////////\n// WEBPACK FOOTER\n// ./~/pouchdb-find/lib/massageCreateIndexRequest.js\n// module id = 32\n// module chunks = 0","'use strict';\n\nfunction _interopDefault (ex) { return (ex && (typeof ex === 'object') && 'default' in ex) ? ex['default'] : ex; }\n\nvar lie = _interopDefault(require('lie'));\n\n/* istanbul ignore next */\nvar PouchPromise = typeof Promise === 'function' ? Promise : lie;\n\nmodule.exports = PouchPromise;\n\n\n//////////////////\n// WEBPACK FOOTER\n// ./~/pouchdb-find/~/pouchdb-promise/lib/index.js\n// module id = 33\n// module chunks = 0","/*jshint bitwise:false*/\n/*global unescape*/\n\n(function (factory) {\n    if (typeof exports === 'object') {\n        // Node/CommonJS\n        module.exports = factory();\n    } else if (typeof define === 'function' && define.amd) {\n        // AMD\n        define(factory);\n    } else {\n        // Browser globals (with support for web workers)\n        var glob;\n        try {\n            glob = window;\n        } catch (e) {\n            glob = self;\n        }\n\n        glob.SparkMD5 = factory();\n    }\n}(function (undefined) {\n\n    'use strict';\n\n    ////////////////////////////////////////////////////////////////////////////\n\n    /*\n     * Fastest md5 implementation around (JKM md5)\n     * Credits: Joseph Myers\n     *\n     * @see http://www.myersdaily.org/joseph/javascript/md5-text.html\n     * @see http://jsperf.com/md5-shootout/7\n     */\n\n    /* this function is much faster,\n      so if possible we use it. Some IEs\n      are the only ones I know of that\n      need the idiotic second function,\n      generated by an if clause.  */\n    var add32 = function (a, b) {\n        return (a + b) & 0xFFFFFFFF;\n    },\n\n    cmn = function (q, a, b, x, s, t) {\n        a = add32(add32(a, q), add32(x, t));\n        return add32((a << s) | (a >>> (32 - s)), b);\n    },\n\n    ff = function (a, b, c, d, x, s, t) {\n        return cmn((b & c) | ((~b) & d), a, b, x, s, t);\n    },\n\n    gg = function (a, b, c, d, x, s, t) {\n        return cmn((b & d) | (c & (~d)), a, b, x, s, t);\n    },\n\n    hh = function (a, b, c, d, x, s, t) {\n        return cmn(b ^ c ^ d, a, b, x, s, t);\n    },\n\n    ii = function (a, b, c, d, x, s, t) {\n        return cmn(c ^ (b | (~d)), a, b, x, s, t);\n    },\n\n    md5cycle = function (x, k) {\n        var a = x[0],\n            b = x[1],\n            c = x[2],\n            d = x[3];\n\n        a = ff(a, b, c, d, k[0], 7, -680876936);\n        d = ff(d, a, b, c, k[1], 12, -389564586);\n        c = ff(c, d, a, b, k[2], 17, 606105819);\n        b = ff(b, c, d, a, k[3], 22, -1044525330);\n        a = ff(a, b, c, d, k[4], 7, -176418897);\n        d = ff(d, a, b, c, k[5], 12, 1200080426);\n        c = ff(c, d, a, b, k[6], 17, -1473231341);\n        b = ff(b, c, d, a, k[7], 22, -45705983);\n        a = ff(a, b, c, d, k[8], 7, 1770035416);\n        d = ff(d, a, b, c, k[9], 12, -1958414417);\n        c = ff(c, d, a, b, k[10], 17, -42063);\n        b = ff(b, c, d, a, k[11], 22, -1990404162);\n        a = ff(a, b, c, d, k[12], 7, 1804603682);\n        d = ff(d, a, b, c, k[13], 12, -40341101);\n        c = ff(c, d, a, b, k[14], 17, -1502002290);\n        b = ff(b, c, d, a, k[15], 22, 1236535329);\n\n        a = gg(a, b, c, d, k[1], 5, -165796510);\n        d = gg(d, a, b, c, k[6], 9, -1069501632);\n        c = gg(c, d, a, b, k[11], 14, 643717713);\n        b = gg(b, c, d, a, k[0], 20, -373897302);\n        a = gg(a, b, c, d, k[5], 5, -701558691);\n        d = gg(d, a, b, c, k[10], 9, 38016083);\n        c = gg(c, d, a, b, k[15], 14, -660478335);\n        b = gg(b, c, d, a, k[4], 20, -405537848);\n        a = gg(a, b, c, d, k[9], 5, 568446438);\n        d = gg(d, a, b, c, k[14], 9, -1019803690);\n        c = gg(c, d, a, b, k[3], 14, -187363961);\n        b = gg(b, c, d, a, k[8], 20, 1163531501);\n        a = gg(a, b, c, d, k[13], 5, -1444681467);\n        d = gg(d, a, b, c, k[2], 9, -51403784);\n        c = gg(c, d, a, b, k[7], 14, 1735328473);\n        b = gg(b, c, d, a, k[12], 20, -1926607734);\n\n        a = hh(a, b, c, d, k[5], 4, -378558);\n        d = hh(d, a, b, c, k[8], 11, -2022574463);\n        c = hh(c, d, a, b, k[11], 16, 1839030562);\n        b = hh(b, c, d, a, k[14], 23, -35309556);\n        a = hh(a, b, c, d, k[1], 4, -1530992060);\n        d = hh(d, a, b, c, k[4], 11, 1272893353);\n        c = hh(c, d, a, b, k[7], 16, -155497632);\n        b = hh(b, c, d, a, k[10], 23, -1094730640);\n        a = hh(a, b, c, d, k[13], 4, 681279174);\n        d = hh(d, a, b, c, k[0], 11, -358537222);\n        c = hh(c, d, a, b, k[3], 16, -722521979);\n        b = hh(b, c, d, a, k[6], 23, 76029189);\n        a = hh(a, b, c, d, k[9], 4, -640364487);\n        d = hh(d, a, b, c, k[12], 11, -421815835);\n        c = hh(c, d, a, b, k[15], 16, 530742520);\n        b = hh(b, c, d, a, k[2], 23, -995338651);\n\n        a = ii(a, b, c, d, k[0], 6, -198630844);\n        d = ii(d, a, b, c, k[7], 10, 1126891415);\n        c = ii(c, d, a, b, k[14], 15, -1416354905);\n        b = ii(b, c, d, a, k[5], 21, -57434055);\n        a = ii(a, b, c, d, k[12], 6, 1700485571);\n        d = ii(d, a, b, c, k[3], 10, -1894986606);\n        c = ii(c, d, a, b, k[10], 15, -1051523);\n        b = ii(b, c, d, a, k[1], 21, -2054922799);\n        a = ii(a, b, c, d, k[8], 6, 1873313359);\n        d = ii(d, a, b, c, k[15], 10, -30611744);\n        c = ii(c, d, a, b, k[6], 15, -1560198380);\n        b = ii(b, c, d, a, k[13], 21, 1309151649);\n        a = ii(a, b, c, d, k[4], 6, -145523070);\n        d = ii(d, a, b, c, k[11], 10, -1120210379);\n        c = ii(c, d, a, b, k[2], 15, 718787259);\n        b = ii(b, c, d, a, k[9], 21, -343485551);\n\n        x[0] = add32(a, x[0]);\n        x[1] = add32(b, x[1]);\n        x[2] = add32(c, x[2]);\n        x[3] = add32(d, x[3]);\n    },\n\n    /* there needs to be support for Unicode here,\n       * unless we pretend that we can redefine the MD-5\n       * algorithm for multi-byte characters (perhaps\n       * by adding every four 16-bit characters and\n       * shortening the sum to 32 bits). Otherwise\n       * I suggest performing MD-5 as if every character\n       * was two bytes--e.g., 0040 0025 = @%--but then\n       * how will an ordinary MD-5 sum be matched?\n       * There is no way to standardize text to something\n       * like UTF-8 before transformation; speed cost is\n       * utterly prohibitive. The JavaScript standard\n       * itself needs to look at this: it should start\n       * providing access to strings as preformed UTF-8\n       * 8-bit unsigned value arrays.\n       */\n    md5blk = function (s) {\n        var md5blks = [],\n            i; /* Andy King said do it this way. */\n\n        for (i = 0; i < 64; i += 4) {\n            md5blks[i >> 2] = s.charCodeAt(i) + (s.charCodeAt(i + 1) << 8) + (s.charCodeAt(i + 2) << 16) + (s.charCodeAt(i + 3) << 24);\n        }\n        return md5blks;\n    },\n\n    md5blk_array = function (a) {\n        var md5blks = [],\n            i; /* Andy King said do it this way. */\n\n        for (i = 0; i < 64; i += 4) {\n            md5blks[i >> 2] = a[i] + (a[i + 1] << 8) + (a[i + 2] << 16) + (a[i + 3] << 24);\n        }\n        return md5blks;\n    },\n\n    md51 = function (s) {\n        var n = s.length,\n            state = [1732584193, -271733879, -1732584194, 271733878],\n            i,\n            length,\n            tail,\n            tmp,\n            lo,\n            hi;\n\n        for (i = 64; i <= n; i += 64) {\n            md5cycle(state, md5blk(s.substring(i - 64, i)));\n        }\n        s = s.substring(i - 64);\n        length = s.length;\n        tail = [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0];\n        for (i = 0; i < length; i += 1) {\n            tail[i >> 2] |= s.charCodeAt(i) << ((i % 4) << 3);\n        }\n        tail[i >> 2] |= 0x80 << ((i % 4) << 3);\n        if (i > 55) {\n            md5cycle(state, tail);\n            for (i = 0; i < 16; i += 1) {\n                tail[i] = 0;\n            }\n        }\n\n        // Beware that the final length might not fit in 32 bits so we take care of that\n        tmp = n * 8;\n        tmp = tmp.toString(16).match(/(.*?)(.{0,8})$/);\n        lo = parseInt(tmp[2], 16);\n        hi = parseInt(tmp[1], 16) || 0;\n\n        tail[14] = lo;\n        tail[15] = hi;\n\n        md5cycle(state, tail);\n        return state;\n    },\n\n    md51_array = function (a) {\n        var n = a.length,\n            state = [1732584193, -271733879, -1732584194, 271733878],\n            i,\n            length,\n            tail,\n            tmp,\n            lo,\n            hi;\n\n        for (i = 64; i <= n; i += 64) {\n            md5cycle(state, md5blk_array(a.subarray(i - 64, i)));\n        }\n\n        // Not sure if it is a bug, however IE10 will always produce a sub array of length 1\n        // containing the last element of the parent array if the sub array specified starts\n        // beyond the length of the parent array - weird.\n        // https://connect.microsoft.com/IE/feedback/details/771452/typed-array-subarray-issue\n        a = (i - 64) < n ? a.subarray(i - 64) : new Uint8Array(0);\n\n        length = a.length;\n        tail = [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0];\n        for (i = 0; i < length; i += 1) {\n            tail[i >> 2] |= a[i] << ((i % 4) << 3);\n        }\n\n        tail[i >> 2] |= 0x80 << ((i % 4) << 3);\n        if (i > 55) {\n            md5cycle(state, tail);\n            for (i = 0; i < 16; i += 1) {\n                tail[i] = 0;\n            }\n        }\n\n        // Beware that the final length might not fit in 32 bits so we take care of that\n        tmp = n * 8;\n        tmp = tmp.toString(16).match(/(.*?)(.{0,8})$/);\n        lo = parseInt(tmp[2], 16);\n        hi = parseInt(tmp[1], 16) || 0;\n\n        tail[14] = lo;\n        tail[15] = hi;\n\n        md5cycle(state, tail);\n\n        return state;\n    },\n\n    hex_chr = ['0', '1', '2', '3', '4', '5', '6', '7', '8', '9', 'a', 'b', 'c', 'd', 'e', 'f'],\n\n    rhex = function (n) {\n        var s = '',\n            j;\n        for (j = 0; j < 4; j += 1) {\n            s += hex_chr[(n >> (j * 8 + 4)) & 0x0F] + hex_chr[(n >> (j * 8)) & 0x0F];\n        }\n        return s;\n    },\n\n    hex = function (x) {\n        var i;\n        for (i = 0; i < x.length; i += 1) {\n            x[i] = rhex(x[i]);\n        }\n        return x.join('');\n    },\n\n    md5 = function (s) {\n        return hex(md51(s));\n    },\n\n\n\n    ////////////////////////////////////////////////////////////////////////////\n\n    /**\n     * SparkMD5 OOP implementation.\n     *\n     * Use this class to perform an incremental md5, otherwise use the\n     * static methods instead.\n     */\n    SparkMD5 = function () {\n        // call reset to init the instance\n        this.reset();\n    };\n\n\n    // In some cases the fast add32 function cannot be used..\n    if (md5('hello') !== '5d41402abc4b2a76b9719d911017c592') {\n        add32 = function (x, y) {\n            var lsw = (x & 0xFFFF) + (y & 0xFFFF),\n                msw = (x >> 16) + (y >> 16) + (lsw >> 16);\n            return (msw << 16) | (lsw & 0xFFFF);\n        };\n    }\n\n\n    /**\n     * Appends a string.\n     * A conversion will be applied if an utf8 string is detected.\n     *\n     * @param {String} str The string to be appended\n     *\n     * @return {SparkMD5} The instance itself\n     */\n    SparkMD5.prototype.append = function (str) {\n        // converts the string to utf8 bytes if necessary\n        if (/[\\u0080-\\uFFFF]/.test(str)) {\n            str = unescape(encodeURIComponent(str));\n        }\n\n        // then append as binary\n        this.appendBinary(str);\n\n        return this;\n    };\n\n    /**\n     * Appends a binary string.\n     *\n     * @param {String} contents The binary string to be appended\n     *\n     * @return {SparkMD5} The instance itself\n     */\n    SparkMD5.prototype.appendBinary = function (contents) {\n        this._buff += contents;\n        this._length += contents.length;\n\n        var length = this._buff.length,\n            i;\n\n        for (i = 64; i <= length; i += 64) {\n            md5cycle(this._state, md5blk(this._buff.substring(i - 64, i)));\n        }\n\n        this._buff = this._buff.substr(i - 64);\n\n        return this;\n    };\n\n    /**\n     * Finishes the incremental computation, reseting the internal state and\n     * returning the result.\n     * Use the raw parameter to obtain the raw result instead of the hex one.\n     *\n     * @param {Boolean} raw True to get the raw result, false to get the hex result\n     *\n     * @return {String|Array} The result\n     */\n    SparkMD5.prototype.end = function (raw) {\n        var buff = this._buff,\n            length = buff.length,\n            i,\n            tail = [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0],\n            ret;\n\n        for (i = 0; i < length; i += 1) {\n            tail[i >> 2] |= buff.charCodeAt(i) << ((i % 4) << 3);\n        }\n\n        this._finish(tail, length);\n        ret = !!raw ? this._state : hex(this._state);\n\n        this.reset();\n\n        return ret;\n    };\n\n    /**\n     * Finish the final calculation based on the tail.\n     *\n     * @param {Array}  tail   The tail (will be modified)\n     * @param {Number} length The length of the remaining buffer\n     */\n    SparkMD5.prototype._finish = function (tail, length) {\n        var i = length,\n            tmp,\n            lo,\n            hi;\n\n        tail[i >> 2] |= 0x80 << ((i % 4) << 3);\n        if (i > 55) {\n            md5cycle(this._state, tail);\n            for (i = 0; i < 16; i += 1) {\n                tail[i] = 0;\n            }\n        }\n\n        // Do the final computation based on the tail and length\n        // Beware that the final length may not fit in 32 bits so we take care of that\n        tmp = this._length * 8;\n        tmp = tmp.toString(16).match(/(.*?)(.{0,8})$/);\n        lo = parseInt(tmp[2], 16);\n        hi = parseInt(tmp[1], 16) || 0;\n\n        tail[14] = lo;\n        tail[15] = hi;\n        md5cycle(this._state, tail);\n    };\n\n    /**\n     * Resets the internal state of the computation.\n     *\n     * @return {SparkMD5} The instance itself\n     */\n    SparkMD5.prototype.reset = function () {\n        this._buff = \"\";\n        this._length = 0;\n        this._state = [1732584193, -271733879, -1732584194, 271733878];\n\n        return this;\n    };\n\n    /**\n     * Releases memory used by the incremental buffer and other aditional\n     * resources. If you plan to use the instance again, use reset instead.\n     */\n    SparkMD5.prototype.destroy = function () {\n        delete this._state;\n        delete this._buff;\n        delete this._length;\n    };\n\n\n    /**\n     * Performs the md5 hash on a string.\n     * A conversion will be applied if utf8 string is detected.\n     *\n     * @param {String}  str The string\n     * @param {Boolean} raw True to get the raw result, false to get the hex result\n     *\n     * @return {String|Array} The result\n     */\n    SparkMD5.hash = function (str, raw) {\n        // converts the string to utf8 bytes if necessary\n        if (/[\\u0080-\\uFFFF]/.test(str)) {\n            str = unescape(encodeURIComponent(str));\n        }\n\n        var hash = md51(str);\n\n        return !!raw ? hash : hex(hash);\n    };\n\n    /**\n     * Performs the md5 hash on a binary string.\n     *\n     * @param {String}  content The binary string\n     * @param {Boolean} raw     True to get the raw result, false to get the hex result\n     *\n     * @return {String|Array} The result\n     */\n    SparkMD5.hashBinary = function (content, raw) {\n        var hash = md51(content);\n\n        return !!raw ? hash : hex(hash);\n    };\n\n    /**\n     * SparkMD5 OOP implementation for array buffers.\n     *\n     * Use this class to perform an incremental md5 ONLY for array buffers.\n     */\n    SparkMD5.ArrayBuffer = function () {\n        // call reset to init the instance\n        this.reset();\n    };\n\n    ////////////////////////////////////////////////////////////////////////////\n\n    /**\n     * Appends an array buffer.\n     *\n     * @param {ArrayBuffer} arr The array to be appended\n     *\n     * @return {SparkMD5.ArrayBuffer} The instance itself\n     */\n    SparkMD5.ArrayBuffer.prototype.append = function (arr) {\n        // TODO: we could avoid the concatenation here but the algorithm would be more complex\n        //       if you find yourself needing extra performance, please make a PR.\n        var buff = this._concatArrayBuffer(this._buff, arr),\n            length = buff.length,\n            i;\n\n        this._length += arr.byteLength;\n\n        for (i = 64; i <= length; i += 64) {\n            md5cycle(this._state, md5blk_array(buff.subarray(i - 64, i)));\n        }\n\n        // Avoids IE10 weirdness (documented above)\n        this._buff = (i - 64) < length ? buff.subarray(i - 64) : new Uint8Array(0);\n\n        return this;\n    };\n\n    /**\n     * Finishes the incremental computation, reseting the internal state and\n     * returning the result.\n     * Use the raw parameter to obtain the raw result instead of the hex one.\n     *\n     * @param {Boolean} raw True to get the raw result, false to get the hex result\n     *\n     * @return {String|Array} The result\n     */\n    SparkMD5.ArrayBuffer.prototype.end = function (raw) {\n        var buff = this._buff,\n            length = buff.length,\n            tail = [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0],\n            i,\n            ret;\n\n        for (i = 0; i < length; i += 1) {\n            tail[i >> 2] |= buff[i] << ((i % 4) << 3);\n        }\n\n        this._finish(tail, length);\n        ret = !!raw ? this._state : hex(this._state);\n\n        this.reset();\n\n        return ret;\n    };\n\n    SparkMD5.ArrayBuffer.prototype._finish = SparkMD5.prototype._finish;\n\n    /**\n     * Resets the internal state of the computation.\n     *\n     * @return {SparkMD5.ArrayBuffer} The instance itself\n     */\n    SparkMD5.ArrayBuffer.prototype.reset = function () {\n        this._buff = new Uint8Array(0);\n        this._length = 0;\n        this._state = [1732584193, -271733879, -1732584194, 271733878];\n\n        return this;\n    };\n\n    /**\n     * Releases memory used by the incremental buffer and other aditional\n     * resources. If you plan to use the instance again, use reset instead.\n     */\n    SparkMD5.ArrayBuffer.prototype.destroy = SparkMD5.prototype.destroy;\n\n    /**\n     * Concats two array buffers, returning a new one.\n     *\n     * @param  {ArrayBuffer} first  The first array buffer\n     * @param  {ArrayBuffer} second The second array buffer\n     *\n     * @return {ArrayBuffer} The new array buffer\n     */\n    SparkMD5.ArrayBuffer.prototype._concatArrayBuffer = function (first, second) {\n        var firstLength = first.length,\n            result = new Uint8Array(firstLength + second.byteLength);\n\n        result.set(first);\n        result.set(new Uint8Array(second), firstLength);\n\n        return result;\n    };\n\n    /**\n     * Performs the md5 hash on an array buffer.\n     *\n     * @param {ArrayBuffer} arr The array buffer\n     * @param {Boolean}     raw True to get the raw result, false to get the hex result\n     *\n     * @return {String|Array} The result\n     */\n    SparkMD5.ArrayBuffer.hash = function (arr, raw) {\n        var hash = md51_array(new Uint8Array(arr));\n\n        return !!raw ? hash : hex(hash);\n    };\n\n    return SparkMD5;\n}));\n\n\n\n//////////////////\n// WEBPACK FOOTER\n// ./~/pouchdb-find/~/spark-md5/spark-md5.js\n// module id = 34\n// module chunks = 0","'use strict';\n\nvar PouchPromise = require('pouchdb-promise');\n\n// this is essentially the \"update sugar\" function from daleharvey/pouchdb#1388\n// the diffFun tells us what delta to apply to the doc.  it either returns\n// the doc, or false if it doesn't need to do an update after all\nfunction upsertInner(db, docId, diffFun) {\n  if (typeof docId !== 'string') {\n    return PouchPromise.reject(new Error('doc id is required'));\n  }\n\n  return db.get(docId).catch(function (err) {\n    /* istanbul ignore next */\n    if (err.status !== 404) {\n      throw err;\n    }\n    return {};\n  }).then(function (doc) {\n    // the user might change the _rev, so save it for posterity\n    var docRev = doc._rev;\n    var newDoc = diffFun(doc);\n\n    if (!newDoc) {\n      // if the diffFun returns falsy, we short-circuit as\n      // an optimization\n      return { updated: false, rev: docRev };\n    }\n\n    // users aren't allowed to modify these values,\n    // so reset them here\n    newDoc._id = docId;\n    newDoc._rev = docRev;\n    return tryAndPut(db, newDoc, diffFun);\n  });\n}\n\nfunction tryAndPut(db, doc, diffFun) {\n  return db.put(doc).then(function (res) {\n    return {\n      updated: true,\n      rev: res.rev\n    };\n  }, function (err) {\n    /* istanbul ignore next */\n    if (err.status !== 409) {\n      throw err;\n    }\n    return upsertInner(db, doc._id, diffFun);\n  });\n}\n\nexports.upsert = function upsert(docId, diffFun, cb) {\n  var db = this;\n  var promise = upsertInner(db, docId, diffFun);\n  if (typeof cb !== 'function') {\n    return promise;\n  }\n  promise.then(function (resp) {\n    cb(null, resp);\n  }, cb);\n};\n\nexports.putIfNotExists = function putIfNotExists(docId, doc, cb) {\n  var db = this;\n\n  if (typeof docId !== 'string') {\n    cb = doc;\n    doc = docId;\n    docId = doc._id;\n  }\n\n  var diffFun = function (existingDoc) {\n    if (existingDoc._rev) {\n      return false; // do nothing\n    }\n    return doc;\n  };\n\n  var promise = upsertInner(db, docId, diffFun);\n  if (typeof cb !== 'function') {\n    return promise;\n  }\n  promise.then(function (resp) {\n    cb(null, resp);\n  }, cb);\n};\n\n\n/* istanbul ignore next */\nif (typeof window !== 'undefined' && window.PouchDB) {\n  window.PouchDB.plugin(exports);\n}\n\n\n\n//////////////////\n// WEBPACK FOOTER\n// ./~/pouchdb-upsert/index.js\n// module id = 35\n// module chunks = 0","export class LocalStorage {\n  constructor (storage, prefix) {\n    if (!storage && typeof window !== 'undefined') {\n      storage = window.localStorage\n    }\n    this.storage = storage\n    this.prefix = prefix || 'cozy:oauth:'\n  }\n\n  save (key, value) {\n    return new Promise(resolve => {\n      this.storage.setItem(this.prefix + key, JSON.stringify(value))\n      resolve(value)\n    })\n  }\n\n  load (key) {\n    return new Promise(resolve => {\n      const item = this.storage.getItem(this.prefix + key)\n      if (!item) {\n        resolve()\n      } else {\n        resolve(JSON.parse(item))\n      }\n    })\n  }\n\n  delete (key) {\n    return new Promise(resolve => resolve(\n      this.storage.removeItem(this.prefix + key)))\n  }\n\n  clear () {\n    return new Promise(resolve => {\n      const storage = this.storage\n      for (let i = 0; i < storage.length; i++) {\n        const key = storage.key(i)\n        if (key.indexOf(this.prefix) === 0) {\n          storage.removeItem(key)\n        }\n      }\n      resolve()\n    })\n  }\n}\n\nexport class MemoryStorage {\n  constructor () {\n    this.hash = Object.create(null)\n  }\n\n  save (key, value) {\n    this.hash[key] = value\n    return Promise.resolve(value)\n  }\n\n  load (key) {\n    return Promise.resolve(this.hash[key])\n  }\n\n  delete (key) {\n    const deleted = delete this.hash[key]\n    return Promise.resolve(deleted)\n  }\n\n  clear () {\n    this.hash = Object.create(null)\n    return Promise.resolve()\n  }\n}\n\n\n\n// WEBPACK FOOTER //\n// ./src/auth_storage.js","/* global btoa */\nconst V2TOKEN_ABORT_TIMEOUT = 3000\n\nexport function getAppToken () {\n  return new Promise(function (resolve, reject) {\n    if (typeof window === 'undefined') {\n      return reject(new Error('getV2Token should be used in browser'))\n    } else if (!window.parent) {\n      return reject(new Error('getV2Token should be used in iframe'))\n    } else if (!window.parent.postMessage) {\n      return reject(new Error('getV2Token should be used in modern browser'))\n    }\n    const origin = window.location.origin\n    const intent = {action: 'getToken'}\n    let timeout = null\n    const receiver = function (event) {\n      let token\n      try {\n        token = new AppToken({\n          appName: event.data.appName,\n          token: event.data.token\n        })\n      } catch (e) {\n        reject(e)\n        return\n      }\n      window.removeEventListener('message', receiver)\n      clearTimeout(timeout)\n      resolve({ client: null, token })\n    }\n    window.addEventListener('message', receiver, false)\n    window.parent.postMessage(intent, origin)\n    timeout = setTimeout(() => {\n      reject(new Error('No response from parent iframe after 3s'))\n    }, V2TOKEN_ABORT_TIMEOUT)\n  })\n}\n\nexport class AppToken {\n  constructor (opts) {\n    this.appName = opts.appName || ''\n    this.token = opts.token || ''\n  }\n\n  toAuthHeader () {\n    return 'Basic ' + btoa(`${this.appName}:${this.token}`)\n  }\n}\n\n\n\n// WEBPACK FOOTER //\n// ./src/auth_v2.js","import {createPath} from './utils'\nimport {normalizeDoctype} from './doctypes'\nimport {cozyFetchJSON} from './fetch'\n\nconst NOREV = 'stack-v2-no-rev'\n\nexport function create (cozy, doctype, attributes) {\n  return cozy.isV2().then((isV2) => {\n    doctype = normalizeDoctype(cozy, isV2, doctype)\n    if (isV2) {\n      attributes.docType = doctype\n    }\n    const path = createPath(cozy, isV2, doctype, attributes._id)\n    const httpVerb = attributes._id ? 'PUT' : 'POST'\n    delete attributes._id\n    return cozyFetchJSON(cozy, httpVerb, path, attributes).then((resp) => {\n      if (isV2) {\n        return find(cozy, doctype, resp._id)\n      } else {\n        return resp.data\n      }\n    })\n  })\n}\n\nexport function find (cozy, doctype, id) {\n  return cozy.isV2().then((isV2) => {\n    doctype = normalizeDoctype(cozy, isV2, doctype)\n\n    if (!id) {\n      return Promise.reject(new Error('Missing id parameter'))\n    }\n\n    const path = createPath(cozy, isV2, doctype, id)\n    return cozyFetchJSON(cozy, 'GET', path).then((resp) => {\n      if (isV2) {\n        return Object.assign(resp, {_rev: NOREV})\n      } else {\n        return resp\n      }\n    })\n  })\n}\n\nexport function findMany (cozy, doctype, ids) {\n  if (!(ids instanceof Array)) {\n    return Promise.reject(new Error('Parameter ids must be a non-empty array'))\n  }\n  if (ids.length === 0) {\n    // So users don't need to be defensive regarding the array content.\n    // This should not hide issues in user code since the result will be an\n    // empty object anyway.\n    return Promise.resolve({})\n  }\n\n  return cozy.isV2().then((isV2) => {\n    if (isV2) {\n      return Promise.reject(new Error('findMany is not available on v2'))\n    }\n\n    const path = createPath(cozy, isV2, doctype, '_all_docs', {include_docs: true})\n\n    return cozyFetchJSON(cozy, 'POST', path, {keys: ids})\n      .then((resp) => {\n        const docs = {}\n\n        for (const row of resp.rows) {\n          const {key, doc, error} = row\n          docs[key] = error ? {error} : {doc}\n        }\n\n        return docs\n      })\n      .catch((error) => {\n        if (error.status !== 404) return Promise.reject(error)\n\n        // When no doc was ever created and the database does not exist yet,\n        // the response will be a 404 error.\n        const docs = {}\n\n        for (const id of ids) {\n          docs[id] = {error}\n        }\n\n        return docs\n      })\n  })\n}\n\nexport function findAll (cozy, doctype) {\n  return cozy.isV2().then((isV2) => {\n    if (isV2) {\n      return Promise.reject(new Error('findAll is not available on v2'))\n    }\n\n    const path = createPath(cozy, isV2, doctype, '_all_docs', {include_docs: true})\n\n    return cozyFetchJSON(cozy, 'POST', path, {})\n    .then((resp) => {\n      const docs = []\n\n      for (const row of resp.rows) {\n        const { doc } = row\n        // if not couchDB indexes\n        if (!doc._id.match(/_design\\//)) docs.push(doc)\n      }\n      return docs\n    })\n    .catch(error => {\n      // the _all_docs endpoint returns a 404 error if no document with the given\n      // doctype exists.\n      if (error.status === 404) return []\n      throw error\n    })\n  })\n}\n\nexport function changesFeed (cozy, doctype, options) {\n  return cozy.isV2().then((isV2) => {\n    doctype = normalizeDoctype(cozy, isV2, doctype)\n    const path = createPath(cozy, isV2, doctype, '_changes', options)\n    return cozyFetchJSON(cozy, 'GET', path)\n  })\n}\n\nexport function update (cozy, doctype, doc, changes) {\n  return cozy.isV2().then((isV2) => {\n    doctype = normalizeDoctype(cozy, isV2, doctype)\n    const {_id, _rev} = doc\n\n    if (!_id) {\n      return Promise.reject(new Error('Missing _id field in passed document'))\n    }\n\n    if (!isV2 && !_rev) {\n      return Promise.reject(new Error('Missing _rev field in passed document'))\n    }\n\n    if (isV2) {\n      changes = Object.assign({ _id }, changes)\n    } else {\n      changes = Object.assign({ _id, _rev }, changes)\n    }\n\n    const path = createPath(cozy, isV2, doctype, _id)\n    return cozyFetchJSON(cozy, 'PUT', path, changes).then((resp) => {\n      if (isV2) {\n        return find(cozy, doctype, _id)\n      } else {\n        return resp.data\n      }\n    })\n  })\n}\n\nexport function updateAttributes (cozy, doctype, _id, changes, tries = 3) {\n  return cozy.isV2().then((isV2) => {\n    doctype = normalizeDoctype(cozy, isV2, doctype)\n    return find(cozy, doctype, _id)\n      .then((doc) => {\n        return update(cozy, doctype, doc, Object.assign({ _id }, doc, changes))\n      })\n      .catch((err) => {\n        if (tries > 0) {\n          return updateAttributes(cozy, doctype, _id, changes, tries - 1)\n        } else {\n          throw err\n        }\n      })\n  })\n}\n\nexport function _delete (cozy, doctype, doc) {\n  return cozy.isV2().then((isV2) => {\n    doctype = normalizeDoctype(cozy, isV2, doctype)\n    const {_id, _rev} = doc\n\n    if (!_id) {\n      return Promise.reject(new Error('Missing _id field in passed document'))\n    }\n\n    if (!isV2 && !_rev) {\n      return Promise.reject(new Error('Missing _rev field in passed document'))\n    }\n\n    const query = isV2 ? null : { rev: _rev }\n    const path = createPath(cozy, isV2, doctype, _id, query)\n    return cozyFetchJSON(cozy, 'DELETE', path).then((resp) => {\n      if (isV2) {\n        return {id: _id, rev: NOREV}\n      } else {\n        return resp\n      }\n    })\n  })\n}\n\n\n\n// WEBPACK FOOTER //\n// ./src/data.js","/* global Blob, File */\nimport { cozyFetch, cozyFetchJSON } from './fetch'\nimport jsonapi from './jsonapi'\nimport { DOCTYPE_FILES } from './doctypes'\n\n// global variables\nexport const ROOT_DIR_ID = 'io.cozy.files.root-dir'\nexport const TRASH_DIR_ID = 'io.cozy.files.trash-dir'\n\nconst contentTypeOctetStream = 'application/octet-stream'\n\nfunction sanitizeFileName (name) {\n  return name && name.trim()\n}\n\nfunction getFileTypeFromName (name) {\n  if (/\\.heic$/i.test(name)) return 'image/heic'\n  else if (/\\.heif$/i.test(name)) return 'image/heif'\n  else return null\n}\n\nfunction doUpload (cozy, data, method, path, options) {\n  if (!data) {\n    throw new Error('missing data argument')\n  }\n\n  // transform any ArrayBufferView to ArrayBuffer\n  if (data.buffer && data.buffer instanceof ArrayBuffer) {\n    data = data.buffer\n  }\n\n  const isBuffer = (typeof ArrayBuffer !== 'undefined' && data instanceof ArrayBuffer)\n  const isFile = (typeof File !== 'undefined' && data instanceof File)\n  const isBlob = (typeof Blob !== 'undefined' && data instanceof Blob)\n  const isStream = (data.readable === true && typeof data.pipe === 'function')\n  const isString = (typeof data === 'string')\n\n  if (!isBuffer && !isFile && !isBlob && !isStream && !isString) {\n    throw new Error('invalid data type')\n  }\n\n  let {contentType, contentLength, checksum, lastModifiedDate, ifMatch} = options || {}\n  if (!contentType) {\n    if (isBuffer) {\n      contentType = contentTypeOctetStream\n    } else if (isFile) {\n      contentType = data.type || getFileTypeFromName(data.name.toLowerCase()) || contentTypeOctetStream\n      if (!lastModifiedDate) {\n        lastModifiedDate = data.lastModifiedDate\n      }\n    } else if (isBlob) {\n      contentType = data.type || contentTypeOctetStream\n    } else if (isStream) {\n      contentType = contentTypeOctetStream\n    } else if (typeof data === 'string') {\n      contentType = 'text/plain'\n    }\n  }\n\n  if (lastModifiedDate && typeof lastModifiedDate === 'string') {\n    lastModifiedDate = new Date(lastModifiedDate)\n  }\n\n  const headers = {\n    'Content-Type': contentType\n  }\n  if (contentLength) headers['Content-Length'] = String(contentLength)\n  if (checksum) headers['Content-MD5'] = checksum\n  if (lastModifiedDate) headers['Date'] = lastModifiedDate.toGMTString()\n  if (ifMatch) headers['If-Match'] = ifMatch\n\n  return cozyFetch(cozy, path, {\n    method: method,\n    headers: headers,\n    body: data\n  })\n    .then((res) => {\n      const json = res.json()\n      if (!res.ok) {\n        return json.then(err => { throw err })\n      } else {\n        return json.then(jsonapi)\n      }\n    })\n}\n\nexport function create (cozy, data, options) {\n  let {name, dirID, executable} = options || {}\n\n  // handle case where data is a file and contains the name\n  if (!name && typeof data.name === 'string') {\n    name = data.name\n  }\n\n  name = sanitizeFileName(name)\n\n  if (typeof name !== 'string' || name === '') {\n    throw new Error('missing name argument')\n  }\n\n  if (executable === undefined) {\n    executable = false\n  }\n\n  const path = `/files/${encodeURIComponent(dirID || '')}`\n  const query = `?Name=${encodeURIComponent(name)}&Type=file&Executable=${executable}`\n  return doUpload(cozy, data, 'POST', `${path}${query}`, options)\n}\n\nexport function createDirectory (cozy, options) {\n  let {name, dirID, lastModifiedDate} = options || {}\n\n  name = sanitizeFileName(name)\n\n  if (typeof name !== 'string' || name === '') {\n    throw new Error('missing name argument')\n  }\n\n  if (lastModifiedDate && typeof lastModifiedDate === 'string') {\n    lastModifiedDate = new Date(lastModifiedDate)\n  }\n\n  const path = `/files/${encodeURIComponent(dirID || '')}`\n  const query = `?Name=${encodeURIComponent(name)}&Type=directory`\n  return cozyFetchJSON(cozy, 'POST', `${path}${query}`, undefined, {\n    headers: {\n      'Date': lastModifiedDate ? lastModifiedDate.toGMTString() : ''\n    }\n  })\n}\n\nfunction getDirectoryOrCreate (cozy, name, parentDirectory) {\n  if (parentDirectory && !parentDirectory.attributes) throw new Error('Malformed parent directory')\n\n  name = sanitizeFileName(name)\n\n  const path = `${parentDirectory._id === ROOT_DIR_ID ? '' : parentDirectory.attributes.path}/${name}`\n\n  return cozy.files.statByPath(path || '/')\n    .catch(error => {\n      const parsedError = JSON.parse(error.message)\n      const errors = parsedError.errors\n      if (errors && errors.length && errors[0].status === '404') {\n        return cozy.files.createDirectory({\n          name: name,\n          dirID: parentDirectory && parentDirectory._id\n        })\n      }\n\n      throw errors\n    })\n}\n\nexport function createDirectoryByPath (cozy, path, offline) {\n  const parts = path.split('/').filter(part => part !== '')\n\n  const rootDirectoryPromise = cozy.files.statById(ROOT_DIR_ID, offline)\n\n  return parts.length\n    ? parts.reduce((parentDirectoryPromise, part) => {\n      return parentDirectoryPromise\n        .then(parentDirectory => getDirectoryOrCreate(cozy, part, parentDirectory))\n    }, rootDirectoryPromise)\n      : rootDirectoryPromise\n}\n\nexport function updateById (cozy, id, data, options) {\n  return doUpload(cozy, data, 'PUT', `/files/${encodeURIComponent(id)}`, options)\n}\n\nfunction doUpdateAttributes (cozy, attrs, path, options) {\n  if (!attrs || typeof attrs !== 'object') {\n    throw new Error('missing attrs argument')\n  }\n\n  const {ifMatch} = options || {}\n  const body = {\n    data: {\n      attributes: Object.assign(\n        {},\n        attrs,\n        { name: sanitizeFileName(attrs.name) }\n      )\n    }\n  }\n  return cozyFetchJSON(cozy, 'PATCH', path, body, {\n    headers: {\n      'If-Match': ifMatch || ''\n    }\n  })\n}\n\nexport function updateAttributesById (cozy, id, attrs, options) {\n  return doUpdateAttributes(cozy, attrs,\n    `/files/${encodeURIComponent(id)}`, options)\n}\n\nexport function updateAttributesByPath (cozy, path, attrs, options) {\n  return doUpdateAttributes(cozy, attrs,\n    `/files/metadata?Path=${encodeURIComponent(path)}`, options)\n}\n\nexport function trashById (cozy, id, options) {\n  if (typeof id !== 'string' || id === '') {\n    throw new Error('missing id argument')\n  }\n  const {ifMatch} = options || {}\n  return cozyFetchJSON(cozy, 'DELETE', `/files/${encodeURIComponent(id)}`, undefined, {\n    headers: {\n      'If-Match': ifMatch || ''\n    }\n  })\n}\n\nexport function statById (cozy, id, offline = true, options = {}) {\n  if (offline && cozy.offline.hasDatabase(DOCTYPE_FILES)) {\n    let db = cozy.offline.getDatabase(DOCTYPE_FILES)\n    return Promise.all([\n      db.get(id),\n      db.find(Object.assign({ selector: { 'dir_id': id } }, options))\n    ]).then(([doc, children]) => {\n      if (id === ROOT_DIR_ID) {\n        children.docs = children.docs.filter(doc => doc._id !== TRASH_DIR_ID)\n      }\n      children = sortFiles(children.docs.map(doc => addIsDir(toJsonApi(cozy, doc))))\n      return addIsDir(toJsonApi(cozy, doc, children))\n    })\n  }\n  const query = Object.keys(options).length === 0 ? '' : `?${encodePageOptions(options)}`\n  return cozyFetchJSON(cozy, 'GET', `/files/${encodeURIComponent(id)}${query}`)\n    .then(addIsDir)\n}\n\nexport function statByPath (cozy, path) {\n  return cozyFetchJSON(cozy, 'GET', `/files/metadata?Path=${encodeURIComponent(path)}`)\n    .then(addIsDir)\n}\n\nexport function downloadById (cozy, id) {\n  return cozyFetch(cozy, `/files/download/${encodeURIComponent(id)}`)\n}\n\nexport function downloadByPath (cozy, path) {\n  return cozyFetch(cozy, `/files/download?Path=${encodeURIComponent(path)}`)\n}\n\nfunction extractResponseLinkRelated (res) {\n  let href = res.links && res.links.related\n  if (!href) throw new Error('No related link in server response')\n  return href\n}\n\nexport function getDownloadLinkByPath (cozy, path) {\n  return cozyFetchJSON(cozy, 'POST', `/files/downloads?Path=${encodeURIComponent(path)}`)\n    .then(extractResponseLinkRelated)\n}\n\nexport function getDownloadLinkById (cozy, id) {\n  return cozyFetchJSON(cozy, 'POST', `/files/downloads?Id=${encodeURIComponent(id)}`)\n    .then(extractResponseLinkRelated)\n}\n\nexport function getFilePath (cozy, file = {}, folder) {\n  if (!folder || !folder.attributes) {\n    throw Error('Folder should be valid with an attributes.path property')\n  }\n\n  const folderPath = folder.attributes.path.endsWith('/')\n    ? folder.attributes.path\n      : `${folder.attributes.path}/`\n\n  return `${folderPath}${file.name}`\n}\n\nexport function getCollectionShareLink (cozy, id, collectionType) {\n  if (!id) {\n    return Promise.reject(Error('An id should be provided to create a share link'))\n  }\n  return cozyFetchJSON(cozy, 'POST', `/permissions?codes=email`, {\n    data: {\n      type: 'io.cozy.permissions',\n      attributes: {\n        permissions: {\n          files: {\n            type: 'io.cozy.files',\n            verbs: ['GET'],\n            values: [id],\n            selector: 'referenced_by'\n          },\n          collection: {\n            type: collectionType,\n            verbs: ['GET'],\n            values: [id]\n          }\n        }\n      }\n    }\n  }).then(data => ({sharecode: `sharecode=${data.attributes.codes.email}`, id: `id=${id}`}))\n}\n\nexport function getArchiveLinkByPaths (cozy, paths, name = 'files') {\n  const archive = {\n    type: 'io.cozy.archives',\n    attributes: {\n      name: name,\n      files: paths\n    }\n  }\n  return cozyFetchJSON(cozy, 'POST', `/files/archive`, {data: archive})\n  .then(extractResponseLinkRelated)\n}\n\nexport function getArchiveLinkByIds (cozy, ids, name = 'files') {\n  const archive = {\n    type: 'io.cozy.archives',\n    attributes: {\n      name: name,\n      ids: ids\n    }\n  }\n  return cozyFetchJSON(cozy, 'POST', `/files/archive`, {data: archive})\n  .then(extractResponseLinkRelated)\n}\n\nexport function listTrash (cozy) {\n  return cozyFetchJSON(cozy, 'GET', `/files/trash`)\n}\n\nexport function clearTrash (cozy) {\n  return cozyFetchJSON(cozy, 'DELETE', `/files/trash`)\n}\n\nexport function restoreById (cozy, id) {\n  return cozyFetchJSON(cozy, 'POST', `/files/trash/${encodeURIComponent(id)}`)\n}\n\nexport function destroyById (cozy, id, options) {\n  const {ifMatch} = options || {}\n  return cozyFetchJSON(cozy, 'DELETE', `/files/trash/${encodeURIComponent(id)}`, undefined, {\n    headers: {\n      'If-Match': ifMatch || ''\n    }\n  })\n}\n\nfunction addIsDir (obj) {\n  obj.isDir = obj.attributes.type === 'directory'\n  return obj\n}\n\nfunction encodePageOptions (options) {\n  let opts = []\n  for (const name in options) {\n    opts.push(`page[${encodeURIComponent(name)}]=${encodeURIComponent(options[name])}`)\n  }\n  return opts.join('&')\n}\n\nfunction toJsonApi (cozy, doc, contents = []) {\n  let clone = JSON.parse(JSON.stringify(doc))\n  delete clone._id\n  delete clone._rev\n  return {\n    _id: doc._id,\n    _rev: doc._rev,\n    _type: DOCTYPE_FILES,\n    attributes: clone,\n    relationships: {\n      contents: {\n        data: contents,\n        meta: {\n          count: contents.length\n        }\n      }\n    },\n    relations: (name) => {\n      if (name === 'contents') {\n        return contents\n      }\n    }\n  }\n}\n\nfunction sortFiles (allFiles) {\n  const folders = allFiles.filter(f => f.attributes.type === 'directory')\n  const files = allFiles.filter(f => f.attributes.type !== 'directory')\n  const sort = files => files.sort((a, b) => a.attributes.name.localeCompare(b.attributes.name))\n  return sort(folders).concat(sort(files))\n}\n\n\n\n// WEBPACK FOOTER //\n// ./src/files.js","/* global fetch URL */\nimport 'core-js/modules/es6.object.assign'\nimport {unpromiser, retry, warn} from './utils'\nimport {LocalStorage, MemoryStorage} from './auth_storage'\nimport {AppToken as AppTokenV2, getAppToken as getAppTokenV2} from './auth_v2'\nimport * as auth from './auth_v3'\nimport * as data from './data'\nimport * as cozyFetch from './fetch'\nimport * as mango from './mango'\nimport * as files from './files'\nimport * as intents from './intents'\nimport * as jobs from './jobs'\nimport * as offline from './offline'\nimport * as settings from './settings'\nimport * as relations from './relations'\n\nconst {\n  AppToken: AppTokenV3,\n  AccessToken: AccessTokenV3,\n  Client: ClientV3\n} = auth\n\nconst AuthNone = 0\nconst AuthRunning = 1\nconst AuthError = 2\nconst AuthOK = 3\n\nconst defaultClientParams = {\n  softwareID: 'github.com/cozy/cozy-client-js'\n}\n\nconst dataProto = {\n  create: data.create,\n  find: data.find,\n  findMany: data.findMany,\n  findAll: data.findAll,\n  update: data.update,\n  delete: data._delete,\n  updateAttributes: data.updateAttributes,\n  changesFeed: data.changesFeed,\n  defineIndex: mango.defineIndex,\n  query: mango.query,\n  addReferencedFiles: relations.addReferencedFiles,\n  removeReferencedFiles: relations.removeReferencedFiles,\n  listReferencedFiles: relations.listReferencedFiles,\n  fetchReferencedFiles: relations.fetchReferencedFiles,\n  destroy: function (...args) {\n    warn('destroy is deprecated, use cozy.data.delete instead.')\n    return data._delete(...args)\n  }\n}\n\nconst authProto = {\n  client: auth.client,\n  registerClient: auth.registerClient,\n  updateClient: auth.updateClient,\n  unregisterClient: auth.unregisterClient,\n  getClient: auth.getClient,\n  getAuthCodeURL: auth.getAuthCodeURL,\n  getAccessToken: auth.getAccessToken,\n  refreshToken: auth.refreshToken\n}\n\nconst filesProto = {\n  create: files.create,\n  createDirectory: files.createDirectory,\n  createDirectoryByPath: files.createDirectoryByPath,\n  updateById: files.updateById,\n  updateAttributesById: files.updateAttributesById,\n  updateAttributesByPath: files.updateAttributesByPath,\n  trashById: files.trashById,\n  statById: files.statById,\n  statByPath: files.statByPath,\n  downloadById: files.downloadById,\n  downloadByPath: files.downloadByPath,\n  getDownloadLinkById: files.getDownloadLinkById,\n  getDownloadLink: files.getDownloadLinkByPath, // DEPRECATED, should be removed very soon\n  getDownloadLinkByPath: files.getDownloadLinkByPath,\n  getArchiveLink: function (...args) {\n    warn('getArchiveLink is deprecated, use cozy.files.getArchiveLinkByPaths instead.')\n    return files.getArchiveLinkByPaths(...args)\n  },\n  getArchiveLinkByPaths: files.getArchiveLinkByPaths,\n  getArchiveLinkByIds: files.getArchiveLinkByIds,\n  getFilePath: files.getFilePath,\n  getCollectionShareLink: files.getCollectionShareLink,\n  query: mango.queryFiles,\n  listTrash: files.listTrash,\n  clearTrash: files.clearTrash,\n  restoreById: files.restoreById,\n  destroyById: files.destroyById\n}\n\nconst intentsProto = {\n  create: intents.create,\n  createService: intents.createService,\n  getRedirectionURL: intents.getRedirectionURL,\n  redirect: intents.redirect\n}\n\nconst jobsProto = {\n  create: jobs.create,\n  count: jobs.count,\n  queued: jobs.queued\n}\n\nconst offlineProto = {\n  init: offline.init,\n  getDoctypes: offline.getDoctypes,\n  // database\n  hasDatabase: offline.hasDatabase,\n  getDatabase: offline.getDatabase,\n  createDatabase: offline.createDatabase,\n  destroyDatabase: offline.destroyDatabase,\n  destroyAllDatabase: offline.destroyAllDatabase,\n  // replication\n  hasReplication: offline.hasReplication,\n  replicateFromCozy: offline.replicateFromCozy,\n  stopReplication: offline.stopReplication,\n  stopAllReplication: offline.stopAllReplication,\n  // repeated replication\n  hasRepeatedReplication: offline.hasRepeatedReplication,\n  startRepeatedReplication: offline.startRepeatedReplication,\n  stopRepeatedReplication: offline.stopRepeatedReplication,\n  stopAllRepeatedReplication: offline.stopAllRepeatedReplication\n}\n\nconst settingsProto = {\n  diskUsage: settings.diskUsage,\n  changePassphrase: settings.changePassphrase,\n  getInstance: settings.getInstance,\n  updateInstance: settings.updateInstance,\n  getClients: settings.getClients,\n  deleteClientById: settings.deleteClientById,\n  updateLastSync: settings.updateLastSync\n}\n\nconst ensureHasReconnectParam = _url => {\n  const url = new URL(_url)\n  if (url.searchParams && !url.searchParams.has('reconnect')) {\n    url.searchParams.append('reconnect', 1)\n  } else if (!url.search || url.search.indexOf('reconnect') === -1) {\n    // Some old navigators do not have the searchParams API\n    // and it is not polyfilled by babel-polyfill\n    url.search = url.search + '&reconnect=1'\n  }\n  return url.toString()\n}\n\nclass Client {\n  constructor (options) {\n    this.data = {}\n    this.files = {}\n    this.intents = {}\n    this.jobs = {}\n    this.offline = {}\n    this.settings = {}\n    this.auth = {\n      Client: ClientV3,\n      AccessToken: AccessTokenV3,\n      AppToken: AppTokenV3,\n      AppTokenV2: AppTokenV2,\n      LocalStorage: LocalStorage,\n      MemoryStorage: MemoryStorage\n    }\n    this._inited = false\n    if (options) {\n      this.init(options)\n    }\n  }\n\n  init (options = {}) {\n    this._inited = true\n    this._oauth = false // is oauth activated or not\n    this._token = null  // application token\n    this._authstate = AuthNone\n    this._authcreds = null\n    this._storage = null\n    this._version = options.version || null\n    this._offline = null\n\n    const token = options.token\n    const oauth = options.oauth\n    if (token && oauth) {\n      throw new Error('Cannot specify an application token with a oauth activated')\n    }\n\n    if (token) {\n      this._token = new AppTokenV3({ token })\n    } else if (oauth) {\n      this._oauth = true\n      this._storage = oauth.storage\n      this._clientParams = Object.assign({}, defaultClientParams, oauth.clientParams)\n      this._onRegistered = oauth.onRegistered || nopOnRegistered\n    }\n\n    let url = options.cozyURL || ''\n    while (url[url.length - 1] === '/') {\n      url = url.slice(0, -1)\n    }\n\n    this._url = url\n\n    this._invalidTokenErrorHandler = options.onInvalidTokenError !== undefined ? options.onInvalidTokenError : cozyFetch.handleInvalidTokenError\n\n    const disablePromises = !!options.disablePromises\n    addToProto(this, this.data, dataProto, disablePromises)\n    addToProto(this, this.auth, authProto, disablePromises)\n    addToProto(this, this.files, filesProto, disablePromises)\n    addToProto(this, this.intents, intentsProto, disablePromises)\n    addToProto(this, this.jobs, jobsProto, disablePromises)\n    addToProto(this, this.offline, offlineProto, disablePromises)\n    addToProto(this, this.settings, settingsProto, disablePromises)\n\n    if (options.offline) {\n      this.offline.init(options.offline)\n    }\n\n    // Exposing cozyFetchJSON to make some development easier. Should be temporary.\n    this.fetchJSON = function _fetchJSON () {\n      const args = [this].concat(Array.prototype.slice.call(arguments))\n      return cozyFetch.cozyFetchJSON.apply(this, args)\n    }\n  }\n\n  authorize (forceTokenRefresh = false) {\n    const state = this._authstate\n    if (state === AuthOK || state === AuthRunning) {\n      return this._authcreds\n    }\n\n    this._authstate = AuthRunning\n    this._authcreds = this.isV2().then((isV2) => {\n      if (isV2 && this._oauth) {\n        throw new Error('OAuth is not supported on the V2 stack')\n      }\n      if (this._oauth) {\n        if (forceTokenRefresh && this._clientParams.redirectURI) {\n          this._clientParams.redirectURI = ensureHasReconnectParam(this._clientParams.redirectURI)\n        }\n        return auth.oauthFlow(\n          this,\n          this._storage,\n          this._clientParams,\n          this._onRegistered,\n          forceTokenRefresh\n        )\n      }\n      // we expect to be on a client side application running in a browser\n      // with cookie-based authentication.\n      if (isV2) {\n        return getAppTokenV2()\n      } else if (this._token) {\n        return Promise.resolve({client: null, token: this._token})\n      } else {\n        throw new Error('Missing application token')\n      }\n    })\n\n    this._authcreds.then(\n      () => { this._authstate = AuthOK },\n      () => { this._authstate = AuthError })\n\n    return this._authcreds\n  }\n\n  saveCredentials (client, token) {\n    const creds = {client, token}\n    if (!this._storage || this._authstate === AuthRunning) {\n      return Promise.resolve(creds)\n    }\n    this._storage.save(auth.CredsKey, creds)\n    this._authcreds = Promise.resolve(creds)\n    return this._authcreds\n  }\n\n  fullpath (path) {\n    return this.isV2().then((isV2) => {\n      const pathprefix = isV2 ? '/ds-api' : ''\n      return this._url + pathprefix + path\n    })\n  }\n\n  isV2 () {\n    if (!this._version) {\n      return retry(() => fetch(`${this._url}/status/`), 3)()\n        .then((res) => {\n          if (!res.ok) {\n            throw new Error('Could not fetch cozy status')\n          } else {\n            return res.json()\n          }\n        })\n        .then((status) => {\n          this._version = status.datasystem !== undefined ? 2 : 3\n          return this.isV2()\n        })\n    }\n    return Promise.resolve(this._version === 2)\n  }\n}\n\nfunction nopOnRegistered () {\n  throw new Error('Missing onRegistered callback')\n}\n\nfunction protoify (context, fn) {\n  return function prototyped (...args) {\n    return fn(context, ...args)\n  }\n}\n\nfunction addToProto (ctx, obj, proto, disablePromises) {\n  for (const attr in proto) {\n    let fn = protoify(ctx, proto[attr])\n    if (disablePromises) {\n      fn = unpromiser(fn)\n    }\n    obj[attr] = fn\n  }\n}\n\nmodule.exports = new Client()\nObject.assign(module.exports, {Client, LocalStorage, MemoryStorage})\n\n\n\n// WEBPACK FOOTER //\n// ./src/index.js","import {cozyFetchJSON} from './fetch'\n\nconst intentClass = 'coz-intent'\n\n// helper to serialize/deserialize an error for/from postMessage\nconst errorSerializer = (() => {\n  function mapErrorProperties (from, to) {\n    const result = Object.assign(to, from)\n    const nativeProperties = ['name', 'message']\n    return nativeProperties.reduce((result, property) => {\n      if (from[property]) {\n        to[property] = from[property]\n      }\n      return result\n    }, result)\n  }\n  return {\n    serialize: (error) => mapErrorProperties(error, {}),\n    deserialize: (data) => mapErrorProperties(data, new Error(data.message))\n  }\n})()\n\n// inject iframe for service in given element\nfunction injectService (url, element, intent, data, onReadyCallback) {\n  const document = element.ownerDocument\n  if (!document) throw new Error('Cannot retrieve document object from given element')\n\n  const window = document.defaultView\n  if (!window) throw new Error('Cannot retrieve window object from document')\n\n  const iframe = document.createElement('iframe')\n  // if callback provided for when iframe is loaded\n  if (typeof onReadyCallback === 'function') iframe.onload = onReadyCallback\n  // TODO: implement 'title' attribute\n  iframe.setAttribute('src', url)\n  iframe.classList.add(intentClass)\n  element.appendChild(iframe)\n  iframe.focus()\n\n  // Keeps only http://domain:port/\n  const serviceOrigin = url.split('/', 3).join('/')\n\n  return new Promise((resolve, reject) => {\n    let handshaken = false\n    const messageHandler = (event) => {\n      if (event.origin !== serviceOrigin) return\n\n      const eventType = event.data.type\n      if (eventType === 'load') {\n        // Safari 9.1 (At least) send a MessageEvent when the iframe loads,\n        // making the handshake fails.\n        console.warn && console.warn('Cozy Client ignored MessageEvent having data.type `load`.')\n        return\n      }\n\n      if (eventType === `intent-${intent._id}:ready`) {\n        handshaken = true\n        return event.source.postMessage(data, event.origin)\n      }\n\n      if (handshaken && eventType === `intent-${intent._id}:resize`) {\n        ['width', 'height', 'maxWidth', 'maxHeight'].forEach(prop => {\n          if (event.data.transition) element.style.transition = event.data.transition\n          if (event.data.dimensions[prop]) element.style[prop] = `${event.data.dimensions[prop]}px`\n        })\n\n        return true\n      }\n\n      window.removeEventListener('message', messageHandler)\n      const removeIntentFrame = () => {\n        // check if the parent node has not been already removed from the DOM\n        iframe.parentNode && iframe.parentNode.removeChild(iframe)\n      }\n\n      if (handshaken && eventType === `intent-${intent._id}:exposeFrameRemoval`) {\n        return resolve({removeIntentFrame, doc: event.data.document})\n      }\n\n      removeIntentFrame()\n\n      if (eventType === `intent-${intent._id}:error`) {\n        return reject(errorSerializer.deserialize(event.data.error))\n      }\n\n      if (handshaken && eventType === `intent-${intent._id}:cancel`) {\n        return resolve(null)\n      }\n\n      if (handshaken && eventType === `intent-${intent._id}:done`) {\n        return resolve(event.data.document)\n      }\n\n      if (!handshaken) {\n        return reject(new Error('Unexpected handshake message from intent service'))\n      }\n\n      // We may be in a state where the messageHandler is still attached to then\n      // window, but will not be needed anymore. For example, the service failed\n      // before adding the `unload` listener, so no `intent:cancel` message has\n      // never been sent.\n      // So we simply ignore other messages, and this listener will stay here,\n      // waiting for a message which will never come, forever (almost).\n    }\n\n    window.addEventListener('message', messageHandler)\n  })\n}\n\nconst first = arr => arr && arr[0]\n// In a far future, the user will have to pick the desired service from a list.\n// For now it's our job, an easy job as we arbitrary pick the first service of\n// the list.\nfunction pickService (intent, filterServices) {\n  const services = intent.attributes.services\n  const filteredServices = filterServices\n    ? (services || []).filter(filterServices)\n    : services\n  return first(filteredServices)\n}\n\nexport function create (cozy, action, type, data = {}, permissions = []) {\n  if (!action) throw new Error(`Misformed intent, \"action\" property must be provided`)\n  if (!type) throw new Error(`Misformed intent, \"type\" property must be provided`)\n\n  const createPromise = cozyFetchJSON(cozy, 'POST', '/intents', {\n    data: {\n      type: 'io.cozy.intents',\n      attributes: {\n        action: action,\n        type: type,\n        data: data,\n        permissions: permissions\n      }\n    }\n  })\n\n  createPromise.start = (element, onReadyCallback) => {\n    return createPromise.then(intent => {\n      const service = pickService(intent, data.filterServices)\n      const restData = Object.assign({}, data)\n      delete restData.filterServices\n\n      if (!service) {\n        return Promise.reject(new Error('Unable to find a service'))\n      }\n\n      return injectService(service.href, element, intent, restData, onReadyCallback)\n    })\n  }\n\n  return createPromise\n}\n\nfunction listenClientData (intent, window) {\n  return new Promise((resolve, reject) => {\n    const messageEventListener = (event) => {\n      if (event.origin !== intent.attributes.client) return\n\n      window.removeEventListener('message', messageEventListener)\n      resolve(event.data)\n    }\n\n    window.addEventListener('message', messageEventListener)\n    window.parent.postMessage({\n      type: `intent-${intent._id}:ready`\n    }, intent.attributes.client)\n  })\n}\n\n// returns a service to communicate with intent client\nexport function createService (cozy, intentId, serviceWindow) {\n  serviceWindow = serviceWindow || typeof window !== 'undefined' && window\n  if (!serviceWindow) throw new Error('Intent service should be used in browser')\n\n  intentId = intentId || serviceWindow.location.search.split('=')[1]\n  if (!intentId) throw new Error('Cannot retrieve intent from URL')\n\n  return cozyFetchJSON(cozy, 'GET', `/intents/${intentId}`)\n    .then(intent => {\n      let terminated = false\n\n      const terminate = (message) => {\n        if (terminated) throw new Error('Intent service has already been terminated')\n        terminated = true\n        serviceWindow.parent.postMessage(message, intent.attributes.client)\n      }\n\n      const resizeClient = (dimensions, transitionProperty) => {\n        if (terminated) throw new Error('Intent service has been terminated')\n\n        const message = {\n          type: `intent-${intent._id}:resize`,\n          // if a dom element is passed, calculate its size\n          dimensions: dimensions.element\n            ? Object.assign({}, dimensions, {\n              maxHeight: dimensions.element.clientHeight,\n              maxWidth: dimensions.element.clientWidth\n            })\n              : dimensions,\n          transition: transitionProperty\n        }\n\n        serviceWindow.parent.postMessage(message, intent.attributes.client)\n      }\n\n      const cancel = () => {\n        terminate({type: `intent-${intent._id}:cancel`})\n      }\n\n      // Prevent unfulfilled client promises when this window unloads for a\n      // reason or another.\n      serviceWindow.addEventListener('unload', () => {\n        if (!terminated) cancel()\n      })\n\n      return listenClientData(intent, serviceWindow)\n        .then(data => {\n          return {\n            getData: () => data,\n            getIntent: () => intent,\n            terminate: (doc) => {\n              const eventName = (data && data.exposeIntentFrameRemoval\n                ? 'exposeFrameRemoval' : 'done'\n              )\n              return terminate({\n                type: `intent-${intent._id}:${eventName}`,\n                document: doc\n              })\n            },\n            throw: error => terminate({\n              type: `intent-${intent._id}:error`,\n              error: errorSerializer.serialize(error)\n            }),\n            resizeClient: resizeClient,\n            cancel: cancel\n          }\n        })\n    })\n}\n\n// Redirect to an app able to handle the doctype\n// Redirections are more or less a hack of the intent API to retrieve an URL for\n// accessing a given doctype or a given document.\n// It needs to use a special action `REDIRECT`\nexport async function getRedirectionURL (cozy, type, data) {\n  if (!type && !data) throw new Error(`Cannot retrieve redirection, at least type or doc must be provided`)\n\n  const intent = await create(cozy, 'REDIRECT', type, data)\n\n  const service = pickService(intent)\n  if (!service) throw new Error('Unable to find a service')\n\n  // Intents cannot be deleted now\n  // await deleteIntent(cozy, intent)\n\n  // ignore query string and intent id\n  const baseURL = service.href.split('?')[0]\n  // FIXME: Handle the fact that the stack encode the '#' character in the URL\n  const sanitizedURL = baseURL.replace('%23', '#')\n  return data ? buildRedirectionURL(sanitizedURL, data) : sanitizedURL\n}\n\nfunction isSerializable (value) {\n  return !['object', 'function'].includes(typeof value)\n}\n\nfunction buildRedirectionURL (url, data) {\n  const parameterStrings = Object.keys(data)\n    .filter(key => isSerializable(data[key]))\n    .map(key => `${key}=${data[key]}`)\n\n  return parameterStrings.length ? `${url}?${parameterStrings.join('&')}` : url\n}\n\nexport async function redirect (cozy, type, doc) {\n  if (!window) throw new Error('redirect() method can only be called in a browser')\n  const redirectionURL = await getRedirectionURL(cozy, type, doc)\n  window.location.href = redirectionURL\n}\n\n\n\n// WEBPACK FOOTER //\n// ./src/intents.js","import {cozyFetchJSON} from './fetch'\n\nexport function count (cozy, workerType) {\n  return cozyFetchJSON(cozy, 'GET', `/jobs/queue/${workerType}`)\n    .then(data => data.length)\n}\n\nexport function queued (cozy, workerType) {\n  return cozyFetchJSON(cozy, 'GET', `/jobs/queue/${workerType}`)\n}\n\nexport function create (cozy, workerType, args, options) {\n  return cozyFetchJSON(cozy, 'POST', `/jobs/queue/${workerType}`, {\n    data: {\n      type: 'io.cozy.jobs',\n      attributes: {\n        arguments: args || {},\n        options: options || {}\n      }\n    }\n  })\n}\n\n\n\n// WEBPACK FOOTER //\n// ./src/jobs.js","import {warn, createPath, sleep} from './utils'\nimport {normalizeDoctype} from './doctypes'\nimport {cozyFetchJSON, cozyFetchRawJSON} from './fetch'\n\nexport function defineIndex (cozy, doctype, fields) {\n  return cozy.isV2().then((isV2) => {\n    doctype = normalizeDoctype(cozy, isV2, doctype)\n    if (!Array.isArray(fields) || fields.length === 0) {\n      throw new Error('defineIndex fields should be a non-empty array')\n    }\n    if (isV2) {\n      return defineIndexV2(cozy, doctype, fields)\n    } else {\n      return defineIndexV3(cozy, doctype, fields)\n    }\n  })\n}\n\nexport function query (cozy, indexRef, options) {\n  return cozy.isV2().then((isV2) => {\n    if (!indexRef) {\n      throw new Error('query should be passed the indexRef')\n    }\n    if (isV2) {\n      return queryV2(cozy, indexRef, options)\n    } else {\n      return queryV3(cozy, indexRef, options)\n    }\n  })\n}\n\nexport function queryFiles (cozy, indexRef, options) {\n  const opts = getV3Options(indexRef, options)\n  return cozyFetchRawJSON(cozy, 'POST', '/files/_find', opts)\n    .then((response) => options.wholeResponse ? response : response.docs)\n}\n\n// Internals\n\nconst VALUEOPERATORS = ['$eq', '$gt', '$gte', '$lt', '$lte']\nconst LOGICOPERATORS = ['$or', '$and', '$not']\n\n/* eslint-disable */\nconst MAP_TEMPLATE = (function (doc) {\n  if (doc.docType.toLowerCase() === 'DOCTYPEPLACEHOLDER'){\n    emit(FIELDSPLACEHOLDER, doc)\n  }\n}).toString().replace(/ /g, '').replace(/\\n/g, '')\nconst COUCHDB_INFINITY = {\"\\uFFFF\": \"\\uFFFF\"}\nconst COUCHDB_LOWEST = null\n/* eslint-enable */\n\n// defineIndexV2 is equivalent to defineIndex but only works for V2.\n// It transforms the index fields into a map reduce view.\nfunction defineIndexV2 (cozy, doctype, fields) {\n  let indexName = 'by' + fields.map(capitalize).join('')\n  let indexDefinition = { map: makeMapFunction(doctype, fields), reduce: '_count' }\n  let path = `/request/${doctype}/${indexName}/`\n  return cozyFetchJSON(cozy, 'PUT', path, indexDefinition)\n    .then(() => ({ doctype: doctype, type: 'mapreduce', name: indexName, fields: fields }))\n}\n\nfunction defineIndexV3 (cozy, doctype, fields) {\n  let path = createPath(cozy, false, doctype, '_index')\n  let indexDefinition = {'index': {fields}}\n  return cozyFetchJSON(cozy, 'POST', path, indexDefinition)\n    .then((response) => {\n      const indexResult = { doctype: doctype, type: 'mango', name: response.id, fields }\n\n      if (response.result === 'exists') return indexResult\n\n      // indexes might not be usable right after being created; so we delay the resolving until they are\n      const selector = {}\n      selector[fields[0]] = {'$gt': null}\n\n      const opts = getV3Options(indexResult, {'selector': selector})\n      let path = createPath(cozy, false, indexResult.doctype, '_find')\n      return cozyFetchJSON(cozy, 'POST', path, opts)\n      .then(() => indexResult)\n      .catch(() => { // one retry\n        return sleep(1000)\n        .then(() => cozyFetchJSON(cozy, 'POST', path, opts))\n        .then(() => indexResult)\n        .catch(() => {\n          return sleep(500).then(() => indexResult)\n        })\n      })\n    })\n}\n\n// queryV2 is equivalent to query but only works for V2.\n// It transforms the query into a _views call using makeMapReduceQuery\nfunction queryV2 (cozy, indexRef, options) {\n  if (indexRef.type !== 'mapreduce') {\n    throw new Error('query indexRef should be the return value of defineIndexV2')\n  }\n  if (options.fields) {\n    warn('query fields will be ignored on v2')\n  }\n\n  let path = `/request/${indexRef.doctype}/${indexRef.name}/`\n  let opts = makeMapReduceQuery(indexRef, options)\n  return cozyFetchJSON(cozy, 'POST', path, opts)\n    .then((response) => response.map(r => r.value))\n}\n\n// queryV3 is equivalent to query but only works for V3\nfunction queryV3 (cozy, indexRef, options) {\n  const opts = getV3Options(indexRef, options)\n\n  let path = createPath(cozy, false, indexRef.doctype, '_find')\n  return cozyFetchJSON(cozy, 'POST', path, opts)\n    .then((response) => options.wholeResponse ? response : response.docs)\n}\n\nfunction getV3Options (indexRef, options) {\n  if (indexRef.type !== 'mango') {\n    throw new Error('indexRef should be the return value of defineIndexV3')\n  }\n\n  let opts = {\n    use_index: indexRef.name,\n    fields: options.fields,\n    selector: options.selector,\n    limit: options.limit,\n    skip: options.skip,\n    since: options.since,\n    sort: options.sort\n  }\n\n  if (options.descending) {\n    opts.sort = indexRef.fields.map(f => ({ [f]: 'desc' }))\n  }\n\n  return opts\n}\n\n// misc\nfunction capitalize (name) {\n  return name.charAt(0).toUpperCase() + name.slice(1)\n}\n\nfunction makeMapFunction (doctype, fields) {\n  fields = '[' + fields.map(name => 'doc.' + name).join(',') + ']'\n\n  return MAP_TEMPLATE.replace('DOCTYPEPLACEHOLDER', doctype.toLowerCase())\n                     .replace('FIELDSPLACEHOLDER', fields)\n}\n\n// parseSelector takes a mango selector and returns it as an array of filter\n// a filter is [path, operator, value] array\n// a path is an array of field names\n// This function is only exported so it can be unit tested.\n// Example :\n// parseSelector({\"test\":{\"deep\": {\"$gt\": 3}}})\n// [[['test', 'deep'], '$gt', 3 ]]\nexport function parseSelector (selector, path = [], operator = '$eq') {\n  if ((typeof selector) !== 'object') {\n    return [[path, operator, selector]]\n  }\n\n  let keys = Object.keys(selector)\n  if (keys.length === 0) {\n    throw new Error('empty selector')\n  } else {\n    return keys.reduce(function (acc, k) {\n      if (LOGICOPERATORS.indexOf(k) !== -1) {\n        throw new Error('cozy-client-js does not support mango logic ops')\n      } else if (VALUEOPERATORS.indexOf(k) !== -1) {\n        return acc.concat(parseSelector(selector[k], path, k))\n      } else {\n        return acc.concat(parseSelector(selector[k], path.concat(k), '$eq'))\n      }\n    }, [])\n  }\n}\n\n// normalizeSelector takes a mango selector and returns it as an object\n// normalized.\n// This function is only exported so it can be unit tested.\n// Example :\n// parseSelector({\"test\":{\"deep\": {\"$gt\": 3}}})\n// {\"test.deep\": {\"$gt\": 3}}\nexport function normalizeSelector (selector) {\n  var filters = parseSelector(selector)\n  return filters.reduce(function (acc, filter) {\n    let [path, op, value] = filter\n    let field = path.join('.')\n    acc[field] = acc[field] || {}\n    acc[field][op] = value\n    return acc\n  }, {})\n}\n\n// applySelector takes the normalized selector for the current field\n// and append the proper values to opts.startkey, opts.endkey\nfunction applySelector (selector, opts) {\n  let value = selector['$eq']\n  let lower = COUCHDB_LOWEST\n  let upper = COUCHDB_INFINITY\n  let inclusiveEnd\n\n  if (value) {\n    opts.startkey.push(value)\n    opts.endkey.push(value)\n    return false\n  }\n\n  value = selector['$gt']\n  if (value) {\n    throw new Error('operator $gt (strict greater than) not supported')\n  }\n\n  value = selector['$gte']\n  if (value) {\n    lower = value\n  }\n\n  value = selector['$lte']\n  if (value) {\n    upper = value\n    inclusiveEnd = true\n  }\n\n  value = selector['$lt']\n  if (value) {\n    upper = value\n    inclusiveEnd = false\n  }\n\n  opts.startkey.push(lower)\n  opts.endkey.push(upper)\n  if (inclusiveEnd !== undefined) opts.inclusive_end = inclusiveEnd\n  return true\n}\n\n// makeMapReduceQuery takes a mango query and generate _views call parameters\n// to obtain same results depending on fields in the passed indexRef.\nexport function makeMapReduceQuery (indexRef, query) {\n  let mrquery = {\n    startkey: [],\n    endkey: [],\n    reduce: false\n  }\n  let firstFreeValueField = null\n  let normalizedSelector = normalizeSelector(query.selector)\n\n  indexRef.fields.forEach(function (field) {\n    let selector = normalizedSelector[field]\n\n    if (selector && firstFreeValueField != null) {\n      throw new Error('Selector on field ' + field + ', but not on ' + firstFreeValueField + ' which is higher in index fields.')\n    } else if (selector) {\n      selector.used = true\n      let isFreeValue = applySelector(selector, mrquery)\n      if (isFreeValue) firstFreeValueField = field\n    } else if (firstFreeValueField == null) {\n      firstFreeValueField = field\n      mrquery.endkey.push(COUCHDB_INFINITY)\n    }\n  })\n\n  Object.keys(normalizedSelector).forEach(function (field) {\n    if (!normalizedSelector[field].used) {\n      throw new Error('Cant apply selector on ' + field + ', it is not in index')\n    }\n  })\n\n  if (query.descending) {\n    mrquery = {\n      descending: true,\n      reduce: false,\n      startkey: mrquery.endkey,\n      endkey: mrquery.startkey,\n      inclusive_end: mrquery.inclusive_end\n    }\n  }\n\n  return mrquery\n}\n\n\n\n// WEBPACK FOOTER //\n// ./src/mango.js","/* global pouchdbAdapterCordovaSqlite */\nimport {DOCTYPE_FILES} from './doctypes'\nimport {refreshToken} from './auth_v3'\nimport {isOffline} from './utils'\nimport PouchDB from 'pouchdb'\nimport pouchdbFind from 'pouchdb-find'\n\nexport const replicationOfflineError = 'Replication abort, your device is actually offline.'\n\nlet pluginLoaded = false\n\n/*\n  For each doctype we have some parameters:\n  cozy._offline[doctype] = {\n    database: pouchdb database\n    replication: the pouchdb replication\n    replicationPromise: promise of replication\n    interval: repeated replication interval\n  }\n*/\n\nexport function init (cozy, { options = {}, doctypes = [] }) {\n  for (let doctype of doctypes) {\n    createDatabase(cozy, doctype, options)\n  }\n}\n\n// helper\n\nfunction getInfo (cozy, doctype) {\n  cozy._offline = cozy._offline || []\n  cozy._offline[doctype] = cozy._offline[doctype] || {}\n  return cozy._offline[doctype]\n}\n\nexport function getDoctypes (cozy) {\n  cozy._offline = cozy._offline || []\n  return Object.keys(cozy._offline)\n}\n\n//\n// DATABASE\n//\n\nexport function hasDatabase (cozy, doctype) {\n  return getDatabase(cozy, doctype) !== undefined\n}\n\nexport function getDatabase (cozy, doctype) {\n  return getInfo(cozy, doctype).database\n}\n\nexport function setDatabase (cozy, doctype, database) {\n  cozy._offline[doctype].database = database\n  return getDatabase(cozy, doctype)\n}\n\nexport function createDatabase (cozy, doctype, options = {}) {\n  if (!pluginLoaded) {\n    PouchDB.plugin(pouchdbFind)\n    if (typeof pouchdbAdapterCordovaSqlite !== 'undefined') PouchDB.plugin(pouchdbAdapterCordovaSqlite)\n    pluginLoaded = true\n  }\n\n  if (hasDatabase(cozy, doctype)) {\n    return Promise.resolve(getDatabase(cozy, doctype))\n  }\n\n  setDatabase(cozy, doctype, new PouchDB(doctype, options))\n  return createIndexes(cozy, doctype).then(() => getDatabase(cozy, doctype))\n}\n\nexport function destroyDatabase (cozy, doctype) {\n  if (!hasDatabase(cozy, doctype)) {\n    return Promise.resolve(false)\n  }\n\n  return stopRepeatedReplication(cozy, doctype)\n    .then(() => stopReplication(cozy, doctype))\n    .then(() => getDatabase(cozy, doctype).destroy())\n    .then(response => {\n      setDatabase(cozy, doctype, undefined)\n      return response\n    })\n}\n\nexport function destroyAllDatabase (cozy) {\n  const doctypes = getDoctypes(cozy)\n  const destroy = (doctype) => destroyDatabase(cozy, doctype)\n  return Promise.all(doctypes.map(destroy))\n}\n\nfunction createIndexes (cozy, doctype) {\n  if (doctype === DOCTYPE_FILES) {\n    return getDatabase(cozy, doctype).createIndex({index: {fields: ['dir_id']}})\n  }\n  return Promise.resolve()\n}\n\n//\n// REPLICATION\n//\n\nexport function hasReplication (cozy, doctype) {\n  return getReplication(cozy, doctype) !== undefined\n}\n\nfunction getReplication (cozy, doctype) {\n  return getInfo(cozy, doctype).replication\n}\n\nfunction setReplication (cozy, doctype, replication) {\n  cozy._offline[doctype].replication = replication\n  return getReplication(cozy, doctype)\n}\n\nfunction getReplicationUrl (cozy, doctype) {\n  return cozy.authorize()\n    .then(credentials => {\n      const basic = credentials.token.toBasicAuth()\n      return (cozy._url + '/data/' + doctype).replace('//', `//${basic}`)\n    })\n}\n\nfunction getReplicationPromise (cozy, doctype) {\n  return getInfo(cozy, doctype).replicationPromise\n}\n\nfunction setReplicationPromise (cozy, doctype, promise) {\n  cozy._offline[doctype].replicationPromise = promise\n  return getReplicationPromise(cozy, doctype)\n}\n\nexport function replicateFromCozy (cozy, doctype, options = {}) {\n  return setReplicationPromise(cozy, doctype, new Promise((resolve, reject) => {\n    if (!hasDatabase(cozy, doctype)) {\n      createDatabase(cozy, doctype)\n    }\n    if (options.live === true) {\n      return reject(new Error('You can\\'t use `live` option with Cozy couchdb.'))\n    }\n\n    if (isOffline()) {\n      reject(replicationOfflineError)\n      options.onError && options.onError(replicationOfflineError)\n      return\n    }\n\n    getReplicationUrl(cozy, doctype)\n      .then(url => setReplication(cozy, doctype,\n        getDatabase(cozy, doctype).replicate.from(url, options).on('complete', (info) => {\n          setReplication(cozy, doctype, undefined)\n          resolve(info)\n          options.onComplete && options.onComplete(info)\n        }).on('error', (err) => {\n          if (err.error === 'code=400, message=Expired token') {\n            cozy.authorize().then(({client, token}) => {\n              refreshToken(cozy, client, token)\n                .then((newToken) => cozy.saveCredentials(client, newToken))\n                .then((credentials) => replicateFromCozy(cozy, doctype, options))\n            })\n          } else {\n            console.warn(`ReplicateFromCozy '${doctype}' Error:`)\n            console.warn(err)\n            setReplication(cozy, doctype, undefined)\n            reject(err)\n            options.onError && options.onError(err)\n          }\n        })\n      ))\n  }))\n}\n\nexport function stopReplication (cozy, doctype) {\n  if (!getDatabase(cozy, doctype) || !hasReplication(cozy, doctype)) {\n    return Promise.resolve()\n  }\n\n  return new Promise(resolve => {\n    try {\n      getReplicationPromise(cozy, doctype).then(() => {\n        resolve()\n      })\n      getReplication(cozy, doctype).cancel()\n      // replication is set to undefined by complete replication\n    } catch (e) {\n      resolve()\n    }\n  })\n}\n\nexport function stopAllReplication (cozy) {\n  const doctypes = getDoctypes(cozy)\n  const stop = (doctype) => stopReplication(cozy, doctype)\n  return Promise.all(doctypes.map(stop))\n}\n\n//\n// REPEATED REPLICATION\n//\n\nfunction getRepeatedReplication (cozy, doctype) {\n  return getInfo(cozy, doctype).interval\n}\n\nfunction setRepeatedReplication (cozy, doctype, interval) {\n  cozy._offline[doctype].interval = interval\n}\n\nexport function hasRepeatedReplication (cozy, doctype) {\n  return getRepeatedReplication(cozy, doctype) !== undefined\n}\n\nexport function startRepeatedReplication (cozy, doctype, timer, options = {}) {\n  // TODO: add timer limitation for not flooding Gozy\n  if (hasRepeatedReplication(cozy, doctype)) {\n    return getRepeatedReplication(cozy, doctype)\n  }\n\n  return setRepeatedReplication(cozy, doctype, setInterval(() => {\n    if (isOffline()) {\n      // network is offline, replication cannot be launched\n      console.info(replicationOfflineError)\n      return\n    }\n    if (!hasReplication(cozy, doctype)) {\n      replicateFromCozy(cozy, doctype, options)\n      // TODO: add replicationToCozy\n    }\n  }, timer * 1000))\n}\n\nexport function stopRepeatedReplication (cozy, doctype) {\n  if (hasRepeatedReplication(cozy, doctype)) {\n    clearInterval(getRepeatedReplication(cozy, doctype))\n    setRepeatedReplication(cozy, doctype, undefined)\n  }\n  if (hasReplication(cozy, doctype)) {\n    return stopReplication(cozy, doctype)\n  }\n\n  return Promise.resolve()\n}\n\nexport function stopAllRepeatedReplication (cozy) {\n  const doctypes = getDoctypes(cozy)\n  const stop = (doctype) => stopRepeatedReplication(cozy, doctype)\n  return Promise.all(doctypes.map(stop))\n}\n\n\n\n// WEBPACK FOOTER //\n// ./src/offline.js","import { cozyFetchJSON, cozyFetchRawJSON } from './fetch'\nimport { DOCTYPE_FILES } from './doctypes'\n\nfunction updateRelations (verb) {\n  return function (cozy, doc, ids) {\n    if (!doc) throw new Error('missing doc argument')\n    if (!Array.isArray(ids)) ids = [ids]\n\n    const refs = ids.map((id) => ({type: DOCTYPE_FILES, id}))\n\n    return cozyFetchJSON(cozy, verb, makeReferencesPath(doc), {data: refs})\n  }\n}\n\nexport const addReferencedFiles = updateRelations('POST')\nexport const removeReferencedFiles = updateRelations('DELETE')\n\nexport function listReferencedFiles (cozy, doc) {\n  if (!doc) throw new Error('missing doc argument')\n  return cozyFetchJSON(cozy, 'GET', makeReferencesPath(doc))\n    .then((files) => files.map((file) => file._id))\n}\n\nexport function fetchReferencedFiles (cozy, doc, options) {\n  if (!doc) throw new Error('missing doc argument')\n  const params = Object.keys(options).map(key => `&page[${key}]=${options[key]}`).join('')\n  // As datetime is the only sort option available, I see no reason to not have it by default\n  return cozyFetchRawJSON(cozy, 'GET', `${makeReferencesPath(doc)}?include=files&sort=datetime${params}`)\n}\n\nfunction makeReferencesPath (doc) {\n  const type = encodeURIComponent(doc._type)\n  const id = encodeURIComponent(doc._id)\n  return `/data/${type}/${id}/relationships/references`\n}\n\n\n\n// WEBPACK FOOTER //\n// ./src/relations.js","import {cozyFetchJSON} from './fetch'\n\nexport function diskUsage (cozy) {\n  return cozyFetchJSON(cozy, 'GET', `/settings/disk-usage`)\n}\n\nexport function changePassphrase (cozy, currentPassPhrase, newPassPhrase) {\n  return cozyFetchJSON(cozy, 'PUT', `/settings/passphrase`, {\n    current_passphrase: currentPassPhrase,\n    new_passphrase: newPassPhrase\n  })\n}\n\nexport function getInstance (cozy) {\n  return cozyFetchJSON(cozy, 'GET', `/settings/instance`)\n}\n\nexport function updateInstance (cozy, instance) {\n  return cozyFetchJSON(cozy, 'PUT', `/settings/instance`, instance)\n}\n\nexport function getClients (cozy) {\n  return cozyFetchJSON(cozy, 'GET', `/settings/clients`)\n}\n\nexport function deleteClientById (cozy, id) {\n  return cozyFetchJSON(cozy, 'DELETE', `/settings/clients/${id}`)\n}\n\nexport function updateLastSync (cozy) {\n  return cozyFetchJSON(cozy, 'POST', '/settings/synchronized')\n}\n\n\n\n// WEBPACK FOOTER //\n// ./src/settings.js","module.exports = require(\"regenerator-runtime\");\n\n\n\n//////////////////\n// WEBPACK FOOTER\n// ./~/babel-runtime/regenerator/index.js\n// module id = 47\n// module chunks = 0","module.exports = function (it) {\n  if (typeof it != 'function') throw TypeError(it + ' is not a function!');\n  return it;\n};\n\n\n\n//////////////////\n// WEBPACK FOOTER\n// ./~/core-js/modules/_a-function.js\n// module id = 48\n// module chunks = 0","var isObject = require('./_is-object');\nmodule.exports = function (it) {\n  if (!isObject(it)) throw TypeError(it + ' is not an object!');\n  return it;\n};\n\n\n\n//////////////////\n// WEBPACK FOOTER\n// ./~/core-js/modules/_an-object.js\n// module id = 49\n// module chunks = 0","// false -> Array#indexOf\n// true  -> Array#includes\nvar toIObject = require('./_to-iobject');\nvar toLength = require('./_to-length');\nvar toAbsoluteIndex = require('./_to-absolute-index');\nmodule.exports = function (IS_INCLUDES) {\n  return function ($this, el, fromIndex) {\n    var O = toIObject($this);\n    var length = toLength(O.length);\n    var index = toAbsoluteIndex(fromIndex, length);\n    var value;\n    // Array#includes uses SameValueZero equality algorithm\n    // eslint-disable-next-line no-self-compare\n    if (IS_INCLUDES && el != el) while (length > index) {\n      value = O[index++];\n      // eslint-disable-next-line no-self-compare\n      if (value != value) return true;\n    // Array#indexOf ignores holes, Array#includes - not\n    } else for (;length > index; index++) if (IS_INCLUDES || index in O) {\n      if (O[index] === el) return IS_INCLUDES || index || 0;\n    } return !IS_INCLUDES && -1;\n  };\n};\n\n\n\n//////////////////\n// WEBPACK FOOTER\n// ./~/core-js/modules/_array-includes.js\n// module id = 50\n// module chunks = 0","var toString = {}.toString;\n\nmodule.exports = function (it) {\n  return toString.call(it).slice(8, -1);\n};\n\n\n\n//////////////////\n// WEBPACK FOOTER\n// ./~/core-js/modules/_cof.js\n// module id = 51\n// module chunks = 0","// optional / simple context binding\nvar aFunction = require('./_a-function');\nmodule.exports = function (fn, that, length) {\n  aFunction(fn);\n  if (that === undefined) return fn;\n  switch (length) {\n    case 1: return function (a) {\n      return fn.call(that, a);\n    };\n    case 2: return function (a, b) {\n      return fn.call(that, a, b);\n    };\n    case 3: return function (a, b, c) {\n      return fn.call(that, a, b, c);\n    };\n  }\n  return function (/* ...args */) {\n    return fn.apply(that, arguments);\n  };\n};\n\n\n\n//////////////////\n// WEBPACK FOOTER\n// ./~/core-js/modules/_ctx.js\n// module id = 52\n// module chunks = 0","var isObject = require('./_is-object');\nvar document = require('./_global').document;\n// typeof document.createElement is 'object' in old IE\nvar is = isObject(document) && isObject(document.createElement);\nmodule.exports = function (it) {\n  return is ? document.createElement(it) : {};\n};\n\n\n\n//////////////////\n// WEBPACK FOOTER\n// ./~/core-js/modules/_dom-create.js\n// module id = 53\n// module chunks = 0","// IE 8- don't enum bug keys\nmodule.exports = (\n  'constructor,hasOwnProperty,isPrototypeOf,propertyIsEnumerable,toLocaleString,toString,valueOf'\n).split(',');\n\n\n\n//////////////////\n// WEBPACK FOOTER\n// ./~/core-js/modules/_enum-bug-keys.js\n// module id = 54\n// module chunks = 0","var global = require('./_global');\nvar core = require('./_core');\nvar hide = require('./_hide');\nvar redefine = require('./_redefine');\nvar ctx = require('./_ctx');\nvar PROTOTYPE = 'prototype';\n\nvar $export = function (type, name, source) {\n  var IS_FORCED = type & $export.F;\n  var IS_GLOBAL = type & $export.G;\n  var IS_STATIC = type & $export.S;\n  var IS_PROTO = type & $export.P;\n  var IS_BIND = type & $export.B;\n  var target = IS_GLOBAL ? global : IS_STATIC ? global[name] || (global[name] = {}) : (global[name] || {})[PROTOTYPE];\n  var exports = IS_GLOBAL ? core : core[name] || (core[name] = {});\n  var expProto = exports[PROTOTYPE] || (exports[PROTOTYPE] = {});\n  var key, own, out, exp;\n  if (IS_GLOBAL) source = name;\n  for (key in source) {\n    // contains in native\n    own = !IS_FORCED && target && target[key] !== undefined;\n    // export native or passed\n    out = (own ? target : source)[key];\n    // bind timers to global for call from export context\n    exp = IS_BIND && own ? ctx(out, global) : IS_PROTO && typeof out == 'function' ? ctx(Function.call, out) : out;\n    // extend global\n    if (target) redefine(target, key, out, type & $export.U);\n    // export\n    if (exports[key] != out) hide(exports, key, exp);\n    if (IS_PROTO && expProto[key] != out) expProto[key] = out;\n  }\n};\nglobal.core = core;\n// type bitmap\n$export.F = 1;   // forced\n$export.G = 2;   // global\n$export.S = 4;   // static\n$export.P = 8;   // proto\n$export.B = 16;  // bind\n$export.W = 32;  // wrap\n$export.U = 64;  // safe\n$export.R = 128; // real proto method for `library`\nmodule.exports = $export;\n\n\n\n//////////////////\n// WEBPACK FOOTER\n// ./~/core-js/modules/_export.js\n// module id = 55\n// module chunks = 0","module.exports = !require('./_descriptors') && !require('./_fails')(function () {\n  return Object.defineProperty(require('./_dom-create')('div'), 'a', { get: function () { return 7; } }).a != 7;\n});\n\n\n\n//////////////////\n// WEBPACK FOOTER\n// ./~/core-js/modules/_ie8-dom-define.js\n// module id = 56\n// module chunks = 0","'use strict';\n// 19.1.2.1 Object.assign(target, source, ...)\nvar getKeys = require('./_object-keys');\nvar gOPS = require('./_object-gops');\nvar pIE = require('./_object-pie');\nvar toObject = require('./_to-object');\nvar IObject = require('./_iobject');\nvar $assign = Object.assign;\n\n// should work with symbols and should have deterministic property order (V8 bug)\nmodule.exports = !$assign || require('./_fails')(function () {\n  var A = {};\n  var B = {};\n  // eslint-disable-next-line no-undef\n  var S = Symbol();\n  var K = 'abcdefghijklmnopqrst';\n  A[S] = 7;\n  K.split('').forEach(function (k) { B[k] = k; });\n  return $assign({}, A)[S] != 7 || Object.keys($assign({}, B)).join('') != K;\n}) ? function assign(target, source) { // eslint-disable-line no-unused-vars\n  var T = toObject(target);\n  var aLen = arguments.length;\n  var index = 1;\n  var getSymbols = gOPS.f;\n  var isEnum = pIE.f;\n  while (aLen > index) {\n    var S = IObject(arguments[index++]);\n    var keys = getSymbols ? getKeys(S).concat(getSymbols(S)) : getKeys(S);\n    var length = keys.length;\n    var j = 0;\n    var key;\n    while (length > j) if (isEnum.call(S, key = keys[j++])) T[key] = S[key];\n  } return T;\n} : $assign;\n\n\n\n//////////////////\n// WEBPACK FOOTER\n// ./~/core-js/modules/_object-assign.js\n// module id = 57\n// module chunks = 0","var anObject = require('./_an-object');\nvar IE8_DOM_DEFINE = require('./_ie8-dom-define');\nvar toPrimitive = require('./_to-primitive');\nvar dP = Object.defineProperty;\n\nexports.f = require('./_descriptors') ? Object.defineProperty : function defineProperty(O, P, Attributes) {\n  anObject(O);\n  P = toPrimitive(P, true);\n  anObject(Attributes);\n  if (IE8_DOM_DEFINE) try {\n    return dP(O, P, Attributes);\n  } catch (e) { /* empty */ }\n  if ('get' in Attributes || 'set' in Attributes) throw TypeError('Accessors not supported!');\n  if ('value' in Attributes) O[P] = Attributes.value;\n  return O;\n};\n\n\n\n//////////////////\n// WEBPACK FOOTER\n// ./~/core-js/modules/_object-dp.js\n// module id = 58\n// module chunks = 0","exports.f = Object.getOwnPropertySymbols;\n\n\n\n//////////////////\n// WEBPACK FOOTER\n// ./~/core-js/modules/_object-gops.js\n// module id = 59\n// module chunks = 0","var has = require('./_has');\nvar toIObject = require('./_to-iobject');\nvar arrayIndexOf = require('./_array-includes')(false);\nvar IE_PROTO = require('./_shared-key')('IE_PROTO');\n\nmodule.exports = function (object, names) {\n  var O = toIObject(object);\n  var i = 0;\n  var result = [];\n  var key;\n  for (key in O) if (key != IE_PROTO) has(O, key) && result.push(key);\n  // Don't enum bug & hidden keys\n  while (names.length > i) if (has(O, key = names[i++])) {\n    ~arrayIndexOf(result, key) || result.push(key);\n  }\n  return result;\n};\n\n\n\n//////////////////\n// WEBPACK FOOTER\n// ./~/core-js/modules/_object-keys-internal.js\n// module id = 60\n// module chunks = 0","// 19.1.2.14 / 15.2.3.14 Object.keys(O)\nvar $keys = require('./_object-keys-internal');\nvar enumBugKeys = require('./_enum-bug-keys');\n\nmodule.exports = Object.keys || function keys(O) {\n  return $keys(O, enumBugKeys);\n};\n\n\n\n//////////////////\n// WEBPACK FOOTER\n// ./~/core-js/modules/_object-keys.js\n// module id = 61\n// module chunks = 0","exports.f = {}.propertyIsEnumerable;\n\n\n\n//////////////////\n// WEBPACK FOOTER\n// ./~/core-js/modules/_object-pie.js\n// module id = 62\n// module chunks = 0","module.exports = function (bitmap, value) {\n  return {\n    enumerable: !(bitmap & 1),\n    configurable: !(bitmap & 2),\n    writable: !(bitmap & 4),\n    value: value\n  };\n};\n\n\n\n//////////////////\n// WEBPACK FOOTER\n// ./~/core-js/modules/_property-desc.js\n// module id = 63\n// module chunks = 0","var global = require('./_global');\nvar hide = require('./_hide');\nvar has = require('./_has');\nvar SRC = require('./_uid')('src');\nvar TO_STRING = 'toString';\nvar $toString = Function[TO_STRING];\nvar TPL = ('' + $toString).split(TO_STRING);\n\nrequire('./_core').inspectSource = function (it) {\n  return $toString.call(it);\n};\n\n(module.exports = function (O, key, val, safe) {\n  var isFunction = typeof val == 'function';\n  if (isFunction) has(val, 'name') || hide(val, 'name', key);\n  if (O[key] === val) return;\n  if (isFunction) has(val, SRC) || hide(val, SRC, O[key] ? '' + O[key] : TPL.join(String(key)));\n  if (O === global) {\n    O[key] = val;\n  } else if (!safe) {\n    delete O[key];\n    hide(O, key, val);\n  } else if (O[key]) {\n    O[key] = val;\n  } else {\n    hide(O, key, val);\n  }\n// add fake Function#toString for correct work wrapped methods / constructors with methods like LoDash isNative\n})(Function.prototype, TO_STRING, function toString() {\n  return typeof this == 'function' && this[SRC] || $toString.call(this);\n});\n\n\n\n//////////////////\n// WEBPACK FOOTER\n// ./~/core-js/modules/_redefine.js\n// module id = 64\n// module chunks = 0","var shared = require('./_shared')('keys');\nvar uid = require('./_uid');\nmodule.exports = function (key) {\n  return shared[key] || (shared[key] = uid(key));\n};\n\n\n\n//////////////////\n// WEBPACK FOOTER\n// ./~/core-js/modules/_shared-key.js\n// module id = 65\n// module chunks = 0","var global = require('./_global');\nvar SHARED = '__core-js_shared__';\nvar store = global[SHARED] || (global[SHARED] = {});\nmodule.exports = function (key) {\n  return store[key] || (store[key] = {});\n};\n\n\n\n//////////////////\n// WEBPACK FOOTER\n// ./~/core-js/modules/_shared.js\n// module id = 66\n// module chunks = 0","var toInteger = require('./_to-integer');\nvar max = Math.max;\nvar min = Math.min;\nmodule.exports = function (index, length) {\n  index = toInteger(index);\n  return index < 0 ? max(index + length, 0) : min(index, length);\n};\n\n\n\n//////////////////\n// WEBPACK FOOTER\n// ./~/core-js/modules/_to-absolute-index.js\n// module id = 67\n// module chunks = 0","// 7.1.15 ToLength\nvar toInteger = require('./_to-integer');\nvar min = Math.min;\nmodule.exports = function (it) {\n  return it > 0 ? min(toInteger(it), 0x1fffffffffffff) : 0; // pow(2, 53) - 1 == 9007199254740991\n};\n\n\n\n//////////////////\n// WEBPACK FOOTER\n// ./~/core-js/modules/_to-length.js\n// module id = 68\n// module chunks = 0","// 7.1.13 ToObject(argument)\nvar defined = require('./_defined');\nmodule.exports = function (it) {\n  return Object(defined(it));\n};\n\n\n\n//////////////////\n// WEBPACK FOOTER\n// ./~/core-js/modules/_to-object.js\n// module id = 69\n// module chunks = 0","// 7.1.1 ToPrimitive(input [, PreferredType])\nvar isObject = require('./_is-object');\n// instead of the ES6 spec version, we didn't implement @@toPrimitive case\n// and the second argument - flag - preferred type is a string\nmodule.exports = function (it, S) {\n  if (!isObject(it)) return it;\n  var fn, val;\n  if (S && typeof (fn = it.toString) == 'function' && !isObject(val = fn.call(it))) return val;\n  if (typeof (fn = it.valueOf) == 'function' && !isObject(val = fn.call(it))) return val;\n  if (!S && typeof (fn = it.toString) == 'function' && !isObject(val = fn.call(it))) return val;\n  throw TypeError(\"Can't convert object to primitive value\");\n};\n\n\n\n//////////////////\n// WEBPACK FOOTER\n// ./~/core-js/modules/_to-primitive.js\n// module id = 70\n// module chunks = 0","// 19.1.3.1 Object.assign(target, source)\nvar $export = require('./_export');\n\n$export($export.S + $export.F, 'Object', { assign: require('./_object-assign') });\n\n\n\n//////////////////\n// WEBPACK FOOTER\n// ./~/core-js/modules/es6.object.assign.js\n// module id = 71\n// module chunks = 0","/**\n * Helpers.\n */\n\nvar s = 1000\nvar m = s * 60\nvar h = m * 60\nvar d = h * 24\nvar y = d * 365.25\n\n/**\n * Parse or format the given `val`.\n *\n * Options:\n *\n *  - `long` verbose formatting [false]\n *\n * @param {String|Number} val\n * @param {Object} options\n * @throws {Error} throw an error if val is not a non-empty string or a number\n * @return {String|Number}\n * @api public\n */\n\nmodule.exports = function (val, options) {\n  options = options || {}\n  var type = typeof val\n  if (type === 'string' && val.length > 0) {\n    return parse(val)\n  } else if (type === 'number' && isNaN(val) === false) {\n    return options.long ?\n\t\t\tfmtLong(val) :\n\t\t\tfmtShort(val)\n  }\n  throw new Error('val is not a non-empty string or a valid number. val=' + JSON.stringify(val))\n}\n\n/**\n * Parse the given `str` and return milliseconds.\n *\n * @param {String} str\n * @return {Number}\n * @api private\n */\n\nfunction parse(str) {\n  str = String(str)\n  if (str.length > 10000) {\n    return\n  }\n  var match = /^((?:\\d+)?\\.?\\d+) *(milliseconds?|msecs?|ms|seconds?|secs?|s|minutes?|mins?|m|hours?|hrs?|h|days?|d|years?|yrs?|y)?$/i.exec(str)\n  if (!match) {\n    return\n  }\n  var n = parseFloat(match[1])\n  var type = (match[2] || 'ms').toLowerCase()\n  switch (type) {\n    case 'years':\n    case 'year':\n    case 'yrs':\n    case 'yr':\n    case 'y':\n      return n * y\n    case 'days':\n    case 'day':\n    case 'd':\n      return n * d\n    case 'hours':\n    case 'hour':\n    case 'hrs':\n    case 'hr':\n    case 'h':\n      return n * h\n    case 'minutes':\n    case 'minute':\n    case 'mins':\n    case 'min':\n    case 'm':\n      return n * m\n    case 'seconds':\n    case 'second':\n    case 'secs':\n    case 'sec':\n    case 's':\n      return n * s\n    case 'milliseconds':\n    case 'millisecond':\n    case 'msecs':\n    case 'msec':\n    case 'ms':\n      return n\n    default:\n      return undefined\n  }\n}\n\n/**\n * Short format for `ms`.\n *\n * @param {Number} ms\n * @return {String}\n * @api private\n */\n\nfunction fmtShort(ms) {\n  if (ms >= d) {\n    return Math.round(ms / d) + 'd'\n  }\n  if (ms >= h) {\n    return Math.round(ms / h) + 'h'\n  }\n  if (ms >= m) {\n    return Math.round(ms / m) + 'm'\n  }\n  if (ms >= s) {\n    return Math.round(ms / s) + 's'\n  }\n  return ms + 'ms'\n}\n\n/**\n * Long format for `ms`.\n *\n * @param {Number} ms\n * @return {String}\n * @api private\n */\n\nfunction fmtLong(ms) {\n  return plural(ms, d, 'day') ||\n    plural(ms, h, 'hour') ||\n    plural(ms, m, 'minute') ||\n    plural(ms, s, 'second') ||\n    ms + ' ms'\n}\n\n/**\n * Pluralization helper.\n */\n\nfunction plural(ms, n, name) {\n  if (ms < n) {\n    return\n  }\n  if (ms < n * 1.5) {\n    return Math.floor(ms / n) + ' ' + name\n  }\n  return Math.ceil(ms / n) + ' ' + name + 's'\n}\n\n\n\n//////////////////\n// WEBPACK FOOTER\n// ./~/debug/~/ms/index.js\n// module id = 72\n// module chunks = 0","\n/**\n * This is the common logic for both the Node.js and web browser\n * implementations of `debug()`.\n *\n * Expose `debug()` as the module.\n */\n\nexports = module.exports = createDebug.debug = createDebug.default = createDebug;\nexports.coerce = coerce;\nexports.disable = disable;\nexports.enable = enable;\nexports.enabled = enabled;\nexports.humanize = require('ms');\n\n/**\n * The currently active debug mode names, and names to skip.\n */\n\nexports.names = [];\nexports.skips = [];\n\n/**\n * Map of special \"%n\" handling functions, for the debug \"format\" argument.\n *\n * Valid key names are a single, lower or upper-case letter, i.e. \"n\" and \"N\".\n */\n\nexports.formatters = {};\n\n/**\n * Previous log timestamp.\n */\n\nvar prevTime;\n\n/**\n * Select a color.\n * @param {String} namespace\n * @return {Number}\n * @api private\n */\n\nfunction selectColor(namespace) {\n  var hash = 0, i;\n\n  for (i in namespace) {\n    hash  = ((hash << 5) - hash) + namespace.charCodeAt(i);\n    hash |= 0; // Convert to 32bit integer\n  }\n\n  return exports.colors[Math.abs(hash) % exports.colors.length];\n}\n\n/**\n * Create a debugger with the given `namespace`.\n *\n * @param {String} namespace\n * @return {Function}\n * @api public\n */\n\nfunction createDebug(namespace) {\n\n  function debug() {\n    // disabled?\n    if (!debug.enabled) return;\n\n    var self = debug;\n\n    // set `diff` timestamp\n    var curr = +new Date();\n    var ms = curr - (prevTime || curr);\n    self.diff = ms;\n    self.prev = prevTime;\n    self.curr = curr;\n    prevTime = curr;\n\n    // turn the `arguments` into a proper Array\n    var args = new Array(arguments.length);\n    for (var i = 0; i < args.length; i++) {\n      args[i] = arguments[i];\n    }\n\n    args[0] = exports.coerce(args[0]);\n\n    if ('string' !== typeof args[0]) {\n      // anything else let's inspect with %O\n      args.unshift('%O');\n    }\n\n    // apply any `formatters` transformations\n    var index = 0;\n    args[0] = args[0].replace(/%([a-zA-Z%])/g, function(match, format) {\n      // if we encounter an escaped % then don't increase the array index\n      if (match === '%%') return match;\n      index++;\n      var formatter = exports.formatters[format];\n      if ('function' === typeof formatter) {\n        var val = args[index];\n        match = formatter.call(self, val);\n\n        // now we need to remove `args[index]` since it's inlined in the `format`\n        args.splice(index, 1);\n        index--;\n      }\n      return match;\n    });\n\n    // apply env-specific formatting (colors, etc.)\n    exports.formatArgs.call(self, args);\n\n    var logFn = debug.log || exports.log || console.log.bind(console);\n    logFn.apply(self, args);\n  }\n\n  debug.namespace = namespace;\n  debug.enabled = exports.enabled(namespace);\n  debug.useColors = exports.useColors();\n  debug.color = selectColor(namespace);\n\n  // env-specific initialization logic for debug instances\n  if ('function' === typeof exports.init) {\n    exports.init(debug);\n  }\n\n  return debug;\n}\n\n/**\n * Enables a debug mode by namespaces. This can include modes\n * separated by a colon and wildcards.\n *\n * @param {String} namespaces\n * @api public\n */\n\nfunction enable(namespaces) {\n  exports.save(namespaces);\n\n  var split = (namespaces || '').split(/[\\s,]+/);\n  var len = split.length;\n\n  for (var i = 0; i < len; i++) {\n    if (!split[i]) continue; // ignore empty strings\n    namespaces = split[i].replace(/\\*/g, '.*?');\n    if (namespaces[0] === '-') {\n      exports.skips.push(new RegExp('^' + namespaces.substr(1) + '$'));\n    } else {\n      exports.names.push(new RegExp('^' + namespaces + '$'));\n    }\n  }\n}\n\n/**\n * Disable debug output.\n *\n * @api public\n */\n\nfunction disable() {\n  exports.enable('');\n}\n\n/**\n * Returns true if the given mode name is enabled, false otherwise.\n *\n * @param {String} name\n * @return {Boolean}\n * @api public\n */\n\nfunction enabled(name) {\n  var i, len;\n  for (i = 0, len = exports.skips.length; i < len; i++) {\n    if (exports.skips[i].test(name)) {\n      return false;\n    }\n  }\n  for (i = 0, len = exports.names.length; i < len; i++) {\n    if (exports.names[i].test(name)) {\n      return true;\n    }\n  }\n  return false;\n}\n\n/**\n * Coerce `val`.\n *\n * @param {Mixed} val\n * @return {Mixed}\n * @api private\n */\n\nfunction coerce(val) {\n  if (val instanceof Error) return val.stack || val.message;\n  return val;\n}\n\n\n\n//////////////////\n// WEBPACK FOOTER\n// ./~/debug/src/debug.js\n// module id = 73\n// module chunks = 0","// Copyright Joyent, Inc. and other Node contributors.\n//\n// Permission is hereby granted, free of charge, to any person obtaining a\n// copy of this software and associated documentation files (the\n// \"Software\"), to deal in the Software without restriction, including\n// without limitation the rights to use, copy, modify, merge, publish,\n// distribute, sublicense, and/or sell copies of the Software, and to permit\n// persons to whom the Software is furnished to do so, subject to the\n// following conditions:\n//\n// The above copyright notice and this permission notice shall be included\n// in all copies or substantial portions of the Software.\n//\n// THE SOFTWARE IS PROVIDED \"AS IS\", WITHOUT WARRANTY OF ANY KIND, EXPRESS\n// OR IMPLIED, INCLUDING BUT NOT LIMITED TO THE WARRANTIES OF\n// MERCHANTABILITY, FITNESS FOR A PARTICULAR PURPOSE AND NONINFRINGEMENT. IN\n// NO EVENT SHALL THE AUTHORS OR COPYRIGHT HOLDERS BE LIABLE FOR ANY CLAIM,\n// DAMAGES OR OTHER LIABILITY, WHETHER IN AN ACTION OF CONTRACT, TORT OR\n// OTHERWISE, ARISING FROM, OUT OF OR IN CONNECTION WITH THE SOFTWARE OR THE\n// USE OR OTHER DEALINGS IN THE SOFTWARE.\n\nfunction EventEmitter() {\n  this._events = this._events || {};\n  this._maxListeners = this._maxListeners || undefined;\n}\nmodule.exports = EventEmitter;\n\n// Backwards-compat with node 0.10.x\nEventEmitter.EventEmitter = EventEmitter;\n\nEventEmitter.prototype._events = undefined;\nEventEmitter.prototype._maxListeners = undefined;\n\n// By default EventEmitters will print a warning if more than 10 listeners are\n// added to it. This is a useful default which helps finding memory leaks.\nEventEmitter.defaultMaxListeners = 10;\n\n// Obviously not all Emitters should be limited to 10. This function allows\n// that to be increased. Set to zero for unlimited.\nEventEmitter.prototype.setMaxListeners = function(n) {\n  if (!isNumber(n) || n < 0 || isNaN(n))\n    throw TypeError('n must be a positive number');\n  this._maxListeners = n;\n  return this;\n};\n\nEventEmitter.prototype.emit = function(type) {\n  var er, handler, len, args, i, listeners;\n\n  if (!this._events)\n    this._events = {};\n\n  // If there is no 'error' event listener then throw.\n  if (type === 'error') {\n    if (!this._events.error ||\n        (isObject(this._events.error) && !this._events.error.length)) {\n      er = arguments[1];\n      if (er instanceof Error) {\n        throw er; // Unhandled 'error' event\n      } else {\n        // At least give some kind of context to the user\n        var err = new Error('Uncaught, unspecified \"error\" event. (' + er + ')');\n        err.context = er;\n        throw err;\n      }\n    }\n  }\n\n  handler = this._events[type];\n\n  if (isUndefined(handler))\n    return false;\n\n  if (isFunction(handler)) {\n    switch (arguments.length) {\n      // fast cases\n      case 1:\n        handler.call(this);\n        break;\n      case 2:\n        handler.call(this, arguments[1]);\n        break;\n      case 3:\n        handler.call(this, arguments[1], arguments[2]);\n        break;\n      // slower\n      default:\n        args = Array.prototype.slice.call(arguments, 1);\n        handler.apply(this, args);\n    }\n  } else if (isObject(handler)) {\n    args = Array.prototype.slice.call(arguments, 1);\n    listeners = handler.slice();\n    len = listeners.length;\n    for (i = 0; i < len; i++)\n      listeners[i].apply(this, args);\n  }\n\n  return true;\n};\n\nEventEmitter.prototype.addListener = function(type, listener) {\n  var m;\n\n  if (!isFunction(listener))\n    throw TypeError('listener must be a function');\n\n  if (!this._events)\n    this._events = {};\n\n  // To avoid recursion in the case that type === \"newListener\"! Before\n  // adding it to the listeners, first emit \"newListener\".\n  if (this._events.newListener)\n    this.emit('newListener', type,\n              isFunction(listener.listener) ?\n              listener.listener : listener);\n\n  if (!this._events[type])\n    // Optimize the case of one listener. Don't need the extra array object.\n    this._events[type] = listener;\n  else if (isObject(this._events[type]))\n    // If we've already got an array, just append.\n    this._events[type].push(listener);\n  else\n    // Adding the second element, need to change to array.\n    this._events[type] = [this._events[type], listener];\n\n  // Check for listener leak\n  if (isObject(this._events[type]) && !this._events[type].warned) {\n    if (!isUndefined(this._maxListeners)) {\n      m = this._maxListeners;\n    } else {\n      m = EventEmitter.defaultMaxListeners;\n    }\n\n    if (m && m > 0 && this._events[type].length > m) {\n      this._events[type].warned = true;\n      console.error('(node) warning: possible EventEmitter memory ' +\n                    'leak detected. %d listeners added. ' +\n                    'Use emitter.setMaxListeners() to increase limit.',\n                    this._events[type].length);\n      if (typeof console.trace === 'function') {\n        // not supported in IE 10\n        console.trace();\n      }\n    }\n  }\n\n  return this;\n};\n\nEventEmitter.prototype.on = EventEmitter.prototype.addListener;\n\nEventEmitter.prototype.once = function(type, listener) {\n  if (!isFunction(listener))\n    throw TypeError('listener must be a function');\n\n  var fired = false;\n\n  function g() {\n    this.removeListener(type, g);\n\n    if (!fired) {\n      fired = true;\n      listener.apply(this, arguments);\n    }\n  }\n\n  g.listener = listener;\n  this.on(type, g);\n\n  return this;\n};\n\n// emits a 'removeListener' event iff the listener was removed\nEventEmitter.prototype.removeListener = function(type, listener) {\n  var list, position, length, i;\n\n  if (!isFunction(listener))\n    throw TypeError('listener must be a function');\n\n  if (!this._events || !this._events[type])\n    return this;\n\n  list = this._events[type];\n  length = list.length;\n  position = -1;\n\n  if (list === listener ||\n      (isFunction(list.listener) && list.listener === listener)) {\n    delete this._events[type];\n    if (this._events.removeListener)\n      this.emit('removeListener', type, listener);\n\n  } else if (isObject(list)) {\n    for (i = length; i-- > 0;) {\n      if (list[i] === listener ||\n          (list[i].listener && list[i].listener === listener)) {\n        position = i;\n        break;\n      }\n    }\n\n    if (position < 0)\n      return this;\n\n    if (list.length === 1) {\n      list.length = 0;\n      delete this._events[type];\n    } else {\n      list.splice(position, 1);\n    }\n\n    if (this._events.removeListener)\n      this.emit('removeListener', type, listener);\n  }\n\n  return this;\n};\n\nEventEmitter.prototype.removeAllListeners = function(type) {\n  var key, listeners;\n\n  if (!this._events)\n    return this;\n\n  // not listening for removeListener, no need to emit\n  if (!this._events.removeListener) {\n    if (arguments.length === 0)\n      this._events = {};\n    else if (this._events[type])\n      delete this._events[type];\n    return this;\n  }\n\n  // emit removeListener for all listeners on all events\n  if (arguments.length === 0) {\n    for (key in this._events) {\n      if (key === 'removeListener') continue;\n      this.removeAllListeners(key);\n    }\n    this.removeAllListeners('removeListener');\n    this._events = {};\n    return this;\n  }\n\n  listeners = this._events[type];\n\n  if (isFunction(listeners)) {\n    this.removeListener(type, listeners);\n  } else if (listeners) {\n    // LIFO order\n    while (listeners.length)\n      this.removeListener(type, listeners[listeners.length - 1]);\n  }\n  delete this._events[type];\n\n  return this;\n};\n\nEventEmitter.prototype.listeners = function(type) {\n  var ret;\n  if (!this._events || !this._events[type])\n    ret = [];\n  else if (isFunction(this._events[type]))\n    ret = [this._events[type]];\n  else\n    ret = this._events[type].slice();\n  return ret;\n};\n\nEventEmitter.prototype.listenerCount = function(type) {\n  if (this._events) {\n    var evlistener = this._events[type];\n\n    if (isFunction(evlistener))\n      return 1;\n    else if (evlistener)\n      return evlistener.length;\n  }\n  return 0;\n};\n\nEventEmitter.listenerCount = function(emitter, type) {\n  return emitter.listenerCount(type);\n};\n\nfunction isFunction(arg) {\n  return typeof arg === 'function';\n}\n\nfunction isNumber(arg) {\n  return typeof arg === 'number';\n}\n\nfunction isObject(arg) {\n  return typeof arg === 'object' && arg !== null;\n}\n\nfunction isUndefined(arg) {\n  return arg === void 0;\n}\n\n\n\n//////////////////\n// WEBPACK FOOTER\n// ./~/events/events.js\n// module id = 74\n// module chunks = 0","\n/**\n * isArray\n */\n\nvar isArray = Array.isArray;\n\n/**\n * toString\n */\n\nvar str = Object.prototype.toString;\n\n/**\n * Whether or not the given `val`\n * is an array.\n *\n * example:\n *\n *        isArray([]);\n *        // > true\n *        isArray(arguments);\n *        // > false\n *        isArray('');\n *        // > false\n *\n * @param {mixed} val\n * @return {bool}\n */\n\nmodule.exports = isArray || function (val) {\n  return !! val && '[object Array]' == str.call(val);\n};\n\n\n\n//////////////////\n// WEBPACK FOOTER\n// ./~/is-array/index.js\n// module id = 75\n// module chunks = 0","// the whatwg-fetch polyfill installs the fetch() function\n// on the global object (window or self)\n//\n// Return that as the export for use in Webpack, Browserify etc.\nrequire('whatwg-fetch');\nmodule.exports = self.fetch.bind(self);\n\n\n\n//////////////////\n// WEBPACK FOOTER\n// ./~/isomorphic-fetch/fetch-npm-browserify.js\n// module id = 76\n// module chunks = 0","'use strict';\n\nfunction pad(str, padWith, upToLength) {\n  var padding = '';\n  var targetLength = upToLength - str.length;\n  while (padding.length < targetLength) {\n    padding += padWith;\n  }\n  return padding;\n}\n\nexports.padLeft = function (str, padWith, upToLength) {\n  var padding = pad(str, padWith, upToLength);\n  return padding + str;\n};\n\nexports.padRight = function (str, padWith, upToLength) {\n  var padding = pad(str, padWith, upToLength);\n  return str + padding;\n};\n\nexports.stringLexCompare = function (a, b) {\n\n  var aLen = a.length;\n  var bLen = b.length;\n\n  var i;\n  for (i = 0; i < aLen; i++) {\n    if (i === bLen) {\n      // b is shorter substring of a\n      return 1;\n    }\n    var aChar = a.charAt(i);\n    var bChar = b.charAt(i);\n    if (aChar !== bChar) {\n      return aChar < bChar ? -1 : 1;\n    }\n  }\n\n  if (aLen < bLen) {\n    // a is shorter substring of b\n    return -1;\n  }\n\n  return 0;\n};\n\n/*\n * returns the decimal form for the given integer, i.e. writes\n * out all the digits (in base-10) instead of using scientific notation\n */\nexports.intToDecimalForm = function (int) {\n\n  var isNeg = int < 0;\n  var result = '';\n\n  do {\n    var remainder = isNeg ? -Math.ceil(int % 10) : Math.floor(int % 10);\n\n    result = remainder + result;\n    int = isNeg ? Math.ceil(int / 10) : Math.floor(int / 10);\n  } while (int);\n\n\n  if (isNeg && result !== '0') {\n    result = '-' + result;\n  }\n\n  return result;\n};\n\n\n//////////////////\n// WEBPACK FOOTER\n// ./~/pouchdb-collate/lib/utils.js\n// module id = 77\n// module chunks = 0","'use strict';\n\nvar upsert = require('./upsert');\nvar utils = require('./utils');\nvar Promise = utils.Promise;\n\nfunction stringify(input) {\n  if (!input) {\n    return 'undefined'; // backwards compat for empty reduce\n  }\n  // for backwards compat with mapreduce, functions/strings are stringified\n  // as-is. everything else is JSON-stringified.\n  switch (typeof input) {\n    case 'function':\n      // e.g. a mapreduce map\n      return input.toString();\n    case 'string':\n      // e.g. a mapreduce built-in _reduce function\n      return input.toString();\n    default:\n      // e.g. a JSON object in the case of mango queries\n      return JSON.stringify(input);\n  }\n}\n\nmodule.exports = function (opts) {\n  var sourceDB = opts.db;\n  var viewName = opts.viewName;\n  var mapFun = opts.map;\n  var reduceFun = opts.reduce;\n  var temporary = opts.temporary;\n  var pluginName = opts.pluginName;\n\n  // the \"undefined\" part is for backwards compatibility\n  var viewSignature = stringify(mapFun) + stringify(reduceFun) +\n    'undefined';\n\n  if (!temporary && sourceDB._cachedViews) {\n    var cachedView = sourceDB._cachedViews[viewSignature];\n    if (cachedView) {\n      return Promise.resolve(cachedView);\n    }\n  }\n\n  return sourceDB.info().then(function (info) {\n\n    var depDbName = info.db_name + '-mrview-' +\n      (temporary ? 'temp' : utils.MD5(viewSignature));\n\n    // save the view name in the source PouchDB so it can be cleaned up if necessary\n    // (e.g. when the _design doc is deleted, remove all associated view data)\n    function diffFunction(doc) {\n      doc.views = doc.views || {};\n      var fullViewName = viewName;\n      if (fullViewName.indexOf('/') === -1) {\n        fullViewName = viewName + '/' + viewName;\n      }\n      var depDbs = doc.views[fullViewName] = doc.views[fullViewName] || {};\n      /* istanbul ignore if */\n      if (depDbs[depDbName]) {\n        return; // no update necessary\n      }\n      depDbs[depDbName] = true;\n      return doc;\n    }\n    return upsert(sourceDB, '_local/' + pluginName, diffFunction).then(function () {\n      return sourceDB.registerDependentDatabase(depDbName).then(function (res) {\n        var db = res.db;\n        db.auto_compaction = true;\n        var view = {\n          name: depDbName,\n          db: db, \n          sourceDB: sourceDB,\n          adapter: sourceDB.adapter,\n          mapFun: mapFun,\n          reduceFun: reduceFun\n        };\n        return view.db.get('_local/lastSeq').catch(function (err) {\n          /* istanbul ignore if */\n          if (err.status !== 404) {\n            throw err;\n          }\n        }).then(function (lastSeqDoc) {\n          view.seq = lastSeqDoc ? lastSeqDoc.seq : 0;\n          if (!temporary) {\n            sourceDB._cachedViews = sourceDB._cachedViews || {};\n            sourceDB._cachedViews[viewSignature] = view;\n            view.db.on('destroyed', function () {\n              delete sourceDB._cachedViews[viewSignature];\n            });\n          }\n          return view;\n        });\n      });\n    });\n  });\n};\n\n\n\n//////////////////\n// WEBPACK FOOTER\n// ./~/pouchdb-find/lib/abstract-mapreduce/create-view.js\n// module id = 78\n// module chunks = 0","'use strict';\n\nvar pouchCollate = require('pouchdb-collate');\nvar TaskQueue = require('./taskqueue');\nvar collate = pouchCollate.collate;\nvar toIndexableString = pouchCollate.toIndexableString;\nvar normalizeKey = pouchCollate.normalizeKey;\nvar createView = require('./create-view');\nvar log;\n/* istanbul ignore else */\nif ((typeof console !== 'undefined') && (typeof console.log === 'function')) {\n  log = Function.prototype.bind.call(console.log, console);\n} else {\n  log = function () {};\n}\nvar utils = require('./utils');\nvar Promise = utils.Promise;\nvar persistentQueues = {};\nvar tempViewQueue = new TaskQueue();\nvar CHANGES_BATCH_SIZE = 50;\n\nfunction QueryParseError(message) {\n  this.status = 400;\n  this.name = 'query_parse_error';\n  this.message = message;\n  this.error = true;\n  try {\n    Error.captureStackTrace(this, QueryParseError);\n  } catch (e) {}\n}\n\nutils.inherits(QueryParseError, Error);\n\nfunction NotFoundError(message) {\n  this.status = 404;\n  this.name = 'not_found';\n  this.message = message;\n  this.error = true;\n  try {\n    Error.captureStackTrace(this, NotFoundError);\n  } catch (e) {}\n}\n\nutils.inherits(NotFoundError, Error);\n\nfunction parseViewName(name) {\n  // can be either 'ddocname/viewname' or just 'viewname'\n  // (where the ddoc name is the same)\n  return name.indexOf('/') === -1 ? [name, name] : name.split('/');\n}\n\nfunction isGenOne(changes) {\n  // only return true if the current change is 1-\n  // and there are no other leafs\n  return changes.length === 1 && /^1-/.test(changes[0].rev);\n}\n\nfunction sortByKeyThenValue(x, y) {\n  var keyCompare = collate(x.key, y.key);\n  return keyCompare !== 0 ? keyCompare : collate(x.value, y.value);\n}\n\nfunction sliceResults(results, limit, skip) {\n  skip = skip || 0;\n  if (typeof limit === 'number') {\n    return results.slice(skip, limit + skip);\n  } else if (skip > 0) {\n    return results.slice(skip);\n  }\n  return results;\n}\n\nfunction rowToDocId(row) {\n  var val = row.value;\n  // Users can explicitly specify a joined doc _id, or it\n  // defaults to the doc _id that emitted the key/value.\n  var docId = (val && typeof val === 'object' && val._id) || row.id;\n  return docId;\n}\n\nfunction emitError(db, e) {\n  try {\n    db.emit('error', e);\n  } catch (err) {\n    console.error(\n      'The user\\'s map/reduce function threw an uncaught error.\\n' +\n      'You can debug this error by doing:\\n' +\n      'myDatabase.on(\\'error\\', function (err) { debugger; });\\n' +\n      'Please double-check your map/reduce function.');\n    console.error(e);\n  }\n}\n\nfunction tryCode(db, fun, args) {\n  // emit an event if there was an error thrown by a map/reduce function.\n  // putting try/catches in a single function also avoids deoptimizations.\n  try {\n    return {\n      output : fun.apply(null, args)\n    };\n  } catch (e) {\n    emitError(db, e);\n    return {error: e};\n  }\n}\n\nfunction checkQueryParseError(options, fun) {\n  var startkeyName = options.descending ? 'endkey' : 'startkey';\n  var endkeyName = options.descending ? 'startkey' : 'endkey';\n\n  if (typeof options[startkeyName] !== 'undefined' &&\n    typeof options[endkeyName] !== 'undefined' &&\n    collate(options[startkeyName], options[endkeyName]) > 0) {\n    throw new QueryParseError('No rows can match your key range, reverse your ' +\n    'start_key and end_key or set {descending : true}');\n  } else if (fun.reduce && options.reduce !== false) {\n    if (options.include_docs) {\n      throw new QueryParseError('{include_docs:true} is invalid for reduce');\n    } else if (options.keys && options.keys.length > 1 &&\n      !options.group && !options.group_level) {\n      throw new QueryParseError('Multi-key fetches for reduce views must use {group: true}');\n    }\n  }\n  if (options.group_level) {\n    if (typeof options.group_level !== 'number') {\n      throw new QueryParseError('Invalid value for integer: \"' + options.group_level + '\"');\n    }\n    if (options.group_level < 0) {\n      throw new QueryParseError('Invalid value for positive integer: ' +\n      '\"' + options.group_level + '\"');\n    }\n  }\n}\n\nfunction defaultsTo(value) {\n  return function (reason) {\n    /* istanbul ignore else */\n    if (reason.status === 404) {\n      return value;\n    } else {\n      throw reason;\n    }\n  };\n}\n\nfunction createIndexer(def) {\n\n  var pluginName = def.name;\n  var mapper = def.mapper;\n  var reducer = def.reducer;\n  var ddocValidator = def.ddocValidator;\n\n\n  // returns a promise for a list of docs to update, based on the input docId.\n  // the order doesn't matter, because post-3.2.0, bulkDocs\n  // is an atomic operation in all three adapters.\n  function getDocsToPersist(docId, view, docIdsToChangesAndEmits) {\n    var metaDocId = '_local/doc_' + docId;\n    var defaultMetaDoc = {_id: metaDocId, keys: []};\n    var docData = docIdsToChangesAndEmits[docId];\n    var indexableKeysToKeyValues = docData.indexableKeysToKeyValues;\n    var changes = docData.changes;\n\n    function getMetaDoc() {\n      if (isGenOne(changes)) {\n        // generation 1, so we can safely assume initial state\n        // for performance reasons (avoids unnecessary GETs)\n        return Promise.resolve(defaultMetaDoc);\n      }\n      return view.db.get(metaDocId).catch(defaultsTo(defaultMetaDoc));\n    }\n\n    function getKeyValueDocs(metaDoc) {\n      if (!metaDoc.keys.length) {\n        // no keys, no need for a lookup\n        return Promise.resolve({rows: []});\n      }\n      return view.db.allDocs({\n        keys: metaDoc.keys,\n        include_docs: true\n      });\n    }\n\n    function processKvDocs(metaDoc, kvDocsRes) {\n      var kvDocs = [];\n      var oldKeysMap = {};\n\n      for (var i = 0, len = kvDocsRes.rows.length; i < len; i++) {\n        var row = kvDocsRes.rows[i];\n        var doc = row.doc;\n        if (!doc) { // deleted\n          continue;\n        }\n        kvDocs.push(doc);\n        oldKeysMap[doc._id] = true;\n        doc._deleted = !indexableKeysToKeyValues[doc._id];\n        if (!doc._deleted) {\n          var keyValue = indexableKeysToKeyValues[doc._id];\n          if ('value' in keyValue) {\n            doc.value = keyValue.value;\n          }\n        }\n      }\n\n      var newKeys = Object.keys(indexableKeysToKeyValues);\n      newKeys.forEach(function (key) {\n        if (!oldKeysMap[key]) {\n          // new doc\n          var kvDoc = {\n            _id: key\n          };\n          var keyValue = indexableKeysToKeyValues[key];\n          if ('value' in keyValue) {\n            kvDoc.value = keyValue.value;\n          }\n          kvDocs.push(kvDoc);\n        }\n      });\n      metaDoc.keys = utils.uniq(newKeys.concat(metaDoc.keys));\n      kvDocs.push(metaDoc);\n\n      return kvDocs;\n    }\n\n    return getMetaDoc().then(function (metaDoc) {\n      return getKeyValueDocs(metaDoc).then(function (kvDocsRes) {\n        return processKvDocs(metaDoc, kvDocsRes);\n      });\n    });\n  }\n\n  // updates all emitted key/value docs and metaDocs in the mrview database\n  // for the given batch of documents from the source database\n  function saveKeyValues(view, docIdsToChangesAndEmits, seq) {\n    var seqDocId = '_local/lastSeq';\n    return view.db.get(seqDocId)\n    .catch(defaultsTo({_id: seqDocId, seq: 0}))\n    .then(function (lastSeqDoc) {\n      var docIds = Object.keys(docIdsToChangesAndEmits);\n      return Promise.all(docIds.map(function (docId) {\n        return getDocsToPersist(docId, view, docIdsToChangesAndEmits);\n      })).then(function (listOfDocsToPersist) {\n        var docsToPersist = utils.flatten(listOfDocsToPersist);\n        lastSeqDoc.seq = seq;\n        docsToPersist.push(lastSeqDoc);\n        // write all docs in a single operation, update the seq once\n        return view.db.bulkDocs({docs : docsToPersist});\n      });\n    });\n  }\n\n  function getQueue(view) {\n    var viewName = typeof view === 'string' ? view : view.name;\n    var queue = persistentQueues[viewName];\n    if (!queue) {\n      queue = persistentQueues[viewName] = new TaskQueue();\n    }\n    return queue;\n  }\n\n  function updateView(view) {\n    return utils.sequentialize(getQueue(view), function () {\n      return updateViewInQueue(view);\n    })();\n  }\n\n  function updateViewInQueue(view) {\n    // bind the emit function once\n    var mapResults;\n    var doc;\n\n    function emit(key, value) {\n      var output = {id: doc._id, key: normalizeKey(key)};\n      // Don't explicitly store the value unless it's defined and non-null.\n      // This saves on storage space, because often people don't use it.\n      if (typeof value !== 'undefined' && value !== null) {\n        output.value = normalizeKey(value);\n      }\n      mapResults.push(output);\n    }\n\n    var mapFun = mapper(view.mapFun, emit);\n\n    var currentSeq = view.seq || 0;\n\n    function processChange(docIdsToChangesAndEmits, seq) {\n      return function () {\n        return saveKeyValues(view, docIdsToChangesAndEmits, seq);\n      };\n    }\n\n    var queue = new TaskQueue();\n\n    return new Promise(function (resolve, reject) {\n\n      function complete() {\n        queue.finish().then(function () {\n          view.seq = currentSeq;\n          resolve();\n        });\n      }\n\n      function processNextBatch() {\n        view.sourceDB.changes({\n          conflicts: true,\n          include_docs: true,\n          style: 'all_docs',\n          since: currentSeq,\n          limit: CHANGES_BATCH_SIZE\n        }).on('complete', function (response) {\n          var results = response.results;\n          if (!results.length) {\n            return complete();\n          }\n          var docIdsToChangesAndEmits = {};\n          for (var i = 0, l = results.length; i < l; i++) {\n            var change = results[i];\n            if (change.doc._id[0] !== '_') {\n              mapResults = [];\n              doc = change.doc;\n\n              if (!doc._deleted) {\n                tryCode(view.sourceDB, mapFun, [doc]);\n              }\n              mapResults.sort(sortByKeyThenValue);\n\n              var indexableKeysToKeyValues = {};\n              var lastKey;\n              for (var j = 0, jl = mapResults.length; j < jl; j++) {\n                var obj = mapResults[j];\n                var complexKey = [obj.key, obj.id];\n                if (collate(obj.key, lastKey) === 0) {\n                  complexKey.push(j); // dup key+id, so make it unique\n                }\n                var indexableKey = toIndexableString(complexKey);\n                indexableKeysToKeyValues[indexableKey] = obj;\n                lastKey = obj.key;\n              }\n              docIdsToChangesAndEmits[change.doc._id] = {\n                indexableKeysToKeyValues: indexableKeysToKeyValues,\n                changes: change.changes\n              };\n            }\n            currentSeq = change.seq;\n          }\n          queue.add(processChange(docIdsToChangesAndEmits, currentSeq));\n          if (results.length < CHANGES_BATCH_SIZE) {\n            return complete();\n          }\n          return processNextBatch();\n        }).on('error', onError);\n        /* istanbul ignore next */\n        function onError(err) {\n          reject(err);\n        }\n      }\n\n      processNextBatch();\n    });\n  }\n\n  function reduceView(view, results, options) {\n    if (options.group_level === 0) {\n      delete options.group_level;\n    }\n\n    var shouldGroup = options.group || options.group_level;\n\n    var reduceFun = reducer(view.reduceFun);\n\n    var groups = [];\n    var lvl = options.group_level;\n    results.forEach(function (e) {\n      var last = groups[groups.length - 1];\n      var key = shouldGroup ? e.key : null;\n\n      // only set group_level for array keys\n      if (shouldGroup && Array.isArray(key) && typeof lvl === 'number') {\n        key = key.length > lvl ? key.slice(0, lvl) : key;\n      }\n\n      if (last && collate(last.key[0][0], key) === 0) {\n        last.key.push([key, e.id]);\n        last.value.push(e.value);\n        return;\n      }\n      groups.push({key: [\n        [key, e.id]\n      ], value: [e.value]});\n    });\n    for (var i = 0, len = groups.length; i < len; i++) {\n      var e = groups[i];\n      var reduceTry = tryCode(view.sourceDB, reduceFun, [e.key, e.value, false]);\n      // TODO: can't do instanceof BuiltInError because this class is buried\n      // in mapreduce.js\n      if (reduceTry.error && /BuiltInError/.test(reduceTry.error.constructor)) {\n        // CouchDB returns an error if a built-in errors out\n        throw reduceTry.error;\n      }\n      // CouchDB just sets the value to null if a non-built-in errors out\n      e.value = reduceTry.error ? null : reduceTry.output;\n      e.key = e.key[0][0];\n    }\n    // no total_rows/offset when reducing\n    return {rows: sliceResults(groups, options.limit, options.skip)};\n  }\n\n  function queryView(view, opts) {\n    return utils.sequentialize(getQueue(view), function () {\n      return queryViewInQueue(view, opts);\n    })();\n  }\n\n  function queryViewInQueue(view, opts) {\n    var totalRows;\n    var shouldReduce = view.reduceFun && opts.reduce !== false;\n    var skip = opts.skip || 0;\n    if (typeof opts.keys !== 'undefined' && !opts.keys.length) {\n      // equivalent query\n      opts.limit = 0;\n      delete opts.keys;\n    }\n\n    function fetchFromView(viewOpts) {\n      viewOpts.include_docs = true;\n      return view.db.allDocs(viewOpts).then(function (res) {\n        totalRows = res.total_rows;\n        return res.rows.map(function (result) {\n\n          // implicit migration - in older versions of PouchDB,\n          // we explicitly stored the doc as {id: ..., key: ..., value: ...}\n          // this is tested in a migration test\n          /* istanbul ignore next */\n          if ('value' in result.doc && typeof result.doc.value === 'object' &&\n              result.doc.value !== null) {\n            var keys = Object.keys(result.doc.value).sort();\n            // this detection method is not perfect, but it's unlikely the user\n            // emitted a value which was an object with these 3 exact keys\n            var expectedKeys = ['id', 'key', 'value'];\n            if (!(keys < expectedKeys || keys > expectedKeys)) {\n              return result.doc.value;\n            }\n          }\n\n          var parsedKeyAndDocId = pouchCollate.parseIndexableString(result.doc._id);\n          return {\n            key: parsedKeyAndDocId[0],\n            id: parsedKeyAndDocId[1],\n            value: ('value' in result.doc ? result.doc.value : null)\n          };\n        });\n      });\n    }\n\n    function onMapResultsReady(rows) {\n      var finalResults;\n      if (shouldReduce) {\n        finalResults = reduceView(view, rows, opts);\n      } else {\n        finalResults = {\n          total_rows: totalRows,\n          offset: skip,\n          rows: rows\n        };\n      }\n      if (opts.include_docs) {\n        var docIds = utils.uniq(rows.map(rowToDocId));\n\n        return view.sourceDB.allDocs({\n          keys: docIds,\n          include_docs: true,\n          conflicts: opts.conflicts,\n          attachments: opts.attachments,\n          binary: opts.binary\n        }).then(function (allDocsRes) {\n          var docIdsToDocs = {};\n          allDocsRes.rows.forEach(function (row) {\n            if (row.doc) {\n              docIdsToDocs['$' + row.id] = row.doc;\n            }\n          });\n          rows.forEach(function (row) {\n            var docId = rowToDocId(row);\n            var doc = docIdsToDocs['$' + docId];\n            if (doc) {\n              row.doc = doc;\n            }\n          });\n          return finalResults;\n        });\n      } else {\n        return finalResults;\n      }\n    }\n\n    var flatten = function (array) {\n      return array.reduce(function (prev, cur) {\n        return prev.concat(cur);\n      });\n    };\n\n    if (typeof opts.keys !== 'undefined') {\n      var keys = opts.keys;\n      var fetchPromises = keys.map(function (key) {\n        var viewOpts = {\n          startkey : toIndexableString([key]),\n          endkey   : toIndexableString([key, {}])\n        };\n        return fetchFromView(viewOpts);\n      });\n      return Promise.all(fetchPromises).then(flatten).then(onMapResultsReady);\n    } else { // normal query, no 'keys'\n      var viewOpts = {\n        descending : opts.descending\n      };\n      if (typeof opts.startkey !== 'undefined') {\n        viewOpts.startkey = opts.descending ?\n          toIndexableString([opts.startkey, {}]) :\n          toIndexableString([opts.startkey]);\n      }\n      if (typeof opts.endkey !== 'undefined') {\n        var inclusiveEnd = opts.inclusive_end !== false;\n        if (opts.descending) {\n          inclusiveEnd = !inclusiveEnd;\n        }\n\n        viewOpts.endkey = toIndexableString(inclusiveEnd ? [opts.endkey, {}] : [opts.endkey]);\n      }\n      if (typeof opts.key !== 'undefined') {\n        var keyStart = toIndexableString([opts.key]);\n        var keyEnd = toIndexableString([opts.key, {}]);\n        if (viewOpts.descending) {\n          viewOpts.endkey = keyStart;\n          viewOpts.startkey = keyEnd;\n        } else {\n          viewOpts.startkey = keyStart;\n          viewOpts.endkey = keyEnd;\n        }\n      }\n      if (!shouldReduce) {\n        if (typeof opts.limit === 'number') {\n          viewOpts.limit = opts.limit;\n        }\n        viewOpts.skip = skip;\n      }\n      return fetchFromView(viewOpts).then(onMapResultsReady);\n    }\n  }\n\n  function localViewCleanup(db) {\n    return db.get('_local/' + pluginName).then(function (metaDoc) {\n      var docsToViews = {};\n      Object.keys(metaDoc.views).forEach(function (fullViewName) {\n        var parts = parseViewName(fullViewName);\n        var designDocName = '_design/' + parts[0];\n        var viewName = parts[1];\n        docsToViews[designDocName] = docsToViews[designDocName] || {};\n        docsToViews[designDocName][viewName] = true;\n      });\n      var opts = {\n        keys : Object.keys(docsToViews),\n        include_docs : true\n      };\n      return db.allDocs(opts).then(function (res) {\n        var viewsToStatus = {};\n        res.rows.forEach(function (row) {\n          var ddocName = row.key.substring(8);\n          Object.keys(docsToViews[row.key]).forEach(function (viewName) {\n            var fullViewName = ddocName + '/' + viewName;\n            /* istanbul ignore if */\n            if (!metaDoc.views[fullViewName]) {\n              // new format, without slashes, to support PouchDB 2.2.0\n              // migration test in pouchdb's browser.migration.js verifies this\n              fullViewName = viewName;\n            }\n            var viewDBNames = Object.keys(metaDoc.views[fullViewName]);\n            // design doc deleted, or view function nonexistent\n            var statusIsGood = row.doc && row.doc.views && row.doc.views[viewName];\n            viewDBNames.forEach(function (viewDBName) {\n              viewsToStatus[viewDBName] = viewsToStatus[viewDBName] || statusIsGood;\n            });\n          });\n        });\n        var dbsToDelete = Object.keys(viewsToStatus).filter(function (viewDBName) {\n          return !viewsToStatus[viewDBName];\n        });\n        var destroyPromises = dbsToDelete.map(function (viewDBName) {\n          return utils.sequentialize(getQueue(viewDBName), function () {\n            return new db.constructor(viewDBName, db.__opts).destroy();\n          })();\n        });\n        return Promise.all(destroyPromises).then(function () {\n          return {ok: true};\n        });\n      });\n    }, defaultsTo({ok: true}));\n  }\n\n  function queryPromised(db, fun, opts) {\n    if (typeof fun !== 'string') {\n      // temp_view\n      checkQueryParseError(opts, fun);\n\n      var createViewOpts = {\n        db : db,\n        viewName : 'temp_view/temp_view',\n        map : fun.map,\n        reduce : fun.reduce,\n        temporary : true,\n        pluginName: pluginName\n      };\n      tempViewQueue.add(function () {\n        return createView(createViewOpts).then(function (view) {\n          function cleanup() {\n            return view.db.destroy();\n          }\n          return utils.fin(updateView(view).then(function () {\n            return queryView(view, opts);\n          }), cleanup);\n        });\n      });\n      return tempViewQueue.finish();\n    } else {\n      // persistent view\n      var fullViewName = fun;\n      var parts = parseViewName(fullViewName);\n      var designDocName = parts[0];\n      var viewName = parts[1];\n      return db.get('_design/' + designDocName).then(function (doc) {\n        var fun = doc.views && doc.views[viewName];\n\n        if (!fun) {\n          // basic validator; it's assumed that every subclass would want this\n          throw new NotFoundError('ddoc ' + doc._id + ' has no view named ' +\n            viewName);\n        }\n\n        ddocValidator(doc, viewName);\n        checkQueryParseError(opts, fun);\n\n        var createViewOpts = {\n          db : db,\n          viewName : fullViewName,\n          map : fun.map,\n          reduce : fun.reduce,\n          pluginName: pluginName\n        };\n        return createView(createViewOpts).then(function (view) {\n          if (opts.stale === 'ok' || opts.stale === 'update_after') {\n            if (opts.stale === 'update_after') {\n              process.nextTick(function () {\n                updateView(view);\n              });\n            }\n            return queryView(view, opts);\n          } else { // stale not ok\n            return updateView(view).then(function () {\n              return queryView(view, opts);\n            });\n          }\n        });\n      });\n    }\n  }\n\n  var query = function (fun, opts, callback) {\n    var db = this;\n    if (typeof opts === 'function') {\n      callback = opts;\n      opts = {};\n    }\n    opts = utils.extend(true, {}, opts);\n\n    if (typeof fun === 'function') {\n      fun = {map : fun};\n    }\n\n    var promise = Promise.resolve().then(function () {\n      return queryPromised(db, fun, opts);\n    });\n    utils.promisedCallback(promise, callback);\n    return promise;\n  };\n\n  var viewCleanup = utils.callbackify(function () {\n    var db = this;\n    return localViewCleanup(db);\n  });\n\n  return {\n    query: query,\n    viewCleanup: viewCleanup\n  };\n}\n\nmodule.exports = createIndexer;\n\n\n\n//////////////////\n// WEBPACK FOOTER\n// ./~/pouchdb-find/lib/abstract-mapreduce/index.js\n// module id = 79\n// module chunks = 0","'use strict';\n/*\n * Simple task queue to sequentialize actions. Assumes callbacks will eventually fire (once).\n */\n\nvar Promise = require('./utils').Promise;\n\nfunction TaskQueue() {\n  this.promise = new Promise(function (fulfill) {fulfill(); });\n}\nTaskQueue.prototype.add = function (promiseFactory) {\n  this.promise = this.promise.catch(function () {\n    // just recover\n  }).then(function () {\n    return promiseFactory();\n  });\n  return this.promise;\n};\nTaskQueue.prototype.finish = function () {\n  return this.promise;\n};\n\nmodule.exports = TaskQueue;\n\n\n\n//////////////////\n// WEBPACK FOOTER\n// ./~/pouchdb-find/lib/abstract-mapreduce/taskqueue.js\n// module id = 80\n// module chunks = 0","'use strict';\n\nvar massageCreateIndexRequest = require('../../massageCreateIndexRequest');\n\nfunction createIndex(db, requestDef, callback) {\n  requestDef = massageCreateIndexRequest(requestDef);\n\n  db.request({\n    method: 'POST',\n    url: '_index',\n    body: requestDef\n  }, callback);\n}\n\nfunction find(db, requestDef, callback) {\n  db.request({\n    method: 'POST',\n    url: '_find',\n    body: requestDef\n  }, callback);\n}\n\nfunction getIndexes(db, callback) {\n  db.request({\n    method: 'GET',\n    url: '_index'\n  }, callback);\n}\n\nfunction deleteIndex(db, indexDef, callback) {\n\n\n  var ddoc = indexDef.ddoc;\n  var type = indexDef.type || 'json';\n  var name = indexDef.name;\n\n  if (!ddoc) {\n    return callback(new Error('you must provide an index\\'s ddoc'));\n  }\n\n  if (!name) {\n    return callback(new Error('you must provide an index\\'s name'));\n  }\n\n  var url = '_index/' + [ddoc, type, name].map(encodeURIComponent).join('/');\n\n  db.request({\n    method: 'DELETE',\n    url: url\n  }, callback);\n}\n\nexports.createIndex = createIndex;\nexports.find = find;\nexports.getIndexes = getIndexes;\nexports.deleteIndex = deleteIndex;\n\n\n//////////////////\n// WEBPACK FOOTER\n// ./~/pouchdb-find/lib/adapters/http/index.js\n// module id = 81\n// module chunks = 0","'use strict';\n\nvar utils = require('../../../utils');\nvar log = utils.log;\n\nvar pouchUpsert = require('pouchdb-upsert');\nvar abstractMapper = require('../abstract-mapper');\nvar localUtils = require('../utils');\nvar validateIndex = localUtils.validateIndex;\nvar massageIndexDef = localUtils.massageIndexDef;\nvar massageCreateIndexRequest = require('../../../massageCreateIndexRequest');\n\nfunction upsert(db, docId, diffFun) {\n  return pouchUpsert.upsert.call(db, docId, diffFun);\n}\n\nfunction createIndex(db, requestDef) {\n  requestDef = massageCreateIndexRequest(requestDef);\n  var originalIndexDef = utils.clone(requestDef.index);\n  requestDef.index = massageIndexDef(requestDef.index);\n\n  validateIndex(requestDef.index);\n\n  var md5 = utils.MD5(JSON.stringify(requestDef));\n\n  var viewName = requestDef.name || ('idx-' + md5);\n\n  var ddocName = requestDef.ddoc || ('idx-' + md5);\n  var ddocId = '_design/' + ddocName;\n\n  var hasInvalidLanguage = false;\n  var viewExists = false;\n\n  function updateDdoc(doc) {\n    if (doc._rev && doc.language !== 'query') {\n      hasInvalidLanguage = true;\n    }\n    doc.language = 'query';\n    doc.views = doc.views || {};\n\n    viewExists = !!doc.views[viewName];\n\n    if (viewExists) {\n      return false;\n    }\n\n    doc.views[viewName] = {\n      map: {\n        fields: utils.mergeObjects(requestDef.index.fields)\n      },\n      reduce: '_count',\n      options: {\n        def: originalIndexDef\n      }\n    };\n\n    return doc;\n  }\n\n  log('creating index', ddocId);\n\n  return upsert(db, ddocId, updateDdoc).then(function () {\n    if (hasInvalidLanguage) {\n      throw new Error('invalid language for ddoc with id \"' +\n      ddocId +\n      '\" (should be \"query\")');\n    }\n  }).then(function () {\n    // kick off a build\n    // TODO: abstract-pouchdb-mapreduce should support auto-updating\n    // TODO: should also use update_after, but pouchdb/pouchdb#3415 blocks me\n    var signature = ddocName + '/' + viewName;\n    return abstractMapper.query.call(db, signature, {\n      limit: 0,\n      reduce: false\n    }).then(function () {\n      return {\n        id: ddocId,\n        name: viewName,\n        result: viewExists ? 'exists' : 'created'\n      };\n    });\n  });\n}\n\nmodule.exports = createIndex;\n\n\n\n//////////////////\n// WEBPACK FOOTER\n// ./~/pouchdb-find/lib/adapters/local/create-index/index.js\n// module id = 82\n// module chunks = 0","'use strict';\n\nvar abstractMapper = require('../abstract-mapper');\nvar upsert = require('../../../abstract-mapreduce/upsert');\n\nfunction deleteIndex(db, index) {\n\n  if (!index.ddoc) {\n    throw new Error('you must supply an index.ddoc when deleting');\n  }\n\n  if (!index.name) {\n    throw new Error('you must supply an index.name when deleting');\n  }\n\n  var docId = index.ddoc;\n  var viewName = index.name;\n\n  function deltaFun (doc) {\n    if (Object.keys(doc.views).length === 1 && doc.views[viewName]) {\n      // only one view in this ddoc, delete the whole ddoc\n      return {_id: docId, _deleted: true};\n    }\n    // more than one view here, just remove the view\n    delete doc.views[viewName];\n    return doc;\n  }\n\n  return upsert(db, docId, deltaFun).then(function () {\n    return abstractMapper.viewCleanup.apply(db);\n  }).then(function () {\n    return {ok: true};\n  });\n}\n\nmodule.exports = deleteIndex;\n\n\n//////////////////\n// WEBPACK FOOTER\n// ./~/pouchdb-find/lib/adapters/local/delete-index/index.js\n// module id = 83\n// module chunks = 0","'use strict';\n\n//\n// Do an in-memory filtering of rows that aren't covered by the index.\n// E.g. if the user is asking for foo=1 and bar=2, but the index\n// only covers \"foo\", then this in-memory filter would take care of\n// \"bar\".\n//\n\nvar isArray = require('is-array');\nvar collate = require('pouchdb-collate').collate;\nvar localUtils = require('../utils');\nvar isCombinationalField = localUtils.isCombinationalField;\nvar getKey = localUtils.getKey;\nvar getValue = localUtils.getValue;\nvar parseField = localUtils.parseField;\nvar utils = require('../../../utils');\nvar getFieldFromDoc = utils.getFieldFromDoc;\n\n// create a comparator based on the sort object\nfunction createFieldSorter(sort) {\n\n  function getFieldValuesAsArray(doc) {\n    return sort.map(function (sorting) {\n      var fieldName = getKey(sorting);\n      var parsedField = parseField(fieldName);\n      var docFieldValue = getFieldFromDoc(doc, parsedField);\n      return docFieldValue;\n    });\n  }\n\n  return function (aRow, bRow) {\n    var aFieldValues = getFieldValuesAsArray(aRow.doc);\n    var bFieldValues = getFieldValuesAsArray(bRow.doc);\n    var collation = collate(aFieldValues, bFieldValues);\n    if (collation !== 0) {\n      return collation;\n    }\n    // this is what mango seems to do\n    return utils.compare(aRow.doc._id, bRow.doc._id);\n  };\n}\n\nfunction filterInMemoryFields (rows, requestDef, inMemoryFields) {\n  rows = rows.filter(function (row) {\n    return rowFilter(row.doc, requestDef.selector, inMemoryFields);\n  });\n\n  if (requestDef.sort) {\n    // in-memory sort\n    var fieldSorter = createFieldSorter(requestDef.sort);\n    rows = rows.sort(fieldSorter);\n    if (typeof requestDef.sort[0] !== 'string' &&\n        getValue(requestDef.sort[0]) === 'desc') {\n      rows = rows.reverse();\n    }\n  }\n\n  if ('limit' in requestDef || 'skip' in requestDef) {\n    // have to do the limit in-memory\n    var skip = requestDef.skip || 0;\n    var limit = ('limit' in requestDef ? requestDef.limit : rows.length) + skip;\n    rows = rows.slice(skip, limit);\n  }\n  return rows;\n}\n\nfunction rowFilter (doc, selector, inMemoryFields) {\n  return inMemoryFields.every(function (field) {\n    var matcher = selector[field];\n    var parsedField = parseField(field);\n    var docFieldValue = getFieldFromDoc(doc, parsedField);\n    if (isCombinationalField(field)) {\n      return matchCominationalSelector(field, matcher, doc);\n    }\n\n    return matchSelector(matcher, doc, parsedField, docFieldValue);\n  });\n}\n\nfunction matchSelector (matcher, doc, parsedField, docFieldValue) {\n  if (!matcher) {\n    // no filtering necessary; this field is just needed for sorting\n    return true;\n  }\n\n  return Object.keys(matcher).every(function (userOperator) {\n    var userValue = matcher[userOperator];\n    return match(userOperator, doc, userValue, parsedField, docFieldValue);\n  });\n}\n\nfunction matchCominationalSelector (field, matcher, doc) {\n\n  if (field === '$or') {\n    return matcher.some(function (orMatchers) {\n      return rowFilter(doc, orMatchers, Object.keys(orMatchers));\n    });\n  }\n\n  if (field === '$not') {\n    return !rowFilter(doc, matcher, Object.keys(matcher));\n  }\n\n  //`$nor`\n  return !matcher.find(function (orMatchers) {\n    return rowFilter(doc, orMatchers, Object.keys(orMatchers));\n  });\n\n}\n\nfunction match(userOperator, doc, userValue, parsedField, docFieldValue) {\n  if (!matchers[userOperator]) {\n    throw new Error('unknown operator \"' + userOperator +\n      '\" - should be one of $eq, $lte, $lt, $gt, $gte, $exists, $ne, $in, ' +\n      '$nin, $size, $mod, $regex, $elemMatch, $type or $all');\n  }\n  return matchers[userOperator](doc, userValue, parsedField, docFieldValue);\n}\n\nfunction fieldExists(docFieldValue) {\n  return typeof docFieldValue !== 'undefined' && docFieldValue !== null;\n}\n\nfunction fieldIsNotUndefined(docFieldValue) {\n  return typeof docFieldValue !== 'undefined';\n}\n\nfunction modField (docFieldValue, userValue) {\n  var divisor = userValue[0];\n  var mod = userValue[1];\n  if (divisor === 0) {\n    throw new Error('Bad divisor, cannot divide by zero');\n  }\n\n  if (parseInt(divisor, 10) !== divisor ) {\n    throw new Error('Divisor is not an integer');\n  }\n\n  if (parseInt(mod, 10) !== mod ) {\n    throw new Error('Modulus is not an integer');\n  }\n\n  if (parseInt(docFieldValue, 10) !== docFieldValue) {\n    return false;\n  }\n\n  return docFieldValue % divisor === mod;\n}\n\nfunction arrayContainsValue (docFieldValue, userValue) {\n  return userValue.some(function (val) {\n    if (docFieldValue instanceof Array) {\n      return docFieldValue.indexOf(val) > -1;\n    }\n\n    return docFieldValue === val;\n  });\n}\n\nfunction arrayContainsAllValues (docFieldValue, userValue) {\n  return userValue.every(function (val) {\n    return docFieldValue.indexOf(val) > -1;\n  });\n}\n\nfunction arraySize (docFieldValue, userValue) {\n  return docFieldValue.length === userValue;\n}\n\nfunction regexMatch(docFieldValue, userValue) {\n  var re = new RegExp(userValue);\n\n  return re.test(docFieldValue);\n}\n\nfunction typeMatch(docFieldValue, userValue) {\n\n  switch (userValue) {\n    case 'null':\n      return docFieldValue === null;\n    case 'boolean':\n      return typeof(docFieldValue) === 'boolean';\n    case 'number':\n      return typeof(docFieldValue) === 'number';\n    case 'string':\n      return typeof(docFieldValue) === 'string';\n    case 'array':\n      return docFieldValue instanceof Array;\n    case 'object':\n      return ({}).toString.call(docFieldValue) === '[object Object]';\n  }\n\n  throw new Error(userValue + ' not supported as a type.' +\n                  'Please use one of object, string, array, number, boolean or null.');\n\n}\n\nvar matchers = {\n\n  '$elemMatch': function (doc, userValue, parsedField, docFieldValue) {\n    if (!isArray(docFieldValue)) {\n      return false;\n    }\n\n    if (docFieldValue.length === 0) {\n      return false;\n    }\n\n    if (typeof docFieldValue[0] === 'object') {\n      return docFieldValue.some(function (val) {\n        return rowFilter(val, userValue, Object.keys(userValue));\n      });\n    }\n\n    return docFieldValue.some(function (val) {\n      return matchSelector(userValue, doc, parsedField, val);\n    });\n  },\n\n  '$eq': function (doc, userValue, parsedField, docFieldValue) {\n    return fieldIsNotUndefined(docFieldValue) && collate(docFieldValue, userValue) === 0;\n  },\n\n  '$gte': function (doc, userValue, parsedField, docFieldValue) {\n    return fieldIsNotUndefined(docFieldValue) && collate(docFieldValue, userValue) >= 0;\n  },\n\n  '$gt': function (doc, userValue, parsedField, docFieldValue) {\n    return fieldIsNotUndefined(docFieldValue) && collate(docFieldValue, userValue) > 0;\n  },\n\n  '$lte': function (doc, userValue, parsedField, docFieldValue) {\n    return fieldIsNotUndefined(docFieldValue) && collate(docFieldValue, userValue) <= 0;\n  },\n\n  '$lt': function (doc, userValue, parsedField, docFieldValue) {\n    return fieldIsNotUndefined(docFieldValue) && collate(docFieldValue, userValue) < 0;\n  },\n\n  '$exists': function (doc, userValue, parsedField, docFieldValue) {\n    //a field that is null is still considered to exist\n    if (userValue) {\n      return fieldIsNotUndefined(docFieldValue);\n    }\n\n    return !fieldIsNotUndefined(docFieldValue);\n  },\n\n  '$mod': function (doc, userValue, parsedField, docFieldValue) {\n    return fieldExists(docFieldValue) && modField(docFieldValue, userValue);\n  },\n\n  '$ne': function (doc, userValue, parsedField, docFieldValue) {\n    return userValue.every(function (neValue) {\n      return collate(docFieldValue, neValue) !== 0;\n    });\n  },\n  '$in': function (doc, userValue, parsedField, docFieldValue) {\n    return fieldExists(docFieldValue) && arrayContainsValue(docFieldValue, userValue);\n  },\n\n  '$nin': function (doc, userValue, parsedField, docFieldValue) {\n    return fieldExists(docFieldValue) && !arrayContainsValue(docFieldValue, userValue);\n  },\n\n  '$size': function (doc, userValue, parsedField, docFieldValue) {\n    return fieldExists(docFieldValue) && arraySize(docFieldValue, userValue);\n  },\n\n  '$all': function (doc, userValue, parsedField, docFieldValue) {\n    return isArray(docFieldValue) && arrayContainsAllValues(docFieldValue, userValue);\n  },\n\n  '$regex': function (doc, userValue, parsedField, docFieldValue) {\n    return fieldExists(docFieldValue) && regexMatch(docFieldValue, userValue);\n  },\n\n  '$type': function (doc, userValue, parsedField, docFieldValue) {\n    return typeMatch(docFieldValue, userValue);\n  }\n};\n\nmodule.exports = filterInMemoryFields;\n\n\n\n//////////////////\n// WEBPACK FOOTER\n// ./~/pouchdb-find/lib/adapters/local/find/in-memory-filter.js\n// module id = 84\n// module chunks = 0","'use strict';\n\nvar utils = require('../../../utils');\nvar clone = utils.clone;\nvar getIndexes = require('../get-indexes');\nvar collate = require('pouchdb-collate').collate;\nvar abstractMapper = require('../abstract-mapper');\nvar planQuery = require('./query-planner');\nvar localUtils = require('../utils');\nvar filterInMemoryFields = require('./in-memory-filter');\nvar massageSelector = localUtils.massageSelector;\nvar massageSort = localUtils.massageSort;\nvar getValue = localUtils.getValue;\nvar validateFindRequest = localUtils.validateFindRequest;\nvar validateSort = localUtils.validateSort;\nvar reverseOptions = localUtils.reverseOptions;\nvar filterInclusiveStart = localUtils.filterInclusiveStart;\nvar Promise = utils.Promise;\n\nfunction indexToSignature(index) {\n  // remove '_design/'\n  return index.ddoc.substring(8) + '/' + index.name;\n}\n\nfunction doAllDocs(db, originalOpts) {\n  var opts = clone(originalOpts);\n\n  // CouchDB responds in weird ways when you provide a non-string to _id;\n  // we mimic the behavior for consistency. See issue66 tests for details.\n\n  if (opts.descending) {\n    if ('endkey' in opts && typeof opts.endkey !== 'string') {\n      opts.endkey = '';\n    }\n    if ('startkey' in opts && typeof opts.startkey !== 'string') {\n      opts.limit = 0;\n    }\n  } else {\n    if ('startkey' in opts && typeof opts.startkey !== 'string') {\n      opts.startkey = '';\n    }\n    if ('endkey' in opts && typeof opts.endkey !== 'string') {\n      opts.limit = 0;\n    }\n  }\n  if ('key' in opts && typeof opts.key !== 'string') {\n    opts.limit = 0;\n  }\n\n  return db.allDocs(opts);\n}\n\nfunction find(db, requestDef) {\n\n  if (requestDef.selector) {\n    requestDef.selector = massageSelector(requestDef.selector);\n  }\n  if (requestDef.sort) {\n    requestDef.sort = massageSort(requestDef.sort);\n  }\n\n  validateFindRequest(requestDef);\n\n  return getIndexes(db).then(function (getIndexesRes) {\n\n    var queryPlan = planQuery(requestDef, getIndexesRes.indexes);\n\n    var indexToUse = queryPlan.index;\n\n    validateSort(requestDef, indexToUse);\n\n    var opts = utils.extend(true, {\n      include_docs: true,\n      reduce: false\n    }, queryPlan.queryOpts);\n\n    if ('startkey' in opts && 'endkey' in opts &&\n        collate(opts.startkey, opts.endkey) > 0) {\n      // can't possibly return any results, startkey > endkey\n      return {docs: []};\n    }\n\n    var isDescending = requestDef.sort &&\n      typeof requestDef.sort[0] !== 'string' &&\n      getValue(requestDef.sort[0]) === 'desc';\n\n    if (isDescending) {\n      // either all descending or all ascending\n      opts.descending = true;\n      opts = reverseOptions(opts);\n    }\n\n    if (!queryPlan.inMemoryFields.length) {\n      // no in-memory filtering necessary, so we can let the\n      // database do the limit/skip for us\n      if ('limit' in requestDef) {\n        opts.limit = requestDef.limit;\n      }\n      if ('skip' in requestDef) {\n        opts.skip = requestDef.skip;\n      }\n    }\n\n    return Promise.resolve().then(function () {\n      if (indexToUse.name === '_all_docs') {\n        return doAllDocs(db, opts);\n      } else {\n        var signature = indexToSignature(indexToUse);\n        return abstractMapper.query.call(db, signature, opts);\n      }\n    }).then(function (res) {\n\n      if (opts.inclusive_start === false) {\n        // may have to manually filter the first one,\n        // since couchdb has no true inclusive_start option\n        res.rows = filterInclusiveStart(res.rows, opts.startkey, indexToUse);\n      }\n\n      if (queryPlan.inMemoryFields.length) {\n        // need to filter some stuff in-memory\n        res.rows = filterInMemoryFields(res.rows, requestDef, queryPlan.inMemoryFields);\n      }\n\n      var resp = {\n        docs: res.rows.map(function (row) {\n          var doc = row.doc;\n          if (requestDef.fields) {\n            return utils.pick(doc, requestDef.fields);\n          }\n          return doc;\n        })\n      };\n\n      if (indexToUse.defaultUsed) {\n        resp.warning = 'no matching index found, create an index to optimize query time';\n      }\n\n      return resp;\n    });\n  });\n}\n\nmodule.exports = find;\n\n\n\n//////////////////\n// WEBPACK FOOTER\n// ./~/pouchdb-find/lib/adapters/local/find/index.js\n// module id = 85\n// module chunks = 0","'use strict';\n\nvar utils = require('../../../utils');\nvar log = utils.log;\nvar localUtils = require('../utils');\nvar getKey = localUtils.getKey;\nvar getUserFields = localUtils.getUserFields;\n\n// couchdb lowest collation value\nvar COLLATE_LO = null;\n\n// couchdb highest collation value (TODO: well not really, but close enough amirite)\nvar COLLATE_HI = {\"\\uffff\": {}};\n\n// couchdb second-lowest collation value\n\nfunction checkFieldInIndex(index, field) {\n  var indexFields = index.def.fields.map(getKey);\n  for (var i = 0, len = indexFields.length; i < len; i++) {\n    var indexField = indexFields[i];\n    if (field === indexField) {\n      return true;\n    }\n  }\n  return false;\n}\n\n// so when you do e.g. $eq/$eq, we can do it entirely in the database.\n// but when you do e.g. $gt/$eq, the first part can be done\n// in the database, but the second part has to be done in-memory,\n// because $gt has forced us to lose precision.\n// so that's what this determines\nfunction userOperatorLosesPrecision(selector, field) {\n  var matcher = selector[field];\n  var userOperator = getKey(matcher);\n\n  return userOperator !== '$eq';\n}\n\n// sort the user fields by their position in the index,\n// if they're in the index\nfunction sortFieldsByIndex(userFields, index) {\n  var indexFields = index.def.fields.map(getKey);\n\n  return userFields.slice().sort(function (a, b) {\n    var aIdx = indexFields.indexOf(a);\n    var bIdx = indexFields.indexOf(b);\n    if (aIdx === -1) {\n      aIdx = Number.MAX_VALUE;\n    }\n    if (bIdx === -1) {\n      bIdx = Number.MAX_VALUE;\n    }\n    return utils.compare(aIdx, bIdx);\n  });\n}\n\n// first pass to try to find fields that will need to be sorted in-memory\nfunction getBasicInMemoryFields(index, selector, userFields) {\n\n  userFields = sortFieldsByIndex(userFields, index);\n\n  // check if any of the user selectors lose precision\n  var needToFilterInMemory = false;\n  for (var i = 0, len = userFields.length; i < len; i++) {\n    var field = userFields[i];\n    if (needToFilterInMemory || !checkFieldInIndex(index, field)) {\n      return userFields.slice(i);\n    }\n    if (i < len - 1 && userOperatorLosesPrecision(selector, field)) {\n      needToFilterInMemory = true;\n    }\n  }\n  return [];\n}\n\nfunction getInMemoryFieldsFromNe(selector) {\n  var fields = [];\n  Object.keys(selector).forEach(function (field) {\n    var matcher = selector[field];\n    Object.keys(matcher).forEach(function (operator) {\n      if (operator === '$ne') {\n        fields.push(field);\n      }\n    });\n  });\n  return fields;\n}\n\nfunction getInMemoryFields(coreInMemoryFields, index, selector, userFields) {\n  var result = utils.flatten(\n    // in-memory fields reported as necessary by the query planner\n    coreInMemoryFields,\n    // combine with another pass that checks for any we may have missed\n    getBasicInMemoryFields(index, selector, userFields),\n    // combine with another pass that checks for $ne's\n    getInMemoryFieldsFromNe(selector)\n  );\n\n  return sortFieldsByIndex(utils.uniq(result), index);\n}\n\n// check that at least one field in the user's query is represented\n// in the index. order matters in the case of sorts\nfunction checkIndexFieldsMatch(indexFields, sortOrder, fields) {\n  if (sortOrder) {\n    // array has to be a strict subarray of index array. furthermore,\n    // the sortOrder fields need to all be represented in the index\n    var sortMatches = utils.oneArrayIsStrictSubArrayOfOther(sortOrder, indexFields);\n    var selectorMatches = utils.oneArrayIsSubArrayOfOther(fields, indexFields);\n\n    return sortMatches && selectorMatches;\n  }\n\n  // all of the user's specified fields still need to be\n  // on the left side of the index array, although the order\n  // doesn't matter\n  return utils.oneSetIsSubArrayOfOther(fields, indexFields);\n}\n\nvar logicalMatchers = ['$eq', '$gt', '$gte', '$lt', '$lte'];\nfunction isNonLogicalMatcher (matcher) {\n  return logicalMatchers.indexOf(matcher) === -1;\n}\n\n// check all the index fields for usages of '$ne'\n// e.g. if the user queries {foo: {$ne: 'foo'}, bar: {$eq: 'bar'}},\n// then we can neither use an index on ['foo'] nor an index on\n// ['foo', 'bar'], but we can use an index on ['bar'] or ['bar', 'foo']\nfunction checkFieldsLogicallySound(indexFields, selector) {\n  var firstField = indexFields[0];\n  var matcher = selector[firstField];\n\n  var hasLogicalOperator = Object.keys(matcher).some(function (matcherKey) {\n    return !(isNonLogicalMatcher(matcherKey));\n  });\n\n  if (!hasLogicalOperator) {\n    return false;\n  }\n\n  var isInvalidNe = Object.keys(matcher).length === 1 &&\n    getKey(matcher) === '$ne';\n\n  return !isInvalidNe;\n}\n\nfunction checkIndexMatches(index, sortOrder, fields, selector) {\n\n  var indexFields = index.def.fields.map(getKey);\n\n  var fieldsMatch = checkIndexFieldsMatch(indexFields, sortOrder, fields);\n\n  if (!fieldsMatch) {\n    return false;\n  }\n\n  return checkFieldsLogicallySound(indexFields, selector);\n}\n\n//\n// the algorithm is very simple:\n// take all the fields the user supplies, and if those fields\n// are a strict subset of the fields in some index,\n// then use that index\n//\n//\nfunction findMatchingIndexes(selector, userFields, sortOrder, indexes) {\n\n  return indexes.reduce(function (res, index) {\n    var indexMatches = checkIndexMatches(index, sortOrder, userFields, selector);\n    if (indexMatches) {\n      res.push(index);\n    }\n    return res;\n  }, []);\n}\n\n// find the best index, i.e. the one that matches the most fields\n// in the user's query\nfunction findBestMatchingIndex(selector, userFields, sortOrder, indexes) {\n\n  var matchingIndexes = findMatchingIndexes(selector, userFields, sortOrder, indexes);\n\n  if (matchingIndexes.length === 0) {\n    //return `all_docs` as a default index;\n    //I'm assuming that _all_docs is always first\n    var defaultIndex = indexes[0];\n    defaultIndex.defaultUsed = true;\n    return defaultIndex;\n  }\n  if (matchingIndexes.length === 1) {\n    return matchingIndexes[0];\n  }\n\n  var userFieldsMap = utils.arrayToObject(userFields);\n\n  function scoreIndex(index) {\n    var indexFields = index.def.fields.map(getKey);\n    var score = 0;\n    for (var i = 0, len = indexFields.length; i < len; i++) {\n      var indexField = indexFields[i];\n      if (userFieldsMap[indexField]) {\n        score++;\n      }\n    }\n    return score;\n  }\n\n  return utils.max(matchingIndexes, scoreIndex);\n}\n\nfunction getSingleFieldQueryOptsFor(userOperator, userValue) {\n  switch (userOperator) {\n    case '$eq':\n      return {key: userValue};\n    case '$lte':\n      return {endkey: userValue};\n    case '$gte':\n      return {startkey: userValue};\n    case '$lt':\n      return {\n        endkey: userValue,\n        inclusive_end: false\n      };\n    case '$gt':\n      return {\n        startkey: userValue,\n        inclusive_start: false\n      };\n  }\n}\n\nfunction getSingleFieldCoreQueryPlan(selector, index) {\n  var field = getKey(index.def.fields[0]);\n  var matcher = selector[field];\n  var inMemoryFields = [];\n\n  var userOperators = Object.keys(matcher);\n\n  var combinedOpts;\n\n  userOperators.forEach(function (userOperator) {\n\n    if (isNonLogicalMatcher(userOperator)) {\n      inMemoryFields.push(field);\n      return;\n    }\n\n    var userValue = matcher[userOperator];\n\n    var newQueryOpts = getSingleFieldQueryOptsFor(userOperator, userValue);\n\n    if (combinedOpts) {\n      combinedOpts = utils.mergeObjects([combinedOpts, newQueryOpts]);\n    } else {\n      combinedOpts = newQueryOpts;\n    }\n  });\n\n  return {\n    queryOpts: combinedOpts,\n    inMemoryFields: inMemoryFields\n  };\n}\n\nfunction getMultiFieldCoreQueryPlan(userOperator, userValue) {\n  switch (userOperator) {\n    case '$eq':\n      return {\n        startkey: userValue,\n        endkey: userValue\n      };\n    case '$lte':\n      return {\n        endkey: userValue\n      };\n    case '$gte':\n      return {\n        startkey: userValue\n      };\n    case '$lt':\n      return {\n        endkey: userValue,\n        inclusive_end: false\n      };\n    case '$gt':\n      return {\n        startkey: userValue,\n        inclusive_start: false\n      };\n  }\n}\n\nfunction getMultiFieldQueryOpts(selector, index) {\n\n  var indexFields = index.def.fields.map(getKey);\n\n  var inMemoryFields = [];\n  var startkey = [];\n  var endkey = [];\n  var inclusiveStart;\n  var inclusiveEnd;\n\n\n  function finish(i) {\n\n    if (inclusiveStart !== false) {\n      startkey.push(COLLATE_LO);\n    }\n    if (inclusiveEnd !== false) {\n      endkey.push(COLLATE_HI);\n    }\n    // keep track of the fields where we lost specificity,\n    // and therefore need to filter in-memory\n    inMemoryFields = indexFields.slice(i);\n  }\n\n  for (var i = 0, len = indexFields.length; i < len; i++) {\n    var indexField = indexFields[i];\n\n    var matcher = selector[indexField];\n\n    if (!matcher) { // fewer fields in user query than in index\n      finish(i);\n      break;\n    } else if (i > 0) {\n      if ('$ne' in matcher) { // unusable $ne index\n        finish(i);\n        break;\n      }\n      var usingGtlt = (\n        '$gt' in matcher || '$gte' in matcher ||\n        '$lt' in matcher || '$lte' in matcher);\n      var previousKeys = Object.keys(selector[indexFields[i - 1]]);\n      var previousWasEq = utils.arrayEquals(previousKeys, ['$eq']);\n      var previousWasSame = utils.arrayEquals(previousKeys, Object.keys(matcher));\n      var gtltLostSpecificity = usingGtlt && !previousWasEq && !previousWasSame;\n      if (gtltLostSpecificity) {\n        finish(i);\n        break;\n      }\n    }\n\n    var userOperators = Object.keys(matcher);\n\n    var combinedOpts = null;\n\n    for (var j = 0; j < userOperators.length; j++) {\n      var userOperator = userOperators[j];\n      var userValue = matcher[userOperator];\n\n      var newOpts = getMultiFieldCoreQueryPlan(userOperator, userValue);\n\n      if (combinedOpts) {\n        combinedOpts = utils.mergeObjects([combinedOpts, newOpts]);\n      } else {\n        combinedOpts = newOpts;\n      }\n    }\n\n    startkey.push('startkey' in combinedOpts ? combinedOpts.startkey : COLLATE_LO);\n    endkey.push('endkey' in combinedOpts ? combinedOpts.endkey : COLLATE_HI);\n    if ('inclusive_start' in combinedOpts) {\n      inclusiveStart = combinedOpts.inclusive_start;\n    }\n    if ('inclusive_end' in combinedOpts) {\n      inclusiveEnd = combinedOpts.inclusive_end;\n    }\n  }\n\n  var res = {\n    startkey: startkey,\n    endkey: endkey\n  };\n\n  if (typeof inclusiveStart !== 'undefined') {\n    res.inclusive_start = inclusiveStart;\n  }\n  if (typeof inclusiveEnd !== 'undefined') {\n    res.inclusive_end = inclusiveEnd;\n  }\n\n  return {\n    queryOpts: res,\n    inMemoryFields: inMemoryFields\n  };\n}\n\nfunction getDefaultQueryPlan () {\n  return {\n    queryOpts: {startkey: null},\n    //getInMemoryFields will do the work here later\n    inMemoryFields: []\n  };\n}\n\nfunction getCoreQueryPlan(selector, index) {\n  if (index.defaultUsed) {\n    return getDefaultQueryPlan(selector, index);\n  }\n\n  if (index.def.fields.length === 1) {\n    // one field in index, so the value was indexed as a singleton\n    return getSingleFieldCoreQueryPlan(selector, index);\n  }\n  // else index has multiple fields, so the value was indexed as an array\n  return getMultiFieldQueryOpts(selector, index);\n}\n\nfunction planQuery(request, indexes) {\n\n  log('planning query', request);\n\n  var selector = request.selector;\n  var sort = request.sort;\n\n  var userFieldsRes = getUserFields(selector, sort);\n\n  var userFields = userFieldsRes.fields;\n  var sortOrder = userFieldsRes.sortOrder;\n  var index = findBestMatchingIndex(selector, userFields, sortOrder, indexes);\n\n  var coreQueryPlan = getCoreQueryPlan(selector, index);\n  var queryOpts = coreQueryPlan.queryOpts;\n  var coreInMemoryFields = coreQueryPlan.inMemoryFields;\n\n  var inMemoryFields = getInMemoryFields(coreInMemoryFields, index, selector, userFields);\n\n  var res = {\n    queryOpts: queryOpts,\n    index: index,\n    inMemoryFields: inMemoryFields\n  };\n  log('query plan', res);\n  return res;\n}\n\nmodule.exports = planQuery;\n\n\n\n//////////////////\n// WEBPACK FOOTER\n// ./~/pouchdb-find/lib/adapters/local/find/query-planner.js\n// module id = 86\n// module chunks = 0","'use strict';\n\nvar utils = require('../../utils');\nvar callbackify = utils.callbackify;\n\nexports.createIndex = callbackify(require('./create-index'));\nexports.find = callbackify(require('./find'));\nexports.getIndexes = callbackify(require('./get-indexes'));\nexports.deleteIndex = callbackify(require('./delete-index'));\n\n\n//////////////////\n// WEBPACK FOOTER\n// ./~/pouchdb-find/lib/adapters/local/index.js\n// module id = 87\n// module chunks = 0","'use strict';\n\nvar utils = require('./utils');\n\nvar httpIndexes = require('./adapters/http');\nvar localIndexes = require('./adapters/local');\n\nvar plugin = {};\nplugin.createIndex = utils.toPromise(function (requestDef, callback) {\n\n  if (typeof requestDef !== 'object') {\n    return callback(new Error('you must provide an index to create'));\n  }\n\n  var adapter = this.type() === 'http' ? httpIndexes : localIndexes;\n\n  adapter.createIndex(this, requestDef, callback);\n});\n\nplugin.find = utils.toPromise(function (requestDef, callback) {\n\n  if (typeof callback === 'undefined') {\n    callback = requestDef;\n    requestDef = undefined;\n  }\n\n  if (typeof requestDef !== 'object') {\n    return callback(new Error('you must provide search parameters to find()'));\n  }\n\n  var adapter = this.type() === 'http' ? httpIndexes : localIndexes;\n\n  adapter.find(this, requestDef, callback);\n});\n\nplugin.getIndexes = utils.toPromise(function (callback) {\n\n  var adapter = this.type() === 'http' ? httpIndexes : localIndexes;\n\n  adapter.getIndexes(this, callback);\n});\n\nplugin.deleteIndex = utils.toPromise(function (indexDef, callback) {\n\n  if (typeof indexDef !== 'object') {\n    return callback(new Error('you must provide an index to delete'));\n  }\n\n  var adapter = this.type() === 'http' ? httpIndexes : localIndexes;\n\n  adapter.deleteIndex(this, indexDef, callback);\n});\n\nmodule.exports = plugin;\n\n/* istanbul ignore next */\nif (typeof window !== 'undefined' && window.PouchDB) {\n  window.PouchDB.plugin(plugin);\n}\n\n\n\n//////////////////\n// WEBPACK FOOTER\n// ./~/pouchdb-find/lib/index.js\n// module id = 88\n// module chunks = 0","'use strict';\n\nfunction _interopDefault (ex) { return (ex && (typeof ex === 'object') && 'default' in ex) ? ex['default'] : ex; }\n\nvar lie = _interopDefault(require('lie'));\nvar getArguments = _interopDefault(require('argsarray'));\nvar debug = _interopDefault(require('debug'));\nvar events = require('events');\nvar inherits = _interopDefault(require('inherits'));\nvar nextTick = _interopDefault(require('immediate'));\nvar scopedEval = _interopDefault(require('scope-eval'));\nvar Md5 = _interopDefault(require('spark-md5'));\nvar vuvuzela = _interopDefault(require('vuvuzela'));\n\n/* istanbul ignore next */\nvar PouchPromise$1 = typeof Promise === 'function' ? Promise : lie;\n\nfunction isBinaryObject(object) {\n  return (typeof ArrayBuffer !== 'undefined' && object instanceof ArrayBuffer) ||\n    (typeof Blob !== 'undefined' && object instanceof Blob);\n}\n\nfunction cloneArrayBuffer(buff) {\n  if (typeof buff.slice === 'function') {\n    return buff.slice(0);\n  }\n  // IE10-11 slice() polyfill\n  var target = new ArrayBuffer(buff.byteLength);\n  var targetArray = new Uint8Array(target);\n  var sourceArray = new Uint8Array(buff);\n  targetArray.set(sourceArray);\n  return target;\n}\n\nfunction cloneBinaryObject(object) {\n  if (object instanceof ArrayBuffer) {\n    return cloneArrayBuffer(object);\n  }\n  var size = object.size;\n  var type = object.type;\n  // Blob\n  if (typeof object.slice === 'function') {\n    return object.slice(0, size, type);\n  }\n  // PhantomJS slice() replacement\n  return object.webkitSlice(0, size, type);\n}\n\n// most of this is borrowed from lodash.isPlainObject:\n// https://github.com/fis-components/lodash.isplainobject/\n// blob/29c358140a74f252aeb08c9eb28bef86f2217d4a/index.js\n\nvar funcToString = Function.prototype.toString;\nvar objectCtorString = funcToString.call(Object);\n\nfunction isPlainObject(value) {\n  var proto = Object.getPrototypeOf(value);\n  /* istanbul ignore if */\n  if (proto === null) { // not sure when this happens, but I guess it can\n    return true;\n  }\n  var Ctor = proto.constructor;\n  return (typeof Ctor == 'function' &&\n    Ctor instanceof Ctor && funcToString.call(Ctor) == objectCtorString);\n}\n\nfunction clone(object) {\n  var newObject;\n  var i;\n  var len;\n\n  if (!object || typeof object !== 'object') {\n    return object;\n  }\n\n  if (Array.isArray(object)) {\n    newObject = [];\n    for (i = 0, len = object.length; i < len; i++) {\n      newObject[i] = clone(object[i]);\n    }\n    return newObject;\n  }\n\n  // special case: to avoid inconsistencies between IndexedDB\n  // and other backends, we automatically stringify Dates\n  if (object instanceof Date) {\n    return object.toISOString();\n  }\n\n  if (isBinaryObject(object)) {\n    return cloneBinaryObject(object);\n  }\n\n  if (!isPlainObject(object)) {\n    return object; // don't clone objects like Workers\n  }\n\n  newObject = {};\n  for (i in object) {\n    /* istanbul ignore else */\n    if (Object.prototype.hasOwnProperty.call(object, i)) {\n      var value = clone(object[i]);\n      if (typeof value !== 'undefined') {\n        newObject[i] = value;\n      }\n    }\n  }\n  return newObject;\n}\n\nfunction once(fun) {\n  var called = false;\n  return getArguments(function (args) {\n    /* istanbul ignore if */\n    if (called) {\n      // this is a smoke test and should never actually happen\n      throw new Error('once called more than once');\n    } else {\n      called = true;\n      fun.apply(this, args);\n    }\n  });\n}\n\nfunction toPromise(func) {\n  //create the function we will be returning\n  return getArguments(function (args) {\n    // Clone arguments\n    args = clone(args);\n    var self = this;\n    // if the last argument is a function, assume its a callback\n    var usedCB = (typeof args[args.length - 1] === 'function') ? args.pop() : false;\n    var promise = new PouchPromise$1(function (fulfill, reject) {\n      var resp;\n      try {\n        var callback = once(function (err, mesg) {\n          if (err) {\n            reject(err);\n          } else {\n            fulfill(mesg);\n          }\n        });\n        // create a callback for this invocation\n        // apply the function in the orig context\n        args.push(callback);\n        resp = func.apply(self, args);\n        if (resp && typeof resp.then === 'function') {\n          fulfill(resp);\n        }\n      } catch (e) {\n        reject(e);\n      }\n    });\n    // if there is a callback, call it back\n    if (usedCB) {\n      promise.then(function (result) {\n        usedCB(null, result);\n      }, usedCB);\n    }\n    return promise;\n  });\n}\n\nvar log = debug('pouchdb:api');\n\nfunction adapterFun(name, callback) {\n  function logApiCall(self, name, args) {\n    /* istanbul ignore if */\n    if (log.enabled) {\n      var logArgs = [self.name, name];\n      for (var i = 0; i < args.length - 1; i++) {\n        logArgs.push(args[i]);\n      }\n      log.apply(null, logArgs);\n\n      // override the callback itself to log the response\n      var origCallback = args[args.length - 1];\n      args[args.length - 1] = function (err, res) {\n        var responseArgs = [self.name, name];\n        responseArgs = responseArgs.concat(\n          err ? ['error', err] : ['success', res]\n        );\n        log.apply(null, responseArgs);\n        origCallback(err, res);\n      };\n    }\n  }\n\n  return toPromise(getArguments(function (args) {\n    if (this._closed) {\n      return PouchPromise$1.reject(new Error('database is closed'));\n    }\n    if (this._destroyed) {\n      return PouchPromise$1.reject(new Error('database is destroyed'));\n    }\n    var self = this;\n    logApiCall(self, name, args);\n    if (!this.taskqueue.isReady) {\n      return new PouchPromise$1(function (fulfill, reject) {\n        self.taskqueue.addTask(function (failed) {\n          if (failed) {\n            reject(failed);\n          } else {\n            fulfill(self[name].apply(self, args));\n          }\n        });\n      });\n    }\n    return callback.apply(this, args);\n  }));\n}\n\n// like underscore/lodash _.pick()\nfunction pick(obj, arr) {\n  var res = {};\n  for (var i = 0, len = arr.length; i < len; i++) {\n    var prop = arr[i];\n    if (prop in obj) {\n      res[prop] = obj[prop];\n    }\n  }\n  return res;\n}\n\nfunction mangle(key) {\n  return '$' + key;\n}\nfunction unmangle(key) {\n  return key.substring(1);\n}\nfunction Map$1() {\n  this._store = {};\n}\nMap$1.prototype.get = function (key) {\n  var mangled = mangle(key);\n  return this._store[mangled];\n};\nMap$1.prototype.set = function (key, value) {\n  var mangled = mangle(key);\n  this._store[mangled] = value;\n  return true;\n};\nMap$1.prototype.has = function (key) {\n  var mangled = mangle(key);\n  return mangled in this._store;\n};\nMap$1.prototype.delete = function (key) {\n  var mangled = mangle(key);\n  var res = mangled in this._store;\n  delete this._store[mangled];\n  return res;\n};\nMap$1.prototype.forEach = function (cb) {\n  var keys = Object.keys(this._store);\n  for (var i = 0, len = keys.length; i < len; i++) {\n    var key = keys[i];\n    var value = this._store[key];\n    key = unmangle(key);\n    cb(value, key);\n  }\n};\nObject.defineProperty(Map$1.prototype, 'size', {\n  get: function () {\n    return Object.keys(this._store).length;\n  }\n});\n\nfunction Set$1(array) {\n  this._store = new Map$1();\n\n  // init with an array\n  if (array && Array.isArray(array)) {\n    for (var i = 0, len = array.length; i < len; i++) {\n      this.add(array[i]);\n    }\n  }\n}\nSet$1.prototype.add = function (key) {\n  return this._store.set(key, true);\n};\nSet$1.prototype.has = function (key) {\n  return this._store.has(key);\n};\nSet$1.prototype.forEach = function (cb) {\n  this._store.forEach(function (value, key) {\n    cb(key);\n  });\n};\nObject.defineProperty(Set$1.prototype, 'size', {\n  get: function () {\n    return this._store.size;\n  }\n});\n\n/* global Map,Set,Symbol */\n// Based on https://kangax.github.io/compat-table/es6/ we can sniff out\n// incomplete Map/Set implementations which would otherwise cause our tests to fail.\n// Notably they fail in IE11 and iOS 8.4, which this prevents.\nfunction supportsMapAndSet() {\n  if (typeof Symbol === 'undefined' || typeof Map === 'undefined' || typeof Set === 'undefined') {\n    return false;\n  }\n  var prop = Object.getOwnPropertyDescriptor(Map, Symbol.species);\n  return prop && 'get' in prop && Map[Symbol.species] === Map;\n}\n\n// based on https://github.com/montagejs/collections\n/* global Map,Set */\n\nvar ExportedSet;\nvar ExportedMap;\n\n{\n  if (supportsMapAndSet()) { // prefer built-in Map/Set\n    ExportedSet = Set;\n    ExportedMap = Map;\n  } else { // fall back to our polyfill\n    ExportedSet = Set$1;\n    ExportedMap = Map$1;\n  }\n}\n\n// Most browsers throttle concurrent requests at 6, so it's silly\n// to shim _bulk_get by trying to launch potentially hundreds of requests\n// and then letting the majority time out. We can handle this ourselves.\nvar MAX_NUM_CONCURRENT_REQUESTS = 6;\n\nfunction identityFunction(x) {\n  return x;\n}\n\nfunction formatResultForOpenRevsGet(result) {\n  return [{\n    ok: result\n  }];\n}\n\n// shim for P/CouchDB adapters that don't directly implement _bulk_get\nfunction bulkGet(db, opts, callback) {\n  var requests = opts.docs;\n\n  // consolidate into one request per doc if possible\n  var requestsById = new ExportedMap();\n  requests.forEach(function (request) {\n    if (requestsById.has(request.id)) {\n      requestsById.get(request.id).push(request);\n    } else {\n      requestsById.set(request.id, [request]);\n    }\n  });\n\n  var numDocs = requestsById.size;\n  var numDone = 0;\n  var perDocResults = new Array(numDocs);\n\n  function collapseResultsAndFinish() {\n    var results = [];\n    perDocResults.forEach(function (res) {\n      res.docs.forEach(function (info) {\n        results.push({\n          id: res.id,\n          docs: [info]\n        });\n      });\n    });\n    callback(null, {results: results});\n  }\n\n  function checkDone() {\n    if (++numDone === numDocs) {\n      collapseResultsAndFinish();\n    }\n  }\n\n  function gotResult(docIndex, id, docs) {\n    perDocResults[docIndex] = {id: id, docs: docs};\n    checkDone();\n  }\n\n  var allRequests = [];\n  requestsById.forEach(function (value, key) {\n    allRequests.push(key);\n  });\n\n  var i = 0;\n\n  function nextBatch() {\n\n    if (i >= allRequests.length) {\n      return;\n    }\n\n    var upTo = Math.min(i + MAX_NUM_CONCURRENT_REQUESTS, allRequests.length);\n    var batch = allRequests.slice(i, upTo);\n    processBatch(batch, i);\n    i += batch.length;\n  }\n\n  function processBatch(batch, offset) {\n    batch.forEach(function (docId, j) {\n      var docIdx = offset + j;\n      var docRequests = requestsById.get(docId);\n\n      // just use the first request as the \"template\"\n      // TODO: The _bulk_get API allows for more subtle use cases than this,\n      // but for now it is unlikely that there will be a mix of different\n      // \"atts_since\" or \"attachments\" in the same request, since it's just\n      // replicate.js that is using this for the moment.\n      // Also, atts_since is aspirational, since we don't support it yet.\n      var docOpts = pick(docRequests[0], ['atts_since', 'attachments']);\n      docOpts.open_revs = docRequests.map(function (request) {\n        // rev is optional, open_revs disallowed\n        return request.rev;\n      });\n\n      // remove falsey / undefined revisions\n      docOpts.open_revs = docOpts.open_revs.filter(identityFunction);\n\n      var formatResult = identityFunction;\n\n      if (docOpts.open_revs.length === 0) {\n        delete docOpts.open_revs;\n\n        // when fetching only the \"winning\" leaf,\n        // transform the result so it looks like an open_revs\n        // request\n        formatResult = formatResultForOpenRevsGet;\n      }\n\n      // globally-supplied options\n      ['revs', 'attachments', 'binary', 'ajax', 'latest'].forEach(function (param) {\n        if (param in opts) {\n          docOpts[param] = opts[param];\n        }\n      });\n      db.get(docId, docOpts, function (err, res) {\n        var result;\n        /* istanbul ignore if */\n        if (err) {\n          result = [{error: err}];\n        } else {\n          result = formatResult(res);\n        }\n        gotResult(docIdx, docId, result);\n        nextBatch();\n      });\n    });\n  }\n\n  nextBatch();\n\n}\n\nfunction isChromeApp() {\n  return (typeof chrome !== \"undefined\" &&\n    typeof chrome.storage !== \"undefined\" &&\n    typeof chrome.storage.local !== \"undefined\");\n}\n\nvar hasLocal;\n\nif (isChromeApp()) {\n  hasLocal = false;\n} else {\n  try {\n    localStorage.setItem('_pouch_check_localstorage', 1);\n    hasLocal = !!localStorage.getItem('_pouch_check_localstorage');\n  } catch (e) {\n    hasLocal = false;\n  }\n}\n\nfunction hasLocalStorage() {\n  return hasLocal;\n}\n\ninherits(Changes, events.EventEmitter);\n\n/* istanbul ignore next */\nfunction attachBrowserEvents(self) {\n  if (isChromeApp()) {\n    chrome.storage.onChanged.addListener(function (e) {\n      // make sure it's event addressed to us\n      if (e.db_name != null) {\n        //object only has oldValue, newValue members\n        self.emit(e.dbName.newValue);\n      }\n    });\n  } else if (hasLocalStorage()) {\n    if (typeof addEventListener !== 'undefined') {\n      addEventListener(\"storage\", function (e) {\n        self.emit(e.key);\n      });\n    } else { // old IE\n      window.attachEvent(\"storage\", function (e) {\n        self.emit(e.key);\n      });\n    }\n  }\n}\n\nfunction Changes() {\n  events.EventEmitter.call(this);\n  this._listeners = {};\n\n  attachBrowserEvents(this);\n}\nChanges.prototype.addListener = function (dbName, id, db, opts) {\n  /* istanbul ignore if */\n  if (this._listeners[id]) {\n    return;\n  }\n  var self = this;\n  var inprogress = false;\n  function eventFunction() {\n    /* istanbul ignore if */\n    if (!self._listeners[id]) {\n      return;\n    }\n    if (inprogress) {\n      inprogress = 'waiting';\n      return;\n    }\n    inprogress = true;\n    var changesOpts = pick(opts, [\n      'style', 'include_docs', 'attachments', 'conflicts', 'filter',\n      'doc_ids', 'view', 'since', 'query_params', 'binary'\n    ]);\n\n    /* istanbul ignore next */\n    function onError() {\n      inprogress = false;\n    }\n\n    db.changes(changesOpts).on('change', function (c) {\n      if (c.seq > opts.since && !opts.cancelled) {\n        opts.since = c.seq;\n        opts.onChange(c);\n      }\n    }).on('complete', function () {\n      if (inprogress === 'waiting') {\n        nextTick(eventFunction);\n      }\n      inprogress = false;\n    }).on('error', onError);\n  }\n  this._listeners[id] = eventFunction;\n  this.on(dbName, eventFunction);\n};\n\nChanges.prototype.removeListener = function (dbName, id) {\n  /* istanbul ignore if */\n  if (!(id in this._listeners)) {\n    return;\n  }\n  events.EventEmitter.prototype.removeListener.call(this, dbName,\n    this._listeners[id]);\n  delete this._listeners[id];\n};\n\n\n/* istanbul ignore next */\nChanges.prototype.notifyLocalWindows = function (dbName) {\n  //do a useless change on a storage thing\n  //in order to get other windows's listeners to activate\n  if (isChromeApp()) {\n    chrome.storage.local.set({dbName: dbName});\n  } else if (hasLocalStorage()) {\n    localStorage[dbName] = (localStorage[dbName] === \"a\") ? \"b\" : \"a\";\n  }\n};\n\nChanges.prototype.notify = function (dbName) {\n  this.emit(dbName);\n  this.notifyLocalWindows(dbName);\n};\n\nfunction guardedConsole(method) {\n  /* istanbul ignore else */\n  if (console !== 'undefined' && method in console) {\n    var args = Array.prototype.slice.call(arguments, 1);\n    console[method].apply(console, args);\n  }\n}\n\nfunction randomNumber(min, max) {\n  var maxTimeout = 600000; // Hard-coded default of 10 minutes\n  min = parseInt(min, 10) || 0;\n  max = parseInt(max, 10);\n  if (max !== max || max <= min) {\n    max = (min || 1) << 1; //doubling\n  } else {\n    max = max + 1;\n  }\n  // In order to not exceed maxTimeout, pick a random value between half of maxTimeout and maxTimeout\n  if(max > maxTimeout) {\n    min = maxTimeout >> 1; // divide by two\n    max = maxTimeout;\n  }\n  var ratio = Math.random();\n  var range = max - min;\n\n  return ~~(range * ratio + min); // ~~ coerces to an int, but fast.\n}\n\nfunction defaultBackOff(min) {\n  var max = 0;\n  if (!min) {\n    max = 2000;\n  }\n  return randomNumber(min, max);\n}\n\n// designed to give info to browser users, who are disturbed\n// when they see http errors in the console\nfunction explainError(status, str) {\n  guardedConsole('info', 'The above ' + status + ' is totally normal. ' + str);\n}\n\nvar assign;\n{\n  if (typeof Object.assign === 'function') {\n    assign = Object.assign;\n  } else {\n    // lite Object.assign polyfill based on\n    // https://developer.mozilla.org/en-US/docs/Web/JavaScript/Reference/Global_Objects/Object/assign\n    assign = function (target) {\n      var to = Object(target);\n\n      for (var index = 1; index < arguments.length; index++) {\n        var nextSource = arguments[index];\n\n        if (nextSource != null) { // Skip over if undefined or null\n          for (var nextKey in nextSource) {\n            // Avoid bugs when hasOwnProperty is shadowed\n            if (Object.prototype.hasOwnProperty.call(nextSource, nextKey)) {\n              to[nextKey] = nextSource[nextKey];\n            }\n          }\n        }\n      }\n      return to;\n    };\n  }\n}\n\nvar assign$1 = assign;\n\ninherits(PouchError, Error);\n\nfunction PouchError(status, error, reason) {\n  Error.call(this, reason);\n  this.status = status;\n  this.name = error;\n  this.message = reason;\n  this.error = true;\n}\n\nPouchError.prototype.toString = function () {\n  return JSON.stringify({\n    status: this.status,\n    name: this.name,\n    message: this.message,\n    reason: this.reason\n  });\n};\n\nvar UNAUTHORIZED = new PouchError(401, 'unauthorized', \"Name or password is incorrect.\");\nvar MISSING_BULK_DOCS = new PouchError(400, 'bad_request', \"Missing JSON list of 'docs'\");\nvar MISSING_DOC = new PouchError(404, 'not_found', 'missing');\nvar REV_CONFLICT = new PouchError(409, 'conflict', 'Document update conflict');\nvar INVALID_ID = new PouchError(400, 'bad_request', '_id field must contain a string');\nvar MISSING_ID = new PouchError(412, 'missing_id', '_id is required for puts');\nvar RESERVED_ID = new PouchError(400, 'bad_request', 'Only reserved document ids may start with underscore.');\nvar NOT_OPEN = new PouchError(412, 'precondition_failed', 'Database not open');\nvar UNKNOWN_ERROR = new PouchError(500, 'unknown_error', 'Database encountered an unknown error');\nvar BAD_ARG = new PouchError(500, 'badarg', 'Some query argument is invalid');\nvar INVALID_REQUEST = new PouchError(400, 'invalid_request', 'Request was invalid');\nvar QUERY_PARSE_ERROR = new PouchError(400, 'query_parse_error', 'Some query parameter is invalid');\nvar DOC_VALIDATION = new PouchError(500, 'doc_validation', 'Bad special document member');\nvar BAD_REQUEST = new PouchError(400, 'bad_request', 'Something wrong with the request');\nvar NOT_AN_OBJECT = new PouchError(400, 'bad_request', 'Document must be a JSON object');\nvar DB_MISSING = new PouchError(404, 'not_found', 'Database not found');\nvar IDB_ERROR = new PouchError(500, 'indexed_db_went_bad', 'unknown');\nvar WSQ_ERROR = new PouchError(500, 'web_sql_went_bad', 'unknown');\nvar LDB_ERROR = new PouchError(500, 'levelDB_went_went_bad', 'unknown');\nvar FORBIDDEN = new PouchError(403, 'forbidden', 'Forbidden by design doc validate_doc_update function');\nvar INVALID_REV = new PouchError(400, 'bad_request', 'Invalid rev format');\nvar FILE_EXISTS = new PouchError(412, 'file_exists', 'The database could not be created, the file already exists.');\nvar MISSING_STUB = new PouchError(412, 'missing_stub', 'A pre-existing attachment stub wasn\\'t found');\nvar INVALID_URL = new PouchError(413, 'invalid_url', 'Provided URL is invalid');\n\nfunction createError(error, reason) {\n  function CustomPouchError(reason) {\n    // inherit error properties from our parent error manually\n    // so as to allow proper JSON parsing.\n    /* jshint ignore:start */\n    for (var p in error) {\n      if (typeof error[p] !== 'function') {\n        this[p] = error[p];\n      }\n    }\n    /* jshint ignore:end */\n    if (reason !== undefined) {\n      this.reason = reason;\n    }\n  }\n  CustomPouchError.prototype = PouchError.prototype;\n  return new CustomPouchError(reason);\n}\n\nfunction generateErrorFromResponse(err) {\n\n  if (typeof err !== 'object') {\n    var data = err;\n    err = UNKNOWN_ERROR;\n    err.data = data;\n  }\n\n  if ('error' in err && err.error === 'conflict') {\n    err.name = 'conflict';\n    err.status = 409;\n  }\n\n  if (!('name' in err)) {\n    err.name = err.error || 'unknown';\n  }\n\n  if (!('status' in err)) {\n    err.status = 500;\n  }\n\n  if (!('message' in err)) {\n    err.message = err.message || err.reason;\n  }\n\n  return err;\n}\n\nfunction tryFilter(filter, doc, req) {\n  try {\n    return !filter(doc, req);\n  } catch (err) {\n    var msg = 'Filter function threw: ' + err.toString();\n    return createError(BAD_REQUEST, msg);\n  }\n}\n\nfunction filterChange(opts) {\n  var req = {};\n  var hasFilter = opts.filter && typeof opts.filter === 'function';\n  req.query = opts.query_params;\n\n  return function filter(change) {\n    if (!change.doc) {\n      // CSG sends events on the changes feed that don't have documents,\n      // this hack makes a whole lot of existing code robust.\n      change.doc = {};\n    }\n\n    var filterReturn = hasFilter && tryFilter(opts.filter, change.doc, req);\n\n    if (typeof filterReturn === 'object') {\n      return filterReturn;\n    }\n\n    if (filterReturn) {\n      return false;\n    }\n\n    if (!opts.include_docs) {\n      delete change.doc;\n    } else if (!opts.attachments) {\n      for (var att in change.doc._attachments) {\n        /* istanbul ignore else */\n        if (change.doc._attachments.hasOwnProperty(att)) {\n          change.doc._attachments[att].stub = true;\n        }\n      }\n    }\n    return true;\n  };\n}\n\nfunction flatten(arrs) {\n  var res = [];\n  for (var i = 0, len = arrs.length; i < len; i++) {\n    res = res.concat(arrs[i]);\n  }\n  return res;\n}\n\n// shim for Function.prototype.name,\n// for browsers that don't support it like IE\n\n/* istanbul ignore next */\nfunction f() {}\n\nvar hasName = f.name;\nvar res;\n\n// We dont run coverage in IE\n/* istanbul ignore else */\nif (hasName) {\n  res = function (fun) {\n    return fun.name;\n  };\n} else {\n  res = function (fun) {\n    return fun.toString().match(/^\\s*function\\s*(\\S*)\\s*\\(/)[1];\n  };\n}\n\n// Determine id an ID is valid\n//   - invalid IDs begin with an underescore that does not begin '_design' or\n//     '_local'\n//   - any other string value is a valid id\n// Returns the specific error object for each case\nfunction invalidIdError(id) {\n  var err;\n  if (!id) {\n    err = createError(MISSING_ID);\n  } else if (typeof id !== 'string') {\n    err = createError(INVALID_ID);\n  } else if (/^_/.test(id) && !(/^_(design|local)/).test(id)) {\n    err = createError(RESERVED_ID);\n  }\n  if (err) {\n    throw err;\n  }\n}\n\nfunction listenerCount(ee, type) {\n  return 'listenerCount' in ee ? ee.listenerCount(type) :\n                                 events.EventEmitter.listenerCount(ee, type);\n}\n\n// Custom nextTick() shim for browsers. In node, this will just be process.nextTick(). We\n// avoid using process.nextTick() directly because the polyfill is very large and we don't\n// need all of it (see: https://github.com/defunctzombie/node-process).\n// \"immediate\" 3.0.8 is used by lie, and it's a smaller version of the latest \"immediate\"\n// package, so it's the one we use.\n// When we use nextTick() in our codebase, we only care about not releasing Zalgo\n// (see: http://blog.izs.me/post/59142742143/designing-apis-for-asynchrony).\n// Microtask vs macrotask doesn't matter to us. So we're free to use the fastest\n// (least latency) option, which is \"immediate\" due to use of microtasks.\n// All of our nextTicks are isolated to this one function so we can easily swap out one\n// implementation for another.\n\nfunction parseDesignDocFunctionName(s) {\n  if (!s) {\n    return null;\n  }\n  var parts = s.split('/');\n  if (parts.length === 2) {\n    return parts;\n  }\n  if (parts.length === 1) {\n    return [s, s];\n  }\n  return null;\n}\n\nfunction normalizeDesignDocFunctionName(s) {\n  var normalized = parseDesignDocFunctionName(s);\n  return normalized ? normalized.join('/') : null;\n}\n\n// originally parseUri 1.2.2, now patched by us\n// (c) Steven Levithan <stevenlevithan.com>\n// MIT License\nvar keys = [\"source\", \"protocol\", \"authority\", \"userInfo\", \"user\", \"password\",\n    \"host\", \"port\", \"relative\", \"path\", \"directory\", \"file\", \"query\", \"anchor\"];\nvar qName =\"queryKey\";\nvar qParser = /(?:^|&)([^&=]*)=?([^&]*)/g;\n\n// use the \"loose\" parser\n/* jshint maxlen: false */\nvar parser = /^(?:(?![^:@]+:[^:@\\/]*@)([^:\\/?#.]+):)?(?:\\/\\/)?((?:(([^:@]*)(?::([^:@]*))?)?@)?([^:\\/?#]*)(?::(\\d*))?)(((\\/(?:[^?#](?![^?#\\/]*\\.[^?#\\/.]+(?:[?#]|$)))*\\/?)?([^?#\\/]*))(?:\\?([^#]*))?(?:#(.*))?)/;\n\nfunction parseUri(str) {\n  var m = parser.exec(str);\n  var uri = {};\n  var i = 14;\n\n  while (i--) {\n    var key = keys[i];\n    var value = m[i] || \"\";\n    var encoded = ['user', 'password'].indexOf(key) !== -1;\n    uri[key] = encoded ? decodeURIComponent(value) : value;\n  }\n\n  uri[qName] = {};\n  uri[keys[12]].replace(qParser, function ($0, $1, $2) {\n    if ($1) {\n      uri[qName][$1] = $2;\n    }\n  });\n\n  return uri;\n}\n\n// this is essentially the \"update sugar\" function from daleharvey/pouchdb#1388\n// the diffFun tells us what delta to apply to the doc.  it either returns\n// the doc, or false if it doesn't need to do an update after all\nfunction upsert(db, docId, diffFun) {\n  return new PouchPromise$1(function (fulfill, reject) {\n    db.get(docId, function (err, doc) {\n      if (err) {\n        /* istanbul ignore next */\n        if (err.status !== 404) {\n          return reject(err);\n        }\n        doc = {};\n      }\n\n      // the user might change the _rev, so save it for posterity\n      var docRev = doc._rev;\n      var newDoc = diffFun(doc);\n\n      if (!newDoc) {\n        // if the diffFun returns falsy, we short-circuit as\n        // an optimization\n        return fulfill({updated: false, rev: docRev});\n      }\n\n      // users aren't allowed to modify these values,\n      // so reset them here\n      newDoc._id = docId;\n      newDoc._rev = docRev;\n      fulfill(tryAndPut(db, newDoc, diffFun));\n    });\n  });\n}\n\nfunction tryAndPut(db, doc, diffFun) {\n  return db.put(doc).then(function (res) {\n    return {\n      updated: true,\n      rev: res.rev\n    };\n  }, function (err) {\n    /* istanbul ignore next */\n    if (err.status !== 409) {\n      throw err;\n    }\n    return upsert(db, doc._id, diffFun);\n  });\n}\n\n// BEGIN Math.uuid.js\n\n/*!\nMath.uuid.js (v1.4)\nhttp://www.broofa.com\nmailto:robert@broofa.com\n\nCopyright (c) 2010 Robert Kieffer\nDual licensed under the MIT and GPL licenses.\n*/\n\n/*\n * Generate a random uuid.\n *\n * USAGE: Math.uuid(length, radix)\n *   length - the desired number of characters\n *   radix  - the number of allowable values for each character.\n *\n * EXAMPLES:\n *   // No arguments  - returns RFC4122, version 4 ID\n *   >>> Math.uuid()\n *   \"92329D39-6F5C-4520-ABFC-AAB64544E172\"\n *\n *   // One argument - returns ID of the specified length\n *   >>> Math.uuid(15)     // 15 character ID (default base=62)\n *   \"VcydxgltxrVZSTV\"\n *\n *   // Two arguments - returns ID of the specified length, and radix. \n *   // (Radix must be <= 62)\n *   >>> Math.uuid(8, 2)  // 8 character ID (base=2)\n *   \"01001010\"\n *   >>> Math.uuid(8, 10) // 8 character ID (base=10)\n *   \"47473046\"\n *   >>> Math.uuid(8, 16) // 8 character ID (base=16)\n *   \"098F4D35\"\n */\nvar chars = (\n  '0123456789ABCDEFGHIJKLMNOPQRSTUVWXYZ' +\n  'abcdefghijklmnopqrstuvwxyz'\n).split('');\nfunction getValue(radix) {\n  return 0 | Math.random() * radix;\n}\nfunction uuid(len, radix) {\n  radix = radix || chars.length;\n  var out = '';\n  var i = -1;\n\n  if (len) {\n    // Compact form\n    while (++i < len) {\n      out += chars[getValue(radix)];\n    }\n    return out;\n  }\n    // rfc4122, version 4 form\n    // Fill in random data.  At i==19 set the high bits of clock sequence as\n    // per rfc4122, sec. 4.1.5\n  while (++i < 36) {\n    switch (i) {\n      case 8:\n      case 13:\n      case 18:\n      case 23:\n        out += '-';\n        break;\n      case 19:\n        out += chars[(getValue(16) & 0x3) | 0x8];\n        break;\n      default:\n        out += chars[getValue(16)];\n    }\n  }\n\n  return out;\n}\n\n// We fetch all leafs of the revision tree, and sort them based on tree length\n// and whether they were deleted, undeleted documents with the longest revision\n// tree (most edits) win\n// The final sort algorithm is slightly documented in a sidebar here:\n// http://guide.couchdb.org/draft/conflicts.html\nfunction winningRev(metadata) {\n  var winningId;\n  var winningPos;\n  var winningDeleted;\n  var toVisit = metadata.rev_tree.slice();\n  var node;\n  while ((node = toVisit.pop())) {\n    var tree = node.ids;\n    var branches = tree[2];\n    var pos = node.pos;\n    if (branches.length) { // non-leaf\n      for (var i = 0, len = branches.length; i < len; i++) {\n        toVisit.push({pos: pos + 1, ids: branches[i]});\n      }\n      continue;\n    }\n    var deleted = !!tree[1].deleted;\n    var id = tree[0];\n    // sort by deleted, then pos, then id\n    if (!winningId || (winningDeleted !== deleted ? winningDeleted :\n        winningPos !== pos ? winningPos < pos : winningId < id)) {\n      winningId = id;\n      winningPos = pos;\n      winningDeleted = deleted;\n    }\n  }\n\n  return winningPos + '-' + winningId;\n}\n\n// Pretty much all below can be combined into a higher order function to\n// traverse revisions\n// The return value from the callback will be passed as context to all\n// children of that node\nfunction traverseRevTree(revs, callback) {\n  var toVisit = revs.slice();\n\n  var node;\n  while ((node = toVisit.pop())) {\n    var pos = node.pos;\n    var tree = node.ids;\n    var branches = tree[2];\n    var newCtx =\n      callback(branches.length === 0, pos, tree[0], node.ctx, tree[1]);\n    for (var i = 0, len = branches.length; i < len; i++) {\n      toVisit.push({pos: pos + 1, ids: branches[i], ctx: newCtx});\n    }\n  }\n}\n\nfunction sortByPos(a, b) {\n  return a.pos - b.pos;\n}\n\nfunction collectLeaves(revs) {\n  var leaves = [];\n  traverseRevTree(revs, function (isLeaf, pos, id, acc, opts) {\n    if (isLeaf) {\n      leaves.push({rev: pos + \"-\" + id, pos: pos, opts: opts});\n    }\n  });\n  leaves.sort(sortByPos).reverse();\n  for (var i = 0, len = leaves.length; i < len; i++) {\n    delete leaves[i].pos;\n  }\n  return leaves;\n}\n\n// returns revs of all conflicts that is leaves such that\n// 1. are not deleted and\n// 2. are different than winning revision\nfunction collectConflicts(metadata) {\n  var win = winningRev(metadata);\n  var leaves = collectLeaves(metadata.rev_tree);\n  var conflicts = [];\n  for (var i = 0, len = leaves.length; i < len; i++) {\n    var leaf = leaves[i];\n    if (leaf.rev !== win && !leaf.opts.deleted) {\n      conflicts.push(leaf.rev);\n    }\n  }\n  return conflicts;\n}\n\n// compact a tree by marking its non-leafs as missing,\n// and return a list of revs to delete\nfunction compactTree(metadata) {\n  var revs = [];\n  traverseRevTree(metadata.rev_tree, function (isLeaf, pos,\n                                               revHash, ctx, opts) {\n    if (opts.status === 'available' && !isLeaf) {\n      revs.push(pos + '-' + revHash);\n      opts.status = 'missing';\n    }\n  });\n  return revs;\n}\n\n// build up a list of all the paths to the leafs in this revision tree\nfunction rootToLeaf(revs) {\n  var paths = [];\n  var toVisit = revs.slice();\n  var node;\n  while ((node = toVisit.pop())) {\n    var pos = node.pos;\n    var tree = node.ids;\n    var id = tree[0];\n    var opts = tree[1];\n    var branches = tree[2];\n    var isLeaf = branches.length === 0;\n\n    var history = node.history ? node.history.slice() : [];\n    history.push({id: id, opts: opts});\n    if (isLeaf) {\n      paths.push({pos: (pos + 1 - history.length), ids: history});\n    }\n    for (var i = 0, len = branches.length; i < len; i++) {\n      toVisit.push({pos: pos + 1, ids: branches[i], history: history});\n    }\n  }\n  return paths.reverse();\n}\n\n// for a better overview of what this is doing, read:\n// https://github.com/apache/couchdb-couch/blob/master/src/couch_key_tree.erl\n//\n// But for a quick intro, CouchDB uses a revision tree to store a documents\n// history, A -> B -> C, when a document has conflicts, that is a branch in the\n// tree, A -> (B1 | B2 -> C), We store these as a nested array in the format\n//\n// KeyTree = [Path ... ]\n// Path = {pos: position_from_root, ids: Tree}\n// Tree = [Key, Opts, [Tree, ...]], in particular single node: [Key, []]\n\nfunction sortByPos$1(a, b) {\n  return a.pos - b.pos;\n}\n\n// classic binary search\nfunction binarySearch(arr, item, comparator) {\n  var low = 0;\n  var high = arr.length;\n  var mid;\n  while (low < high) {\n    mid = (low + high) >>> 1;\n    if (comparator(arr[mid], item) < 0) {\n      low = mid + 1;\n    } else {\n      high = mid;\n    }\n  }\n  return low;\n}\n\n// assuming the arr is sorted, insert the item in the proper place\nfunction insertSorted(arr, item, comparator) {\n  var idx = binarySearch(arr, item, comparator);\n  arr.splice(idx, 0, item);\n}\n\n// Turn a path as a flat array into a tree with a single branch.\n// If any should be stemmed from the beginning of the array, that's passed\n// in as the second argument\nfunction pathToTree(path, numStemmed) {\n  var root;\n  var leaf;\n  for (var i = numStemmed, len = path.length; i < len; i++) {\n    var node = path[i];\n    var currentLeaf = [node.id, node.opts, []];\n    if (leaf) {\n      leaf[2].push(currentLeaf);\n      leaf = currentLeaf;\n    } else {\n      root = leaf = currentLeaf;\n    }\n  }\n  return root;\n}\n\n// compare the IDs of two trees\nfunction compareTree(a, b) {\n  return a[0] < b[0] ? -1 : 1;\n}\n\n// Merge two trees together\n// The roots of tree1 and tree2 must be the same revision\nfunction mergeTree(in_tree1, in_tree2) {\n  var queue = [{tree1: in_tree1, tree2: in_tree2}];\n  var conflicts = false;\n  while (queue.length > 0) {\n    var item = queue.pop();\n    var tree1 = item.tree1;\n    var tree2 = item.tree2;\n\n    if (tree1[1].status || tree2[1].status) {\n      tree1[1].status =\n        (tree1[1].status ===  'available' ||\n        tree2[1].status === 'available') ? 'available' : 'missing';\n    }\n\n    for (var i = 0; i < tree2[2].length; i++) {\n      if (!tree1[2][0]) {\n        conflicts = 'new_leaf';\n        tree1[2][0] = tree2[2][i];\n        continue;\n      }\n\n      var merged = false;\n      for (var j = 0; j < tree1[2].length; j++) {\n        if (tree1[2][j][0] === tree2[2][i][0]) {\n          queue.push({tree1: tree1[2][j], tree2: tree2[2][i]});\n          merged = true;\n        }\n      }\n      if (!merged) {\n        conflicts = 'new_branch';\n        insertSorted(tree1[2], tree2[2][i], compareTree);\n      }\n    }\n  }\n  return {conflicts: conflicts, tree: in_tree1};\n}\n\nfunction doMerge(tree, path, dontExpand) {\n  var restree = [];\n  var conflicts = false;\n  var merged = false;\n  var res;\n\n  if (!tree.length) {\n    return {tree: [path], conflicts: 'new_leaf'};\n  }\n\n  for (var i = 0, len = tree.length; i < len; i++) {\n    var branch = tree[i];\n    if (branch.pos === path.pos && branch.ids[0] === path.ids[0]) {\n      // Paths start at the same position and have the same root, so they need\n      // merged\n      res = mergeTree(branch.ids, path.ids);\n      restree.push({pos: branch.pos, ids: res.tree});\n      conflicts = conflicts || res.conflicts;\n      merged = true;\n    } else if (dontExpand !== true) {\n      // The paths start at a different position, take the earliest path and\n      // traverse up until it as at the same point from root as the path we\n      // want to merge.  If the keys match we return the longer path with the\n      // other merged After stemming we dont want to expand the trees\n\n      var t1 = branch.pos < path.pos ? branch : path;\n      var t2 = branch.pos < path.pos ? path : branch;\n      var diff = t2.pos - t1.pos;\n\n      var candidateParents = [];\n\n      var trees = [];\n      trees.push({ids: t1.ids, diff: diff, parent: null, parentIdx: null});\n      while (trees.length > 0) {\n        var item = trees.pop();\n        if (item.diff === 0) {\n          if (item.ids[0] === t2.ids[0]) {\n            candidateParents.push(item);\n          }\n          continue;\n        }\n        var elements = item.ids[2];\n        for (var j = 0, elementsLen = elements.length; j < elementsLen; j++) {\n          trees.push({\n            ids: elements[j],\n            diff: item.diff - 1,\n            parent: item.ids,\n            parentIdx: j\n          });\n        }\n      }\n\n      var el = candidateParents[0];\n\n      if (!el) {\n        restree.push(branch);\n      } else {\n        res = mergeTree(el.ids, t2.ids);\n        el.parent[2][el.parentIdx] = res.tree;\n        restree.push({pos: t1.pos, ids: t1.ids});\n        conflicts = conflicts || res.conflicts;\n        merged = true;\n      }\n    } else {\n      restree.push(branch);\n    }\n  }\n\n  // We didnt find\n  if (!merged) {\n    restree.push(path);\n  }\n\n  restree.sort(sortByPos$1);\n\n  return {\n    tree: restree,\n    conflicts: conflicts || 'internal_node'\n  };\n}\n\n// To ensure we dont grow the revision tree infinitely, we stem old revisions\nfunction stem(tree, depth) {\n  // First we break out the tree into a complete list of root to leaf paths\n  var paths = rootToLeaf(tree);\n  var maybeStem = {};\n\n  var result;\n  for (var i = 0, len = paths.length; i < len; i++) {\n    // Then for each path, we cut off the start of the path based on the\n    // `depth` to stem to, and generate a new set of flat trees\n    var path = paths[i];\n    var stemmed = path.ids;\n    var numStemmed = Math.max(0, stemmed.length - depth);\n    var stemmedNode = {\n      pos: path.pos + numStemmed,\n      ids: pathToTree(stemmed, numStemmed)\n    };\n\n    for (var s = 0; s < numStemmed; s++) {\n      var rev = (path.pos + s) + '-' + stemmed[s].id;\n      maybeStem[rev] = true;\n    }\n\n    // Then we remerge all those flat trees together, ensuring that we dont\n    // connect trees that would go beyond the depth limit\n    if (result) {\n      result = doMerge(result, stemmedNode, true).tree;\n    } else {\n      result = [stemmedNode];\n    }\n  }\n\n  traverseRevTree(result, function (isLeaf, pos, revHash) {\n    // some revisions may have been removed in a branch but not in another\n    delete maybeStem[pos + '-' + revHash];\n  });\n\n  return {\n    tree: result,\n    revs: Object.keys(maybeStem)\n  };\n}\n\nfunction merge(tree, path, depth) {\n  var newTree = doMerge(tree, path);\n  var stemmed = stem(newTree.tree, depth);\n  return {\n    tree: stemmed.tree,\n    stemmedRevs: stemmed.revs,\n    conflicts: newTree.conflicts\n  };\n}\n\n// return true if a rev exists in the rev tree, false otherwise\nfunction revExists(revs, rev) {\n  var toVisit = revs.slice();\n  var splitRev = rev.split('-');\n  var targetPos = parseInt(splitRev[0], 10);\n  var targetId = splitRev[1];\n\n  var node;\n  while ((node = toVisit.pop())) {\n    if (node.pos === targetPos && node.ids[0] === targetId) {\n      return true;\n    }\n    var branches = node.ids[2];\n    for (var i = 0, len = branches.length; i < len; i++) {\n      toVisit.push({pos: node.pos + 1, ids: branches[i]});\n    }\n  }\n  return false;\n}\n\nfunction getTrees(node) {\n  return node.ids;\n}\n\n// check if a specific revision of a doc has been deleted\n//  - metadata: the metadata object from the doc store\n//  - rev: (optional) the revision to check. defaults to winning revision\nfunction isDeleted(metadata, rev) {\n  if (!rev) {\n    rev = winningRev(metadata);\n  }\n  var id = rev.substring(rev.indexOf('-') + 1);\n  var toVisit = metadata.rev_tree.map(getTrees);\n\n  var tree;\n  while ((tree = toVisit.pop())) {\n    if (tree[0] === id) {\n      return !!tree[1].deleted;\n    }\n    toVisit = toVisit.concat(tree[2]);\n  }\n}\n\nfunction isLocalId(id) {\n  return (/^_local/).test(id);\n}\n\n// returns the current leaf node for a given revision\nfunction latest(rev, metadata) {\n  var toVisit = metadata.rev_tree.slice();\n  var node;\n  while ((node = toVisit.pop())) {\n    var pos = node.pos;\n    var tree = node.ids;\n    var id = tree[0];\n    var opts = tree[1];\n    var branches = tree[2];\n    var isLeaf = branches.length === 0;\n\n    var history = node.history ? node.history.slice() : [];\n    history.push({id: id, pos: pos, opts: opts});\n\n    if (isLeaf) {\n      for (var i = 0, len = history.length; i < len; i++) {\n        var historyNode = history[i];\n        var historyRev = historyNode.pos + '-' + historyNode.id;\n\n        if (historyRev === rev) {\n          // return the rev of this leaf\n          return pos + '-' + id;\n        }\n      }\n    }\n\n    for (var j = 0, l = branches.length; j < l; j++) {\n      toVisit.push({pos: pos + 1, ids: branches[j], history: history});\n    }\n  }\n\n  /* istanbul ignore next */\n  throw new Error('Unable to resolve latest revision for id ' + metadata.id + ', rev ' + rev);\n}\n\nfunction evalFilter(input) {\n  return scopedEval('\"use strict\";\\nreturn ' + input + ';', {});\n}\n\nfunction evalView(input) {\n  var code = [\n    'return function(doc) {',\n    '  \"use strict\";',\n    '  var emitted = false;',\n    '  var emit = function (a, b) {',\n    '    emitted = true;',\n    '  };',\n    '  var view = ' + input + ';',\n    '  view(doc);',\n    '  if (emitted) {',\n    '    return true;',\n    '  }',\n    '};'\n  ].join('\\n');\n\n  return scopedEval(code, {});\n}\n\ninherits(Changes$2, events.EventEmitter);\n\nfunction tryCatchInChangeListener(self, change) {\n  // isolate try/catches to avoid V8 deoptimizations\n  try {\n    self.emit('change', change);\n  } catch (e) {\n    guardedConsole('error', 'Error in .on(\"change\", function):', e);\n  }\n}\n\nfunction Changes$2(db, opts, callback) {\n  events.EventEmitter.call(this);\n  var self = this;\n  this.db = db;\n  opts = opts ? clone(opts) : {};\n  var complete = opts.complete = once(function (err, resp) {\n    if (err) {\n      if (listenerCount(self, 'error') > 0) {\n        self.emit('error', err);\n      }\n    } else {\n      self.emit('complete', resp);\n    }\n    self.removeAllListeners();\n    db.removeListener('destroyed', onDestroy);\n  });\n  if (callback) {\n    self.on('complete', function (resp) {\n      callback(null, resp);\n    });\n    self.on('error', callback);\n  }\n  function onDestroy() {\n    self.cancel();\n  }\n  db.once('destroyed', onDestroy);\n\n  opts.onChange = function (change) {\n    /* istanbul ignore if */\n    if (self.isCancelled) {\n      return;\n    }\n    tryCatchInChangeListener(self, change);\n  };\n\n  var promise = new PouchPromise$1(function (fulfill, reject) {\n    opts.complete = function (err, res) {\n      if (err) {\n        reject(err);\n      } else {\n        fulfill(res);\n      }\n    };\n  });\n  self.once('cancel', function () {\n    db.removeListener('destroyed', onDestroy);\n    opts.complete(null, {status: 'cancelled'});\n  });\n  this.then = promise.then.bind(promise);\n  this['catch'] = promise['catch'].bind(promise);\n  this.then(function (result) {\n    complete(null, result);\n  }, complete);\n\n\n\n  if (!db.taskqueue.isReady) {\n    db.taskqueue.addTask(function (failed) {\n      if (failed) {\n        opts.complete(failed);\n      } else if (self.isCancelled) {\n        self.emit('cancel');\n      } else {\n        self.doChanges(opts);\n      }\n    });\n  } else {\n    self.doChanges(opts);\n  }\n}\nChanges$2.prototype.cancel = function () {\n  this.isCancelled = true;\n  if (this.db.taskqueue.isReady) {\n    this.emit('cancel');\n  }\n};\nfunction processChange(doc, metadata, opts) {\n  var changeList = [{rev: doc._rev}];\n  if (opts.style === 'all_docs') {\n    changeList = collectLeaves(metadata.rev_tree)\n    .map(function (x) { return {rev: x.rev}; });\n  }\n  var change = {\n    id: metadata.id,\n    changes: changeList,\n    doc: doc\n  };\n\n  if (isDeleted(metadata, doc._rev)) {\n    change.deleted = true;\n  }\n  if (opts.conflicts) {\n    change.doc._conflicts = collectConflicts(metadata);\n    if (!change.doc._conflicts.length) {\n      delete change.doc._conflicts;\n    }\n  }\n  return change;\n}\n\nChanges$2.prototype.doChanges = function (opts) {\n  var self = this;\n  var callback = opts.complete;\n\n  opts = clone(opts);\n  if ('live' in opts && !('continuous' in opts)) {\n    opts.continuous = opts.live;\n  }\n  opts.processChange = processChange;\n\n  if (opts.since === 'latest') {\n    opts.since = 'now';\n  }\n  if (!opts.since) {\n    opts.since = 0;\n  }\n  if (opts.since === 'now') {\n    this.db.info().then(function (info) {\n      /* istanbul ignore if */\n      if (self.isCancelled) {\n        callback(null, {status: 'cancelled'});\n        return;\n      }\n      opts.since = info.update_seq;\n      self.doChanges(opts);\n    }, callback);\n    return;\n  }\n\n\n  if (opts.view && !opts.filter) {\n    opts.filter = '_view';\n  }\n\n  if (opts.filter && typeof opts.filter === 'string') {\n    if (opts.filter === '_view') {\n      opts.view = normalizeDesignDocFunctionName(opts.view);\n    } else {\n      opts.filter = normalizeDesignDocFunctionName(opts.filter);\n    }\n\n    if (this.db.type() !== 'http' && !opts.doc_ids) {\n      return this.filterChanges(opts);\n    }\n  }\n\n  if (!('descending' in opts)) {\n    opts.descending = false;\n  }\n\n  // 0 and 1 should return 1 document\n  opts.limit = opts.limit === 0 ? 1 : opts.limit;\n  opts.complete = callback;\n  var newPromise = this.db._changes(opts);\n  /* istanbul ignore else */\n  if (newPromise && typeof newPromise.cancel === 'function') {\n    var cancel = self.cancel;\n    self.cancel = getArguments(function (args) {\n      newPromise.cancel();\n      cancel.apply(this, args);\n    });\n  }\n};\n\nChanges$2.prototype.filterChanges = function (opts) {\n  var self = this;\n  var callback = opts.complete;\n  if (opts.filter === '_view') {\n    if (!opts.view || typeof opts.view !== 'string') {\n      var err = createError(BAD_REQUEST,\n        '`view` filter parameter not found or invalid.');\n      return callback(err);\n    }\n    // fetch a view from a design doc, make it behave like a filter\n    var viewName = parseDesignDocFunctionName(opts.view);\n    this.db.get('_design/' + viewName[0], function (err, ddoc) {\n      /* istanbul ignore if */\n      if (self.isCancelled) {\n        return callback(null, {status: 'cancelled'});\n      }\n      /* istanbul ignore next */\n      if (err) {\n        return callback(generateErrorFromResponse(err));\n      }\n      var mapFun = ddoc && ddoc.views && ddoc.views[viewName[1]] &&\n        ddoc.views[viewName[1]].map;\n      if (!mapFun) {\n        return callback(createError(MISSING_DOC,\n          (ddoc.views ? 'missing json key: ' + viewName[1] :\n            'missing json key: views')));\n      }\n      opts.filter = evalView(mapFun);\n      self.doChanges(opts);\n    });\n  } else {\n    // fetch a filter from a design doc\n    var filterName = parseDesignDocFunctionName(opts.filter);\n    if (!filterName) {\n      return self.doChanges(opts);\n    }\n    this.db.get('_design/' + filterName[0], function (err, ddoc) {\n      /* istanbul ignore if */\n      if (self.isCancelled) {\n        return callback(null, {status: 'cancelled'});\n      }\n      /* istanbul ignore next */\n      if (err) {\n        return callback(generateErrorFromResponse(err));\n      }\n      var filterFun = ddoc && ddoc.filters && ddoc.filters[filterName[1]];\n      if (!filterFun) {\n        return callback(createError(MISSING_DOC,\n          ((ddoc && ddoc.filters) ? 'missing json key: ' + filterName[1]\n            : 'missing json key: filters')));\n      }\n      opts.filter = evalFilter(filterFun);\n      self.doChanges(opts);\n    });\n  }\n};\n\n/*\n * A generic pouch adapter\n */\n\nfunction compare(left, right) {\n  return left < right ? -1 : left > right ? 1 : 0;\n}\n\n// Wrapper for functions that call the bulkdocs api with a single doc,\n// if the first result is an error, return an error\nfunction yankError(callback) {\n  return function (err, results) {\n    if (err || (results[0] && results[0].error)) {\n      callback(err || results[0]);\n    } else {\n      callback(null, results.length ? results[0]  : results);\n    }\n  };\n}\n\n// clean docs given to us by the user\nfunction cleanDocs(docs) {\n  for (var i = 0; i < docs.length; i++) {\n    var doc = docs[i];\n    if (doc._deleted) {\n      delete doc._attachments; // ignore atts for deleted docs\n    } else if (doc._attachments) {\n      // filter out extraneous keys from _attachments\n      var atts = Object.keys(doc._attachments);\n      for (var j = 0; j < atts.length; j++) {\n        var att = atts[j];\n        doc._attachments[att] = pick(doc._attachments[att],\n          ['data', 'digest', 'content_type', 'length', 'revpos', 'stub']);\n      }\n    }\n  }\n}\n\n// compare two docs, first by _id then by _rev\nfunction compareByIdThenRev(a, b) {\n  var idCompare = compare(a._id, b._id);\n  if (idCompare !== 0) {\n    return idCompare;\n  }\n  var aStart = a._revisions ? a._revisions.start : 0;\n  var bStart = b._revisions ? b._revisions.start : 0;\n  return compare(aStart, bStart);\n}\n\n// for every node in a revision tree computes its distance from the closest\n// leaf\nfunction computeHeight(revs) {\n  var height = {};\n  var edges = [];\n  traverseRevTree(revs, function (isLeaf, pos, id, prnt) {\n    var rev = pos + \"-\" + id;\n    if (isLeaf) {\n      height[rev] = 0;\n    }\n    if (prnt !== undefined) {\n      edges.push({from: prnt, to: rev});\n    }\n    return rev;\n  });\n\n  edges.reverse();\n  edges.forEach(function (edge) {\n    if (height[edge.from] === undefined) {\n      height[edge.from] = 1 + height[edge.to];\n    } else {\n      height[edge.from] = Math.min(height[edge.from], 1 + height[edge.to]);\n    }\n  });\n  return height;\n}\n\nfunction allDocsKeysQuery(api, opts, callback) {\n  var keys =  ('limit' in opts) ?\n      opts.keys.slice(opts.skip, opts.limit + opts.skip) :\n      (opts.skip > 0) ? opts.keys.slice(opts.skip) : opts.keys;\n  if (opts.descending) {\n    keys.reverse();\n  }\n  if (!keys.length) {\n    return api._allDocs({limit: 0}, callback);\n  }\n  var finalResults = {\n    offset: opts.skip\n  };\n  return PouchPromise$1.all(keys.map(function (key) {\n    var subOpts = assign$1({key: key, deleted: 'ok'}, opts);\n    ['limit', 'skip', 'keys'].forEach(function (optKey) {\n      delete subOpts[optKey];\n    });\n    return new PouchPromise$1(function (resolve, reject) {\n      api._allDocs(subOpts, function (err, res) {\n        /* istanbul ignore if */\n        if (err) {\n          return reject(err);\n        }\n        finalResults.total_rows = res.total_rows;\n        resolve(res.rows[0] || {key: key, error: 'not_found'});\n      });\n    });\n  })).then(function (results) {\n    finalResults.rows = results;\n    return finalResults;\n  });\n}\n\n// all compaction is done in a queue, to avoid attaching\n// too many listeners at once\nfunction doNextCompaction(self) {\n  var task = self._compactionQueue[0];\n  var opts = task.opts;\n  var callback = task.callback;\n  self.get('_local/compaction').catch(function () {\n    return false;\n  }).then(function (doc) {\n    if (doc && doc.last_seq) {\n      opts.last_seq = doc.last_seq;\n    }\n    self._compact(opts, function (err, res) {\n      /* istanbul ignore if */\n      if (err) {\n        callback(err);\n      } else {\n        callback(null, res);\n      }\n      nextTick(function () {\n        self._compactionQueue.shift();\n        if (self._compactionQueue.length) {\n          doNextCompaction(self);\n        }\n      });\n    });\n  });\n}\n\nfunction attachmentNameError(name) {\n  if (name.charAt(0) === '_') {\n    return name + 'is not a valid attachment name, attachment ' +\n      'names cannot start with \\'_\\'';\n  }\n  return false;\n}\n\ninherits(AbstractPouchDB, events.EventEmitter);\n\nfunction AbstractPouchDB() {\n  events.EventEmitter.call(this);\n}\n\nAbstractPouchDB.prototype.post =\n  adapterFun('post', function (doc, opts, callback) {\n  if (typeof opts === 'function') {\n    callback = opts;\n    opts = {};\n  }\n  if (typeof doc !== 'object' || Array.isArray(doc)) {\n    return callback(createError(NOT_AN_OBJECT));\n  }\n  this.bulkDocs({docs: [doc]}, opts, yankError(callback));\n});\n\nAbstractPouchDB.prototype.put = adapterFun('put', function (doc, opts, cb) {\n  if (typeof opts === 'function') {\n    cb = opts;\n    opts = {};\n  }\n  if (typeof doc !== 'object' || Array.isArray(doc)) {\n    return cb(createError(NOT_AN_OBJECT));\n  }\n  invalidIdError(doc._id);\n  if (isLocalId(doc._id) && typeof this._putLocal === 'function') {\n    if (doc._deleted) {\n      return this._removeLocal(doc, cb);\n    } else {\n      return this._putLocal(doc, cb);\n    }\n  }\n  if (typeof this._put === 'function' && opts.new_edits !== false) {\n    this._put(doc, opts, cb);\n  } else {\n    this.bulkDocs({docs: [doc]}, opts, yankError(cb));\n  }\n});\n\nAbstractPouchDB.prototype.putAttachment =\n  adapterFun('putAttachment', function (docId, attachmentId, rev,\n                                              blob, type) {\n  var api = this;\n  if (typeof type === 'function') {\n    type = blob;\n    blob = rev;\n    rev = null;\n  }\n  // Lets fix in https://github.com/pouchdb/pouchdb/issues/3267\n  /* istanbul ignore if */\n  if (typeof type === 'undefined') {\n    type = blob;\n    blob = rev;\n    rev = null;\n  }\n  if (!type) {\n    guardedConsole('warn', 'Attachment', attachmentId, 'on document', docId, 'is missing content_type');\n  }\n\n  function createAttachment(doc) {\n    var prevrevpos = '_rev' in doc ? parseInt(doc._rev, 10) : 0;\n    doc._attachments = doc._attachments || {};\n    doc._attachments[attachmentId] = {\n      content_type: type,\n      data: blob,\n      revpos: ++prevrevpos\n    };\n    return api.put(doc);\n  }\n\n  return api.get(docId).then(function (doc) {\n    if (doc._rev !== rev) {\n      throw createError(REV_CONFLICT);\n    }\n\n    return createAttachment(doc);\n  }, function (err) {\n     // create new doc\n    /* istanbul ignore else */\n    if (err.reason === MISSING_DOC.message) {\n      return createAttachment({_id: docId});\n    } else {\n      throw err;\n    }\n  });\n});\n\nAbstractPouchDB.prototype.removeAttachment =\n  adapterFun('removeAttachment', function (docId, attachmentId, rev,\n                                                 callback) {\n  var self = this;\n  self.get(docId, function (err, obj) {\n    /* istanbul ignore if */\n    if (err) {\n      callback(err);\n      return;\n    }\n    if (obj._rev !== rev) {\n      callback(createError(REV_CONFLICT));\n      return;\n    }\n    /* istanbul ignore if */\n    if (!obj._attachments) {\n      return callback();\n    }\n    delete obj._attachments[attachmentId];\n    if (Object.keys(obj._attachments).length === 0) {\n      delete obj._attachments;\n    }\n    self.put(obj, callback);\n  });\n});\n\nAbstractPouchDB.prototype.remove =\n  adapterFun('remove', function (docOrId, optsOrRev, opts, callback) {\n  var doc;\n  if (typeof optsOrRev === 'string') {\n    // id, rev, opts, callback style\n    doc = {\n      _id: docOrId,\n      _rev: optsOrRev\n    };\n    if (typeof opts === 'function') {\n      callback = opts;\n      opts = {};\n    }\n  } else {\n    // doc, opts, callback style\n    doc = docOrId;\n    if (typeof optsOrRev === 'function') {\n      callback = optsOrRev;\n      opts = {};\n    } else {\n      callback = opts;\n      opts = optsOrRev;\n    }\n  }\n  opts = opts || {};\n  opts.was_delete = true;\n  var newDoc = {_id: doc._id, _rev: (doc._rev || opts.rev)};\n  newDoc._deleted = true;\n  if (isLocalId(newDoc._id) && typeof this._removeLocal === 'function') {\n    return this._removeLocal(doc, callback);\n  }\n  this.bulkDocs({docs: [newDoc]}, opts, yankError(callback));\n});\n\nAbstractPouchDB.prototype.revsDiff =\n  adapterFun('revsDiff', function (req, opts, callback) {\n  if (typeof opts === 'function') {\n    callback = opts;\n    opts = {};\n  }\n  var ids = Object.keys(req);\n\n  if (!ids.length) {\n    return callback(null, {});\n  }\n\n  var count = 0;\n  var missing = new ExportedMap();\n\n  function addToMissing(id, revId) {\n    if (!missing.has(id)) {\n      missing.set(id, {missing: []});\n    }\n    missing.get(id).missing.push(revId);\n  }\n\n  function processDoc(id, rev_tree) {\n    // Is this fast enough? Maybe we should switch to a set simulated by a map\n    var missingForId = req[id].slice(0);\n    traverseRevTree(rev_tree, function (isLeaf, pos, revHash, ctx,\n      opts) {\n        var rev = pos + '-' + revHash;\n        var idx = missingForId.indexOf(rev);\n        if (idx === -1) {\n          return;\n        }\n\n        missingForId.splice(idx, 1);\n        /* istanbul ignore if */\n        if (opts.status !== 'available') {\n          addToMissing(id, rev);\n        }\n      });\n\n    // Traversing the tree is synchronous, so now `missingForId` contains\n    // revisions that were not found in the tree\n    missingForId.forEach(function (rev) {\n      addToMissing(id, rev);\n    });\n  }\n\n  ids.map(function (id) {\n    this._getRevisionTree(id, function (err, rev_tree) {\n      if (err && err.status === 404 && err.message === 'missing') {\n        missing.set(id, {missing: req[id]});\n      } else if (err) {\n        /* istanbul ignore next */\n        return callback(err);\n      } else {\n        processDoc(id, rev_tree);\n      }\n\n      if (++count === ids.length) {\n        // convert LazyMap to object\n        var missingObj = {};\n        missing.forEach(function (value, key) {\n          missingObj[key] = value;\n        });\n        return callback(null, missingObj);\n      }\n    });\n  }, this);\n});\n\n// _bulk_get API for faster replication, as described in\n// https://github.com/apache/couchdb-chttpd/pull/33\n// At the \"abstract\" level, it will just run multiple get()s in\n// parallel, because this isn't much of a performance cost\n// for local databases (except the cost of multiple transactions, which is\n// small). The http adapter overrides this in order\n// to do a more efficient single HTTP request.\nAbstractPouchDB.prototype.bulkGet =\n  adapterFun('bulkGet', function (opts, callback) {\n  bulkGet(this, opts, callback);\n});\n\n// compact one document and fire callback\n// by compacting we mean removing all revisions which\n// are further from the leaf in revision tree than max_height\nAbstractPouchDB.prototype.compactDocument =\n  adapterFun('compactDocument', function (docId, maxHeight, callback) {\n  var self = this;\n  this._getRevisionTree(docId, function (err, revTree) {\n    /* istanbul ignore if */\n    if (err) {\n      return callback(err);\n    }\n    var height = computeHeight(revTree);\n    var candidates = [];\n    var revs = [];\n    Object.keys(height).forEach(function (rev) {\n      if (height[rev] > maxHeight) {\n        candidates.push(rev);\n      }\n    });\n\n    traverseRevTree(revTree, function (isLeaf, pos, revHash, ctx, opts) {\n      var rev = pos + '-' + revHash;\n      if (opts.status === 'available' && candidates.indexOf(rev) !== -1) {\n        revs.push(rev);\n      }\n    });\n    self._doCompaction(docId, revs, callback);\n  });\n});\n\n// compact the whole database using single document\n// compaction\nAbstractPouchDB.prototype.compact =\n  adapterFun('compact', function (opts, callback) {\n  if (typeof opts === 'function') {\n    callback = opts;\n    opts = {};\n  }\n\n  var self = this;\n  opts = opts || {};\n\n  self._compactionQueue = self._compactionQueue || [];\n  self._compactionQueue.push({opts: opts, callback: callback});\n  if (self._compactionQueue.length === 1) {\n    doNextCompaction(self);\n  }\n});\nAbstractPouchDB.prototype._compact = function (opts, callback) {\n  var self = this;\n  var changesOpts = {\n    return_docs: false,\n    last_seq: opts.last_seq || 0\n  };\n  var promises = [];\n\n  function onChange(row) {\n    promises.push(self.compactDocument(row.id, 0));\n  }\n  function onComplete(resp) {\n    var lastSeq = resp.last_seq;\n    PouchPromise$1.all(promises).then(function () {\n      return upsert(self, '_local/compaction', function deltaFunc(doc) {\n        if (!doc.last_seq || doc.last_seq < lastSeq) {\n          doc.last_seq = lastSeq;\n          return doc;\n        }\n        return false; // somebody else got here first, don't update\n      });\n    }).then(function () {\n      callback(null, {ok: true});\n    }).catch(callback);\n  }\n  self.changes(changesOpts)\n    .on('change', onChange)\n    .on('complete', onComplete)\n    .on('error', callback);\n};\n\n/* Begin api wrappers. Specific functionality to storage belongs in the\n   _[method] */\nAbstractPouchDB.prototype.get = adapterFun('get', function (id, opts, cb) {\n  if (typeof opts === 'function') {\n    cb = opts;\n    opts = {};\n  }\n  if (typeof id !== 'string') {\n    return cb(createError(INVALID_ID));\n  }\n  if (isLocalId(id) && typeof this._getLocal === 'function') {\n    return this._getLocal(id, cb);\n  }\n  var leaves = [], self = this;\n\n  function finishOpenRevs() {\n    var result = [];\n    var count = leaves.length;\n    /* istanbul ignore if */\n    if (!count) {\n      return cb(null, result);\n    }\n\n    // order with open_revs is unspecified\n    leaves.forEach(function (leaf) {\n      self.get(id, {\n        rev: leaf,\n        revs: opts.revs,\n        latest: opts.latest,\n        attachments: opts.attachments\n      }, function (err, doc) {\n        if (!err) {\n          // using latest=true can produce duplicates\n          var existing;\n          for (var i = 0, l = result.length; i < l; i++) {\n            if (result[i].ok && result[i].ok._rev === doc._rev) {\n              existing = true;\n              break;\n            }\n          }\n          if (!existing) {\n            result.push({ok: doc});\n          }\n        } else {\n          result.push({missing: leaf});\n        }\n        count--;\n        if (!count) {\n          cb(null, result);\n        }\n      });\n    });\n  }\n\n  if (opts.open_revs) {\n    if (opts.open_revs === \"all\") {\n      this._getRevisionTree(id, function (err, rev_tree) {\n        if (err) {\n          return cb(err);\n        }\n        leaves = collectLeaves(rev_tree).map(function (leaf) {\n          return leaf.rev;\n        });\n        finishOpenRevs();\n      });\n    } else {\n      if (Array.isArray(opts.open_revs)) {\n        leaves = opts.open_revs;\n        for (var i = 0; i < leaves.length; i++) {\n          var l = leaves[i];\n          // looks like it's the only thing couchdb checks\n          if (!(typeof (l) === \"string\" && /^\\d+-/.test(l))) {\n            return cb(createError(INVALID_REV));\n          }\n        }\n        finishOpenRevs();\n      } else {\n        return cb(createError(UNKNOWN_ERROR, 'function_clause'));\n      }\n    }\n    return; // open_revs does not like other options\n  }\n\n  return this._get(id, opts, function (err, result) {\n    if (err) {\n      return cb(err);\n    }\n\n    var doc = result.doc;\n    var metadata = result.metadata;\n    var ctx = result.ctx;\n\n    if (opts.conflicts) {\n      var conflicts = collectConflicts(metadata);\n      if (conflicts.length) {\n        doc._conflicts = conflicts;\n      }\n    }\n\n    if (isDeleted(metadata, doc._rev)) {\n      doc._deleted = true;\n    }\n\n    if (opts.revs || opts.revs_info) {\n      var splittedRev = doc._rev.split('-');\n      var revNo       = parseInt(splittedRev[0], 10);\n      var revHash     = splittedRev[1];\n\n      var paths = rootToLeaf(metadata.rev_tree);\n      var path = null;\n\n      for (var i = 0; i < paths.length; i++) {\n        var currentPath = paths[i];\n        var hashIndex = currentPath.ids.map(function (x) { return x.id; })\n          .indexOf(revHash);\n        var hashFoundAtRevPos = hashIndex === (revNo - 1);\n\n        if (hashFoundAtRevPos || (!path && hashIndex !== -1)) {\n          path = currentPath;\n        }\n      }\n\n      var indexOfRev = path.ids.map(function (x) { return x.id; })\n        .indexOf(doc._rev.split('-')[1]) + 1;\n      var howMany = path.ids.length - indexOfRev;\n      path.ids.splice(indexOfRev, howMany);\n      path.ids.reverse();\n\n      if (opts.revs) {\n        doc._revisions = {\n          start: (path.pos + path.ids.length) - 1,\n          ids: path.ids.map(function (rev) {\n            return rev.id;\n          })\n        };\n      }\n      if (opts.revs_info) {\n        var pos =  path.pos + path.ids.length;\n        doc._revs_info = path.ids.map(function (rev) {\n          pos--;\n          return {\n            rev: pos + '-' + rev.id,\n            status: rev.opts.status\n          };\n        });\n      }\n    }\n\n    if (opts.attachments && doc._attachments) {\n      var attachments = doc._attachments;\n      var count = Object.keys(attachments).length;\n      if (count === 0) {\n        return cb(null, doc);\n      }\n      Object.keys(attachments).forEach(function (key) {\n        this._getAttachment(doc._id, key, attachments[key], {\n          // Previously the revision handling was done in adapter.js\n          // getAttachment, however since idb-next doesnt we need to\n          // pass the rev through\n          rev: doc._rev,\n          binary: opts.binary,\n          ctx: ctx\n        }, function (err, data) {\n          var att = doc._attachments[key];\n          att.data = data;\n          delete att.stub;\n          delete att.length;\n          if (!--count) {\n            cb(null, doc);\n          }\n        });\n      }, self);\n    } else {\n      if (doc._attachments) {\n        for (var key in doc._attachments) {\n          /* istanbul ignore else */\n          if (doc._attachments.hasOwnProperty(key)) {\n            doc._attachments[key].stub = true;\n          }\n        }\n      }\n      cb(null, doc);\n    }\n  });\n});\n\n// TODO: I dont like this, it forces an extra read for every\n// attachment read and enforces a confusing api between\n// adapter.js and the adapter implementation\nAbstractPouchDB.prototype.getAttachment =\n  adapterFun('getAttachment', function (docId, attachmentId, opts, callback) {\n  var self = this;\n  if (opts instanceof Function) {\n    callback = opts;\n    opts = {};\n  }\n  this._get(docId, opts, function (err, res) {\n    if (err) {\n      return callback(err);\n    }\n    if (res.doc._attachments && res.doc._attachments[attachmentId]) {\n      opts.ctx = res.ctx;\n      opts.binary = true;\n      self._getAttachment(docId, attachmentId,\n                          res.doc._attachments[attachmentId], opts, callback);\n    } else {\n      return callback(createError(MISSING_DOC));\n    }\n  });\n});\n\nAbstractPouchDB.prototype.allDocs =\n  adapterFun('allDocs', function (opts, callback) {\n  if (typeof opts === 'function') {\n    callback = opts;\n    opts = {};\n  }\n  opts.skip = typeof opts.skip !== 'undefined' ? opts.skip : 0;\n  if (opts.start_key) {\n    opts.startkey = opts.start_key;\n  }\n  if (opts.end_key) {\n    opts.endkey = opts.end_key;\n  }\n  if ('keys' in opts) {\n    if (!Array.isArray(opts.keys)) {\n      return callback(new TypeError('options.keys must be an array'));\n    }\n    var incompatibleOpt =\n      ['startkey', 'endkey', 'key'].filter(function (incompatibleOpt) {\n      return incompatibleOpt in opts;\n    })[0];\n    if (incompatibleOpt) {\n      callback(createError(QUERY_PARSE_ERROR,\n        'Query parameter `' + incompatibleOpt +\n        '` is not compatible with multi-get'\n      ));\n      return;\n    }\n    if (this.type() !== 'http') {\n      return allDocsKeysQuery(this, opts, callback);\n    }\n  }\n\n  return this._allDocs(opts, callback);\n});\n\nAbstractPouchDB.prototype.changes = function (opts, callback) {\n  if (typeof opts === 'function') {\n    callback = opts;\n    opts = {};\n  }\n  return new Changes$2(this, opts, callback);\n};\n\nAbstractPouchDB.prototype.close = adapterFun('close', function (callback) {\n  this._closed = true;\n  this.emit('closed');\n  return this._close(callback);\n});\n\nAbstractPouchDB.prototype.info = adapterFun('info', function (callback) {\n  var self = this;\n  this._info(function (err, info) {\n    if (err) {\n      return callback(err);\n    }\n    // assume we know better than the adapter, unless it informs us\n    info.db_name = info.db_name || self.name;\n    info.auto_compaction = !!(self.auto_compaction && self.type() !== 'http');\n    info.adapter = self.type();\n    callback(null, info);\n  });\n});\n\nAbstractPouchDB.prototype.id = adapterFun('id', function (callback) {\n  return this._id(callback);\n});\n\n/* istanbul ignore next */\nAbstractPouchDB.prototype.type = function () {\n  return (typeof this._type === 'function') ? this._type() : this.adapter;\n};\n\nAbstractPouchDB.prototype.bulkDocs =\n  adapterFun('bulkDocs', function (req, opts, callback) {\n  if (typeof opts === 'function') {\n    callback = opts;\n    opts = {};\n  }\n\n  opts = opts || {};\n\n  if (Array.isArray(req)) {\n    req = {\n      docs: req\n    };\n  }\n\n  if (!req || !req.docs || !Array.isArray(req.docs)) {\n    return callback(createError(MISSING_BULK_DOCS));\n  }\n\n  for (var i = 0; i < req.docs.length; ++i) {\n    if (typeof req.docs[i] !== 'object' || Array.isArray(req.docs[i])) {\n      return callback(createError(NOT_AN_OBJECT));\n    }\n  }\n\n  var attachmentError;\n  req.docs.forEach(function (doc) {\n    if (doc._attachments) {\n      Object.keys(doc._attachments).forEach(function (name) {\n        attachmentError = attachmentError || attachmentNameError(name);\n        if (!doc._attachments[name].content_type) {\n          guardedConsole('warn', 'Attachment', name, 'on document', doc._id, 'is missing content_type');\n        }\n      });\n    }\n  });\n\n  if (attachmentError) {\n    return callback(createError(BAD_REQUEST, attachmentError));\n  }\n\n  if (!('new_edits' in opts)) {\n    if ('new_edits' in req) {\n      opts.new_edits = req.new_edits;\n    } else {\n      opts.new_edits = true;\n    }\n  }\n\n  var adapter = this;\n  if (!opts.new_edits && adapter.type() !== 'http') {\n    // ensure revisions of the same doc are sorted, so that\n    // the local adapter processes them correctly (#2935)\n    req.docs.sort(compareByIdThenRev);\n  }\n\n  cleanDocs(req.docs);\n\n  // in the case of conflicts, we want to return the _ids to the user\n  // however, the underlying adapter may destroy the docs array, so\n  // create a copy here\n  var ids = req.docs.map(function (doc) {\n    return doc._id;\n  });\n\n  return this._bulkDocs(req, opts, function (err, res) {\n    if (err) {\n      return callback(err);\n    }\n    if (!opts.new_edits) {\n      // this is what couch does when new_edits is false\n      res = res.filter(function (x) {\n        return x.error;\n      });\n    }\n    // add ids for error/conflict responses (not required for CouchDB)\n    if (adapter.type() !== 'http') {\n      for (var i = 0, l = res.length; i < l; i++) {\n        res[i].id = res[i].id || ids[i];\n      }\n    }\n\n    callback(null, res);\n  });\n});\n\nAbstractPouchDB.prototype.registerDependentDatabase =\n  adapterFun('registerDependentDatabase', function (dependentDb,\n                                                          callback) {\n  var depDB = new this.constructor(dependentDb, this.__opts);\n\n  function diffFun(doc) {\n    doc.dependentDbs = doc.dependentDbs || {};\n    if (doc.dependentDbs[dependentDb]) {\n      return false; // no update required\n    }\n    doc.dependentDbs[dependentDb] = true;\n    return doc;\n  }\n  upsert(this, '_local/_pouch_dependentDbs', diffFun)\n    .then(function () {\n      callback(null, {db: depDB});\n    }).catch(callback);\n});\n\nAbstractPouchDB.prototype.destroy =\n  adapterFun('destroy', function (opts, callback) {\n\n  if (typeof opts === 'function') {\n    callback = opts;\n    opts = {};\n  }\n\n  var self = this;\n  var usePrefix = 'use_prefix' in self ? self.use_prefix : true;\n\n  function destroyDb() {\n    // call destroy method of the particular adaptor\n    self._destroy(opts, function (err, resp) {\n      if (err) {\n        return callback(err);\n      }\n      self._destroyed = true;\n      self.emit('destroyed');\n      callback(null, resp || { 'ok': true });\n    });\n  }\n\n  if (self.type() === 'http') {\n    // no need to check for dependent DBs if it's a remote DB\n    return destroyDb();\n  }\n\n  self.get('_local/_pouch_dependentDbs', function (err, localDoc) {\n    if (err) {\n      /* istanbul ignore if */\n      if (err.status !== 404) {\n        return callback(err);\n      } else { // no dependencies\n        return destroyDb();\n      }\n    }\n    var dependentDbs = localDoc.dependentDbs;\n    var PouchDB = self.constructor;\n    var deletedMap = Object.keys(dependentDbs).map(function (name) {\n      // use_prefix is only false in the browser\n      /* istanbul ignore next */\n      var trueName = usePrefix ?\n        name.replace(new RegExp('^' + PouchDB.prefix), '') : name;\n      return new PouchDB(trueName, self.__opts).destroy();\n    });\n    PouchPromise$1.all(deletedMap).then(destroyDb, callback);\n  });\n});\n\nfunction TaskQueue$1() {\n  this.isReady = false;\n  this.failed = false;\n  this.queue = [];\n}\n\nTaskQueue$1.prototype.execute = function () {\n  var fun;\n  if (this.failed) {\n    while ((fun = this.queue.shift())) {\n      fun(this.failed);\n    }\n  } else {\n    while ((fun = this.queue.shift())) {\n      fun();\n    }\n  }\n};\n\nTaskQueue$1.prototype.fail = function (err) {\n  this.failed = err;\n  this.execute();\n};\n\nTaskQueue$1.prototype.ready = function (db) {\n  this.isReady = true;\n  this.db = db;\n  this.execute();\n};\n\nTaskQueue$1.prototype.addTask = function (fun) {\n  this.queue.push(fun);\n  if (this.failed) {\n    this.execute();\n  }\n};\n\nfunction parseAdapter(name, opts) {\n  var match = name.match(/([a-z\\-]*):\\/\\/(.*)/);\n  if (match) {\n    // the http adapter expects the fully qualified name\n    return {\n      name: /https?/.test(match[1]) ? match[1] + '://' + match[2] : match[2],\n      adapter: match[1]\n    };\n  }\n\n  var adapters = PouchDB$5.adapters;\n  var preferredAdapters = PouchDB$5.preferredAdapters;\n  var prefix = PouchDB$5.prefix;\n  var adapterName = opts.adapter;\n\n  if (!adapterName) { // automatically determine adapter\n    for (var i = 0; i < preferredAdapters.length; ++i) {\n      adapterName = preferredAdapters[i];\n      // check for browsers that have been upgraded from websql-only to websql+idb\n      /* istanbul ignore if */\n      if (adapterName === 'idb' && 'websql' in adapters &&\n          hasLocalStorage() && localStorage['_pouch__websqldb_' + prefix + name]) {\n        // log it, because this can be confusing during development\n        guardedConsole('log', 'PouchDB is downgrading \"' + name + '\" to WebSQL to' +\n          ' avoid data loss, because it was already opened with WebSQL.');\n        continue; // keep using websql to avoid user data loss\n      }\n      break;\n    }\n  }\n\n  var adapter = adapters[adapterName];\n\n  // if adapter is invalid, then an error will be thrown later\n  var usePrefix = (adapter && 'use_prefix' in adapter) ?\n    adapter.use_prefix : true;\n\n  return {\n    name: usePrefix ? (prefix + name) : name,\n    adapter: adapterName\n  };\n}\n\n// OK, so here's the deal. Consider this code:\n//     var db1 = new PouchDB('foo');\n//     var db2 = new PouchDB('foo');\n//     db1.destroy();\n// ^ these two both need to emit 'destroyed' events,\n// as well as the PouchDB constructor itself.\n// So we have one db object (whichever one got destroy() called on it)\n// responsible for emitting the initial event, which then gets emitted\n// by the constructor, which then broadcasts it to any other dbs\n// that may have been created with the same name.\nfunction prepareForDestruction(self) {\n\n  var destructionListeners = self.constructor._destructionListeners;\n\n  function onDestroyed() {\n    self.removeListener('closed', onClosed);\n    self.constructor.emit('destroyed', self.name);\n  }\n\n  function onConstructorDestroyed() {\n    self.removeListener('destroyed', onDestroyed);\n    self.removeListener('closed', onClosed);\n    self.emit('destroyed');\n  }\n\n  function onClosed() {\n    self.removeListener('destroyed', onDestroyed);\n    destructionListeners.delete(self.name);\n  }\n\n  self.once('destroyed', onDestroyed);\n  self.once('closed', onClosed);\n\n  // in setup.js, the constructor is primed to listen for destroy events\n  if (!destructionListeners.has(self.name)) {\n    destructionListeners.set(self.name, []);\n  }\n  destructionListeners.get(self.name).push(onConstructorDestroyed);\n}\n\ninherits(PouchDB$5, AbstractPouchDB);\nfunction PouchDB$5(name, opts) {\n  // In Node our test suite only tests this for PouchAlt unfortunately\n  /* istanbul ignore if */\n  if (!(this instanceof PouchDB$5)) {\n    return new PouchDB$5(name, opts);\n  }\n\n  var self = this;\n  opts = opts || {};\n\n  if (name && typeof name === 'object') {\n    opts = name;\n    name = opts.name;\n    delete opts.name;\n  }\n\n  this.__opts = opts = clone(opts);\n\n  self.auto_compaction = opts.auto_compaction;\n  self.prefix = PouchDB$5.prefix;\n\n  if (typeof name !== 'string') {\n    throw new Error('Missing/invalid DB name');\n  }\n\n  var prefixedName = (opts.prefix || '') + name;\n  var backend = parseAdapter(prefixedName, opts);\n\n  opts.name = backend.name;\n  opts.adapter = opts.adapter || backend.adapter;\n\n  self.name = name;\n  self._adapter = opts.adapter;\n  debug('pouchdb:adapter')('Picked adapter: ' + opts.adapter);\n\n  if (!PouchDB$5.adapters[opts.adapter] ||\n      !PouchDB$5.adapters[opts.adapter].valid()) {\n    throw new Error('Invalid Adapter: ' + opts.adapter);\n  }\n\n  AbstractPouchDB.call(self);\n  self.taskqueue = new TaskQueue$1();\n\n  self.adapter = opts.adapter;\n\n  PouchDB$5.adapters[opts.adapter].call(self, opts, function (err) {\n    if (err) {\n      return self.taskqueue.fail(err);\n    }\n    prepareForDestruction(self);\n\n    self.emit('created', self);\n    PouchDB$5.emit('created', self.name);\n    self.taskqueue.ready(self);\n  });\n\n}\n\nPouchDB$5.debug = debug;\n\nPouchDB$5.adapters = {};\nPouchDB$5.preferredAdapters = [];\n\nPouchDB$5.prefix = '_pouch_';\n\nvar eventEmitter = new events.EventEmitter();\n\nfunction setUpEventEmitter(Pouch) {\n  Object.keys(events.EventEmitter.prototype).forEach(function (key) {\n    if (typeof events.EventEmitter.prototype[key] === 'function') {\n      Pouch[key] = eventEmitter[key].bind(eventEmitter);\n    }\n  });\n\n  // these are created in constructor.js, and allow us to notify each DB with\n  // the same name that it was destroyed, via the constructor object\n  var destructListeners = Pouch._destructionListeners = new ExportedMap();\n  Pouch.on('destroyed', function onConstructorDestroyed(name) {\n    destructListeners.get(name).forEach(function (callback) {\n      callback();\n    });\n    destructListeners.delete(name);\n  });\n}\n\nsetUpEventEmitter(PouchDB$5);\n\nPouchDB$5.adapter = function (id, obj, addToPreferredAdapters) {\n  /* istanbul ignore else */\n  if (obj.valid()) {\n    PouchDB$5.adapters[id] = obj;\n    if (addToPreferredAdapters) {\n      PouchDB$5.preferredAdapters.push(id);\n    }\n  }\n};\n\nPouchDB$5.plugin = function (obj) {\n  if (typeof obj === 'function') { // function style for plugins\n    obj(PouchDB$5);\n  } else if (typeof obj !== 'object' || Object.keys(obj).length === 0){\n    throw new Error('Invalid plugin: got \\\"' + obj + '\\\", expected an object or a function');\n  } else {\n    Object.keys(obj).forEach(function (id) { // object style for plugins\n      PouchDB$5.prototype[id] = obj[id];\n    });\n  }\n  return PouchDB$5;\n};\n\nPouchDB$5.defaults = function (defaultOpts) {\n  function PouchAlt(name, opts) {\n    if (!(this instanceof PouchAlt)) {\n      return new PouchAlt(name, opts);\n    }\n\n    opts = opts || {};\n\n    if (name && typeof name === 'object') {\n      opts = name;\n      name = opts.name;\n      delete opts.name;\n    }\n\n    opts = assign$1({}, PouchAlt.__defaults, opts);\n    PouchDB$5.call(this, name, opts);\n  }\n\n  inherits(PouchAlt, PouchDB$5);\n\n  PouchAlt.preferredAdapters = PouchDB$5.preferredAdapters.slice();\n  Object.keys(PouchDB$5).forEach(function (key) {\n    if (!(key in PouchAlt)) {\n      PouchAlt[key] = PouchDB$5[key];\n    }\n  });\n\n  // make default options transitive\n  // https://github.com/pouchdb/pouchdb/issues/5922\n  PouchAlt.__defaults = assign$1({}, this.__defaults, defaultOpts);\n\n  return PouchAlt;\n};\n\n// managed automatically by set-version.js\nvar version = \"6.1.1\";\n\nPouchDB$5.version = version;\n\nfunction toObject(array) {\n  return array.reduce(function (obj, item) {\n    obj[item] = true;\n    return obj;\n  }, {});\n}\n// List of top level reserved words for doc\nvar reservedWords = toObject([\n  '_id',\n  '_rev',\n  '_attachments',\n  '_deleted',\n  '_revisions',\n  '_revs_info',\n  '_conflicts',\n  '_deleted_conflicts',\n  '_local_seq',\n  '_rev_tree',\n  //replication documents\n  '_replication_id',\n  '_replication_state',\n  '_replication_state_time',\n  '_replication_state_reason',\n  '_replication_stats',\n  // Specific to Couchbase Sync Gateway\n  '_removed'\n]);\n\n// List of reserved words that should end up the document\nvar dataWords = toObject([\n  '_attachments',\n  //replication documents\n  '_replication_id',\n  '_replication_state',\n  '_replication_state_time',\n  '_replication_state_reason',\n  '_replication_stats'\n]);\n\nfunction parseRevisionInfo(rev) {\n  if (!/^\\d+\\-./.test(rev)) {\n    return createError(INVALID_REV);\n  }\n  var idx = rev.indexOf('-');\n  var left = rev.substring(0, idx);\n  var right = rev.substring(idx + 1);\n  return {\n    prefix: parseInt(left, 10),\n    id: right\n  };\n}\n\nfunction makeRevTreeFromRevisions(revisions, opts) {\n  var pos = revisions.start - revisions.ids.length + 1;\n\n  var revisionIds = revisions.ids;\n  var ids = [revisionIds[0], opts, []];\n\n  for (var i = 1, len = revisionIds.length; i < len; i++) {\n    ids = [revisionIds[i], {status: 'missing'}, [ids]];\n  }\n\n  return [{\n    pos: pos,\n    ids: ids\n  }];\n}\n\n// Preprocess documents, parse their revisions, assign an id and a\n// revision for new writes that are missing them, etc\nfunction parseDoc(doc, newEdits) {\n\n  var nRevNum;\n  var newRevId;\n  var revInfo;\n  var opts = {status: 'available'};\n  if (doc._deleted) {\n    opts.deleted = true;\n  }\n\n  if (newEdits) {\n    if (!doc._id) {\n      doc._id = uuid();\n    }\n    newRevId = uuid(32, 16).toLowerCase();\n    if (doc._rev) {\n      revInfo = parseRevisionInfo(doc._rev);\n      if (revInfo.error) {\n        return revInfo;\n      }\n      doc._rev_tree = [{\n        pos: revInfo.prefix,\n        ids: [revInfo.id, {status: 'missing'}, [[newRevId, opts, []]]]\n      }];\n      nRevNum = revInfo.prefix + 1;\n    } else {\n      doc._rev_tree = [{\n        pos: 1,\n        ids : [newRevId, opts, []]\n      }];\n      nRevNum = 1;\n    }\n  } else {\n    if (doc._revisions) {\n      doc._rev_tree = makeRevTreeFromRevisions(doc._revisions, opts);\n      nRevNum = doc._revisions.start;\n      newRevId = doc._revisions.ids[0];\n    }\n    if (!doc._rev_tree) {\n      revInfo = parseRevisionInfo(doc._rev);\n      if (revInfo.error) {\n        return revInfo;\n      }\n      nRevNum = revInfo.prefix;\n      newRevId = revInfo.id;\n      doc._rev_tree = [{\n        pos: nRevNum,\n        ids: [newRevId, opts, []]\n      }];\n    }\n  }\n\n  invalidIdError(doc._id);\n\n  doc._rev = nRevNum + '-' + newRevId;\n\n  var result = {metadata : {}, data : {}};\n  for (var key in doc) {\n    /* istanbul ignore else */\n    if (Object.prototype.hasOwnProperty.call(doc, key)) {\n      var specialKey = key[0] === '_';\n      if (specialKey && !reservedWords[key]) {\n        var error = createError(DOC_VALIDATION, key);\n        error.message = DOC_VALIDATION.message + ': ' + key;\n        throw error;\n      } else if (specialKey && !dataWords[key]) {\n        result.metadata[key.slice(1)] = doc[key];\n      } else {\n        result.data[key] = doc[key];\n      }\n    }\n  }\n  return result;\n}\n\nvar thisAtob = function (str) {\n  return atob(str);\n};\n\nvar thisBtoa = function (str) {\n  return btoa(str);\n};\n\n// Abstracts constructing a Blob object, so it also works in older\n// browsers that don't support the native Blob constructor (e.g.\n// old QtWebKit versions, Android < 4.4).\nfunction createBlob(parts, properties) {\n  /* global BlobBuilder,MSBlobBuilder,MozBlobBuilder,WebKitBlobBuilder */\n  parts = parts || [];\n  properties = properties || {};\n  try {\n    return new Blob(parts, properties);\n  } catch (e) {\n    if (e.name !== \"TypeError\") {\n      throw e;\n    }\n    var Builder = typeof BlobBuilder !== 'undefined' ? BlobBuilder :\n                  typeof MSBlobBuilder !== 'undefined' ? MSBlobBuilder :\n                  typeof MozBlobBuilder !== 'undefined' ? MozBlobBuilder :\n                  WebKitBlobBuilder;\n    var builder = new Builder();\n    for (var i = 0; i < parts.length; i += 1) {\n      builder.append(parts[i]);\n    }\n    return builder.getBlob(properties.type);\n  }\n}\n\n// From http://stackoverflow.com/questions/14967647/ (continues on next line)\n// encode-decode-image-with-base64-breaks-image (2013-04-21)\nfunction binaryStringToArrayBuffer(bin) {\n  var length = bin.length;\n  var buf = new ArrayBuffer(length);\n  var arr = new Uint8Array(buf);\n  for (var i = 0; i < length; i++) {\n    arr[i] = bin.charCodeAt(i);\n  }\n  return buf;\n}\n\nfunction binStringToBluffer(binString, type) {\n  return createBlob([binaryStringToArrayBuffer(binString)], {type: type});\n}\n\nfunction b64ToBluffer(b64, type) {\n  return binStringToBluffer(thisAtob(b64), type);\n}\n\n//Can't find original post, but this is close\n//http://stackoverflow.com/questions/6965107/ (continues on next line)\n//converting-between-strings-and-arraybuffers\nfunction arrayBufferToBinaryString(buffer) {\n  var binary = '';\n  var bytes = new Uint8Array(buffer);\n  var length = bytes.byteLength;\n  for (var i = 0; i < length; i++) {\n    binary += String.fromCharCode(bytes[i]);\n  }\n  return binary;\n}\n\n// shim for browsers that don't support it\nfunction readAsBinaryString(blob, callback) {\n  if (typeof FileReader === 'undefined') {\n    // fix for Firefox in a web worker\n    // https://bugzilla.mozilla.org/show_bug.cgi?id=901097\n    return callback(arrayBufferToBinaryString(\n      new FileReaderSync().readAsArrayBuffer(blob)));\n  }\n\n  var reader = new FileReader();\n  var hasBinaryString = typeof reader.readAsBinaryString === 'function';\n  reader.onloadend = function (e) {\n    var result = e.target.result || '';\n    if (hasBinaryString) {\n      return callback(result);\n    }\n    callback(arrayBufferToBinaryString(result));\n  };\n  if (hasBinaryString) {\n    reader.readAsBinaryString(blob);\n  } else {\n    reader.readAsArrayBuffer(blob);\n  }\n}\n\nfunction blobToBinaryString(blobOrBuffer, callback) {\n  readAsBinaryString(blobOrBuffer, function (bin) {\n    callback(bin);\n  });\n}\n\nfunction blobToBase64(blobOrBuffer, callback) {\n  blobToBinaryString(blobOrBuffer, function (base64) {\n    callback(thisBtoa(base64));\n  });\n}\n\n// simplified API. universal browser support is assumed\nfunction readAsArrayBuffer(blob, callback) {\n  if (typeof FileReader === 'undefined') {\n    // fix for Firefox in a web worker:\n    // https://bugzilla.mozilla.org/show_bug.cgi?id=901097\n    return callback(new FileReaderSync().readAsArrayBuffer(blob));\n  }\n\n  var reader = new FileReader();\n  reader.onloadend = function (e) {\n    var result = e.target.result || new ArrayBuffer(0);\n    callback(result);\n  };\n  reader.readAsArrayBuffer(blob);\n}\n\n// this is not used in the browser\n\nvar setImmediateShim = global.setImmediate || global.setTimeout;\nvar MD5_CHUNK_SIZE = 32768;\n\nfunction rawToBase64(raw) {\n  return thisBtoa(raw);\n}\n\nfunction sliceBlob(blob$$1, start, end) {\n  if (blob$$1.webkitSlice) {\n    return blob$$1.webkitSlice(start, end);\n  }\n  return blob$$1.slice(start, end);\n}\n\nfunction appendBlob(buffer, blob$$1, start, end, callback) {\n  if (start > 0 || end < blob$$1.size) {\n    // only slice blob if we really need to\n    blob$$1 = sliceBlob(blob$$1, start, end);\n  }\n  readAsArrayBuffer(blob$$1, function (arrayBuffer) {\n    buffer.append(arrayBuffer);\n    callback();\n  });\n}\n\nfunction appendString(buffer, string, start, end, callback) {\n  if (start > 0 || end < string.length) {\n    // only create a substring if we really need to\n    string = string.substring(start, end);\n  }\n  buffer.appendBinary(string);\n  callback();\n}\n\nfunction binaryMd5(data, callback) {\n  var inputIsString = typeof data === 'string';\n  var len = inputIsString ? data.length : data.size;\n  var chunkSize = Math.min(MD5_CHUNK_SIZE, len);\n  var chunks = Math.ceil(len / chunkSize);\n  var currentChunk = 0;\n  var buffer = inputIsString ? new Md5() : new Md5.ArrayBuffer();\n\n  var append = inputIsString ? appendString : appendBlob;\n\n  function next() {\n    setImmediateShim(loadNextChunk);\n  }\n\n  function done() {\n    var raw = buffer.end(true);\n    var base64 = rawToBase64(raw);\n    callback(base64);\n    buffer.destroy();\n  }\n\n  function loadNextChunk() {\n    var start = currentChunk * chunkSize;\n    var end = start + chunkSize;\n    currentChunk++;\n    if (currentChunk < chunks) {\n      append(buffer, data, start, end, next);\n    } else {\n      append(buffer, data, start, end, done);\n    }\n  }\n  loadNextChunk();\n}\n\nfunction stringMd5(string) {\n  return Md5.hash(string);\n}\n\nfunction parseBase64(data) {\n  try {\n    return thisAtob(data);\n  } catch (e) {\n    var err = createError(BAD_ARG,\n      'Attachment is not a valid base64 string');\n    return {error: err};\n  }\n}\n\nfunction preprocessString(att, blobType, callback) {\n  var asBinary = parseBase64(att.data);\n  if (asBinary.error) {\n    return callback(asBinary.error);\n  }\n\n  att.length = asBinary.length;\n  if (blobType === 'blob') {\n    att.data = binStringToBluffer(asBinary, att.content_type);\n  } else if (blobType === 'base64') {\n    att.data = thisBtoa(asBinary);\n  } else { // binary\n    att.data = asBinary;\n  }\n  binaryMd5(asBinary, function (result) {\n    att.digest = 'md5-' + result;\n    callback();\n  });\n}\n\nfunction preprocessBlob(att, blobType, callback) {\n  binaryMd5(att.data, function (md5) {\n    att.digest = 'md5-' + md5;\n    // size is for blobs (browser), length is for buffers (node)\n    att.length = att.data.size || att.data.length || 0;\n    if (blobType === 'binary') {\n      blobToBinaryString(att.data, function (binString) {\n        att.data = binString;\n        callback();\n      });\n    } else if (blobType === 'base64') {\n      blobToBase64(att.data, function (b64) {\n        att.data = b64;\n        callback();\n      });\n    } else {\n      callback();\n    }\n  });\n}\n\nfunction preprocessAttachment(att, blobType, callback) {\n  if (att.stub) {\n    return callback();\n  }\n  if (typeof att.data === 'string') { // input is a base64 string\n    preprocessString(att, blobType, callback);\n  } else { // input is a blob\n    preprocessBlob(att, blobType, callback);\n  }\n}\n\nfunction preprocessAttachments(docInfos, blobType, callback) {\n\n  if (!docInfos.length) {\n    return callback();\n  }\n\n  var docv = 0;\n  var overallErr;\n\n  docInfos.forEach(function (docInfo) {\n    var attachments = docInfo.data && docInfo.data._attachments ?\n      Object.keys(docInfo.data._attachments) : [];\n    var recv = 0;\n\n    if (!attachments.length) {\n      return done();\n    }\n\n    function processedAttachment(err) {\n      overallErr = err;\n      recv++;\n      if (recv === attachments.length) {\n        done();\n      }\n    }\n\n    for (var key in docInfo.data._attachments) {\n      if (docInfo.data._attachments.hasOwnProperty(key)) {\n        preprocessAttachment(docInfo.data._attachments[key],\n          blobType, processedAttachment);\n      }\n    }\n  });\n\n  function done() {\n    docv++;\n    if (docInfos.length === docv) {\n      if (overallErr) {\n        callback(overallErr);\n      } else {\n        callback();\n      }\n    }\n  }\n}\n\nfunction updateDoc(revLimit, prev, docInfo, results,\n                   i, cb, writeDoc, newEdits) {\n\n  if (revExists(prev.rev_tree, docInfo.metadata.rev)) {\n    results[i] = docInfo;\n    return cb();\n  }\n\n  // sometimes this is pre-calculated. historically not always\n  var previousWinningRev = prev.winningRev || winningRev(prev);\n  var previouslyDeleted = 'deleted' in prev ? prev.deleted :\n    isDeleted(prev, previousWinningRev);\n  var deleted = 'deleted' in docInfo.metadata ? docInfo.metadata.deleted :\n    isDeleted(docInfo.metadata);\n  var isRoot = /^1-/.test(docInfo.metadata.rev);\n\n  if (previouslyDeleted && !deleted && newEdits && isRoot) {\n    var newDoc = docInfo.data;\n    newDoc._rev = previousWinningRev;\n    newDoc._id = docInfo.metadata.id;\n    docInfo = parseDoc(newDoc, newEdits);\n  }\n\n  var merged = merge(prev.rev_tree, docInfo.metadata.rev_tree[0], revLimit);\n\n  var inConflict = newEdits && (((previouslyDeleted && deleted) ||\n    (!previouslyDeleted && merged.conflicts !== 'new_leaf') ||\n    (previouslyDeleted && !deleted && merged.conflicts === 'new_branch')));\n\n  if (inConflict) {\n    var err = createError(REV_CONFLICT);\n    results[i] = err;\n    return cb();\n  }\n\n  var newRev = docInfo.metadata.rev;\n  docInfo.metadata.rev_tree = merged.tree;\n  docInfo.stemmedRevs = merged.stemmedRevs || [];\n  /* istanbul ignore else */\n  if (prev.rev_map) {\n    docInfo.metadata.rev_map = prev.rev_map; // used only by leveldb\n  }\n\n  // recalculate\n  var winningRev$$1 = winningRev(docInfo.metadata);\n  var winningRevIsDeleted = isDeleted(docInfo.metadata, winningRev$$1);\n\n  // calculate the total number of documents that were added/removed,\n  // from the perspective of total_rows/doc_count\n  var delta = (previouslyDeleted === winningRevIsDeleted) ? 0 :\n    previouslyDeleted < winningRevIsDeleted ? -1 : 1;\n\n  var newRevIsDeleted;\n  if (newRev === winningRev$$1) {\n    // if the new rev is the same as the winning rev, we can reuse that value\n    newRevIsDeleted = winningRevIsDeleted;\n  } else {\n    // if they're not the same, then we need to recalculate\n    newRevIsDeleted = isDeleted(docInfo.metadata, newRev);\n  }\n\n  writeDoc(docInfo, winningRev$$1, winningRevIsDeleted, newRevIsDeleted,\n    true, delta, i, cb);\n}\n\nfunction rootIsMissing(docInfo) {\n  return docInfo.metadata.rev_tree[0].ids[1].status === 'missing';\n}\n\nfunction processDocs(revLimit, docInfos, api, fetchedDocs, tx, results,\n                     writeDoc, opts, overallCallback) {\n\n  // Default to 1000 locally\n  revLimit = revLimit || 1000;\n\n  function insertDoc(docInfo, resultsIdx, callback) {\n    // Cant insert new deleted documents\n    var winningRev$$1 = winningRev(docInfo.metadata);\n    var deleted = isDeleted(docInfo.metadata, winningRev$$1);\n    if ('was_delete' in opts && deleted) {\n      results[resultsIdx] = createError(MISSING_DOC, 'deleted');\n      return callback();\n    }\n\n    // 4712 - detect whether a new document was inserted with a _rev\n    var inConflict = newEdits && rootIsMissing(docInfo);\n\n    if (inConflict) {\n      var err = createError(REV_CONFLICT);\n      results[resultsIdx] = err;\n      return callback();\n    }\n\n    var delta = deleted ? 0 : 1;\n\n    writeDoc(docInfo, winningRev$$1, deleted, deleted, false,\n      delta, resultsIdx, callback);\n  }\n\n  var newEdits = opts.new_edits;\n  var idsToDocs = new ExportedMap();\n\n  var docsDone = 0;\n  var docsToDo = docInfos.length;\n\n  function checkAllDocsDone() {\n    if (++docsDone === docsToDo && overallCallback) {\n      overallCallback();\n    }\n  }\n\n  docInfos.forEach(function (currentDoc, resultsIdx) {\n\n    if (currentDoc._id && isLocalId(currentDoc._id)) {\n      var fun = currentDoc._deleted ? '_removeLocal' : '_putLocal';\n      api[fun](currentDoc, {ctx: tx}, function (err, res) {\n        results[resultsIdx] = err || res;\n        checkAllDocsDone();\n      });\n      return;\n    }\n\n    var id = currentDoc.metadata.id;\n    if (idsToDocs.has(id)) {\n      docsToDo--; // duplicate\n      idsToDocs.get(id).push([currentDoc, resultsIdx]);\n    } else {\n      idsToDocs.set(id, [[currentDoc, resultsIdx]]);\n    }\n  });\n\n  // in the case of new_edits, the user can provide multiple docs\n  // with the same id. these need to be processed sequentially\n  idsToDocs.forEach(function (docs, id) {\n    var numDone = 0;\n\n    function docWritten() {\n      if (++numDone < docs.length) {\n        nextDoc();\n      } else {\n        checkAllDocsDone();\n      }\n    }\n    function nextDoc() {\n      var value = docs[numDone];\n      var currentDoc = value[0];\n      var resultsIdx = value[1];\n\n      if (fetchedDocs.has(id)) {\n        updateDoc(revLimit, fetchedDocs.get(id), currentDoc, results,\n          resultsIdx, docWritten, writeDoc, newEdits);\n      } else {\n        // Ensure stemming applies to new writes as well\n        var merged = merge([], currentDoc.metadata.rev_tree[0], revLimit);\n        currentDoc.metadata.rev_tree = merged.tree;\n        currentDoc.stemmedRevs = merged.stemmedRevs || [];\n        insertDoc(currentDoc, resultsIdx, docWritten);\n      }\n    }\n    nextDoc();\n  });\n}\n\n// IndexedDB requires a versioned database structure, so we use the\n// version here to manage migrations.\nvar ADAPTER_VERSION = 5;\n\n// The object stores created for each database\n// DOC_STORE stores the document meta data, its revision history and state\n// Keyed by document id\nvar DOC_STORE = 'document-store';\n// BY_SEQ_STORE stores a particular version of a document, keyed by its\n// sequence id\nvar BY_SEQ_STORE = 'by-sequence';\n// Where we store attachments\nvar ATTACH_STORE = 'attach-store';\n// Where we store many-to-many relations\n// between attachment digests and seqs\nvar ATTACH_AND_SEQ_STORE = 'attach-seq-store';\n\n// Where we store database-wide meta data in a single record\n// keyed by id: META_STORE\nvar META_STORE = 'meta-store';\n// Where we store local documents\nvar LOCAL_STORE = 'local-store';\n// Where we detect blob support\nvar DETECT_BLOB_SUPPORT_STORE = 'detect-blob-support';\n\nfunction safeJsonParse(str) {\n  // This try/catch guards against stack overflow errors.\n  // JSON.parse() is faster than vuvuzela.parse() but vuvuzela\n  // cannot overflow.\n  try {\n    return JSON.parse(str);\n  } catch (e) {\n    /* istanbul ignore next */\n    return vuvuzela.parse(str);\n  }\n}\n\nfunction safeJsonStringify(json) {\n  try {\n    return JSON.stringify(json);\n  } catch (e) {\n    /* istanbul ignore next */\n    return vuvuzela.stringify(json);\n  }\n}\n\nfunction idbError(callback) {\n  return function (evt) {\n    var message = 'unknown_error';\n    if (evt.target && evt.target.error) {\n      message = evt.target.error.name || evt.target.error.message;\n    }\n    callback(createError(IDB_ERROR, message, evt.type));\n  };\n}\n\n// Unfortunately, the metadata has to be stringified\n// when it is put into the database, because otherwise\n// IndexedDB can throw errors for deeply-nested objects.\n// Originally we just used JSON.parse/JSON.stringify; now\n// we use this custom vuvuzela library that avoids recursion.\n// If we could do it all over again, we'd probably use a\n// format for the revision trees other than JSON.\nfunction encodeMetadata(metadata, winningRev, deleted) {\n  return {\n    data: safeJsonStringify(metadata),\n    winningRev: winningRev,\n    deletedOrLocal: deleted ? '1' : '0',\n    seq: metadata.seq, // highest seq for this doc\n    id: metadata.id\n  };\n}\n\nfunction decodeMetadata(storedObject) {\n  if (!storedObject) {\n    return null;\n  }\n  var metadata = safeJsonParse(storedObject.data);\n  metadata.winningRev = storedObject.winningRev;\n  metadata.deleted = storedObject.deletedOrLocal === '1';\n  metadata.seq = storedObject.seq;\n  return metadata;\n}\n\n// read the doc back out from the database. we don't store the\n// _id or _rev because we already have _doc_id_rev.\nfunction decodeDoc(doc) {\n  if (!doc) {\n    return doc;\n  }\n  var idx = doc._doc_id_rev.lastIndexOf(':');\n  doc._id = doc._doc_id_rev.substring(0, idx - 1);\n  doc._rev = doc._doc_id_rev.substring(idx + 1);\n  delete doc._doc_id_rev;\n  return doc;\n}\n\n// Read a blob from the database, encoding as necessary\n// and translating from base64 if the IDB doesn't support\n// native Blobs\nfunction readBlobData(body, type, asBlob, callback) {\n  if (asBlob) {\n    if (!body) {\n      callback(createBlob([''], {type: type}));\n    } else if (typeof body !== 'string') { // we have blob support\n      callback(body);\n    } else { // no blob support\n      callback(b64ToBluffer(body, type));\n    }\n  } else { // as base64 string\n    if (!body) {\n      callback('');\n    } else if (typeof body !== 'string') { // we have blob support\n      readAsBinaryString(body, function (binary) {\n        callback(thisBtoa(binary));\n      });\n    } else { // no blob support\n      callback(body);\n    }\n  }\n}\n\nfunction fetchAttachmentsIfNecessary(doc, opts, txn, cb) {\n  var attachments = Object.keys(doc._attachments || {});\n  if (!attachments.length) {\n    return cb && cb();\n  }\n  var numDone = 0;\n\n  function checkDone() {\n    if (++numDone === attachments.length && cb) {\n      cb();\n    }\n  }\n\n  function fetchAttachment(doc, att) {\n    var attObj = doc._attachments[att];\n    var digest = attObj.digest;\n    var req = txn.objectStore(ATTACH_STORE).get(digest);\n    req.onsuccess = function (e) {\n      attObj.body = e.target.result.body;\n      checkDone();\n    };\n  }\n\n  attachments.forEach(function (att) {\n    if (opts.attachments && opts.include_docs) {\n      fetchAttachment(doc, att);\n    } else {\n      doc._attachments[att].stub = true;\n      checkDone();\n    }\n  });\n}\n\n// IDB-specific postprocessing necessary because\n// we don't know whether we stored a true Blob or\n// a base64-encoded string, and if it's a Blob it\n// needs to be read outside of the transaction context\nfunction postProcessAttachments(results, asBlob) {\n  return PouchPromise$1.all(results.map(function (row) {\n    if (row.doc && row.doc._attachments) {\n      var attNames = Object.keys(row.doc._attachments);\n      return PouchPromise$1.all(attNames.map(function (att) {\n        var attObj = row.doc._attachments[att];\n        if (!('body' in attObj)) { // already processed\n          return;\n        }\n        var body = attObj.body;\n        var type = attObj.content_type;\n        return new PouchPromise$1(function (resolve) {\n          readBlobData(body, type, asBlob, function (data) {\n            row.doc._attachments[att] = assign$1(\n              pick(attObj, ['digest', 'content_type']),\n              {data: data}\n            );\n            resolve();\n          });\n        });\n      }));\n    }\n  }));\n}\n\nfunction compactRevs(revs, docId, txn) {\n\n  var possiblyOrphanedDigests = [];\n  var seqStore = txn.objectStore(BY_SEQ_STORE);\n  var attStore = txn.objectStore(ATTACH_STORE);\n  var attAndSeqStore = txn.objectStore(ATTACH_AND_SEQ_STORE);\n  var count = revs.length;\n\n  function checkDone() {\n    count--;\n    if (!count) { // done processing all revs\n      deleteOrphanedAttachments();\n    }\n  }\n\n  function deleteOrphanedAttachments() {\n    if (!possiblyOrphanedDigests.length) {\n      return;\n    }\n    possiblyOrphanedDigests.forEach(function (digest) {\n      var countReq = attAndSeqStore.index('digestSeq').count(\n        IDBKeyRange.bound(\n          digest + '::', digest + '::\\uffff', false, false));\n      countReq.onsuccess = function (e) {\n        var count = e.target.result;\n        if (!count) {\n          // orphaned\n          attStore.delete(digest);\n        }\n      };\n    });\n  }\n\n  revs.forEach(function (rev) {\n    var index = seqStore.index('_doc_id_rev');\n    var key = docId + \"::\" + rev;\n    index.getKey(key).onsuccess = function (e) {\n      var seq = e.target.result;\n      if (typeof seq !== 'number') {\n        return checkDone();\n      }\n      seqStore.delete(seq);\n\n      var cursor = attAndSeqStore.index('seq')\n        .openCursor(IDBKeyRange.only(seq));\n\n      cursor.onsuccess = function (event) {\n        var cursor = event.target.result;\n        if (cursor) {\n          var digest = cursor.value.digestSeq.split('::')[0];\n          possiblyOrphanedDigests.push(digest);\n          attAndSeqStore.delete(cursor.primaryKey);\n          cursor.continue();\n        } else { // done\n          checkDone();\n        }\n      };\n    };\n  });\n}\n\nfunction openTransactionSafely(idb, stores, mode) {\n  try {\n    return {\n      txn: idb.transaction(stores, mode)\n    };\n  } catch (err) {\n    return {\n      error: err\n    };\n  }\n}\n\nvar changesHandler$$1 = new Changes();\n\nfunction idbBulkDocs(dbOpts, req, opts, api, idb, callback) {\n  var docInfos = req.docs;\n  var txn;\n  var docStore;\n  var bySeqStore;\n  var attachStore;\n  var attachAndSeqStore;\n  var metaStore;\n  var docInfoError;\n  var metaDoc;\n\n  for (var i = 0, len = docInfos.length; i < len; i++) {\n    var doc = docInfos[i];\n    if (doc._id && isLocalId(doc._id)) {\n      continue;\n    }\n    doc = docInfos[i] = parseDoc(doc, opts.new_edits);\n    if (doc.error && !docInfoError) {\n      docInfoError = doc;\n    }\n  }\n\n  if (docInfoError) {\n    return callback(docInfoError);\n  }\n\n  var allDocsProcessed = false;\n  var docCountDelta = 0;\n  var results = new Array(docInfos.length);\n  var fetchedDocs = new ExportedMap();\n  var preconditionErrored = false;\n  var blobType = api._meta.blobSupport ? 'blob' : 'base64';\n\n  preprocessAttachments(docInfos, blobType, function (err) {\n    if (err) {\n      return callback(err);\n    }\n    startTransaction();\n  });\n\n  function startTransaction() {\n\n    var stores = [\n      DOC_STORE, BY_SEQ_STORE,\n      ATTACH_STORE,\n      LOCAL_STORE, ATTACH_AND_SEQ_STORE,\n      META_STORE\n    ];\n    var txnResult = openTransactionSafely(idb, stores, 'readwrite');\n    if (txnResult.error) {\n      return callback(txnResult.error);\n    }\n    txn = txnResult.txn;\n    txn.onabort = idbError(callback);\n    txn.ontimeout = idbError(callback);\n    txn.oncomplete = complete;\n    docStore = txn.objectStore(DOC_STORE);\n    bySeqStore = txn.objectStore(BY_SEQ_STORE);\n    attachStore = txn.objectStore(ATTACH_STORE);\n    attachAndSeqStore = txn.objectStore(ATTACH_AND_SEQ_STORE);\n    metaStore = txn.objectStore(META_STORE);\n\n    metaStore.get(META_STORE).onsuccess = function (e) {\n      metaDoc = e.target.result;\n      updateDocCountIfReady();\n    };\n\n    verifyAttachments(function (err) {\n      if (err) {\n        preconditionErrored = true;\n        return callback(err);\n      }\n      fetchExistingDocs();\n    });\n  }\n\n  function onAllDocsProcessed() {\n    allDocsProcessed = true;\n    updateDocCountIfReady();\n  }\n\n  function idbProcessDocs() {\n    processDocs(dbOpts.revs_limit, docInfos, api, fetchedDocs,\n                txn, results, writeDoc, opts, onAllDocsProcessed);\n  }\n\n  function updateDocCountIfReady() {\n    if (!metaDoc || !allDocsProcessed) {\n      return;\n    }\n    // caching the docCount saves a lot of time in allDocs() and\n    // info(), which is why we go to all the trouble of doing this\n    metaDoc.docCount += docCountDelta;\n    metaStore.put(metaDoc);\n  }\n\n  function fetchExistingDocs() {\n\n    if (!docInfos.length) {\n      return;\n    }\n\n    var numFetched = 0;\n\n    function checkDone() {\n      if (++numFetched === docInfos.length) {\n        idbProcessDocs();\n      }\n    }\n\n    function readMetadata(event) {\n      var metadata = decodeMetadata(event.target.result);\n\n      if (metadata) {\n        fetchedDocs.set(metadata.id, metadata);\n      }\n      checkDone();\n    }\n\n    for (var i = 0, len = docInfos.length; i < len; i++) {\n      var docInfo = docInfos[i];\n      if (docInfo._id && isLocalId(docInfo._id)) {\n        checkDone(); // skip local docs\n        continue;\n      }\n      var req = docStore.get(docInfo.metadata.id);\n      req.onsuccess = readMetadata;\n    }\n  }\n\n  function complete() {\n    if (preconditionErrored) {\n      return;\n    }\n\n    changesHandler$$1.notify(api._meta.name);\n    callback(null, results);\n  }\n\n  function verifyAttachment(digest, callback) {\n\n    var req = attachStore.get(digest);\n    req.onsuccess = function (e) {\n      if (!e.target.result) {\n        var err = createError(MISSING_STUB,\n          'unknown stub attachment with digest ' +\n          digest);\n        err.status = 412;\n        callback(err);\n      } else {\n        callback();\n      }\n    };\n  }\n\n  function verifyAttachments(finish) {\n\n\n    var digests = [];\n    docInfos.forEach(function (docInfo) {\n      if (docInfo.data && docInfo.data._attachments) {\n        Object.keys(docInfo.data._attachments).forEach(function (filename) {\n          var att = docInfo.data._attachments[filename];\n          if (att.stub) {\n            digests.push(att.digest);\n          }\n        });\n      }\n    });\n    if (!digests.length) {\n      return finish();\n    }\n    var numDone = 0;\n    var err;\n\n    function checkDone() {\n      if (++numDone === digests.length) {\n        finish(err);\n      }\n    }\n    digests.forEach(function (digest) {\n      verifyAttachment(digest, function (attErr) {\n        if (attErr && !err) {\n          err = attErr;\n        }\n        checkDone();\n      });\n    });\n  }\n\n  function writeDoc(docInfo, winningRev$$1, winningRevIsDeleted, newRevIsDeleted,\n                    isUpdate, delta, resultsIdx, callback) {\n\n    docInfo.metadata.winningRev = winningRev$$1;\n    docInfo.metadata.deleted = winningRevIsDeleted;\n\n    var doc = docInfo.data;\n    doc._id = docInfo.metadata.id;\n    doc._rev = docInfo.metadata.rev;\n\n    if (newRevIsDeleted) {\n      doc._deleted = true;\n    }\n\n    var hasAttachments = doc._attachments &&\n      Object.keys(doc._attachments).length;\n    if (hasAttachments) {\n      return writeAttachments(docInfo, winningRev$$1, winningRevIsDeleted,\n        isUpdate, resultsIdx, callback);\n    }\n\n    docCountDelta += delta;\n    updateDocCountIfReady();\n\n    finishDoc(docInfo, winningRev$$1, winningRevIsDeleted,\n      isUpdate, resultsIdx, callback);\n  }\n\n  function finishDoc(docInfo, winningRev$$1, winningRevIsDeleted,\n                     isUpdate, resultsIdx, callback) {\n\n    var doc = docInfo.data;\n    var metadata = docInfo.metadata;\n\n    doc._doc_id_rev = metadata.id + '::' + metadata.rev;\n    delete doc._id;\n    delete doc._rev;\n\n    function afterPutDoc(e) {\n      var revsToDelete = docInfo.stemmedRevs || [];\n\n      if (isUpdate && api.auto_compaction) {\n        revsToDelete = revsToDelete.concat(compactTree(docInfo.metadata));\n      }\n\n      if (revsToDelete && revsToDelete.length) {\n        compactRevs(revsToDelete, docInfo.metadata.id, txn);\n      }\n\n      metadata.seq = e.target.result;\n      // Current _rev is calculated from _rev_tree on read\n      // delete metadata.rev;\n      var metadataToStore = encodeMetadata(metadata, winningRev$$1,\n        winningRevIsDeleted);\n      var metaDataReq = docStore.put(metadataToStore);\n      metaDataReq.onsuccess = afterPutMetadata;\n    }\n\n    function afterPutDocError(e) {\n      // ConstraintError, need to update, not put (see #1638 for details)\n      e.preventDefault(); // avoid transaction abort\n      e.stopPropagation(); // avoid transaction onerror\n      var index = bySeqStore.index('_doc_id_rev');\n      var getKeyReq = index.getKey(doc._doc_id_rev);\n      getKeyReq.onsuccess = function (e) {\n        var putReq = bySeqStore.put(doc, e.target.result);\n        putReq.onsuccess = afterPutDoc;\n      };\n    }\n\n    function afterPutMetadata() {\n      results[resultsIdx] = {\n        ok: true,\n        id: metadata.id,\n        rev: metadata.rev\n      };\n      fetchedDocs.set(docInfo.metadata.id, docInfo.metadata);\n      insertAttachmentMappings(docInfo, metadata.seq, callback);\n    }\n\n    var putReq = bySeqStore.put(doc);\n\n    putReq.onsuccess = afterPutDoc;\n    putReq.onerror = afterPutDocError;\n  }\n\n  function writeAttachments(docInfo, winningRev$$1, winningRevIsDeleted,\n                            isUpdate, resultsIdx, callback) {\n\n\n    var doc = docInfo.data;\n\n    var numDone = 0;\n    var attachments = Object.keys(doc._attachments);\n\n    function collectResults() {\n      if (numDone === attachments.length) {\n        finishDoc(docInfo, winningRev$$1, winningRevIsDeleted,\n          isUpdate, resultsIdx, callback);\n      }\n    }\n\n    function attachmentSaved() {\n      numDone++;\n      collectResults();\n    }\n\n    attachments.forEach(function (key) {\n      var att = docInfo.data._attachments[key];\n      if (!att.stub) {\n        var data = att.data;\n        delete att.data;\n        att.revpos = parseInt(winningRev$$1, 10);\n        var digest = att.digest;\n        saveAttachment(digest, data, attachmentSaved);\n      } else {\n        numDone++;\n        collectResults();\n      }\n    });\n  }\n\n  // map seqs to attachment digests, which\n  // we will need later during compaction\n  function insertAttachmentMappings(docInfo, seq, callback) {\n\n    var attsAdded = 0;\n    var attsToAdd = Object.keys(docInfo.data._attachments || {});\n\n    if (!attsToAdd.length) {\n      return callback();\n    }\n\n    function checkDone() {\n      if (++attsAdded === attsToAdd.length) {\n        callback();\n      }\n    }\n\n    function add(att) {\n      var digest = docInfo.data._attachments[att].digest;\n      var req = attachAndSeqStore.put({\n        seq: seq,\n        digestSeq: digest + '::' + seq\n      });\n\n      req.onsuccess = checkDone;\n      req.onerror = function (e) {\n        // this callback is for a constaint error, which we ignore\n        // because this docid/rev has already been associated with\n        // the digest (e.g. when new_edits == false)\n        e.preventDefault(); // avoid transaction abort\n        e.stopPropagation(); // avoid transaction onerror\n        checkDone();\n      };\n    }\n    for (var i = 0; i < attsToAdd.length; i++) {\n      add(attsToAdd[i]); // do in parallel\n    }\n  }\n\n  function saveAttachment(digest, data, callback) {\n\n\n    var getKeyReq = attachStore.count(digest);\n    getKeyReq.onsuccess = function (e) {\n      var count = e.target.result;\n      if (count) {\n        return callback(); // already exists\n      }\n      var newAtt = {\n        digest: digest,\n        body: data\n      };\n      var putReq = attachStore.put(newAtt);\n      putReq.onsuccess = callback;\n    };\n  }\n}\n\n// Abstraction over IDBCursor and getAll()/getAllKeys() that allows us to batch our operations\n// while falling back to a normal IDBCursor operation on browsers that don't support getAll() or\n// getAllKeys(). This allows for a much faster implementation than just straight-up cursors, because\n// we're not processing each document one-at-a-time.\nfunction runBatchedCursor(objectStore, keyRange, descending, batchSize, onBatch) {\n\n  // Bail out of getAll()/getAllKeys() in the following cases:\n  // 1) either method is unsupported - we need both\n  // 2) batchSize is 1 (might as well use IDBCursor), or batchSize is -1 (i.e. batchSize unlimited,\n  //    not really clear the user wants a batched approach where the entire DB is read into memory,\n  //    perhaps they are filtering on a per-doc basis)\n  // 3) descending â no real way to do this via getAll()/getAllKeys()\n\n  var useGetAll = typeof objectStore.getAll === 'function' &&\n    typeof objectStore.getAllKeys === 'function' &&\n    batchSize > 1 && !descending;\n\n  var keysBatch;\n  var valuesBatch;\n  var pseudoCursor;\n\n  function onGetAll(e) {\n    valuesBatch = e.target.result;\n    if (keysBatch) {\n      onBatch(keysBatch, valuesBatch, pseudoCursor);\n    }\n  }\n\n  function onGetAllKeys(e) {\n    keysBatch = e.target.result;\n    if (valuesBatch) {\n      onBatch(keysBatch, valuesBatch, pseudoCursor);\n    }\n  }\n\n  function continuePseudoCursor() {\n    if (!keysBatch.length) { // no more results\n      return onBatch();\n    }\n    // fetch next batch, exclusive start\n    var lastKey = keysBatch[keysBatch.length - 1];\n    var newKeyRange;\n    if (keyRange && keyRange.upper) {\n      try {\n        newKeyRange = IDBKeyRange.bound(lastKey, keyRange.upper,\n          true, keyRange.upperOpen);\n      } catch (e) {\n        if (e.name === \"DataError\" && e.code === 0) {\n          return onBatch(); // we're done, startkey and endkey are equal\n        }\n      }\n    } else {\n      newKeyRange = IDBKeyRange.lowerBound(lastKey, true);\n    }\n    keyRange = newKeyRange;\n    keysBatch = null;\n    valuesBatch = null;\n    objectStore.getAll(keyRange, batchSize).onsuccess = onGetAll;\n    objectStore.getAllKeys(keyRange, batchSize).onsuccess = onGetAllKeys;\n  }\n\n  function onCursor(e) {\n    var cursor = e.target.result;\n    if (!cursor) { // done\n      return onBatch();\n    }\n    // regular IDBCursor acts like a batch where batch size is always 1\n    onBatch([cursor.key], [cursor.value], cursor);\n  }\n\n  if (useGetAll) {\n    pseudoCursor = {\"continue\": continuePseudoCursor};\n    objectStore.getAll(keyRange, batchSize).onsuccess = onGetAll;\n    objectStore.getAllKeys(keyRange, batchSize).onsuccess = onGetAllKeys;\n  } else if (descending) {\n    objectStore.openCursor(keyRange, 'prev').onsuccess = onCursor;\n  } else {\n    objectStore.openCursor(keyRange).onsuccess = onCursor;\n  }\n}\n\n// simple shim for objectStore.getAll(), falling back to IDBCursor\nfunction getAll(objectStore, keyRange, onSuccess) {\n  if (typeof objectStore.getAll === 'function') {\n    // use native getAll\n    objectStore.getAll(keyRange).onsuccess = onSuccess;\n    return;\n  }\n  // fall back to cursors\n  var values = [];\n\n  function onCursor(e) {\n    var cursor = e.target.result;\n    if (cursor) {\n      values.push(cursor.value);\n      cursor.continue();\n    } else {\n      onSuccess({\n        target: {\n          result: values\n        }\n      });\n    }\n  }\n\n  objectStore.openCursor(keyRange).onsuccess = onCursor;\n}\n\nfunction createKeyRange(start, end, inclusiveEnd, key, descending) {\n  try {\n    if (start && end) {\n      if (descending) {\n        return IDBKeyRange.bound(end, start, !inclusiveEnd, false);\n      } else {\n        return IDBKeyRange.bound(start, end, false, !inclusiveEnd);\n      }\n    } else if (start) {\n      if (descending) {\n        return IDBKeyRange.upperBound(start);\n      } else {\n        return IDBKeyRange.lowerBound(start);\n      }\n    } else if (end) {\n      if (descending) {\n        return IDBKeyRange.lowerBound(end, !inclusiveEnd);\n      } else {\n        return IDBKeyRange.upperBound(end, !inclusiveEnd);\n      }\n    } else if (key) {\n      return IDBKeyRange.only(key);\n    }\n  } catch (e) {\n    return {error: e};\n  }\n  return null;\n}\n\nfunction idbAllDocs(opts, idb, callback) {\n  var start = 'startkey' in opts ? opts.startkey : false;\n  var end = 'endkey' in opts ? opts.endkey : false;\n  var key = 'key' in opts ? opts.key : false;\n  var skip = opts.skip || 0;\n  var limit = typeof opts.limit === 'number' ? opts.limit : -1;\n  var inclusiveEnd = opts.inclusive_end !== false;\n\n  var keyRange = createKeyRange(start, end, inclusiveEnd, key, opts.descending);\n  var keyRangeError = keyRange && keyRange.error;\n  if (keyRangeError && !(keyRangeError.name === \"DataError\" &&\n      keyRangeError.code === 0)) {\n    // DataError with error code 0 indicates start is less than end, so\n    // can just do an empty query. Else need to throw\n    return callback(createError(IDB_ERROR,\n      keyRangeError.name, keyRangeError.message));\n  }\n\n  var stores = [DOC_STORE, BY_SEQ_STORE, META_STORE];\n\n  if (opts.attachments) {\n    stores.push(ATTACH_STORE);\n  }\n  var txnResult = openTransactionSafely(idb, stores, 'readonly');\n  if (txnResult.error) {\n    return callback(txnResult.error);\n  }\n  var txn = txnResult.txn;\n  txn.oncomplete = onTxnComplete;\n  txn.onabort = idbError(callback);\n  var docStore = txn.objectStore(DOC_STORE);\n  var seqStore = txn.objectStore(BY_SEQ_STORE);\n  var metaStore = txn.objectStore(META_STORE);\n  var docIdRevIndex = seqStore.index('_doc_id_rev');\n  var results = [];\n  var docCount;\n\n  metaStore.get(META_STORE).onsuccess = function (e) {\n    docCount = e.target.result.docCount;\n  };\n\n  // if the user specifies include_docs=true, then we don't\n  // want to block the main cursor while we're fetching the doc\n  function fetchDocAsynchronously(metadata, row, winningRev$$1) {\n    var key = metadata.id + \"::\" + winningRev$$1;\n    docIdRevIndex.get(key).onsuccess =  function onGetDoc(e) {\n      row.doc = decodeDoc(e.target.result);\n      if (opts.conflicts) {\n        var conflicts = collectConflicts(metadata);\n        if (conflicts.length) {\n          row.doc._conflicts = conflicts;\n        }\n      }\n      fetchAttachmentsIfNecessary(row.doc, opts, txn);\n    };\n  }\n\n  function allDocsInner(winningRev$$1, metadata) {\n    var row = {\n      id: metadata.id,\n      key: metadata.id,\n      value: {\n        rev: winningRev$$1\n      }\n    };\n    var deleted = metadata.deleted;\n    if (opts.deleted === 'ok') {\n      results.push(row);\n      // deleted docs are okay with \"keys\" requests\n      if (deleted) {\n        row.value.deleted = true;\n        row.doc = null;\n      } else if (opts.include_docs) {\n        fetchDocAsynchronously(metadata, row, winningRev$$1);\n      }\n    } else if (!deleted && skip-- <= 0) {\n      results.push(row);\n      if (opts.include_docs) {\n        fetchDocAsynchronously(metadata, row, winningRev$$1);\n      }\n    }\n  }\n\n  function processBatch(batchValues) {\n    for (var i = 0, len = batchValues.length; i < len; i++) {\n      if (results.length === limit) {\n        break;\n      }\n      var batchValue = batchValues[i];\n      var metadata = decodeMetadata(batchValue);\n      var winningRev$$1 = metadata.winningRev;\n      allDocsInner(winningRev$$1, metadata);\n    }\n  }\n\n  function onBatch(batchKeys, batchValues, cursor) {\n    if (!cursor) {\n      return;\n    }\n    processBatch(batchValues);\n    if (results.length < limit) {\n      cursor.continue();\n    }\n  }\n\n  function onGetAll(e) {\n    var values = e.target.result;\n    if (opts.descending) {\n      values = values.reverse();\n    }\n    processBatch(values);\n  }\n\n  function onResultsReady() {\n    callback(null, {\n      total_rows: docCount,\n      offset: opts.skip,\n      rows: results\n    });\n  }\n\n  function onTxnComplete() {\n    if (opts.attachments) {\n      postProcessAttachments(results, opts.binary).then(onResultsReady);\n    } else {\n      onResultsReady();\n    }\n  }\n\n  // don't bother doing any requests if start > end or limit === 0\n  if (keyRangeError || limit === 0) {\n    return;\n  }\n  if (limit === -1) { // just fetch everything\n    return getAll(docStore, keyRange, onGetAll);\n  }\n  // else do a cursor\n  // choose a batch size based on the skip, since we'll need to skip that many\n  runBatchedCursor(docStore, keyRange, opts.descending, limit + skip, onBatch);\n}\n\n//\n// Blobs are not supported in all versions of IndexedDB, notably\n// Chrome <37 and Android <5. In those versions, storing a blob will throw.\n//\n// Various other blob bugs exist in Chrome v37-42 (inclusive).\n// Detecting them is expensive and confusing to users, and Chrome 37-42\n// is at very low usage worldwide, so we do a hacky userAgent check instead.\n//\n// content-type bug: https://code.google.com/p/chromium/issues/detail?id=408120\n// 404 bug: https://code.google.com/p/chromium/issues/detail?id=447916\n// FileReader bug: https://code.google.com/p/chromium/issues/detail?id=447836\n//\nfunction checkBlobSupport(txn) {\n  return new PouchPromise$1(function (resolve) {\n    var blob$$1 = createBlob(['']);\n    var req = txn.objectStore(DETECT_BLOB_SUPPORT_STORE).put(blob$$1, 'key');\n\n    req.onsuccess = function () {\n      var matchedChrome = navigator.userAgent.match(/Chrome\\/(\\d+)/);\n      var matchedEdge = navigator.userAgent.match(/Edge\\//);\n      // MS Edge pretends to be Chrome 42:\n      // https://msdn.microsoft.com/en-us/library/hh869301%28v=vs.85%29.aspx\n      resolve(matchedEdge || !matchedChrome ||\n        parseInt(matchedChrome[1], 10) >= 43);\n    };\n\n    txn.onabort = function (e) {\n      // If the transaction aborts now its due to not being able to\n      // write to the database, likely due to the disk being full\n      e.preventDefault();\n      e.stopPropagation();\n      resolve(false);\n    };\n  }).catch(function () {\n    return false; // error, so assume unsupported\n  });\n}\n\nfunction countDocs(txn, cb) {\n  var index = txn.objectStore(DOC_STORE).index('deletedOrLocal');\n  index.count(IDBKeyRange.only('0')).onsuccess = function (e) {\n    cb(e.target.result);\n  };\n}\n\n// This task queue ensures that IDB open calls are done in their own tick\n// and sequentially - i.e. we wait for the async IDB open to *fully* complete\n// before calling the next one. This works around IE/Edge race conditions in IDB.\n\nvar running = false;\nvar queue = [];\n\nfunction tryCode(fun, err, res, PouchDB) {\n  try {\n    fun(err, res);\n  } catch (err) {\n    // Shouldn't happen, but in some odd cases\n    // IndexedDB implementations might throw a sync\n    // error, in which case this will at least log it.\n    PouchDB.emit('error', err);\n  }\n}\n\nfunction applyNext() {\n  if (running || !queue.length) {\n    return;\n  }\n  running = true;\n  queue.shift()();\n}\n\nfunction enqueueTask(action, callback, PouchDB) {\n  queue.push(function runAction() {\n    action(function runCallback(err, res) {\n      tryCode(callback, err, res, PouchDB);\n      running = false;\n      nextTick(function runNext() {\n        applyNext(PouchDB);\n      });\n    });\n  });\n  applyNext();\n}\n\nfunction changes(opts, api, dbName, idb) {\n  opts = clone(opts);\n\n  if (opts.continuous) {\n    var id = dbName + ':' + uuid();\n    changesHandler$$1.addListener(dbName, id, api, opts);\n    changesHandler$$1.notify(dbName);\n    return {\n      cancel: function () {\n        changesHandler$$1.removeListener(dbName, id);\n      }\n    };\n  }\n\n  var docIds = opts.doc_ids && new ExportedSet(opts.doc_ids);\n\n  opts.since = opts.since || 0;\n  var lastSeq = opts.since;\n\n  var limit = 'limit' in opts ? opts.limit : -1;\n  if (limit === 0) {\n    limit = 1; // per CouchDB _changes spec\n  }\n  var returnDocs;\n  if ('return_docs' in opts) {\n    returnDocs = opts.return_docs;\n  } else if ('returnDocs' in opts) {\n    // TODO: Remove 'returnDocs' in favor of 'return_docs' in a future release\n    returnDocs = opts.returnDocs;\n  } else {\n    returnDocs = true;\n  }\n\n  var results = [];\n  var numResults = 0;\n  var filter = filterChange(opts);\n  var docIdsToMetadata = new ExportedMap();\n\n  var txn;\n  var bySeqStore;\n  var docStore;\n  var docIdRevIndex;\n\n  function onBatch(batchKeys, batchValues, cursor) {\n    if (!cursor || !batchKeys.length) { // done\n      return;\n    }\n\n    var winningDocs = new Array(batchKeys.length);\n    var metadatas = new Array(batchKeys.length);\n\n    function processMetadataAndWinningDoc(metadata, winningDoc) {\n      var change = opts.processChange(winningDoc, metadata, opts);\n      lastSeq = change.seq = metadata.seq;\n\n      var filtered = filter(change);\n      if (typeof filtered === 'object') { // anything but true/false indicates error\n        return opts.complete(filtered);\n      }\n\n      if (filtered) {\n        numResults++;\n        if (returnDocs) {\n          results.push(change);\n        }\n        // process the attachment immediately\n        // for the benefit of live listeners\n        if (opts.attachments && opts.include_docs) {\n          fetchAttachmentsIfNecessary(winningDoc, opts, txn, function () {\n            postProcessAttachments([change], opts.binary).then(function () {\n              opts.onChange(change);\n            });\n          });\n        } else {\n          opts.onChange(change);\n        }\n      }\n    }\n\n    function onBatchDone() {\n      for (var i = 0, len = winningDocs.length; i < len; i++) {\n        if (numResults === limit) {\n          break;\n        }\n        var winningDoc = winningDocs[i];\n        if (!winningDoc) {\n          continue;\n        }\n        var metadata = metadatas[i];\n        processMetadataAndWinningDoc(metadata, winningDoc);\n      }\n\n      if (numResults !== limit) {\n        cursor.continue();\n      }\n    }\n\n    // Fetch all metadatas/winningdocs from this batch in parallel, then process\n    // them all only once all data has been collected. This is done in parallel\n    // because it's faster than doing it one-at-a-time.\n    var numDone = 0;\n    batchValues.forEach(function (value, i) {\n      var doc = decodeDoc(value);\n      var seq = batchKeys[i];\n      fetchWinningDocAndMetadata(doc, seq, function (metadata, winningDoc) {\n        metadatas[i] = metadata;\n        winningDocs[i] = winningDoc;\n        if (++numDone === batchKeys.length) {\n          onBatchDone();\n        }\n      });\n    });\n  }\n\n  function onGetMetadata(doc, seq, metadata, cb) {\n    if (metadata.seq !== seq) {\n      // some other seq is later\n      return cb();\n    }\n\n    if (metadata.winningRev === doc._rev) {\n      // this is the winning doc\n      return cb(metadata, doc);\n    }\n\n    // fetch winning doc in separate request\n    var docIdRev = doc._id + '::' + metadata.winningRev;\n    var req = docIdRevIndex.get(docIdRev);\n    req.onsuccess = function (e) {\n      cb(metadata, decodeDoc(e.target.result));\n    };\n  }\n\n  function fetchWinningDocAndMetadata(doc, seq, cb) {\n    if (docIds && !docIds.has(doc._id)) {\n      return cb();\n    }\n\n    var metadata = docIdsToMetadata.get(doc._id);\n    if (metadata) { // cached\n      return onGetMetadata(doc, seq, metadata, cb);\n    }\n    // metadata not cached, have to go fetch it\n    docStore.get(doc._id).onsuccess = function (e) {\n      metadata = decodeMetadata(e.target.result);\n      docIdsToMetadata.set(doc._id, metadata);\n      onGetMetadata(doc, seq, metadata, cb);\n    };\n  }\n\n  function finish() {\n    opts.complete(null, {\n      results: results,\n      last_seq: lastSeq\n    });\n  }\n\n  function onTxnComplete() {\n    if (!opts.continuous && opts.attachments) {\n      // cannot guarantee that postProcessing was already done,\n      // so do it again\n      postProcessAttachments(results).then(finish);\n    } else {\n      finish();\n    }\n  }\n\n  var objectStores = [DOC_STORE, BY_SEQ_STORE];\n  if (opts.attachments) {\n    objectStores.push(ATTACH_STORE);\n  }\n  var txnResult = openTransactionSafely(idb, objectStores, 'readonly');\n  if (txnResult.error) {\n    return opts.complete(txnResult.error);\n  }\n  txn = txnResult.txn;\n  txn.onabort = idbError(opts.complete);\n  txn.oncomplete = onTxnComplete;\n\n  bySeqStore = txn.objectStore(BY_SEQ_STORE);\n  docStore = txn.objectStore(DOC_STORE);\n  docIdRevIndex = bySeqStore.index('_doc_id_rev');\n\n  var keyRange = (opts.since && !opts.descending) ?\n    IDBKeyRange.lowerBound(opts.since, true) : null;\n\n  runBatchedCursor(bySeqStore, keyRange, opts.descending, limit, onBatch);\n}\n\nvar cachedDBs = new ExportedMap();\nvar blobSupportPromise;\nvar openReqList = new ExportedMap();\n\nfunction IdbPouch(opts, callback) {\n  var api = this;\n\n  enqueueTask(function (thisCallback) {\n    init(api, opts, thisCallback);\n  }, callback, api.constructor);\n}\n\nfunction init(api, opts, callback) {\n\n  var dbName = opts.name;\n\n  var idb = null;\n  api._meta = null;\n\n  // called when creating a fresh new database\n  function createSchema(db) {\n    var docStore = db.createObjectStore(DOC_STORE, {keyPath : 'id'});\n    db.createObjectStore(BY_SEQ_STORE, {autoIncrement: true})\n      .createIndex('_doc_id_rev', '_doc_id_rev', {unique: true});\n    db.createObjectStore(ATTACH_STORE, {keyPath: 'digest'});\n    db.createObjectStore(META_STORE, {keyPath: 'id', autoIncrement: false});\n    db.createObjectStore(DETECT_BLOB_SUPPORT_STORE);\n\n    // added in v2\n    docStore.createIndex('deletedOrLocal', 'deletedOrLocal', {unique : false});\n\n    // added in v3\n    db.createObjectStore(LOCAL_STORE, {keyPath: '_id'});\n\n    // added in v4\n    var attAndSeqStore = db.createObjectStore(ATTACH_AND_SEQ_STORE,\n      {autoIncrement: true});\n    attAndSeqStore.createIndex('seq', 'seq');\n    attAndSeqStore.createIndex('digestSeq', 'digestSeq', {unique: true});\n  }\n\n  // migration to version 2\n  // unfortunately \"deletedOrLocal\" is a misnomer now that we no longer\n  // store local docs in the main doc-store, but whaddyagonnado\n  function addDeletedOrLocalIndex(txn, callback) {\n    var docStore = txn.objectStore(DOC_STORE);\n    docStore.createIndex('deletedOrLocal', 'deletedOrLocal', {unique : false});\n\n    docStore.openCursor().onsuccess = function (event) {\n      var cursor = event.target.result;\n      if (cursor) {\n        var metadata = cursor.value;\n        var deleted = isDeleted(metadata);\n        metadata.deletedOrLocal = deleted ? \"1\" : \"0\";\n        docStore.put(metadata);\n        cursor.continue();\n      } else {\n        callback();\n      }\n    };\n  }\n\n  // migration to version 3 (part 1)\n  function createLocalStoreSchema(db) {\n    db.createObjectStore(LOCAL_STORE, {keyPath: '_id'})\n      .createIndex('_doc_id_rev', '_doc_id_rev', {unique: true});\n  }\n\n  // migration to version 3 (part 2)\n  function migrateLocalStore(txn, cb) {\n    var localStore = txn.objectStore(LOCAL_STORE);\n    var docStore = txn.objectStore(DOC_STORE);\n    var seqStore = txn.objectStore(BY_SEQ_STORE);\n\n    var cursor = docStore.openCursor();\n    cursor.onsuccess = function (event) {\n      var cursor = event.target.result;\n      if (cursor) {\n        var metadata = cursor.value;\n        var docId = metadata.id;\n        var local = isLocalId(docId);\n        var rev = winningRev(metadata);\n        if (local) {\n          var docIdRev = docId + \"::\" + rev;\n          // remove all seq entries\n          // associated with this docId\n          var start = docId + \"::\";\n          var end = docId + \"::~\";\n          var index = seqStore.index('_doc_id_rev');\n          var range = IDBKeyRange.bound(start, end, false, false);\n          var seqCursor = index.openCursor(range);\n          seqCursor.onsuccess = function (e) {\n            seqCursor = e.target.result;\n            if (!seqCursor) {\n              // done\n              docStore.delete(cursor.primaryKey);\n              cursor.continue();\n            } else {\n              var data = seqCursor.value;\n              if (data._doc_id_rev === docIdRev) {\n                localStore.put(data);\n              }\n              seqStore.delete(seqCursor.primaryKey);\n              seqCursor.continue();\n            }\n          };\n        } else {\n          cursor.continue();\n        }\n      } else if (cb) {\n        cb();\n      }\n    };\n  }\n\n  // migration to version 4 (part 1)\n  function addAttachAndSeqStore(db) {\n    var attAndSeqStore = db.createObjectStore(ATTACH_AND_SEQ_STORE,\n      {autoIncrement: true});\n    attAndSeqStore.createIndex('seq', 'seq');\n    attAndSeqStore.createIndex('digestSeq', 'digestSeq', {unique: true});\n  }\n\n  // migration to version 4 (part 2)\n  function migrateAttsAndSeqs(txn, callback) {\n    var seqStore = txn.objectStore(BY_SEQ_STORE);\n    var attStore = txn.objectStore(ATTACH_STORE);\n    var attAndSeqStore = txn.objectStore(ATTACH_AND_SEQ_STORE);\n\n    // need to actually populate the table. this is the expensive part,\n    // so as an optimization, check first that this database even\n    // contains attachments\n    var req = attStore.count();\n    req.onsuccess = function (e) {\n      var count = e.target.result;\n      if (!count) {\n        return callback(); // done\n      }\n\n      seqStore.openCursor().onsuccess = function (e) {\n        var cursor = e.target.result;\n        if (!cursor) {\n          return callback(); // done\n        }\n        var doc = cursor.value;\n        var seq = cursor.primaryKey;\n        var atts = Object.keys(doc._attachments || {});\n        var digestMap = {};\n        for (var j = 0; j < atts.length; j++) {\n          var att = doc._attachments[atts[j]];\n          digestMap[att.digest] = true; // uniq digests, just in case\n        }\n        var digests = Object.keys(digestMap);\n        for (j = 0; j < digests.length; j++) {\n          var digest = digests[j];\n          attAndSeqStore.put({\n            seq: seq,\n            digestSeq: digest + '::' + seq\n          });\n        }\n        cursor.continue();\n      };\n    };\n  }\n\n  // migration to version 5\n  // Instead of relying on on-the-fly migration of metadata,\n  // this brings the doc-store to its modern form:\n  // - metadata.winningrev\n  // - metadata.seq\n  // - stringify the metadata when storing it\n  function migrateMetadata(txn) {\n\n    function decodeMetadataCompat(storedObject) {\n      if (!storedObject.data) {\n        // old format, when we didn't store it stringified\n        storedObject.deleted = storedObject.deletedOrLocal === '1';\n        return storedObject;\n      }\n      return decodeMetadata(storedObject);\n    }\n\n    // ensure that every metadata has a winningRev and seq,\n    // which was previously created on-the-fly but better to migrate\n    var bySeqStore = txn.objectStore(BY_SEQ_STORE);\n    var docStore = txn.objectStore(DOC_STORE);\n    var cursor = docStore.openCursor();\n    cursor.onsuccess = function (e) {\n      var cursor = e.target.result;\n      if (!cursor) {\n        return; // done\n      }\n      var metadata = decodeMetadataCompat(cursor.value);\n\n      metadata.winningRev = metadata.winningRev ||\n        winningRev(metadata);\n\n      function fetchMetadataSeq() {\n        // metadata.seq was added post-3.2.0, so if it's missing,\n        // we need to fetch it manually\n        var start = metadata.id + '::';\n        var end = metadata.id + '::\\uffff';\n        var req = bySeqStore.index('_doc_id_rev').openCursor(\n          IDBKeyRange.bound(start, end));\n\n        var metadataSeq = 0;\n        req.onsuccess = function (e) {\n          var cursor = e.target.result;\n          if (!cursor) {\n            metadata.seq = metadataSeq;\n            return onGetMetadataSeq();\n          }\n          var seq = cursor.primaryKey;\n          if (seq > metadataSeq) {\n            metadataSeq = seq;\n          }\n          cursor.continue();\n        };\n      }\n\n      function onGetMetadataSeq() {\n        var metadataToStore = encodeMetadata(metadata,\n          metadata.winningRev, metadata.deleted);\n\n        var req = docStore.put(metadataToStore);\n        req.onsuccess = function () {\n          cursor.continue();\n        };\n      }\n\n      if (metadata.seq) {\n        return onGetMetadataSeq();\n      }\n\n      fetchMetadataSeq();\n    };\n\n  }\n\n  api.type = function () {\n    return 'idb';\n  };\n\n  api._id = toPromise(function (callback) {\n    callback(null, api._meta.instanceId);\n  });\n\n  api._bulkDocs = function idb_bulkDocs(req, reqOpts, callback) {\n    idbBulkDocs(opts, req, reqOpts, api, idb, callback);\n  };\n\n  // First we look up the metadata in the ids database, then we fetch the\n  // current revision(s) from the by sequence store\n  api._get = function idb_get(id, opts, callback) {\n    var doc;\n    var metadata;\n    var err;\n    var txn = opts.ctx;\n    if (!txn) {\n      var txnResult = openTransactionSafely(idb,\n        [DOC_STORE, BY_SEQ_STORE, ATTACH_STORE], 'readonly');\n      if (txnResult.error) {\n        return callback(txnResult.error);\n      }\n      txn = txnResult.txn;\n    }\n\n    function finish() {\n      callback(err, {doc: doc, metadata: metadata, ctx: txn});\n    }\n\n    txn.objectStore(DOC_STORE).get(id).onsuccess = function (e) {\n      metadata = decodeMetadata(e.target.result);\n      // we can determine the result here if:\n      // 1. there is no such document\n      // 2. the document is deleted and we don't ask about specific rev\n      // When we ask with opts.rev we expect the answer to be either\n      // doc (possibly with _deleted=true) or missing error\n      if (!metadata) {\n        err = createError(MISSING_DOC, 'missing');\n        return finish();\n      }\n\n      var rev;\n      if(!opts.rev) {\n        rev = metadata.winningRev;\n        var deleted = isDeleted(metadata);\n        if (deleted) {\n          err = createError(MISSING_DOC, \"deleted\");\n          return finish();\n        }\n      } else {\n        rev = opts.latest ? latest(opts.rev, metadata) : opts.rev;\n      }\n\n      var objectStore = txn.objectStore(BY_SEQ_STORE);\n      var key = metadata.id + '::' + rev;\n\n      objectStore.index('_doc_id_rev').get(key).onsuccess = function (e) {\n        doc = e.target.result;\n        if (doc) {\n          doc = decodeDoc(doc);\n        }\n        if (!doc) {\n          err = createError(MISSING_DOC, 'missing');\n          return finish();\n        }\n        finish();\n      };\n    };\n  };\n\n  api._getAttachment = function (docId, attachId, attachment, opts, callback) {\n    var txn;\n    if (opts.ctx) {\n      txn = opts.ctx;\n    } else {\n      var txnResult = openTransactionSafely(idb,\n        [DOC_STORE, BY_SEQ_STORE, ATTACH_STORE], 'readonly');\n      if (txnResult.error) {\n        return callback(txnResult.error);\n      }\n      txn = txnResult.txn;\n    }\n    var digest = attachment.digest;\n    var type = attachment.content_type;\n\n    txn.objectStore(ATTACH_STORE).get(digest).onsuccess = function (e) {\n      var body = e.target.result.body;\n      readBlobData(body, type, opts.binary, function (blobData) {\n        callback(null, blobData);\n      });\n    };\n  };\n\n  api._info = function idb_info(callback) {\n    var updateSeq;\n    var docCount;\n\n    var txnResult = openTransactionSafely(idb, [META_STORE, BY_SEQ_STORE], 'readonly');\n    if (txnResult.error) {\n      return callback(txnResult.error);\n    }\n    var txn = txnResult.txn;\n    txn.objectStore(META_STORE).get(META_STORE).onsuccess = function (e) {\n      docCount = e.target.result.docCount;\n    };\n    txn.objectStore(BY_SEQ_STORE).openCursor(null, 'prev').onsuccess = function (e) {\n      var cursor = e.target.result;\n      updateSeq = cursor ? cursor.key : 0;\n    };\n\n    txn.oncomplete = function () {\n      callback(null, {\n        doc_count: docCount,\n        update_seq: updateSeq,\n        // for debugging\n        idb_attachment_format: (api._meta.blobSupport ? 'binary' : 'base64')\n      });\n    };\n  };\n\n  api._allDocs = function idb_allDocs(opts, callback) {\n    idbAllDocs(opts, idb, callback);\n  };\n\n  api._changes = function idbChanges(opts) {\n    changes(opts, api, dbName, idb);\n  };\n\n  api._close = function (callback) {\n    // https://developer.mozilla.org/en-US/docs/IndexedDB/IDBDatabase#close\n    // \"Returns immediately and closes the connection in a separate thread...\"\n    idb.close();\n    cachedDBs.delete(dbName);\n    callback();\n  };\n\n  api._getRevisionTree = function (docId, callback) {\n    var txnResult = openTransactionSafely(idb, [DOC_STORE], 'readonly');\n    if (txnResult.error) {\n      return callback(txnResult.error);\n    }\n    var txn = txnResult.txn;\n    var req = txn.objectStore(DOC_STORE).get(docId);\n    req.onsuccess = function (event) {\n      var doc = decodeMetadata(event.target.result);\n      if (!doc) {\n        callback(createError(MISSING_DOC));\n      } else {\n        callback(null, doc.rev_tree);\n      }\n    };\n  };\n\n  // This function removes revisions of document docId\n  // which are listed in revs and sets this document\n  // revision to to rev_tree\n  api._doCompaction = function (docId, revs, callback) {\n    var stores = [\n      DOC_STORE,\n      BY_SEQ_STORE,\n      ATTACH_STORE,\n      ATTACH_AND_SEQ_STORE\n    ];\n    var txnResult = openTransactionSafely(idb, stores, 'readwrite');\n    if (txnResult.error) {\n      return callback(txnResult.error);\n    }\n    var txn = txnResult.txn;\n\n    var docStore = txn.objectStore(DOC_STORE);\n\n    docStore.get(docId).onsuccess = function (event) {\n      var metadata = decodeMetadata(event.target.result);\n      traverseRevTree(metadata.rev_tree, function (isLeaf, pos,\n                                                         revHash, ctx, opts) {\n        var rev = pos + '-' + revHash;\n        if (revs.indexOf(rev) !== -1) {\n          opts.status = 'missing';\n        }\n      });\n      compactRevs(revs, docId, txn);\n      var winningRev$$1 = metadata.winningRev;\n      var deleted = metadata.deleted;\n      txn.objectStore(DOC_STORE).put(\n        encodeMetadata(metadata, winningRev$$1, deleted));\n    };\n    txn.onabort = idbError(callback);\n    txn.oncomplete = function () {\n      callback();\n    };\n  };\n\n\n  api._getLocal = function (id, callback) {\n    var txnResult = openTransactionSafely(idb, [LOCAL_STORE], 'readonly');\n    if (txnResult.error) {\n      return callback(txnResult.error);\n    }\n    var tx = txnResult.txn;\n    var req = tx.objectStore(LOCAL_STORE).get(id);\n\n    req.onerror = idbError(callback);\n    req.onsuccess = function (e) {\n      var doc = e.target.result;\n      if (!doc) {\n        callback(createError(MISSING_DOC));\n      } else {\n        delete doc['_doc_id_rev']; // for backwards compat\n        callback(null, doc);\n      }\n    };\n  };\n\n  api._putLocal = function (doc, opts, callback) {\n    if (typeof opts === 'function') {\n      callback = opts;\n      opts = {};\n    }\n    delete doc._revisions; // ignore this, trust the rev\n    var oldRev = doc._rev;\n    var id = doc._id;\n    if (!oldRev) {\n      doc._rev = '0-1';\n    } else {\n      doc._rev = '0-' + (parseInt(oldRev.split('-')[1], 10) + 1);\n    }\n\n    var tx = opts.ctx;\n    var ret;\n    if (!tx) {\n      var txnResult = openTransactionSafely(idb, [LOCAL_STORE], 'readwrite');\n      if (txnResult.error) {\n        return callback(txnResult.error);\n      }\n      tx = txnResult.txn;\n      tx.onerror = idbError(callback);\n      tx.oncomplete = function () {\n        if (ret) {\n          callback(null, ret);\n        }\n      };\n    }\n\n    var oStore = tx.objectStore(LOCAL_STORE);\n    var req;\n    if (oldRev) {\n      req = oStore.get(id);\n      req.onsuccess = function (e) {\n        var oldDoc = e.target.result;\n        if (!oldDoc || oldDoc._rev !== oldRev) {\n          callback(createError(REV_CONFLICT));\n        } else { // update\n          var req = oStore.put(doc);\n          req.onsuccess = function () {\n            ret = {ok: true, id: doc._id, rev: doc._rev};\n            if (opts.ctx) { // return immediately\n              callback(null, ret);\n            }\n          };\n        }\n      };\n    } else { // new doc\n      req = oStore.add(doc);\n      req.onerror = function (e) {\n        // constraint error, already exists\n        callback(createError(REV_CONFLICT));\n        e.preventDefault(); // avoid transaction abort\n        e.stopPropagation(); // avoid transaction onerror\n      };\n      req.onsuccess = function () {\n        ret = {ok: true, id: doc._id, rev: doc._rev};\n        if (opts.ctx) { // return immediately\n          callback(null, ret);\n        }\n      };\n    }\n  };\n\n  api._removeLocal = function (doc, opts, callback) {\n    if (typeof opts === 'function') {\n      callback = opts;\n      opts = {};\n    }\n    var tx = opts.ctx;\n    if (!tx) {\n      var txnResult = openTransactionSafely(idb, [LOCAL_STORE], 'readwrite');\n      if (txnResult.error) {\n        return callback(txnResult.error);\n      }\n      tx = txnResult.txn;\n      tx.oncomplete = function () {\n        if (ret) {\n          callback(null, ret);\n        }\n      };\n    }\n    var ret;\n    var id = doc._id;\n    var oStore = tx.objectStore(LOCAL_STORE);\n    var req = oStore.get(id);\n\n    req.onerror = idbError(callback);\n    req.onsuccess = function (e) {\n      var oldDoc = e.target.result;\n      if (!oldDoc || oldDoc._rev !== doc._rev) {\n        callback(createError(MISSING_DOC));\n      } else {\n        oStore.delete(id);\n        ret = {ok: true, id: id, rev: '0-0'};\n        if (opts.ctx) { // return immediately\n          callback(null, ret);\n        }\n      }\n    };\n  };\n\n  api._destroy = function (opts, callback) {\n    changesHandler$$1.removeAllListeners(dbName);\n\n    //Close open request for \"dbName\" database to fix ie delay.\n    var openReq = openReqList.get(dbName);\n    if (openReq && openReq.result) {\n      openReq.result.close();\n      cachedDBs.delete(dbName);\n    }\n    var req = indexedDB.deleteDatabase(dbName);\n\n    req.onsuccess = function () {\n      //Remove open request from the list.\n      openReqList.delete(dbName);\n      if (hasLocalStorage() && (dbName in localStorage)) {\n        delete localStorage[dbName];\n      }\n      callback(null, { 'ok': true });\n    };\n\n    req.onerror = idbError(callback);\n  };\n\n  var cached = cachedDBs.get(dbName);\n\n  if (cached) {\n    idb = cached.idb;\n    api._meta = cached.global;\n    return nextTick(function () {\n      callback(null, api);\n    });\n  }\n\n  var req;\n  if (opts.storage) {\n    req = tryStorageOption(dbName, opts.storage);\n  } else {\n    req = indexedDB.open(dbName, ADAPTER_VERSION);\n  }\n\n  openReqList.set(dbName, req);\n\n  req.onupgradeneeded = function (e) {\n    var db = e.target.result;\n    if (e.oldVersion < 1) {\n      return createSchema(db); // new db, initial schema\n    }\n    // do migrations\n\n    var txn = e.currentTarget.transaction;\n    // these migrations have to be done in this function, before\n    // control is returned to the event loop, because IndexedDB\n\n    if (e.oldVersion < 3) {\n      createLocalStoreSchema(db); // v2 -> v3\n    }\n    if (e.oldVersion < 4) {\n      addAttachAndSeqStore(db); // v3 -> v4\n    }\n\n    var migrations = [\n      addDeletedOrLocalIndex, // v1 -> v2\n      migrateLocalStore,      // v2 -> v3\n      migrateAttsAndSeqs,     // v3 -> v4\n      migrateMetadata         // v4 -> v5\n    ];\n\n    var i = e.oldVersion;\n\n    function next() {\n      var migration = migrations[i - 1];\n      i++;\n      if (migration) {\n        migration(txn, next);\n      }\n    }\n\n    next();\n  };\n\n  req.onsuccess = function (e) {\n\n    idb = e.target.result;\n\n    idb.onversionchange = function () {\n      idb.close();\n      cachedDBs.delete(dbName);\n    };\n\n    idb.onabort = function (e) {\n      guardedConsole('error', 'Database has a global failure', e.target.error);\n      idb.close();\n      cachedDBs.delete(dbName);\n    };\n\n    // Do a few setup operations (in parallel as much as possible):\n    // 1. Fetch meta doc\n    // 2. Check blob support\n    // 3. Calculate docCount\n    // 4. Generate an instanceId if necessary\n    // 5. Store docCount and instanceId on meta doc\n\n    var txn = idb.transaction([\n      META_STORE,\n      DETECT_BLOB_SUPPORT_STORE,\n      DOC_STORE\n    ], 'readwrite');\n\n    var storedMetaDoc = false;\n    var metaDoc;\n    var docCount;\n    var blobSupport;\n    var instanceId;\n\n    function completeSetup() {\n      if (typeof blobSupport === 'undefined' || !storedMetaDoc) {\n        return;\n      }\n      api._meta = {\n        name: dbName,\n        instanceId: instanceId,\n        blobSupport: blobSupport\n      };\n\n      cachedDBs.set(dbName, {\n        idb: idb,\n        global: api._meta\n      });\n      callback(null, api);\n    }\n\n    function storeMetaDocIfReady() {\n      if (typeof docCount === 'undefined' || typeof metaDoc === 'undefined') {\n        return;\n      }\n      var instanceKey = dbName + '_id';\n      if (instanceKey in metaDoc) {\n        instanceId = metaDoc[instanceKey];\n      } else {\n        metaDoc[instanceKey] = instanceId = uuid();\n      }\n      metaDoc.docCount = docCount;\n      txn.objectStore(META_STORE).put(metaDoc);\n    }\n\n    //\n    // fetch or generate the instanceId\n    //\n    txn.objectStore(META_STORE).get(META_STORE).onsuccess = function (e) {\n      metaDoc = e.target.result || { id: META_STORE };\n      storeMetaDocIfReady();\n    };\n\n    //\n    // countDocs\n    //\n    countDocs(txn, function (count) {\n      docCount = count;\n      storeMetaDocIfReady();\n    });\n\n    //\n    // check blob support\n    //\n    if (!blobSupportPromise) {\n      // make sure blob support is only checked once\n      blobSupportPromise = checkBlobSupport(txn);\n    }\n\n    blobSupportPromise.then(function (val) {\n      blobSupport = val;\n      completeSetup();\n    });\n\n    // only when the metadata put transaction has completed,\n    // consider the setup done\n    txn.oncomplete = function () {\n      storedMetaDoc = true;\n      completeSetup();\n    };\n  };\n\n  req.onerror = function () {\n    var msg = 'Failed to open indexedDB, are you in private browsing mode?';\n    guardedConsole('error', msg);\n    callback(createError(IDB_ERROR, msg));\n  };\n}\n\nIdbPouch.valid = function () {\n  // Issue #2533, we finally gave up on doing bug\n  // detection instead of browser sniffing. Safari brought us\n  // to our knees.\n  var isSafari = typeof openDatabase !== 'undefined' &&\n    /(Safari|iPhone|iPad|iPod)/.test(navigator.userAgent) &&\n    !/Chrome/.test(navigator.userAgent) &&\n    !/BlackBerry/.test(navigator.platform);\n\n  // some outdated implementations of IDB that appear on Samsung\n  // and HTC Android devices <4.4 are missing IDBKeyRange\n  return !isSafari && typeof indexedDB !== 'undefined' &&\n    typeof IDBKeyRange !== 'undefined';\n};\n\nfunction tryStorageOption(dbName, storage) {\n  try { // option only available in Firefox 26+\n    return indexedDB.open(dbName, {\n      version: ADAPTER_VERSION,\n      storage: storage\n    });\n  } catch(err) {\n      return indexedDB.open(dbName, ADAPTER_VERSION);\n  }\n}\n\nvar IDBPouch = function (PouchDB) {\n  PouchDB.adapter('idb', IdbPouch, true);\n};\n\n//\n// Parsing hex strings. Yeah.\n//\n// So basically we need this because of a bug in WebSQL:\n// https://code.google.com/p/chromium/issues/detail?id=422690\n// https://bugs.webkit.org/show_bug.cgi?id=137637\n//\n// UTF-8 and UTF-16 are provided as separate functions\n// for meager performance improvements\n//\n\nfunction decodeUtf8(str) {\n  return decodeURIComponent(escape(str));\n}\n\nfunction hexToInt(charCode) {\n  // '0'-'9' is 48-57\n  // 'A'-'F' is 65-70\n  // SQLite will only give us uppercase hex\n  return charCode < 65 ? (charCode - 48) : (charCode - 55);\n}\n\n\n// Example:\n// pragma encoding=utf8;\n// select hex('A');\n// returns '41'\nfunction parseHexUtf8(str, start, end) {\n  var result = '';\n  while (start < end) {\n    result += String.fromCharCode(\n      (hexToInt(str.charCodeAt(start++)) << 4) |\n        hexToInt(str.charCodeAt(start++)));\n  }\n  return result;\n}\n\n// Example:\n// pragma encoding=utf16;\n// select hex('A');\n// returns '4100'\n// notice that the 00 comes after the 41 (i.e. it's swizzled)\nfunction parseHexUtf16(str, start, end) {\n  var result = '';\n  while (start < end) {\n    // UTF-16, so swizzle the bytes\n    result += String.fromCharCode(\n      (hexToInt(str.charCodeAt(start + 2)) << 12) |\n        (hexToInt(str.charCodeAt(start + 3)) << 8) |\n        (hexToInt(str.charCodeAt(start)) << 4) |\n        hexToInt(str.charCodeAt(start + 1)));\n    start += 4;\n  }\n  return result;\n}\n\nfunction parseHexString(str, encoding) {\n  if (encoding === 'UTF-8') {\n    return decodeUtf8(parseHexUtf8(str, 0, str.length));\n  } else {\n    return parseHexUtf16(str, 0, str.length);\n  }\n}\n\nfunction quote(str) {\n  return \"'\" + str + \"'\";\n}\n\nvar ADAPTER_VERSION$1 = 7; // used to manage migrations\n\n// The object stores created for each database\n// DOC_STORE stores the document meta data, its revision history and state\nvar DOC_STORE$1 = quote('document-store');\n// BY_SEQ_STORE stores a particular version of a document, keyed by its\n// sequence id\nvar BY_SEQ_STORE$1 = quote('by-sequence');\n// Where we store attachments\nvar ATTACH_STORE$1 = quote('attach-store');\nvar LOCAL_STORE$1 = quote('local-store');\nvar META_STORE$1 = quote('metadata-store');\n// where we store many-to-many relations between attachment\n// digests and seqs\nvar ATTACH_AND_SEQ_STORE$1 = quote('attach-seq-store');\n\n// escapeBlob and unescapeBlob are workarounds for a websql bug:\n// https://code.google.com/p/chromium/issues/detail?id=422690\n// https://bugs.webkit.org/show_bug.cgi?id=137637\n// The goal is to never actually insert the \\u0000 character\n// in the database.\nfunction escapeBlob(str) {\n  return str\n    .replace(/\\u0002/g, '\\u0002\\u0002')\n    .replace(/\\u0001/g, '\\u0001\\u0002')\n    .replace(/\\u0000/g, '\\u0001\\u0001');\n}\n\nfunction unescapeBlob(str) {\n  return str\n    .replace(/\\u0001\\u0001/g, '\\u0000')\n    .replace(/\\u0001\\u0002/g, '\\u0001')\n    .replace(/\\u0002\\u0002/g, '\\u0002');\n}\n\nfunction stringifyDoc(doc) {\n  // don't bother storing the id/rev. it uses lots of space,\n  // in persistent map/reduce especially\n  delete doc._id;\n  delete doc._rev;\n  return JSON.stringify(doc);\n}\n\nfunction unstringifyDoc(doc, id, rev) {\n  doc = JSON.parse(doc);\n  doc._id = id;\n  doc._rev = rev;\n  return doc;\n}\n\n// question mark groups IN queries, e.g. 3 -> '(?,?,?)'\nfunction qMarks(num) {\n  var s = '(';\n  while (num--) {\n    s += '?';\n    if (num) {\n      s += ',';\n    }\n  }\n  return s + ')';\n}\n\nfunction select(selector, table, joiner, where, orderBy) {\n  return 'SELECT ' + selector + ' FROM ' +\n    (typeof table === 'string' ? table : table.join(' JOIN ')) +\n    (joiner ? (' ON ' + joiner) : '') +\n    (where ? (' WHERE ' +\n    (typeof where === 'string' ? where : where.join(' AND '))) : '') +\n    (orderBy ? (' ORDER BY ' + orderBy) : '');\n}\n\nfunction compactRevs$1(revs, docId, tx) {\n\n  if (!revs.length) {\n    return;\n  }\n\n  var numDone = 0;\n  var seqs = [];\n\n  function checkDone() {\n    if (++numDone === revs.length) { // done\n      deleteOrphans();\n    }\n  }\n\n  function deleteOrphans() {\n    // find orphaned attachment digests\n\n    if (!seqs.length) {\n      return;\n    }\n\n    var sql = 'SELECT DISTINCT digest AS digest FROM ' +\n      ATTACH_AND_SEQ_STORE$1 + ' WHERE seq IN ' + qMarks(seqs.length);\n\n    tx.executeSql(sql, seqs, function (tx, res) {\n\n      var digestsToCheck = [];\n      for (var i = 0; i < res.rows.length; i++) {\n        digestsToCheck.push(res.rows.item(i).digest);\n      }\n      if (!digestsToCheck.length) {\n        return;\n      }\n\n      var sql = 'DELETE FROM ' + ATTACH_AND_SEQ_STORE$1 +\n        ' WHERE seq IN (' +\n        seqs.map(function () { return '?'; }).join(',') +\n        ')';\n      tx.executeSql(sql, seqs, function (tx) {\n\n        var sql = 'SELECT digest FROM ' + ATTACH_AND_SEQ_STORE$1 +\n          ' WHERE digest IN (' +\n          digestsToCheck.map(function () { return '?'; }).join(',') +\n          ')';\n        tx.executeSql(sql, digestsToCheck, function (tx, res) {\n          var nonOrphanedDigests = new ExportedSet();\n          for (var i = 0; i < res.rows.length; i++) {\n            nonOrphanedDigests.add(res.rows.item(i).digest);\n          }\n          digestsToCheck.forEach(function (digest) {\n            if (nonOrphanedDigests.has(digest)) {\n              return;\n            }\n            tx.executeSql(\n              'DELETE FROM ' + ATTACH_AND_SEQ_STORE$1 + ' WHERE digest=?',\n              [digest]);\n            tx.executeSql(\n              'DELETE FROM ' + ATTACH_STORE$1 + ' WHERE digest=?', [digest]);\n          });\n        });\n      });\n    });\n  }\n\n  // update by-seq and attach stores in parallel\n  revs.forEach(function (rev) {\n    var sql = 'SELECT seq FROM ' + BY_SEQ_STORE$1 +\n      ' WHERE doc_id=? AND rev=?';\n\n    tx.executeSql(sql, [docId, rev], function (tx, res) {\n      if (!res.rows.length) { // already deleted\n        return checkDone();\n      }\n      var seq = res.rows.item(0).seq;\n      seqs.push(seq);\n\n      tx.executeSql(\n        'DELETE FROM ' + BY_SEQ_STORE$1 + ' WHERE seq=?', [seq], checkDone);\n    });\n  });\n}\n\nfunction websqlError(callback) {\n  return function (event) {\n    guardedConsole('error', 'WebSQL threw an error', event);\n    // event may actually be a SQLError object, so report is as such\n    var errorNameMatch = event && event.constructor.toString()\n        .match(/function ([^\\(]+)/);\n    var errorName = (errorNameMatch && errorNameMatch[1]) || event.type;\n    var errorReason = event.target || event.message;\n    callback(createError(WSQ_ERROR, errorReason, errorName));\n  };\n}\n\nfunction getSize(opts) {\n  if ('size' in opts) {\n    // triggers immediate popup in iOS, fixes #2347\n    // e.g. 5000001 asks for 5 MB, 10000001 asks for 10 MB,\n    return opts.size * 1000000;\n  }\n  // In iOS, doesn't matter as long as it's <= 5000000.\n  // Except that if you request too much, our tests fail\n  // because of the native \"do you accept?\" popup.\n  // In Android <=4.3, this value is actually used as an\n  // honest-to-god ceiling for data, so we need to\n  // set it to a decently high number.\n  var isAndroid = typeof navigator !== 'undefined' &&\n    /Android/.test(navigator.userAgent);\n  return isAndroid ? 5000000 : 1; // in PhantomJS, if you use 0 it will crash\n}\n\nfunction websqlBulkDocs(dbOpts, req, opts, api, db, websqlChanges, callback) {\n  var newEdits = opts.new_edits;\n  var userDocs = req.docs;\n\n  // Parse the docs, give them a sequence number for the result\n  var docInfos = userDocs.map(function (doc) {\n    if (doc._id && isLocalId(doc._id)) {\n      return doc;\n    }\n    var newDoc = parseDoc(doc, newEdits);\n    return newDoc;\n  });\n\n  var docInfoErrors = docInfos.filter(function (docInfo) {\n    return docInfo.error;\n  });\n  if (docInfoErrors.length) {\n    return callback(docInfoErrors[0]);\n  }\n\n  var tx;\n  var results = new Array(docInfos.length);\n  var fetchedDocs = new ExportedMap();\n\n  var preconditionErrored;\n  function complete() {\n    if (preconditionErrored) {\n      return callback(preconditionErrored);\n    }\n    websqlChanges.notify(api._name);\n    callback(null, results);\n  }\n\n  function verifyAttachment(digest, callback) {\n    var sql = 'SELECT count(*) as cnt FROM ' + ATTACH_STORE$1 +\n      ' WHERE digest=?';\n    tx.executeSql(sql, [digest], function (tx, result) {\n      if (result.rows.item(0).cnt === 0) {\n        var err = createError(MISSING_STUB,\n          'unknown stub attachment with digest ' +\n          digest);\n        callback(err);\n      } else {\n        callback();\n      }\n    });\n  }\n\n  function verifyAttachments(finish) {\n    var digests = [];\n    docInfos.forEach(function (docInfo) {\n      if (docInfo.data && docInfo.data._attachments) {\n        Object.keys(docInfo.data._attachments).forEach(function (filename) {\n          var att = docInfo.data._attachments[filename];\n          if (att.stub) {\n            digests.push(att.digest);\n          }\n        });\n      }\n    });\n    if (!digests.length) {\n      return finish();\n    }\n    var numDone = 0;\n    var err;\n\n    function checkDone() {\n      if (++numDone === digests.length) {\n        finish(err);\n      }\n    }\n    digests.forEach(function (digest) {\n      verifyAttachment(digest, function (attErr) {\n        if (attErr && !err) {\n          err = attErr;\n        }\n        checkDone();\n      });\n    });\n  }\n\n  function writeDoc(docInfo, winningRev$$1, winningRevIsDeleted, newRevIsDeleted,\n                    isUpdate, delta, resultsIdx, callback) {\n\n    function finish() {\n      var data = docInfo.data;\n      var deletedInt = newRevIsDeleted ? 1 : 0;\n\n      var id = data._id;\n      var rev = data._rev;\n      var json = stringifyDoc(data);\n      var sql = 'INSERT INTO ' + BY_SEQ_STORE$1 +\n        ' (doc_id, rev, json, deleted) VALUES (?, ?, ?, ?);';\n      var sqlArgs = [id, rev, json, deletedInt];\n\n      // map seqs to attachment digests, which\n      // we will need later during compaction\n      function insertAttachmentMappings(seq, callback) {\n        var attsAdded = 0;\n        var attsToAdd = Object.keys(data._attachments || {});\n\n        if (!attsToAdd.length) {\n          return callback();\n        }\n        function checkDone() {\n          if (++attsAdded === attsToAdd.length) {\n            callback();\n          }\n          return false; // ack handling a constraint error\n        }\n        function add(att) {\n          var sql = 'INSERT INTO ' + ATTACH_AND_SEQ_STORE$1 +\n            ' (digest, seq) VALUES (?,?)';\n          var sqlArgs = [data._attachments[att].digest, seq];\n          tx.executeSql(sql, sqlArgs, checkDone, checkDone);\n          // second callback is for a constaint error, which we ignore\n          // because this docid/rev has already been associated with\n          // the digest (e.g. when new_edits == false)\n        }\n        for (var i = 0; i < attsToAdd.length; i++) {\n          add(attsToAdd[i]); // do in parallel\n        }\n      }\n\n      tx.executeSql(sql, sqlArgs, function (tx, result) {\n        var seq = result.insertId;\n        insertAttachmentMappings(seq, function () {\n          dataWritten(tx, seq);\n        });\n      }, function () {\n        // constraint error, recover by updating instead (see #1638)\n        var fetchSql = select('seq', BY_SEQ_STORE$1, null,\n          'doc_id=? AND rev=?');\n        tx.executeSql(fetchSql, [id, rev], function (tx, res) {\n          var seq = res.rows.item(0).seq;\n          var sql = 'UPDATE ' + BY_SEQ_STORE$1 +\n            ' SET json=?, deleted=? WHERE doc_id=? AND rev=?;';\n          var sqlArgs = [json, deletedInt, id, rev];\n          tx.executeSql(sql, sqlArgs, function (tx) {\n            insertAttachmentMappings(seq, function () {\n              dataWritten(tx, seq);\n            });\n          });\n        });\n        return false; // ack that we've handled the error\n      });\n    }\n\n    function collectResults(attachmentErr) {\n      if (!err) {\n        if (attachmentErr) {\n          err = attachmentErr;\n          callback(err);\n        } else if (recv === attachments.length) {\n          finish();\n        }\n      }\n    }\n\n    var err = null;\n    var recv = 0;\n\n    docInfo.data._id = docInfo.metadata.id;\n    docInfo.data._rev = docInfo.metadata.rev;\n    var attachments = Object.keys(docInfo.data._attachments || {});\n\n\n    if (newRevIsDeleted) {\n      docInfo.data._deleted = true;\n    }\n\n    function attachmentSaved(err) {\n      recv++;\n      collectResults(err);\n    }\n\n    attachments.forEach(function (key) {\n      var att = docInfo.data._attachments[key];\n      if (!att.stub) {\n        var data = att.data;\n        delete att.data;\n        att.revpos = parseInt(winningRev$$1, 10);\n        var digest = att.digest;\n        saveAttachment(digest, data, attachmentSaved);\n      } else {\n        recv++;\n        collectResults();\n      }\n    });\n\n    if (!attachments.length) {\n      finish();\n    }\n\n    function dataWritten(tx, seq) {\n      var id = docInfo.metadata.id;\n\n      var revsToCompact = docInfo.stemmedRevs || [];\n      if (isUpdate && api.auto_compaction) {\n        revsToCompact = compactTree(docInfo.metadata).concat(revsToCompact);\n      }\n      if (revsToCompact.length) {\n        compactRevs$1(revsToCompact, id, tx);\n      }\n\n      docInfo.metadata.seq = seq;\n      var rev = docInfo.metadata.rev;\n      delete docInfo.metadata.rev;\n\n      var sql = isUpdate ?\n      'UPDATE ' + DOC_STORE$1 +\n      ' SET json=?, max_seq=?, winningseq=' +\n      '(SELECT seq FROM ' + BY_SEQ_STORE$1 +\n      ' WHERE doc_id=' + DOC_STORE$1 + '.id AND rev=?) WHERE id=?'\n        : 'INSERT INTO ' + DOC_STORE$1 +\n      ' (id, winningseq, max_seq, json) VALUES (?,?,?,?);';\n      var metadataStr = safeJsonStringify(docInfo.metadata);\n      var params = isUpdate ?\n        [metadataStr, seq, winningRev$$1, id] :\n        [id, seq, seq, metadataStr];\n      tx.executeSql(sql, params, function () {\n        results[resultsIdx] = {\n          ok: true,\n          id: docInfo.metadata.id,\n          rev: rev\n        };\n        fetchedDocs.set(id, docInfo.metadata);\n        callback();\n      });\n    }\n  }\n\n  function websqlProcessDocs() {\n    processDocs(dbOpts.revs_limit, docInfos, api, fetchedDocs, tx,\n                results, writeDoc, opts);\n  }\n\n  function fetchExistingDocs(callback) {\n    if (!docInfos.length) {\n      return callback();\n    }\n\n    var numFetched = 0;\n\n    function checkDone() {\n      if (++numFetched === docInfos.length) {\n        callback();\n      }\n    }\n\n    docInfos.forEach(function (docInfo) {\n      if (docInfo._id && isLocalId(docInfo._id)) {\n        return checkDone(); // skip local docs\n      }\n      var id = docInfo.metadata.id;\n      tx.executeSql('SELECT json FROM ' + DOC_STORE$1 +\n      ' WHERE id = ?', [id], function (tx, result) {\n        if (result.rows.length) {\n          var metadata = safeJsonParse(result.rows.item(0).json);\n          fetchedDocs.set(id, metadata);\n        }\n        checkDone();\n      });\n    });\n  }\n\n  function saveAttachment(digest, data, callback) {\n    var sql = 'SELECT digest FROM ' + ATTACH_STORE$1 + ' WHERE digest=?';\n    tx.executeSql(sql, [digest], function (tx, result) {\n      if (result.rows.length) { // attachment already exists\n        return callback();\n      }\n      // we could just insert before selecting and catch the error,\n      // but my hunch is that it's cheaper not to serialize the blob\n      // from JS to C if we don't have to (TODO: confirm this)\n      sql = 'INSERT INTO ' + ATTACH_STORE$1 +\n      ' (digest, body, escaped) VALUES (?,?,1)';\n      tx.executeSql(sql, [digest, escapeBlob(data)], function () {\n        callback();\n      }, function () {\n        // ignore constaint errors, means it already exists\n        callback();\n        return false; // ack we handled the error\n      });\n    });\n  }\n\n  preprocessAttachments(docInfos, 'binary', function (err) {\n    if (err) {\n      return callback(err);\n    }\n    db.transaction(function (txn) {\n      tx = txn;\n      verifyAttachments(function (err) {\n        if (err) {\n          preconditionErrored = err;\n        } else {\n          fetchExistingDocs(websqlProcessDocs);\n        }\n      });\n    }, websqlError(callback), complete);\n  });\n}\n\nvar cachedDatabases = new ExportedMap();\n\n// openDatabase passed in through opts (e.g. for node-websql)\nfunction openDatabaseWithOpts(opts) {\n  return opts.websql(opts.name, opts.version, opts.description, opts.size);\n}\n\nfunction openDBSafely(opts) {\n  try {\n    return {\n      db: openDatabaseWithOpts(opts)\n    };\n  } catch (err) {\n    return {\n      error: err\n    };\n  }\n}\n\nfunction openDB$1(opts) {\n  var cachedResult = cachedDatabases.get(opts.name);\n  if (!cachedResult) {\n    cachedResult = openDBSafely(opts);\n    cachedDatabases.set(opts.name, cachedResult);\n  }\n  return cachedResult;\n}\n\nvar websqlChanges = new Changes();\n\nfunction fetchAttachmentsIfNecessary$1(doc, opts, api, txn, cb) {\n  var attachments = Object.keys(doc._attachments || {});\n  if (!attachments.length) {\n    return cb && cb();\n  }\n  var numDone = 0;\n\n  function checkDone() {\n    if (++numDone === attachments.length && cb) {\n      cb();\n    }\n  }\n\n  function fetchAttachment(doc, att) {\n    var attObj = doc._attachments[att];\n    var attOpts = {binary: opts.binary, ctx: txn};\n    api._getAttachment(doc._id, att, attObj, attOpts, function (_, data) {\n      doc._attachments[att] = assign$1(\n        pick(attObj, ['digest', 'content_type']),\n        { data: data }\n      );\n      checkDone();\n    });\n  }\n\n  attachments.forEach(function (att) {\n    if (opts.attachments && opts.include_docs) {\n      fetchAttachment(doc, att);\n    } else {\n      doc._attachments[att].stub = true;\n      checkDone();\n    }\n  });\n}\n\nvar POUCH_VERSION = 1;\n\n// these indexes cover the ground for most allDocs queries\nvar BY_SEQ_STORE_DELETED_INDEX_SQL =\n  'CREATE INDEX IF NOT EXISTS \\'by-seq-deleted-idx\\' ON ' +\n  BY_SEQ_STORE$1 + ' (seq, deleted)';\nvar BY_SEQ_STORE_DOC_ID_REV_INDEX_SQL =\n  'CREATE UNIQUE INDEX IF NOT EXISTS \\'by-seq-doc-id-rev\\' ON ' +\n    BY_SEQ_STORE$1 + ' (doc_id, rev)';\nvar DOC_STORE_WINNINGSEQ_INDEX_SQL =\n  'CREATE INDEX IF NOT EXISTS \\'doc-winningseq-idx\\' ON ' +\n  DOC_STORE$1 + ' (winningseq)';\nvar ATTACH_AND_SEQ_STORE_SEQ_INDEX_SQL =\n  'CREATE INDEX IF NOT EXISTS \\'attach-seq-seq-idx\\' ON ' +\n    ATTACH_AND_SEQ_STORE$1 + ' (seq)';\nvar ATTACH_AND_SEQ_STORE_ATTACH_INDEX_SQL =\n  'CREATE UNIQUE INDEX IF NOT EXISTS \\'attach-seq-digest-idx\\' ON ' +\n    ATTACH_AND_SEQ_STORE$1 + ' (digest, seq)';\n\nvar DOC_STORE_AND_BY_SEQ_JOINER = BY_SEQ_STORE$1 +\n  '.seq = ' + DOC_STORE$1 + '.winningseq';\n\nvar SELECT_DOCS = BY_SEQ_STORE$1 + '.seq AS seq, ' +\n  BY_SEQ_STORE$1 + '.deleted AS deleted, ' +\n  BY_SEQ_STORE$1 + '.json AS data, ' +\n  BY_SEQ_STORE$1 + '.rev AS rev, ' +\n  DOC_STORE$1 + '.json AS metadata';\n\nfunction WebSqlPouch$1(opts, callback) {\n  var api = this;\n  var instanceId = null;\n  var size = getSize(opts);\n  var idRequests = [];\n  var encoding;\n\n  api._name = opts.name;\n\n  // extend the options here, because sqlite plugin has a ton of options\n  // and they are constantly changing, so it's more prudent to allow anything\n  var websqlOpts = assign$1({}, opts, {\n    version: POUCH_VERSION,\n    description: opts.name,\n    size: size\n  });\n  var openDBResult = openDB$1(websqlOpts);\n  if (openDBResult.error) {\n    return websqlError(callback)(openDBResult.error);\n  }\n  var db = openDBResult.db;\n  if (typeof db.readTransaction !== 'function') {\n    // doesn't exist in sqlite plugin\n    db.readTransaction = db.transaction;\n  }\n\n  function dbCreated() {\n    // note the db name in case the browser upgrades to idb\n    if (hasLocalStorage()) {\n      window.localStorage['_pouch__websqldb_' + api._name] = true;\n    }\n    callback(null, api);\n  }\n\n  // In this migration, we added the 'deleted' and 'local' columns to the\n  // by-seq and doc store tables.\n  // To preserve existing user data, we re-process all the existing JSON\n  // and add these values.\n  // Called migration2 because it corresponds to adapter version (db_version) #2\n  function runMigration2(tx, callback) {\n    // index used for the join in the allDocs query\n    tx.executeSql(DOC_STORE_WINNINGSEQ_INDEX_SQL);\n\n    tx.executeSql('ALTER TABLE ' + BY_SEQ_STORE$1 +\n      ' ADD COLUMN deleted TINYINT(1) DEFAULT 0', [], function () {\n      tx.executeSql(BY_SEQ_STORE_DELETED_INDEX_SQL);\n      tx.executeSql('ALTER TABLE ' + DOC_STORE$1 +\n        ' ADD COLUMN local TINYINT(1) DEFAULT 0', [], function () {\n        tx.executeSql('CREATE INDEX IF NOT EXISTS \\'doc-store-local-idx\\' ON ' +\n          DOC_STORE$1 + ' (local, id)');\n\n        var sql = 'SELECT ' + DOC_STORE$1 + '.winningseq AS seq, ' + DOC_STORE$1 +\n          '.json AS metadata FROM ' + BY_SEQ_STORE$1 + ' JOIN ' + DOC_STORE$1 +\n          ' ON ' + BY_SEQ_STORE$1 + '.seq = ' + DOC_STORE$1 + '.winningseq';\n\n        tx.executeSql(sql, [], function (tx, result) {\n\n          var deleted = [];\n          var local = [];\n\n          for (var i = 0; i < result.rows.length; i++) {\n            var item = result.rows.item(i);\n            var seq = item.seq;\n            var metadata = JSON.parse(item.metadata);\n            if (isDeleted(metadata)) {\n              deleted.push(seq);\n            }\n            if (isLocalId(metadata.id)) {\n              local.push(metadata.id);\n            }\n          }\n          tx.executeSql('UPDATE ' + DOC_STORE$1 + 'SET local = 1 WHERE id IN ' +\n            qMarks(local.length), local, function () {\n            tx.executeSql('UPDATE ' + BY_SEQ_STORE$1 +\n              ' SET deleted = 1 WHERE seq IN ' +\n              qMarks(deleted.length), deleted, callback);\n          });\n        });\n      });\n    });\n  }\n\n  // in this migration, we make all the local docs unversioned\n  function runMigration3(tx, callback) {\n    var local = 'CREATE TABLE IF NOT EXISTS ' + LOCAL_STORE$1 +\n      ' (id UNIQUE, rev, json)';\n    tx.executeSql(local, [], function () {\n      var sql = 'SELECT ' + DOC_STORE$1 + '.id AS id, ' +\n        BY_SEQ_STORE$1 + '.json AS data ' +\n        'FROM ' + BY_SEQ_STORE$1 + ' JOIN ' +\n        DOC_STORE$1 + ' ON ' + BY_SEQ_STORE$1 + '.seq = ' +\n        DOC_STORE$1 + '.winningseq WHERE local = 1';\n      tx.executeSql(sql, [], function (tx, res) {\n        var rows = [];\n        for (var i = 0; i < res.rows.length; i++) {\n          rows.push(res.rows.item(i));\n        }\n        function doNext() {\n          if (!rows.length) {\n            return callback(tx);\n          }\n          var row = rows.shift();\n          var rev = JSON.parse(row.data)._rev;\n          tx.executeSql('INSERT INTO ' + LOCAL_STORE$1 +\n              ' (id, rev, json) VALUES (?,?,?)',\n              [row.id, rev, row.data], function (tx) {\n            tx.executeSql('DELETE FROM ' + DOC_STORE$1 + ' WHERE id=?',\n                [row.id], function (tx) {\n              tx.executeSql('DELETE FROM ' + BY_SEQ_STORE$1 + ' WHERE seq=?',\n                  [row.seq], function () {\n                doNext();\n              });\n            });\n          });\n        }\n        doNext();\n      });\n    });\n  }\n\n  // in this migration, we remove doc_id_rev and just use rev\n  function runMigration4(tx, callback) {\n\n    function updateRows(rows) {\n      function doNext() {\n        if (!rows.length) {\n          return callback(tx);\n        }\n        var row = rows.shift();\n        var doc_id_rev = parseHexString(row.hex, encoding);\n        var idx = doc_id_rev.lastIndexOf('::');\n        var doc_id = doc_id_rev.substring(0, idx);\n        var rev = doc_id_rev.substring(idx + 2);\n        var sql = 'UPDATE ' + BY_SEQ_STORE$1 +\n          ' SET doc_id=?, rev=? WHERE doc_id_rev=?';\n        tx.executeSql(sql, [doc_id, rev, doc_id_rev], function () {\n          doNext();\n        });\n      }\n      doNext();\n    }\n\n    var sql = 'ALTER TABLE ' + BY_SEQ_STORE$1 + ' ADD COLUMN doc_id';\n    tx.executeSql(sql, [], function (tx) {\n      var sql = 'ALTER TABLE ' + BY_SEQ_STORE$1 + ' ADD COLUMN rev';\n      tx.executeSql(sql, [], function (tx) {\n        tx.executeSql(BY_SEQ_STORE_DOC_ID_REV_INDEX_SQL, [], function (tx) {\n          var sql = 'SELECT hex(doc_id_rev) as hex FROM ' + BY_SEQ_STORE$1;\n          tx.executeSql(sql, [], function (tx, res) {\n            var rows = [];\n            for (var i = 0; i < res.rows.length; i++) {\n              rows.push(res.rows.item(i));\n            }\n            updateRows(rows);\n          });\n        });\n      });\n    });\n  }\n\n  // in this migration, we add the attach_and_seq table\n  // for issue #2818\n  function runMigration5(tx, callback) {\n\n    function migrateAttsAndSeqs(tx) {\n      // need to actually populate the table. this is the expensive part,\n      // so as an optimization, check first that this database even\n      // contains attachments\n      var sql = 'SELECT COUNT(*) AS cnt FROM ' + ATTACH_STORE$1;\n      tx.executeSql(sql, [], function (tx, res) {\n        var count = res.rows.item(0).cnt;\n        if (!count) {\n          return callback(tx);\n        }\n\n        var offset = 0;\n        var pageSize = 10;\n        function nextPage() {\n          var sql = select(\n            SELECT_DOCS + ', ' + DOC_STORE$1 + '.id AS id',\n            [DOC_STORE$1, BY_SEQ_STORE$1],\n            DOC_STORE_AND_BY_SEQ_JOINER,\n            null,\n            DOC_STORE$1 + '.id '\n          );\n          sql += ' LIMIT ' + pageSize + ' OFFSET ' + offset;\n          offset += pageSize;\n          tx.executeSql(sql, [], function (tx, res) {\n            if (!res.rows.length) {\n              return callback(tx);\n            }\n            var digestSeqs = {};\n            function addDigestSeq(digest, seq) {\n              // uniq digest/seq pairs, just in case there are dups\n              var seqs = digestSeqs[digest] = (digestSeqs[digest] || []);\n              if (seqs.indexOf(seq) === -1) {\n                seqs.push(seq);\n              }\n            }\n            for (var i = 0; i < res.rows.length; i++) {\n              var row = res.rows.item(i);\n              var doc = unstringifyDoc(row.data, row.id, row.rev);\n              var atts = Object.keys(doc._attachments || {});\n              for (var j = 0; j < atts.length; j++) {\n                var att = doc._attachments[atts[j]];\n                addDigestSeq(att.digest, row.seq);\n              }\n            }\n            var digestSeqPairs = [];\n            Object.keys(digestSeqs).forEach(function (digest) {\n              var seqs = digestSeqs[digest];\n              seqs.forEach(function (seq) {\n                digestSeqPairs.push([digest, seq]);\n              });\n            });\n            if (!digestSeqPairs.length) {\n              return nextPage();\n            }\n            var numDone = 0;\n            digestSeqPairs.forEach(function (pair) {\n              var sql = 'INSERT INTO ' + ATTACH_AND_SEQ_STORE$1 +\n                ' (digest, seq) VALUES (?,?)';\n              tx.executeSql(sql, pair, function () {\n                if (++numDone === digestSeqPairs.length) {\n                  nextPage();\n                }\n              });\n            });\n          });\n        }\n        nextPage();\n      });\n    }\n\n    var attachAndRev = 'CREATE TABLE IF NOT EXISTS ' +\n      ATTACH_AND_SEQ_STORE$1 + ' (digest, seq INTEGER)';\n    tx.executeSql(attachAndRev, [], function (tx) {\n      tx.executeSql(\n        ATTACH_AND_SEQ_STORE_ATTACH_INDEX_SQL, [], function (tx) {\n          tx.executeSql(\n            ATTACH_AND_SEQ_STORE_SEQ_INDEX_SQL, [],\n            migrateAttsAndSeqs);\n        });\n    });\n  }\n\n  // in this migration, we use escapeBlob() and unescapeBlob()\n  // instead of reading out the binary as HEX, which is slow\n  function runMigration6(tx, callback) {\n    var sql = 'ALTER TABLE ' + ATTACH_STORE$1 +\n      ' ADD COLUMN escaped TINYINT(1) DEFAULT 0';\n    tx.executeSql(sql, [], callback);\n  }\n\n  // issue #3136, in this migration we need a \"latest seq\" as well\n  // as the \"winning seq\" in the doc store\n  function runMigration7(tx, callback) {\n    var sql = 'ALTER TABLE ' + DOC_STORE$1 +\n      ' ADD COLUMN max_seq INTEGER';\n    tx.executeSql(sql, [], function (tx) {\n      var sql = 'UPDATE ' + DOC_STORE$1 + ' SET max_seq=(SELECT MAX(seq) FROM ' +\n        BY_SEQ_STORE$1 + ' WHERE doc_id=id)';\n      tx.executeSql(sql, [], function (tx) {\n        // add unique index after filling, else we'll get a constraint\n        // error when we do the ALTER TABLE\n        var sql =\n          'CREATE UNIQUE INDEX IF NOT EXISTS \\'doc-max-seq-idx\\' ON ' +\n          DOC_STORE$1 + ' (max_seq)';\n        tx.executeSql(sql, [], callback);\n      });\n    });\n  }\n\n  function checkEncoding(tx, cb) {\n    // UTF-8 on chrome/android, UTF-16 on safari < 7.1\n    tx.executeSql('SELECT HEX(\"a\") AS hex', [], function (tx, res) {\n        var hex = res.rows.item(0).hex;\n        encoding = hex.length === 2 ? 'UTF-8' : 'UTF-16';\n        cb();\n      }\n    );\n  }\n\n  function onGetInstanceId() {\n    while (idRequests.length > 0) {\n      var idCallback = idRequests.pop();\n      idCallback(null, instanceId);\n    }\n  }\n\n  function onGetVersion(tx, dbVersion) {\n    if (dbVersion === 0) {\n      // initial schema\n\n      var meta = 'CREATE TABLE IF NOT EXISTS ' + META_STORE$1 +\n        ' (dbid, db_version INTEGER)';\n      var attach = 'CREATE TABLE IF NOT EXISTS ' + ATTACH_STORE$1 +\n        ' (digest UNIQUE, escaped TINYINT(1), body BLOB)';\n      var attachAndRev = 'CREATE TABLE IF NOT EXISTS ' +\n        ATTACH_AND_SEQ_STORE$1 + ' (digest, seq INTEGER)';\n      // TODO: migrate winningseq to INTEGER\n      var doc = 'CREATE TABLE IF NOT EXISTS ' + DOC_STORE$1 +\n        ' (id unique, json, winningseq, max_seq INTEGER UNIQUE)';\n      var seq = 'CREATE TABLE IF NOT EXISTS ' + BY_SEQ_STORE$1 +\n        ' (seq INTEGER NOT NULL PRIMARY KEY AUTOINCREMENT, ' +\n        'json, deleted TINYINT(1), doc_id, rev)';\n      var local = 'CREATE TABLE IF NOT EXISTS ' + LOCAL_STORE$1 +\n        ' (id UNIQUE, rev, json)';\n\n      // creates\n      tx.executeSql(attach);\n      tx.executeSql(local);\n      tx.executeSql(attachAndRev, [], function () {\n        tx.executeSql(ATTACH_AND_SEQ_STORE_SEQ_INDEX_SQL);\n        tx.executeSql(ATTACH_AND_SEQ_STORE_ATTACH_INDEX_SQL);\n      });\n      tx.executeSql(doc, [], function () {\n        tx.executeSql(DOC_STORE_WINNINGSEQ_INDEX_SQL);\n        tx.executeSql(seq, [], function () {\n          tx.executeSql(BY_SEQ_STORE_DELETED_INDEX_SQL);\n          tx.executeSql(BY_SEQ_STORE_DOC_ID_REV_INDEX_SQL);\n          tx.executeSql(meta, [], function () {\n            // mark the db version, and new dbid\n            var initSeq = 'INSERT INTO ' + META_STORE$1 +\n              ' (db_version, dbid) VALUES (?,?)';\n            instanceId = uuid();\n            var initSeqArgs = [ADAPTER_VERSION$1, instanceId];\n            tx.executeSql(initSeq, initSeqArgs, function () {\n              onGetInstanceId();\n            });\n          });\n        });\n      });\n    } else { // version > 0\n\n      var setupDone = function () {\n        var migrated = dbVersion < ADAPTER_VERSION$1;\n        if (migrated) {\n          // update the db version within this transaction\n          tx.executeSql('UPDATE ' + META_STORE$1 + ' SET db_version = ' +\n            ADAPTER_VERSION$1);\n        }\n        // notify db.id() callers\n        var sql = 'SELECT dbid FROM ' + META_STORE$1;\n        tx.executeSql(sql, [], function (tx, result) {\n          instanceId = result.rows.item(0).dbid;\n          onGetInstanceId();\n        });\n      };\n\n      // would love to use promises here, but then websql\n      // ends the transaction early\n      var tasks = [\n        runMigration2,\n        runMigration3,\n        runMigration4,\n        runMigration5,\n        runMigration6,\n        runMigration7,\n        setupDone\n      ];\n\n      // run each migration sequentially\n      var i = dbVersion;\n      var nextMigration = function (tx) {\n        tasks[i - 1](tx, nextMigration);\n        i++;\n      };\n      nextMigration(tx);\n    }\n  }\n\n  function setup() {\n    db.transaction(function (tx) {\n      // first check the encoding\n      checkEncoding(tx, function () {\n        // then get the version\n        fetchVersion(tx);\n      });\n    }, websqlError(callback), dbCreated);\n  }\n\n  function fetchVersion(tx) {\n    var sql = 'SELECT sql FROM sqlite_master WHERE tbl_name = ' + META_STORE$1;\n    tx.executeSql(sql, [], function (tx, result) {\n      if (!result.rows.length) {\n        // database hasn't even been created yet (version 0)\n        onGetVersion(tx, 0);\n      } else if (!/db_version/.test(result.rows.item(0).sql)) {\n        // table was created, but without the new db_version column,\n        // so add it.\n        tx.executeSql('ALTER TABLE ' + META_STORE$1 +\n          ' ADD COLUMN db_version INTEGER', [], function () {\n          // before version 2, this column didn't even exist\n          onGetVersion(tx, 1);\n        });\n      } else { // column exists, we can safely get it\n        tx.executeSql('SELECT db_version FROM ' + META_STORE$1,\n          [], function (tx, result) {\n          var dbVersion = result.rows.item(0).db_version;\n          onGetVersion(tx, dbVersion);\n        });\n      }\n    });\n  }\n\n  setup();\n\n  function getMaxSeq(tx, callback) {\n    var sql = 'SELECT MAX(seq) AS seq FROM ' + BY_SEQ_STORE$1;\n    tx.executeSql(sql, [], function (tx, res) {\n      var updateSeq = res.rows.item(0).seq || 0;\n      callback(updateSeq);\n    });\n  }\n\n  function countDocs(tx, callback) {\n    // count the total rows\n    var sql = select(\n      'COUNT(' + DOC_STORE$1 + '.id) AS \\'num\\'',\n      [DOC_STORE$1, BY_SEQ_STORE$1],\n      DOC_STORE_AND_BY_SEQ_JOINER,\n      BY_SEQ_STORE$1 + '.deleted=0');\n\n    tx.executeSql(sql, [], function (tx, result) {\n      callback(result.rows.item(0).num);\n    });\n  }\n\n  api.type = function () {\n    return 'websql';\n  };\n\n  api._id = toPromise(function (callback) {\n    callback(null, instanceId);\n  });\n\n  api._info = function (callback) {\n    var seq;\n    var docCount;\n    db.readTransaction(function (tx) {\n      getMaxSeq(tx, function (theSeq) {\n        seq = theSeq;\n      });\n      countDocs(tx, function (theDocCount) {\n        docCount = theDocCount;\n      });\n    }, websqlError(callback), function () {\n      callback(null, {\n        doc_count: docCount,\n        update_seq: seq,\n        websql_encoding: encoding\n      });\n    });\n  };\n\n  api._bulkDocs = function (req, reqOpts, callback) {\n    websqlBulkDocs(opts, req, reqOpts, api, db, websqlChanges, callback);\n  };\n\n  function latest$$1(tx, id, rev, callback, finish) {\n    var sql = select(\n        SELECT_DOCS,\n        [DOC_STORE$1, BY_SEQ_STORE$1],\n        DOC_STORE_AND_BY_SEQ_JOINER,\n        DOC_STORE$1 + '.id=?');\n    var sqlArgs = [id];\n\n    tx.executeSql(sql, sqlArgs, function (a, results) {\n      if (!results.rows.length) {\n        var err = createError(MISSING_DOC, 'missing');\n        return finish(err);\n      }\n      var item = results.rows.item(0);\n      var metadata = safeJsonParse(item.metadata);\n      callback(latest(rev, metadata));\n    });\n  }\n\n  api._get = function (id, opts, callback) {\n    var doc;\n    var metadata;\n    var tx = opts.ctx;\n    if (!tx) {\n      return db.readTransaction(function (txn) {\n        api._get(id, assign$1({ctx: txn}, opts), callback);\n      });\n    }\n\n    function finish(err) {\n      callback(err, {doc: doc, metadata: metadata, ctx: tx});\n    }\n\n    var sql;\n    var sqlArgs;\n\n    if(!opts.rev) {\n      sql = select(\n        SELECT_DOCS,\n        [DOC_STORE$1, BY_SEQ_STORE$1],\n        DOC_STORE_AND_BY_SEQ_JOINER,\n        DOC_STORE$1 + '.id=?');\n      sqlArgs = [id];\n    } else if (opts.latest) {\n      latest$$1(tx, id, opts.rev, function (latestRev) {\n        opts.latest = false;\n        opts.rev = latestRev;\n        api._get(id, opts, callback);\n      }, finish);\n      return;\n    } else {\n      sql = select(\n        SELECT_DOCS,\n        [DOC_STORE$1, BY_SEQ_STORE$1],\n        DOC_STORE$1 + '.id=' + BY_SEQ_STORE$1 + '.doc_id',\n        [BY_SEQ_STORE$1 + '.doc_id=?', BY_SEQ_STORE$1 + '.rev=?']);\n      sqlArgs = [id, opts.rev];\n    }\n\n    tx.executeSql(sql, sqlArgs, function (a, results) {\n      if (!results.rows.length) {\n        var missingErr = createError(MISSING_DOC, 'missing');\n        return finish(missingErr);\n      }\n      var item = results.rows.item(0);\n      metadata = safeJsonParse(item.metadata);\n      if (item.deleted && !opts.rev) {\n        var deletedErr = createError(MISSING_DOC, 'deleted');\n        return finish(deletedErr);\n      }\n      doc = unstringifyDoc(item.data, metadata.id, item.rev);\n      finish();\n    });\n  };\n\n  api._allDocs = function (opts, callback) {\n    var results = [];\n    var totalRows;\n\n    var start = 'startkey' in opts ? opts.startkey : false;\n    var end = 'endkey' in opts ? opts.endkey : false;\n    var key = 'key' in opts ? opts.key : false;\n    var descending = 'descending' in opts ? opts.descending : false;\n    var limit = 'limit' in opts ? opts.limit : -1;\n    var offset = 'skip' in opts ? opts.skip : 0;\n    var inclusiveEnd = opts.inclusive_end !== false;\n\n    var sqlArgs = [];\n    var criteria = [];\n\n    if (key !== false) {\n      criteria.push(DOC_STORE$1 + '.id = ?');\n      sqlArgs.push(key);\n    } else if (start !== false || end !== false) {\n      if (start !== false) {\n        criteria.push(DOC_STORE$1 + '.id ' + (descending ? '<=' : '>=') + ' ?');\n        sqlArgs.push(start);\n      }\n      if (end !== false) {\n        var comparator = descending ? '>' : '<';\n        if (inclusiveEnd) {\n          comparator += '=';\n        }\n        criteria.push(DOC_STORE$1 + '.id ' + comparator + ' ?');\n        sqlArgs.push(end);\n      }\n      if (key !== false) {\n        criteria.push(DOC_STORE$1 + '.id = ?');\n        sqlArgs.push(key);\n      }\n    }\n\n    if (opts.deleted !== 'ok') {\n      // report deleted if keys are specified\n      criteria.push(BY_SEQ_STORE$1 + '.deleted = 0');\n    }\n\n    db.readTransaction(function (tx) {\n      // count the docs in parallel to other operations\n      countDocs(tx, function (docCount) {\n        totalRows = docCount;\n      });\n\n      if (limit === 0) {\n        return;\n      }\n\n      // do a single query to fetch the documents\n      var sql = select(\n        SELECT_DOCS,\n        [DOC_STORE$1, BY_SEQ_STORE$1],\n        DOC_STORE_AND_BY_SEQ_JOINER,\n        criteria,\n        DOC_STORE$1 + '.id ' + (descending ? 'DESC' : 'ASC')\n        );\n      sql += ' LIMIT ' + limit + ' OFFSET ' + offset;\n\n      tx.executeSql(sql, sqlArgs, function (tx, result) {\n        for (var i = 0, l = result.rows.length; i < l; i++) {\n          var item = result.rows.item(i);\n          var metadata = safeJsonParse(item.metadata);\n          var id = metadata.id;\n          var data = unstringifyDoc(item.data, id, item.rev);\n          var winningRev$$1 = data._rev;\n          var doc = {\n            id: id,\n            key: id,\n            value: {rev: winningRev$$1}\n          };\n          if (opts.include_docs) {\n            doc.doc = data;\n            doc.doc._rev = winningRev$$1;\n            if (opts.conflicts) {\n              var conflicts = collectConflicts(metadata);\n              if (conflicts.length) {\n                doc.doc._conflicts = conflicts;\n              }\n            }\n            fetchAttachmentsIfNecessary$1(doc.doc, opts, api, tx);\n          }\n          if (item.deleted) {\n            if (opts.deleted === 'ok') {\n              doc.value.deleted = true;\n              doc.doc = null;\n            } else {\n              continue;\n            }\n          }\n          results.push(doc);\n        }\n      });\n    }, websqlError(callback), function () {\n      callback(null, {\n        total_rows: totalRows,\n        offset: opts.skip,\n        rows: results\n      });\n    });\n  };\n\n  api._changes = function (opts) {\n    opts = clone(opts);\n\n    if (opts.continuous) {\n      var id = api._name + ':' + uuid();\n      websqlChanges.addListener(api._name, id, api, opts);\n      websqlChanges.notify(api._name);\n      return {\n        cancel: function () {\n          websqlChanges.removeListener(api._name, id);\n        }\n      };\n    }\n\n    var descending = opts.descending;\n\n    // Ignore the `since` parameter when `descending` is true\n    opts.since = opts.since && !descending ? opts.since : 0;\n\n    var limit = 'limit' in opts ? opts.limit : -1;\n    if (limit === 0) {\n      limit = 1; // per CouchDB _changes spec\n    }\n\n    var returnDocs;\n    if ('return_docs' in opts) {\n      returnDocs = opts.return_docs;\n    } else if ('returnDocs' in opts) {\n      // TODO: Remove 'returnDocs' in favor of 'return_docs' in a future release\n      returnDocs = opts.returnDocs;\n    } else {\n      returnDocs = true;\n    }\n    var results = [];\n    var numResults = 0;\n\n    function fetchChanges() {\n\n      var selectStmt =\n        DOC_STORE$1 + '.json AS metadata, ' +\n        DOC_STORE$1 + '.max_seq AS maxSeq, ' +\n        BY_SEQ_STORE$1 + '.json AS winningDoc, ' +\n        BY_SEQ_STORE$1 + '.rev AS winningRev ';\n\n      var from = DOC_STORE$1 + ' JOIN ' + BY_SEQ_STORE$1;\n\n      var joiner = DOC_STORE$1 + '.id=' + BY_SEQ_STORE$1 + '.doc_id' +\n        ' AND ' + DOC_STORE$1 + '.winningseq=' + BY_SEQ_STORE$1 + '.seq';\n\n      var criteria = ['maxSeq > ?'];\n      var sqlArgs = [opts.since];\n\n      if (opts.doc_ids) {\n        criteria.push(DOC_STORE$1 + '.id IN ' + qMarks(opts.doc_ids.length));\n        sqlArgs = sqlArgs.concat(opts.doc_ids);\n      }\n\n      var orderBy = 'maxSeq ' + (descending ? 'DESC' : 'ASC');\n\n      var sql = select(selectStmt, from, joiner, criteria, orderBy);\n\n      var filter = filterChange(opts);\n      if (!opts.view && !opts.filter) {\n        // we can just limit in the query\n        sql += ' LIMIT ' + limit;\n      }\n\n      var lastSeq = opts.since || 0;\n      db.readTransaction(function (tx) {\n        tx.executeSql(sql, sqlArgs, function (tx, result) {\n          function reportChange(change) {\n            return function () {\n              opts.onChange(change);\n            };\n          }\n          for (var i = 0, l = result.rows.length; i < l; i++) {\n            var item = result.rows.item(i);\n            var metadata = safeJsonParse(item.metadata);\n            lastSeq = item.maxSeq;\n\n            var doc = unstringifyDoc(item.winningDoc, metadata.id,\n              item.winningRev);\n            var change = opts.processChange(doc, metadata, opts);\n            change.seq = item.maxSeq;\n\n            var filtered = filter(change);\n            if (typeof filtered === 'object') {\n              return opts.complete(filtered);\n            }\n\n            if (filtered) {\n              numResults++;\n              if (returnDocs) {\n                results.push(change);\n              }\n              // process the attachment immediately\n              // for the benefit of live listeners\n              if (opts.attachments && opts.include_docs) {\n                fetchAttachmentsIfNecessary$1(doc, opts, api, tx,\n                  reportChange(change));\n              } else {\n                reportChange(change)();\n              }\n            }\n            if (numResults === limit) {\n              break;\n            }\n          }\n        });\n      }, websqlError(opts.complete), function () {\n        if (!opts.continuous) {\n          opts.complete(null, {\n            results: results,\n            last_seq: lastSeq\n          });\n        }\n      });\n    }\n\n    fetchChanges();\n  };\n\n  api._close = function (callback) {\n    //WebSQL databases do not need to be closed\n    callback();\n  };\n\n  api._getAttachment = function (docId, attachId, attachment, opts, callback) {\n    var res;\n    var tx = opts.ctx;\n    var digest = attachment.digest;\n    var type = attachment.content_type;\n    var sql = 'SELECT escaped, ' +\n      'CASE WHEN escaped = 1 THEN body ELSE HEX(body) END AS body FROM ' +\n      ATTACH_STORE$1 + ' WHERE digest=?';\n    tx.executeSql(sql, [digest], function (tx, result) {\n      // websql has a bug where \\u0000 causes early truncation in strings\n      // and blobs. to work around this, we used to use the hex() function,\n      // but that's not performant. after migration 6, we remove \\u0000\n      // and add it back in afterwards\n      var item = result.rows.item(0);\n      var data = item.escaped ? unescapeBlob(item.body) :\n        parseHexString(item.body, encoding);\n      if (opts.binary) {\n        res = binStringToBluffer(data, type);\n      } else {\n        res = thisBtoa(data);\n      }\n      callback(null, res);\n    });\n  };\n\n  api._getRevisionTree = function (docId, callback) {\n    db.readTransaction(function (tx) {\n      var sql = 'SELECT json AS metadata FROM ' + DOC_STORE$1 + ' WHERE id = ?';\n      tx.executeSql(sql, [docId], function (tx, result) {\n        if (!result.rows.length) {\n          callback(createError(MISSING_DOC));\n        } else {\n          var data = safeJsonParse(result.rows.item(0).metadata);\n          callback(null, data.rev_tree);\n        }\n      });\n    });\n  };\n\n  api._doCompaction = function (docId, revs, callback) {\n    if (!revs.length) {\n      return callback();\n    }\n    db.transaction(function (tx) {\n\n      // update doc store\n      var sql = 'SELECT json AS metadata FROM ' + DOC_STORE$1 + ' WHERE id = ?';\n      tx.executeSql(sql, [docId], function (tx, result) {\n        var metadata = safeJsonParse(result.rows.item(0).metadata);\n        traverseRevTree(metadata.rev_tree, function (isLeaf, pos,\n                                                           revHash, ctx, opts) {\n          var rev = pos + '-' + revHash;\n          if (revs.indexOf(rev) !== -1) {\n            opts.status = 'missing';\n          }\n        });\n\n        var sql = 'UPDATE ' + DOC_STORE$1 + ' SET json = ? WHERE id = ?';\n        tx.executeSql(sql, [safeJsonStringify(metadata), docId]);\n      });\n\n      compactRevs$1(revs, docId, tx);\n    }, websqlError(callback), function () {\n      callback();\n    });\n  };\n\n  api._getLocal = function (id, callback) {\n    db.readTransaction(function (tx) {\n      var sql = 'SELECT json, rev FROM ' + LOCAL_STORE$1 + ' WHERE id=?';\n      tx.executeSql(sql, [id], function (tx, res) {\n        if (res.rows.length) {\n          var item = res.rows.item(0);\n          var doc = unstringifyDoc(item.json, id, item.rev);\n          callback(null, doc);\n        } else {\n          callback(createError(MISSING_DOC));\n        }\n      });\n    });\n  };\n\n  api._putLocal = function (doc, opts, callback) {\n    if (typeof opts === 'function') {\n      callback = opts;\n      opts = {};\n    }\n    delete doc._revisions; // ignore this, trust the rev\n    var oldRev = doc._rev;\n    var id = doc._id;\n    var newRev;\n    if (!oldRev) {\n      newRev = doc._rev = '0-1';\n    } else {\n      newRev = doc._rev = '0-' + (parseInt(oldRev.split('-')[1], 10) + 1);\n    }\n    var json = stringifyDoc(doc);\n\n    var ret;\n    function putLocal(tx) {\n      var sql;\n      var values;\n      if (oldRev) {\n        sql = 'UPDATE ' + LOCAL_STORE$1 + ' SET rev=?, json=? ' +\n          'WHERE id=? AND rev=?';\n        values = [newRev, json, id, oldRev];\n      } else {\n        sql = 'INSERT INTO ' + LOCAL_STORE$1 + ' (id, rev, json) VALUES (?,?,?)';\n        values = [id, newRev, json];\n      }\n      tx.executeSql(sql, values, function (tx, res) {\n        if (res.rowsAffected) {\n          ret = {ok: true, id: id, rev: newRev};\n          if (opts.ctx) { // return immediately\n            callback(null, ret);\n          }\n        } else {\n          callback(createError(REV_CONFLICT));\n        }\n      }, function () {\n        callback(createError(REV_CONFLICT));\n        return false; // ack that we handled the error\n      });\n    }\n\n    if (opts.ctx) {\n      putLocal(opts.ctx);\n    } else {\n      db.transaction(putLocal, websqlError(callback), function () {\n        if (ret) {\n          callback(null, ret);\n        }\n      });\n    }\n  };\n\n  api._removeLocal = function (doc, opts, callback) {\n    if (typeof opts === 'function') {\n      callback = opts;\n      opts = {};\n    }\n    var ret;\n\n    function removeLocal(tx) {\n      var sql = 'DELETE FROM ' + LOCAL_STORE$1 + ' WHERE id=? AND rev=?';\n      var params = [doc._id, doc._rev];\n      tx.executeSql(sql, params, function (tx, res) {\n        if (!res.rowsAffected) {\n          return callback(createError(MISSING_DOC));\n        }\n        ret = {ok: true, id: doc._id, rev: '0-0'};\n        if (opts.ctx) { // return immediately\n          callback(null, ret);\n        }\n      });\n    }\n\n    if (opts.ctx) {\n      removeLocal(opts.ctx);\n    } else {\n      db.transaction(removeLocal, websqlError(callback), function () {\n        if (ret) {\n          callback(null, ret);\n        }\n      });\n    }\n  };\n\n  api._destroy = function (opts, callback) {\n    websqlChanges.removeAllListeners(api._name);\n    db.transaction(function (tx) {\n      var stores = [DOC_STORE$1, BY_SEQ_STORE$1, ATTACH_STORE$1, META_STORE$1,\n        LOCAL_STORE$1, ATTACH_AND_SEQ_STORE$1];\n      stores.forEach(function (store) {\n        tx.executeSql('DROP TABLE IF EXISTS ' + store, []);\n      });\n    }, websqlError(callback), function () {\n      if (hasLocalStorage()) {\n        delete window.localStorage['_pouch__websqldb_' + api._name];\n        delete window.localStorage[api._name];\n      }\n      callback(null, {'ok': true});\n    });\n  };\n}\n\nfunction canOpenTestDB() {\n  try {\n    openDatabase('_pouch_validate_websql', 1, '', 1);\n    return true;\n  } catch (err) {\n    return false;\n  }\n}\n\n// WKWebView had a bug where WebSQL would throw a DOM Exception 18\n// (see https://bugs.webkit.org/show_bug.cgi?id=137760 and\n// https://github.com/pouchdb/pouchdb/issues/5079)\n// This has been fixed in latest WebKit, so we try to detect it here.\nfunction isValidWebSQL() {\n  // WKWebView UA:\n  //   Mozilla/5.0 (iPhone; CPU iPhone OS 9_2 like Mac OS X)\n  //   AppleWebKit/601.1.46 (KHTML, like Gecko) Mobile/13C75\n  // Chrome for iOS UA:\n  //   Mozilla/5.0 (iPhone; U; CPU iPhone OS 5_1_1 like Mac OS X; en)\n  //   AppleWebKit/534.46.0 (KHTML, like Gecko) CriOS/19.0.1084.60\n  //   Mobile/9B206 Safari/7534.48.3\n  // Firefox for iOS UA:\n  //   Mozilla/5.0 (iPhone; CPU iPhone OS 8_3 like Mac OS X) AppleWebKit/600.1.4\n  //   (KHTML, like Gecko) FxiOS/1.0 Mobile/12F69 Safari/600.1.4\n\n  // indexedDB is null on some UIWebViews and undefined in others\n  // see: https://bugs.webkit.org/show_bug.cgi?id=137034\n  if (typeof indexedDB === 'undefined' || indexedDB === null ||\n      !/iP(hone|od|ad)/.test(navigator.userAgent)) {\n    // definitely not WKWebView, avoid creating an unnecessary database\n    return true;\n  }\n  // Cache the result in LocalStorage. Reason we do this is because if we\n  // call openDatabase() too many times, Safari craps out in SauceLabs and\n  // starts throwing DOM Exception 14s.\n  var hasLS = hasLocalStorage();\n  // Include user agent in the hash, so that if Safari is upgraded, we don't\n  // continually think it's broken.\n  var localStorageKey = '_pouch__websqldb_valid_' + navigator.userAgent;\n  if (hasLS && localStorage[localStorageKey]) {\n    return localStorage[localStorageKey] === '1';\n  }\n  var openedTestDB = canOpenTestDB();\n  if (hasLS) {\n    localStorage[localStorageKey] = openedTestDB ? '1' : '0';\n  }\n  return openedTestDB;\n}\n\nfunction valid() {\n  if (typeof openDatabase !== 'function') {\n    return false;\n  }\n  return isValidWebSQL();\n}\n\nfunction openDB(name, version, description, size) {\n  // Traditional WebSQL API\n  return openDatabase(name, version, description, size);\n}\n\nfunction WebSQLPouch(opts, callback) {\n  var _opts = assign$1({\n    websql: openDB\n  }, opts);\n\n  WebSqlPouch$1.call(this, _opts, callback);\n}\n\nWebSQLPouch.valid = valid;\n\nWebSQLPouch.use_prefix = true;\n\nvar WebSqlPouch = function (PouchDB) {\n  PouchDB.adapter('websql', WebSQLPouch, true);\n};\n\n/* global fetch */\n/* global Headers */\nfunction wrappedFetch() {\n  var wrappedPromise = {};\n\n  var promise = new PouchPromise$1(function (resolve, reject) {\n    wrappedPromise.resolve = resolve;\n    wrappedPromise.reject = reject;\n  });\n\n  var args = new Array(arguments.length);\n\n  for (var i = 0; i < args.length; i++) {\n    args[i] = arguments[i];\n  }\n\n  wrappedPromise.promise = promise;\n\n  PouchPromise$1.resolve().then(function () {\n    return fetch.apply(null, args);\n  }).then(function (response) {\n    wrappedPromise.resolve(response);\n  }).catch(function (error) {\n    wrappedPromise.reject(error);\n  });\n\n  return wrappedPromise;\n}\n\nfunction fetchRequest(options, callback) {\n  var wrappedPromise, timer, response;\n\n  var headers = new Headers();\n\n  var fetchOptions = {\n    method: options.method,\n    credentials: 'include',\n    headers: headers\n  };\n\n  if (options.json) {\n    headers.set('Accept', 'application/json');\n    headers.set('Content-Type', options.headers['Content-Type'] ||\n      'application/json');\n  }\n\n  if (options.body &&\n      options.processData &&\n      typeof options.body !== 'string') {\n    fetchOptions.body = JSON.stringify(options.body);\n  } else if ('body' in options) {\n    fetchOptions.body = options.body;\n  } else {\n    fetchOptions.body = null;\n  }\n\n  Object.keys(options.headers).forEach(function (key) {\n    if (options.headers.hasOwnProperty(key)) {\n      headers.set(key, options.headers[key]);\n    }\n  });\n\n  wrappedPromise = wrappedFetch(options.url, fetchOptions);\n\n  if (options.timeout > 0) {\n    timer = setTimeout(function () {\n      wrappedPromise.reject(new Error('Load timeout for resource: ' +\n        options.url));\n    }, options.timeout);\n  }\n\n  wrappedPromise.promise.then(function (fetchResponse) {\n    response = {\n      statusCode: fetchResponse.status\n    };\n\n    if (options.timeout > 0) {\n      clearTimeout(timer);\n    }\n\n    if (response.statusCode >= 200 && response.statusCode < 300) {\n      return options.binary ? fetchResponse.blob() : fetchResponse.text();\n    }\n\n    return fetchResponse.json();\n  }).then(function (result) {\n    if (response.statusCode >= 200 && response.statusCode < 300) {\n      callback(null, response, result);\n    } else {\n      result.status = response.statusCode;\n      callback(result);\n    }\n  }).catch(function (error) {\n    if (!error) {\n      // this happens when the listener is canceled\n      error = new Error('canceled');\n    }\n    callback(error);\n  });\n\n  return {abort: wrappedPromise.reject};\n}\n\nfunction xhRequest(options, callback) {\n\n  var xhr, timer;\n  var timedout = false;\n\n  var abortReq = function () {\n    xhr.abort();\n    cleanUp();\n  };\n\n  var timeoutReq = function () {\n    timedout = true;\n    xhr.abort();\n    cleanUp();\n  };\n\n  var ret = {abort: abortReq};\n\n  var cleanUp = function () {\n    clearTimeout(timer);\n    ret.abort = function () {};\n    if (xhr) {\n      xhr.onprogress = undefined;\n      if (xhr.upload) {\n        xhr.upload.onprogress = undefined;\n      }\n      xhr.onreadystatechange = undefined;\n      xhr = undefined;\n    }\n  };\n\n  if (options.xhr) {\n    xhr = new options.xhr();\n  } else {\n    xhr = new XMLHttpRequest();\n  }\n\n  try {\n    xhr.open(options.method, options.url);\n  } catch (exception) {\n    return callback(new Error(exception.name || 'Url is invalid'));\n  }\n\n  xhr.withCredentials = ('withCredentials' in options) ?\n    options.withCredentials : true;\n\n  if (options.method === 'GET') {\n    delete options.headers['Content-Type'];\n  } else if (options.json) {\n    options.headers.Accept = 'application/json';\n    options.headers['Content-Type'] = options.headers['Content-Type'] ||\n      'application/json';\n    if (options.body &&\n        options.processData &&\n        typeof options.body !== \"string\") {\n      options.body = JSON.stringify(options.body);\n    }\n  }\n\n  if (options.binary) {\n    xhr.responseType = 'arraybuffer';\n  }\n\n  if (!('body' in options)) {\n    options.body = null;\n  }\n\n  for (var key in options.headers) {\n    if (options.headers.hasOwnProperty(key)) {\n      xhr.setRequestHeader(key, options.headers[key]);\n    }\n  }\n\n  if (options.timeout > 0) {\n    timer = setTimeout(timeoutReq, options.timeout);\n    xhr.onprogress = function () {\n      clearTimeout(timer);\n      if(xhr.readyState !== 4) {\n        timer = setTimeout(timeoutReq, options.timeout);\n      }\n    };\n    if (typeof xhr.upload !== 'undefined') { // does not exist in ie9\n      xhr.upload.onprogress = xhr.onprogress;\n    }\n  }\n\n  xhr.onreadystatechange = function () {\n    if (xhr.readyState !== 4) {\n      return;\n    }\n\n    var response = {\n      statusCode: xhr.status\n    };\n\n    if (xhr.status >= 200 && xhr.status < 300) {\n      var data;\n      if (options.binary) {\n        data = createBlob([xhr.response || ''], {\n          type: xhr.getResponseHeader('Content-Type')\n        });\n      } else {\n        data = xhr.responseText;\n      }\n      callback(null, response, data);\n    } else {\n      var err = {};\n      if (timedout) {\n        err = new Error('ETIMEDOUT');\n        err.code = 'ETIMEDOUT';\n      } else if (typeof xhr.response === 'string') {\n        try {\n          err = JSON.parse(xhr.response);\n        } catch(e) {}\n      }\n      err.status = xhr.status;\n      callback(err);\n    }\n    cleanUp();\n  };\n\n  if (options.body && (options.body instanceof Blob)) {\n    readAsArrayBuffer(options.body, function (arrayBuffer) {\n      xhr.send(arrayBuffer);\n    });\n  } else {\n    xhr.send(options.body);\n  }\n\n  return ret;\n}\n\nfunction testXhr() {\n  try {\n    new XMLHttpRequest();\n    return true;\n  } catch (err) {\n    return false;\n  }\n}\n\nvar hasXhr = testXhr();\n\nfunction ajax$1(options, callback) {\n  if (!false && (hasXhr || options.xhr)) {\n    return xhRequest(options, callback);\n  } else {\n    return fetchRequest(options, callback);\n  }\n}\n\n// the blob already has a type; do nothing\nvar res$2 = function () {};\n\nfunction defaultBody() {\n  return '';\n}\n\nfunction ajaxCore$1(options, callback) {\n\n  options = clone(options);\n\n  var defaultOptions = {\n    method : \"GET\",\n    headers: {},\n    json: true,\n    processData: true,\n    timeout: 10000,\n    cache: false\n  };\n\n  options = assign$1(defaultOptions, options);\n\n  function onSuccess(obj, resp, cb) {\n    if (!options.binary && options.json && typeof obj === 'string') {\n      /* istanbul ignore next */\n      try {\n        obj = JSON.parse(obj);\n      } catch (e) {\n        // Probably a malformed JSON from server\n        return cb(e);\n      }\n    }\n    if (Array.isArray(obj)) {\n      obj = obj.map(function (v) {\n        if (v.error || v.missing) {\n          return generateErrorFromResponse(v);\n        } else {\n          return v;\n        }\n      });\n    }\n    if (options.binary) {\n      res$2(obj, resp);\n    }\n    cb(null, obj, resp);\n  }\n\n  if (options.json) {\n    if (!options.binary) {\n      options.headers.Accept = 'application/json';\n    }\n    options.headers['Content-Type'] = options.headers['Content-Type'] ||\n      'application/json';\n  }\n\n  if (options.binary) {\n    options.encoding = null;\n    options.json = false;\n  }\n\n  if (!options.processData) {\n    options.json = false;\n  }\n\n  return ajax$1(options, function (err, response, body) {\n\n    if (err) {\n      return callback(generateErrorFromResponse(err));\n    }\n\n    var error;\n    var content_type = response.headers && response.headers['content-type'];\n    var data = body || defaultBody();\n\n    // CouchDB doesn't always return the right content-type for JSON data, so\n    // we check for ^{ and }$ (ignoring leading/trailing whitespace)\n    if (!options.binary && (options.json || !options.processData) &&\n        typeof data !== 'object' &&\n        (/json/.test(content_type) ||\n         (/^[\\s]*\\{/.test(data) && /\\}[\\s]*$/.test(data)))) {\n      try {\n        data = JSON.parse(data.toString());\n      } catch (e) {}\n    }\n\n    if (response.statusCode >= 200 && response.statusCode < 300) {\n      onSuccess(data, response, callback);\n    } else {\n      error = generateErrorFromResponse(data);\n      error.status = response.statusCode;\n      callback(error);\n    }\n  });\n}\n\nfunction ajax(opts, callback) {\n\n  // cache-buster, specifically designed to work around IE's aggressive caching\n  // see http://www.dashbay.com/2011/05/internet-explorer-caches-ajax/\n  // Also Safari caches POSTs, so we need to cache-bust those too.\n  var ua = (navigator && navigator.userAgent) ?\n    navigator.userAgent.toLowerCase() : '';\n\n  var isSafari = ua.indexOf('safari') !== -1 && ua.indexOf('chrome') === -1;\n  var isIE = ua.indexOf('msie') !== -1;\n  var isEdge = ua.indexOf('edge') !== -1;\n\n  // it appears the new version of safari also caches GETs,\n  // see https://github.com/pouchdb/pouchdb/issues/5010\n  var shouldCacheBust = (isSafari ||\n    ((isIE || isEdge) && opts.method === 'GET'));\n\n  var cache = 'cache' in opts ? opts.cache : true;\n\n  var isBlobUrl = /^blob:/.test(opts.url); // don't append nonces for blob URLs\n\n  if (!isBlobUrl && (shouldCacheBust || !cache)) {\n    var hasArgs = opts.url.indexOf('?') !== -1;\n    opts.url += (hasArgs ? '&' : '?') + '_nonce=' + Date.now();\n  }\n\n  return ajaxCore$1(opts, callback);\n}\n\n// dead simple promise pool, inspired by https://github.com/timdp/es6-promise-pool\n// but much smaller in code size. limits the number of concurrent promises that are executed\n\nfunction pool(promiseFactories, limit) {\n  return new PouchPromise$1(function (resolve, reject) {\n    var running = 0;\n    var current = 0;\n    var done = 0;\n    var len = promiseFactories.length;\n    var err;\n\n    function runNext() {\n      running++;\n      promiseFactories[current++]().then(onSuccess, onError);\n    }\n\n    function doNext() {\n      if (++done === len) {\n        /* istanbul ignore if */\n        if (err) {\n          reject(err);\n        } else {\n          resolve();\n        }\n      } else {\n        runNextBatch();\n      }\n    }\n\n    function onSuccess() {\n      running--;\n      doNext();\n    }\n\n    /* istanbul ignore next */\n    function onError(thisErr) {\n      running--;\n      err = err || thisErr;\n      doNext();\n    }\n\n    function runNextBatch() {\n      while (running < limit && current < len) {\n        runNext();\n      }\n    }\n\n    runNextBatch();\n  });\n}\n\nvar CHANGES_BATCH_SIZE = 25;\nvar MAX_SIMULTANEOUS_REVS = 50;\n\nvar supportsBulkGetMap = {};\n\nvar log$1 = debug('pouchdb:http');\n\nfunction readAttachmentsAsBlobOrBuffer(row) {\n  var atts = row.doc && row.doc._attachments;\n  if (!atts) {\n    return;\n  }\n  Object.keys(atts).forEach(function (filename) {\n    var att = atts[filename];\n    att.data = b64ToBluffer(att.data, att.content_type);\n  });\n}\n\nfunction encodeDocId(id) {\n  if (/^_design/.test(id)) {\n    return '_design/' + encodeURIComponent(id.slice(8));\n  }\n  if (/^_local/.test(id)) {\n    return '_local/' + encodeURIComponent(id.slice(7));\n  }\n  return encodeURIComponent(id);\n}\n\nfunction preprocessAttachments$2(doc) {\n  if (!doc._attachments || !Object.keys(doc._attachments)) {\n    return PouchPromise$1.resolve();\n  }\n\n  return PouchPromise$1.all(Object.keys(doc._attachments).map(function (key) {\n    var attachment = doc._attachments[key];\n    if (attachment.data && typeof attachment.data !== 'string') {\n      return new PouchPromise$1(function (resolve) {\n        blobToBase64(attachment.data, resolve);\n      }).then(function (b64) {\n        attachment.data = b64;\n      });\n    }\n  }));\n}\n\nfunction hasUrlPrefix(opts) {\n  if (!opts.prefix) {\n    return false;\n  }\n\n  var protocol = parseUri(opts.prefix).protocol;\n\n  return protocol === 'http' || protocol === 'https';\n}\n\n// Get all the information you possibly can about the URI given by name and\n// return it as a suitable object.\nfunction getHost(name, opts) {\n\n  // encode db name if opts.prefix is a url (#5574)\n  if (hasUrlPrefix(opts)) {\n    var dbName = opts.name.substr(opts.prefix.length);\n    name = opts.prefix + encodeURIComponent(dbName);\n  }\n\n  // Prase the URI into all its little bits\n  var uri = parseUri(name);\n\n  // Store the user and password as a separate auth object\n  if (uri.user || uri.password) {\n    uri.auth = {username: uri.user, password: uri.password};\n  }\n\n  // Split the path part of the URI into parts using '/' as the delimiter\n  // after removing any leading '/' and any trailing '/'\n  var parts = uri.path.replace(/(^\\/|\\/$)/g, '').split('/');\n\n  // Store the first part as the database name and remove it from the parts\n  // array\n  uri.db = parts.pop();\n  // Prevent double encoding of URI component\n  if (uri.db.indexOf('%') === -1) {\n    uri.db = encodeURIComponent(uri.db);\n  }\n\n  // Restore the path by joining all the remaining parts (all the parts\n  // except for the database name) with '/'s\n  uri.path = parts.join('/');\n\n  return uri;\n}\n\n// Generate a URL with the host data given by opts and the given path\nfunction genDBUrl(opts, path) {\n  return genUrl(opts, opts.db + '/' + path);\n}\n\n// Generate a URL with the host data given by opts and the given path\nfunction genUrl(opts, path) {\n  // If the host already has a path, then we need to have a path delimiter\n  // Otherwise, the path delimiter is the empty string\n  var pathDel = !opts.path ? '' : '/';\n\n  // If the host already has a path, then we need to have a path delimiter\n  // Otherwise, the path delimiter is the empty string\n  return opts.protocol + '://' + opts.host +\n         (opts.port ? (':' + opts.port) : '') +\n         '/' + opts.path + pathDel + path;\n}\n\nfunction paramsToStr(params) {\n  return '?' + Object.keys(params).map(function (k) {\n    return k + '=' + encodeURIComponent(params[k]);\n  }).join('&');\n}\n\n// Implements the PouchDB API for dealing with CouchDB instances over HTTP\nfunction HttpPouch(opts, callback) {\n\n  // The functions that will be publicly available for HttpPouch\n  var api = this;\n\n  var host = getHost(opts.name, opts);\n  var dbUrl = genDBUrl(host, '');\n\n  opts = clone(opts);\n  var ajaxOpts = opts.ajax || {};\n\n  if (opts.auth || host.auth) {\n    var nAuth = opts.auth || host.auth;\n    var str = nAuth.username + ':' + nAuth.password;\n    var token = thisBtoa(unescape(encodeURIComponent(str)));\n    ajaxOpts.headers = ajaxOpts.headers || {};\n    ajaxOpts.headers.Authorization = 'Basic ' + token;\n  }\n\n  // Not strictly necessary, but we do this because numerous tests\n  // rely on swapping ajax in and out.\n  api._ajax = ajax;\n\n  function ajax$$1(userOpts, options, callback) {\n    var reqAjax = userOpts.ajax || {};\n    var reqOpts = assign$1(clone(ajaxOpts), reqAjax, options);\n    log$1(reqOpts.method + ' ' + reqOpts.url);\n    return api._ajax(reqOpts, callback);\n  }\n\n  function ajaxPromise(userOpts, opts) {\n    return new PouchPromise$1(function (resolve, reject) {\n      ajax$$1(userOpts, opts, function (err, res) {\n        /* istanbul ignore if */\n        if (err) {\n          return reject(err);\n        }\n        resolve(res);\n      });\n    });\n  }\n\n  function adapterFun$$1(name, fun) {\n    return adapterFun(name, getArguments(function (args) {\n      setup().then(function () {\n        return fun.apply(this, args);\n      }).catch(function (e) {\n        var callback = args.pop();\n        callback(e);\n      });\n    }));\n  }\n\n  var setupPromise;\n\n  function setup() {\n    // TODO: Remove `skipSetup` in favor of `skip_setup` in a future release\n    if (opts.skipSetup || opts.skip_setup) {\n      return PouchPromise$1.resolve();\n    }\n\n    // If there is a setup in process or previous successful setup\n    // done then we will use that\n    // If previous setups have been rejected we will try again\n    if (setupPromise) {\n      return setupPromise;\n    }\n\n    var checkExists = {method: 'GET', url: dbUrl};\n    setupPromise = ajaxPromise({}, checkExists).catch(function (err) {\n      if (err && err.status && err.status === 404) {\n        // Doesnt exist, create it\n        explainError(404, 'PouchDB is just detecting if the remote exists.');\n        return ajaxPromise({}, {method: 'PUT', url: dbUrl});\n      } else {\n        return PouchPromise$1.reject(err);\n      }\n    }).catch(function (err) {\n      // If we try to create a database that already exists, skipped in\n      // istanbul since its catching a race condition.\n      /* istanbul ignore if */\n      if (err && err.status && err.status === 412) {\n        return true;\n      }\n      return PouchPromise$1.reject(err);\n    });\n\n    setupPromise.catch(function () {\n      setupPromise = null;\n    });\n\n    return setupPromise;\n  }\n\n  nextTick(function () {\n    callback(null, api);\n  });\n\n  api.type = function () {\n    return 'http';\n  };\n\n  api.id = adapterFun$$1('id', function (callback) {\n    ajax$$1({}, {method: 'GET', url: genUrl(host, '')}, function (err, result) {\n      var uuid$$1 = (result && result.uuid) ?\n        (result.uuid + host.db) : genDBUrl(host, '');\n      callback(null, uuid$$1);\n    });\n  });\n\n  api.request = adapterFun$$1('request', function (options, callback) {\n    options.url = genDBUrl(host, options.url);\n    ajax$$1({}, options, callback);\n  });\n\n  // Sends a POST request to the host calling the couchdb _compact function\n  //    version: The version of CouchDB it is running\n  api.compact = adapterFun$$1('compact', function (opts, callback) {\n    if (typeof opts === 'function') {\n      callback = opts;\n      opts = {};\n    }\n    opts = clone(opts);\n    ajax$$1(opts, {\n      url: genDBUrl(host, '_compact'),\n      method: 'POST'\n    }, function () {\n      function ping() {\n        api.info(function (err, res) {\n          if (res && !res.compact_running) {\n            callback(null, {ok: true});\n          } else {\n            setTimeout(ping, opts.interval || 200);\n          }\n        });\n      }\n      // Ping the http if it's finished compaction\n      ping();\n    });\n  });\n\n  api.bulkGet = adapterFun('bulkGet', function (opts, callback) {\n    var self = this;\n\n    function doBulkGet(cb) {\n      var params = {};\n      if (opts.revs) {\n        params.revs = true;\n      }\n      if (opts.attachments) {\n        /* istanbul ignore next */\n        params.attachments = true;\n      }\n      if (opts.latest) {\n        params.latest = true;\n      }\n      ajax$$1(opts, {\n        url: genDBUrl(host, '_bulk_get' + paramsToStr(params)),\n        method: 'POST',\n        body: { docs: opts.docs}\n      }, cb);\n    }\n\n    function doBulkGetShim() {\n      // avoid \"url too long error\" by splitting up into multiple requests\n      var batchSize = MAX_SIMULTANEOUS_REVS;\n      var numBatches = Math.ceil(opts.docs.length / batchSize);\n      var numDone = 0;\n      var results = new Array(numBatches);\n\n      function onResult(batchNum) {\n        return function (err, res) {\n          // err is impossible because shim returns a list of errs in that case\n          results[batchNum] = res.results;\n          if (++numDone === numBatches) {\n            callback(null, {results: flatten(results)});\n          }\n        };\n      }\n\n      for (var i = 0; i < numBatches; i++) {\n        var subOpts = pick(opts, ['revs', 'attachments', 'latest']);\n        subOpts.ajax = ajaxOpts;\n        subOpts.docs = opts.docs.slice(i * batchSize,\n          Math.min(opts.docs.length, (i + 1) * batchSize));\n        bulkGet(self, subOpts, onResult(i));\n      }\n    }\n\n    // mark the whole database as either supporting or not supporting _bulk_get\n    var dbUrl = genUrl(host, '');\n    var supportsBulkGet = supportsBulkGetMap[dbUrl];\n\n    if (typeof supportsBulkGet !== 'boolean') {\n      // check if this database supports _bulk_get\n      doBulkGet(function (err, res) {\n        /* istanbul ignore else */\n        if (err) {\n          supportsBulkGetMap[dbUrl] = false;\n          explainError(\n            err.status,\n            'PouchDB is just detecting if the remote ' +\n            'supports the _bulk_get API.'\n          );\n          doBulkGetShim();\n        } else {\n          supportsBulkGetMap[dbUrl] = true;\n          callback(null, res);\n        }\n      });\n    } else if (supportsBulkGet) {\n      /* istanbul ignore next */\n      doBulkGet(callback);\n    } else {\n      doBulkGetShim();\n    }\n  });\n\n  // Calls GET on the host, which gets back a JSON string containing\n  //    couchdb: A welcome string\n  //    version: The version of CouchDB it is running\n  api._info = function (callback) {\n    setup().then(function () {\n      ajax$$1({}, {\n        method: 'GET',\n        url: genDBUrl(host, '')\n      }, function (err, res) {\n        /* istanbul ignore next */\n        if (err) {\n        return callback(err);\n        }\n        res.host = genDBUrl(host, '');\n        callback(null, res);\n      });\n    }).catch(callback);\n  };\n\n  // Get the document with the given id from the database given by host.\n  // The id could be solely the _id in the database, or it may be a\n  // _design/ID or _local/ID path\n  api.get = adapterFun$$1('get', function (id, opts, callback) {\n    // If no options were given, set the callback to the second parameter\n    if (typeof opts === 'function') {\n      callback = opts;\n      opts = {};\n    }\n    opts = clone(opts);\n\n    // List of parameters to add to the GET request\n    var params = {};\n\n    if (opts.revs) {\n      params.revs = true;\n    }\n\n    if (opts.revs_info) {\n      params.revs_info = true;\n    }\n\n    if (opts.latest) {\n      params.latest = true;\n    }\n\n    if (opts.open_revs) {\n      if (opts.open_revs !== \"all\") {\n        opts.open_revs = JSON.stringify(opts.open_revs);\n      }\n      params.open_revs = opts.open_revs;\n    }\n\n    if (opts.rev) {\n      params.rev = opts.rev;\n    }\n\n    if (opts.conflicts) {\n      params.conflicts = opts.conflicts;\n    }\n\n    id = encodeDocId(id);\n\n    // Set the options for the ajax call\n    var options = {\n      method: 'GET',\n      url: genDBUrl(host, id + paramsToStr(params))\n    };\n\n    function fetchAttachments(doc) {\n      var atts = doc._attachments;\n      var filenames = atts && Object.keys(atts);\n      if (!atts || !filenames.length) {\n        return;\n      }\n      // we fetch these manually in separate XHRs, because\n      // Sync Gateway would normally send it back as multipart/mixed,\n      // which we cannot parse. Also, this is more efficient than\n      // receiving attachments as base64-encoded strings.\n      function fetch(filename) {\n        var att = atts[filename];\n        var path = encodeDocId(doc._id) + '/' + encodeAttachmentId(filename) +\n          '?rev=' + doc._rev;\n        return ajaxPromise(opts, {\n          method: 'GET',\n          url: genDBUrl(host, path),\n          binary: true\n        }).then(function (blob$$1) {\n          if (opts.binary) {\n            return blob$$1;\n          }\n          return new PouchPromise$1(function (resolve) {\n            blobToBase64(blob$$1, resolve);\n          });\n        }).then(function (data) {\n          delete att.stub;\n          delete att.length;\n          att.data = data;\n        });\n      }\n\n      var promiseFactories = filenames.map(function (filename) {\n        return function () {\n          return fetch(filename);\n        };\n      });\n\n      // This limits the number of parallel xhr requests to 5 any time\n      // to avoid issues with maximum browser request limits\n      return pool(promiseFactories, 5);\n    }\n\n    function fetchAllAttachments(docOrDocs) {\n      if (Array.isArray(docOrDocs)) {\n        return PouchPromise$1.all(docOrDocs.map(function (doc) {\n          if (doc.ok) {\n            return fetchAttachments(doc.ok);\n          }\n        }));\n      }\n      return fetchAttachments(docOrDocs);\n    }\n\n    ajaxPromise(opts, options).then(function (res) {\n      return PouchPromise$1.resolve().then(function () {\n        if (opts.attachments) {\n          return fetchAllAttachments(res);\n        }\n      }).then(function () {\n        callback(null, res);\n      });\n    }).catch(callback);\n  });\n\n  // Delete the document given by doc from the database given by host.\n  api.remove = adapterFun$$1('remove',\n      function (docOrId, optsOrRev, opts, callback) {\n    var doc;\n    if (typeof optsOrRev === 'string') {\n      // id, rev, opts, callback style\n      doc = {\n        _id: docOrId,\n        _rev: optsOrRev\n      };\n      if (typeof opts === 'function') {\n        callback = opts;\n        opts = {};\n      }\n    } else {\n      // doc, opts, callback style\n      doc = docOrId;\n      if (typeof optsOrRev === 'function') {\n        callback = optsOrRev;\n        opts = {};\n      } else {\n        callback = opts;\n        opts = optsOrRev;\n      }\n    }\n\n    var rev = (doc._rev || opts.rev);\n\n    // Delete the document\n    ajax$$1(opts, {\n      method: 'DELETE',\n      url: genDBUrl(host, encodeDocId(doc._id)) + '?rev=' + rev\n    }, callback);\n  });\n\n  function encodeAttachmentId(attachmentId) {\n    return attachmentId.split(\"/\").map(encodeURIComponent).join(\"/\");\n  }\n\n  // Get the attachment\n  api.getAttachment =\n    adapterFun$$1('getAttachment', function (docId, attachmentId, opts,\n                                                callback) {\n    if (typeof opts === 'function') {\n      callback = opts;\n      opts = {};\n    }\n    var params = opts.rev ? ('?rev=' + opts.rev) : '';\n    var url = genDBUrl(host, encodeDocId(docId)) + '/' +\n      encodeAttachmentId(attachmentId) + params;\n    ajax$$1(opts, {\n      method: 'GET',\n      url: url,\n      binary: true\n    }, callback);\n  });\n\n  // Remove the attachment given by the id and rev\n  api.removeAttachment =\n    adapterFun$$1('removeAttachment', function (docId, attachmentId, rev,\n                                                   callback) {\n\n    var url = genDBUrl(host, encodeDocId(docId) + '/' +\n      encodeAttachmentId(attachmentId)) + '?rev=' + rev;\n\n    ajax$$1({}, {\n      method: 'DELETE',\n      url: url\n    }, callback);\n  });\n\n  // Add the attachment given by blob and its contentType property\n  // to the document with the given id, the revision given by rev, and\n  // add it to the database given by host.\n  api.putAttachment =\n    adapterFun$$1('putAttachment', function (docId, attachmentId, rev, blob$$1,\n                                                type, callback) {\n    if (typeof type === 'function') {\n      callback = type;\n      type = blob$$1;\n      blob$$1 = rev;\n      rev = null;\n    }\n    var id = encodeDocId(docId) + '/' + encodeAttachmentId(attachmentId);\n    var url = genDBUrl(host, id);\n    if (rev) {\n      url += '?rev=' + rev;\n    }\n\n    if (typeof blob$$1 === 'string') {\n      // input is assumed to be a base64 string\n      var binary;\n      try {\n        binary = thisAtob(blob$$1);\n      } catch (err) {\n        return callback(createError(BAD_ARG,\n                        'Attachment is not a valid base64 string'));\n      }\n      blob$$1 = binary ? binStringToBluffer(binary, type) : '';\n    }\n\n    var opts = {\n      headers: {'Content-Type': type},\n      method: 'PUT',\n      url: url,\n      processData: false,\n      body: blob$$1,\n      timeout: ajaxOpts.timeout || 60000\n    };\n    // Add the attachment\n    ajax$$1({}, opts, callback);\n  });\n\n  // Update/create multiple documents given by req in the database\n  // given by host.\n  api._bulkDocs = function (req, opts, callback) {\n    // If new_edits=false then it prevents the database from creating\n    // new revision numbers for the documents. Instead it just uses\n    // the old ones. This is used in database replication.\n    req.new_edits = opts.new_edits;\n\n    setup().then(function () {\n      return PouchPromise$1.all(req.docs.map(preprocessAttachments$2));\n    }).then(function () {\n      // Update/create the documents\n      ajax$$1(opts, {\n        method: 'POST',\n        url: genDBUrl(host, '_bulk_docs'),\n        timeout: opts.timeout,\n        body: req\n      }, function (err, results) {\n        if (err) {\n          return callback(err);\n        }\n        results.forEach(function (result) {\n          result.ok = true; // smooths out cloudant not adding this\n        });\n        callback(null, results);\n      });\n    }).catch(callback);\n  };\n\n\n  // Update/create document\n  api._put = function (doc, opts, callback) {\n    setup().then(function () {\n      return preprocessAttachments$2(doc);\n    }).then(function () {\n      // Update/create the document\n      ajax$$1(opts, {\n        method: 'PUT',\n        url: genDBUrl(host, encodeDocId(doc._id)),\n        body: doc\n      }, function (err, result) {\n        if (err) {\n          return callback(err);\n        }\n        callback(null, result);\n      });\n    }).catch(callback);\n  };\n\n\n  // Get a listing of the documents in the database given\n  // by host and ordered by increasing id.\n  api.allDocs = adapterFun$$1('allDocs', function (opts, callback) {\n    if (typeof opts === 'function') {\n      callback = opts;\n      opts = {};\n    }\n    opts = clone(opts);\n\n    // List of parameters to add to the GET request\n    var params = {};\n    var body;\n    var method = 'GET';\n\n    if (opts.conflicts) {\n      params.conflicts = true;\n    }\n\n    if (opts.descending) {\n      params.descending = true;\n    }\n\n    if (opts.include_docs) {\n      params.include_docs = true;\n    }\n\n    // added in CouchDB 1.6.0\n    if (opts.attachments) {\n      params.attachments = true;\n    }\n\n    if (opts.key) {\n      params.key = JSON.stringify(opts.key);\n    }\n\n    if (opts.start_key) {\n      opts.startkey = opts.start_key;\n    }\n\n    if (opts.startkey) {\n      params.startkey = JSON.stringify(opts.startkey);\n    }\n\n    if (opts.end_key) {\n      opts.endkey = opts.end_key;\n    }\n\n    if (opts.endkey) {\n      params.endkey = JSON.stringify(opts.endkey);\n    }\n\n    if (typeof opts.inclusive_end !== 'undefined') {\n      params.inclusive_end = !!opts.inclusive_end;\n    }\n\n    if (typeof opts.limit !== 'undefined') {\n      params.limit = opts.limit;\n    }\n\n    if (typeof opts.skip !== 'undefined') {\n      params.skip = opts.skip;\n    }\n\n    var paramStr = paramsToStr(params);\n\n    if (typeof opts.keys !== 'undefined') {\n      method = 'POST';\n      body = {keys: opts.keys};\n    }\n\n    // Get the document listing\n    ajaxPromise(opts, {\n      method: method,\n      url: genDBUrl(host, '_all_docs' + paramStr),\n      body: body\n    }).then(function (res) {\n      if (opts.include_docs && opts.attachments && opts.binary) {\n        res.rows.forEach(readAttachmentsAsBlobOrBuffer);\n      }\n      callback(null, res);\n    }).catch(callback);\n  });\n\n  // Get a list of changes made to documents in the database given by host.\n  // TODO According to the README, there should be two other methods here,\n  // api.changes.addListener and api.changes.removeListener.\n  api._changes = function (opts) {\n\n    // We internally page the results of a changes request, this means\n    // if there is a large set of changes to be returned we can start\n    // processing them quicker instead of waiting on the entire\n    // set of changes to return and attempting to process them at once\n    var batchSize = 'batch_size' in opts ? opts.batch_size : CHANGES_BATCH_SIZE;\n\n    opts = clone(opts);\n    opts.timeout = ('timeout' in opts) ? opts.timeout :\n      ('timeout' in ajaxOpts) ? ajaxOpts.timeout :\n      30 * 1000;\n\n    // We give a 5 second buffer for CouchDB changes to respond with\n    // an ok timeout (if a timeout it set)\n    var params = opts.timeout ? {timeout: opts.timeout - (5 * 1000)} : {};\n    var limit = (typeof opts.limit !== 'undefined') ? opts.limit : false;\n    var returnDocs;\n    if ('return_docs' in opts) {\n      returnDocs = opts.return_docs;\n    } else if ('returnDocs' in opts) {\n      // TODO: Remove 'returnDocs' in favor of 'return_docs' in a future release\n      returnDocs = opts.returnDocs;\n    } else {\n      returnDocs = true;\n    }\n    //\n    var leftToFetch = limit;\n\n    if (opts.style) {\n      params.style = opts.style;\n    }\n\n    if (opts.include_docs || opts.filter && typeof opts.filter === 'function') {\n      params.include_docs = true;\n    }\n\n    if (opts.attachments) {\n      params.attachments = true;\n    }\n\n    if (opts.continuous) {\n      params.feed = 'longpoll';\n    }\n\n    if (opts.conflicts) {\n      params.conflicts = true;\n    }\n\n    if (opts.descending) {\n      params.descending = true;\n    }\n\n    if ('heartbeat' in opts) {\n      // If the heartbeat value is false, it disables the default heartbeat\n      if (opts.heartbeat) {\n        params.heartbeat = opts.heartbeat;\n      }\n    } else if (opts.continuous) {\n      // Default heartbeat to 10 seconds\n      params.heartbeat = 10000;\n    }\n\n    if (opts.filter && typeof opts.filter === 'string') {\n      params.filter = opts.filter;\n    }\n\n    if (opts.view && typeof opts.view === 'string') {\n      params.filter = '_view';\n      params.view = opts.view;\n    }\n\n    // If opts.query_params exists, pass it through to the changes request.\n    // These parameters may be used by the filter on the source database.\n    if (opts.query_params && typeof opts.query_params === 'object') {\n      for (var param_name in opts.query_params) {\n        /* istanbul ignore else */\n        if (opts.query_params.hasOwnProperty(param_name)) {\n          params[param_name] = opts.query_params[param_name];\n        }\n      }\n    }\n\n    var method = 'GET';\n    var body;\n\n    if (opts.doc_ids) {\n      // set this automagically for the user; it's annoying that couchdb\n      // requires both a \"filter\" and a \"doc_ids\" param.\n      params.filter = '_doc_ids';\n      method = 'POST';\n      body = {doc_ids: opts.doc_ids };\n    }\n\n    var xhr;\n    var lastFetchedSeq;\n\n    // Get all the changes starting wtih the one immediately after the\n    // sequence number given by since.\n    var fetch = function (since, callback) {\n      if (opts.aborted) {\n        return;\n      }\n      params.since = since;\n      // \"since\" can be any kind of json object in Coudant/CouchDB 2.x\n      /* istanbul ignore next */\n      if (typeof params.since === \"object\") {\n        params.since = JSON.stringify(params.since);\n      }\n\n      if (opts.descending) {\n        if (limit) {\n          params.limit = leftToFetch;\n        }\n      } else {\n        params.limit = (!limit || leftToFetch > batchSize) ?\n          batchSize : leftToFetch;\n      }\n\n      // Set the options for the ajax call\n      var xhrOpts = {\n        method: method,\n        url: genDBUrl(host, '_changes' + paramsToStr(params)),\n        timeout: opts.timeout,\n        body: body\n      };\n      lastFetchedSeq = since;\n\n      /* istanbul ignore if */\n      if (opts.aborted) {\n        return;\n      }\n\n      // Get the changes\n      setup().then(function () {\n        xhr = ajax$$1(opts, xhrOpts, callback);\n      }).catch(callback);\n    };\n\n    // If opts.since exists, get all the changes from the sequence\n    // number given by opts.since. Otherwise, get all the changes\n    // from the sequence number 0.\n    var results = {results: []};\n\n    var fetched = function (err, res) {\n      if (opts.aborted) {\n        return;\n      }\n      var raw_results_length = 0;\n      // If the result of the ajax call (res) contains changes (res.results)\n      if (res && res.results) {\n        raw_results_length = res.results.length;\n        results.last_seq = res.last_seq;\n        // For each change\n        var req = {};\n        req.query = opts.query_params;\n        res.results = res.results.filter(function (c) {\n          leftToFetch--;\n          var ret = filterChange(opts)(c);\n          if (ret) {\n            if (opts.include_docs && opts.attachments && opts.binary) {\n              readAttachmentsAsBlobOrBuffer(c);\n            }\n            if (returnDocs) {\n              results.results.push(c);\n            }\n            opts.onChange(c);\n          }\n          return ret;\n        });\n      } else if (err) {\n        // In case of an error, stop listening for changes and call\n        // opts.complete\n        opts.aborted = true;\n        opts.complete(err);\n        return;\n      }\n\n      // The changes feed may have timed out with no results\n      // if so reuse last update sequence\n      if (res && res.last_seq) {\n        lastFetchedSeq = res.last_seq;\n      }\n\n      var finished = (limit && leftToFetch <= 0) ||\n        (res && raw_results_length < batchSize) ||\n        (opts.descending);\n\n      if ((opts.continuous && !(limit && leftToFetch <= 0)) || !finished) {\n        // Queue a call to fetch again with the newest sequence number\n        nextTick(function () { fetch(lastFetchedSeq, fetched); });\n      } else {\n        // We're done, call the callback\n        opts.complete(null, results);\n      }\n    };\n\n    fetch(opts.since || 0, fetched);\n\n    // Return a method to cancel this method from processing any more\n    return {\n      cancel: function () {\n        opts.aborted = true;\n        if (xhr) {\n          xhr.abort();\n        }\n      }\n    };\n  };\n\n  // Given a set of document/revision IDs (given by req), tets the subset of\n  // those that do NOT correspond to revisions stored in the database.\n  // See http://wiki.apache.org/couchdb/HttpPostRevsDiff\n  api.revsDiff = adapterFun$$1('revsDiff', function (req, opts, callback) {\n    // If no options were given, set the callback to be the second parameter\n    if (typeof opts === 'function') {\n      callback = opts;\n      opts = {};\n    }\n\n    // Get the missing document/revision IDs\n    ajax$$1(opts, {\n      method: 'POST',\n      url: genDBUrl(host, '_revs_diff'),\n      body: req\n    }, callback);\n  });\n\n  api._close = function (callback) {\n    callback();\n  };\n\n  api._destroy = function (options, callback) {\n    ajax$$1(options, {\n      url: genDBUrl(host, ''),\n      method: 'DELETE'\n    }, function (err, resp) {\n      if (err && err.status && err.status !== 404) {\n        return callback(err);\n      }\n      callback(null, resp);\n    });\n  };\n}\n\n// HttpPouch is a valid adapter.\nHttpPouch.valid = function () {\n  return true;\n};\n\nvar HttpPouch$1 = function (PouchDB) {\n  PouchDB.adapter('http', HttpPouch, false);\n  PouchDB.adapter('https', HttpPouch, false);\n};\n\nfunction pad(str, padWith, upToLength) {\n  var padding = '';\n  var targetLength = upToLength - str.length;\n  /* istanbul ignore next */\n  while (padding.length < targetLength) {\n    padding += padWith;\n  }\n  return padding;\n}\n\nfunction padLeft(str, padWith, upToLength) {\n  var padding = pad(str, padWith, upToLength);\n  return padding + str;\n}\n\nvar MIN_MAGNITUDE = -324; // verified by -Number.MIN_VALUE\nvar MAGNITUDE_DIGITS = 3; // ditto\nvar SEP = ''; // set to '_' for easier debugging \n\nfunction collate(a, b) {\n\n  if (a === b) {\n    return 0;\n  }\n\n  a = normalizeKey(a);\n  b = normalizeKey(b);\n\n  var ai = collationIndex(a);\n  var bi = collationIndex(b);\n  if ((ai - bi) !== 0) {\n    return ai - bi;\n  }\n  switch (typeof a) {\n    case 'number':\n      return a - b;\n    case 'boolean':\n      return a < b ? -1 : 1;\n    case 'string':\n      return stringCollate(a, b);\n  }\n  return Array.isArray(a) ? arrayCollate(a, b) : objectCollate(a, b);\n}\n\n// couch considers null/NaN/Infinity/-Infinity === undefined,\n// for the purposes of mapreduce indexes. also, dates get stringified.\nfunction normalizeKey(key) {\n  switch (typeof key) {\n    case 'undefined':\n      return null;\n    case 'number':\n      if (key === Infinity || key === -Infinity || isNaN(key)) {\n        return null;\n      }\n      return key;\n    case 'object':\n      var origKey = key;\n      if (Array.isArray(key)) {\n        var len = key.length;\n        key = new Array(len);\n        for (var i = 0; i < len; i++) {\n          key[i] = normalizeKey(origKey[i]);\n        }\n      /* istanbul ignore next */\n      } else if (key instanceof Date) {\n        return key.toJSON();\n      } else if (key !== null) { // generic object\n        key = {};\n        for (var k in origKey) {\n          if (origKey.hasOwnProperty(k)) {\n            var val = origKey[k];\n            if (typeof val !== 'undefined') {\n              key[k] = normalizeKey(val);\n            }\n          }\n        }\n      }\n  }\n  return key;\n}\n\nfunction indexify(key) {\n  if (key !== null) {\n    switch (typeof key) {\n      case 'boolean':\n        return key ? 1 : 0;\n      case 'number':\n        return numToIndexableString(key);\n      case 'string':\n        // We've to be sure that key does not contain \\u0000\n        // Do order-preserving replacements:\n        // 0 -> 1, 1\n        // 1 -> 1, 2\n        // 2 -> 2, 2\n        return key\n          .replace(/\\u0002/g, '\\u0002\\u0002')\n          .replace(/\\u0001/g, '\\u0001\\u0002')\n          .replace(/\\u0000/g, '\\u0001\\u0001');\n      case 'object':\n        var isArray = Array.isArray(key);\n        var arr = isArray ? key : Object.keys(key);\n        var i = -1;\n        var len = arr.length;\n        var result = '';\n        if (isArray) {\n          while (++i < len) {\n            result += toIndexableString(arr[i]);\n          }\n        } else {\n          while (++i < len) {\n            var objKey = arr[i];\n            result += toIndexableString(objKey) +\n                toIndexableString(key[objKey]);\n          }\n        }\n        return result;\n    }\n  }\n  return '';\n}\n\n// convert the given key to a string that would be appropriate\n// for lexical sorting, e.g. within a database, where the\n// sorting is the same given by the collate() function.\nfunction toIndexableString(key) {\n  var zero = '\\u0000';\n  key = normalizeKey(key);\n  return collationIndex(key) + SEP + indexify(key) + zero;\n}\n\nfunction parseNumber(str, i) {\n  var originalIdx = i;\n  var num;\n  var zero = str[i] === '1';\n  if (zero) {\n    num = 0;\n    i++;\n  } else {\n    var neg = str[i] === '0';\n    i++;\n    var numAsString = '';\n    var magAsString = str.substring(i, i + MAGNITUDE_DIGITS);\n    var magnitude = parseInt(magAsString, 10) + MIN_MAGNITUDE;\n    /* istanbul ignore next */\n    if (neg) {\n      magnitude = -magnitude;\n    }\n    i += MAGNITUDE_DIGITS;\n    while (true) {\n      var ch = str[i];\n      if (ch === '\\u0000') {\n        break;\n      } else {\n        numAsString += ch;\n      }\n      i++;\n    }\n    numAsString = numAsString.split('.');\n    if (numAsString.length === 1) {\n      num = parseInt(numAsString, 10);\n    } else {\n      /* istanbul ignore next */\n      num = parseFloat(numAsString[0] + '.' + numAsString[1]);\n    }\n    /* istanbul ignore next */\n    if (neg) {\n      num = num - 10;\n    }\n    /* istanbul ignore next */\n    if (magnitude !== 0) {\n      // parseFloat is more reliable than pow due to rounding errors\n      // e.g. Number.MAX_VALUE would return Infinity if we did\n      // num * Math.pow(10, magnitude);\n      num = parseFloat(num + 'e' + magnitude);\n    }\n  }\n  return {num: num, length : i - originalIdx};\n}\n\n// move up the stack while parsing\n// this function moved outside of parseIndexableString for performance\nfunction pop(stack, metaStack) {\n  var obj = stack.pop();\n\n  if (metaStack.length) {\n    var lastMetaElement = metaStack[metaStack.length - 1];\n    if (obj === lastMetaElement.element) {\n      // popping a meta-element, e.g. an object whose value is another object\n      metaStack.pop();\n      lastMetaElement = metaStack[metaStack.length - 1];\n    }\n    var element = lastMetaElement.element;\n    var lastElementIndex = lastMetaElement.index;\n    if (Array.isArray(element)) {\n      element.push(obj);\n    } else if (lastElementIndex === stack.length - 2) { // obj with key+value\n      var key = stack.pop();\n      element[key] = obj;\n    } else {\n      stack.push(obj); // obj with key only\n    }\n  }\n}\n\nfunction parseIndexableString(str) {\n  var stack = [];\n  var metaStack = []; // stack for arrays and objects\n  var i = 0;\n\n  /*eslint no-constant-condition: [\"error\", { \"checkLoops\": false }]*/\n  while (true) {\n    var collationIndex = str[i++];\n    if (collationIndex === '\\u0000') {\n      if (stack.length === 1) {\n        return stack.pop();\n      } else {\n        pop(stack, metaStack);\n        continue;\n      }\n    }\n    switch (collationIndex) {\n      case '1':\n        stack.push(null);\n        break;\n      case '2':\n        stack.push(str[i] === '1');\n        i++;\n        break;\n      case '3':\n        var parsedNum = parseNumber(str, i);\n        stack.push(parsedNum.num);\n        i += parsedNum.length;\n        break;\n      case '4':\n        var parsedStr = '';\n        /*eslint no-constant-condition: [\"error\", { \"checkLoops\": false }]*/\n        while (true) {\n          var ch = str[i];\n          if (ch === '\\u0000') {\n            break;\n          }\n          parsedStr += ch;\n          i++;\n        }\n        // perform the reverse of the order-preserving replacement\n        // algorithm (see above)\n        parsedStr = parsedStr.replace(/\\u0001\\u0001/g, '\\u0000')\n          .replace(/\\u0001\\u0002/g, '\\u0001')\n          .replace(/\\u0002\\u0002/g, '\\u0002');\n        stack.push(parsedStr);\n        break;\n      case '5':\n        var arrayElement = { element: [], index: stack.length };\n        stack.push(arrayElement.element);\n        metaStack.push(arrayElement);\n        break;\n      case '6':\n        var objElement = { element: {}, index: stack.length };\n        stack.push(objElement.element);\n        metaStack.push(objElement);\n        break;\n      /* istanbul ignore next */\n      default:\n        throw new Error(\n          'bad collationIndex or unexpectedly reached end of input: ' +\n            collationIndex);\n    }\n  }\n}\n\nfunction arrayCollate(a, b) {\n  var len = Math.min(a.length, b.length);\n  for (var i = 0; i < len; i++) {\n    var sort = collate(a[i], b[i]);\n    if (sort !== 0) {\n      return sort;\n    }\n  }\n  return (a.length === b.length) ? 0 :\n    (a.length > b.length) ? 1 : -1;\n}\nfunction stringCollate(a, b) {\n  // See: https://github.com/daleharvey/pouchdb/issues/40\n  // This is incompatible with the CouchDB implementation, but its the\n  // best we can do for now\n  return (a === b) ? 0 : ((a > b) ? 1 : -1);\n}\nfunction objectCollate(a, b) {\n  var ak = Object.keys(a), bk = Object.keys(b);\n  var len = Math.min(ak.length, bk.length);\n  for (var i = 0; i < len; i++) {\n    // First sort the keys\n    var sort = collate(ak[i], bk[i]);\n    if (sort !== 0) {\n      return sort;\n    }\n    // if the keys are equal sort the values\n    sort = collate(a[ak[i]], b[bk[i]]);\n    if (sort !== 0) {\n      return sort;\n    }\n\n  }\n  return (ak.length === bk.length) ? 0 :\n    (ak.length > bk.length) ? 1 : -1;\n}\n// The collation is defined by erlangs ordered terms\n// the atoms null, true, false come first, then numbers, strings,\n// arrays, then objects\n// null/undefined/NaN/Infinity/-Infinity are all considered null\nfunction collationIndex(x) {\n  var id = ['boolean', 'number', 'string', 'object'];\n  var idx = id.indexOf(typeof x);\n  //false if -1 otherwise true, but fast!!!!1\n  if (~idx) {\n    if (x === null) {\n      return 1;\n    }\n    if (Array.isArray(x)) {\n      return 5;\n    }\n    return idx < 3 ? (idx + 2) : (idx + 3);\n  }\n  /* istanbul ignore next */\n  if (Array.isArray(x)) {\n    return 5;\n  }\n}\n\n// conversion:\n// x yyy zz...zz\n// x = 0 for negative, 1 for 0, 2 for positive\n// y = exponent (for negative numbers negated) moved so that it's >= 0\n// z = mantisse\nfunction numToIndexableString(num) {\n\n  if (num === 0) {\n    return '1';\n  }\n\n  // convert number to exponential format for easier and\n  // more succinct string sorting\n  var expFormat = num.toExponential().split(/e\\+?/);\n  var magnitude = parseInt(expFormat[1], 10);\n\n  var neg = num < 0;\n\n  var result = neg ? '0' : '2';\n\n  // first sort by magnitude\n  // it's easier if all magnitudes are positive\n  var magForComparison = ((neg ? -magnitude : magnitude) - MIN_MAGNITUDE);\n  var magString = padLeft((magForComparison).toString(), '0', MAGNITUDE_DIGITS);\n\n  result += SEP + magString;\n\n  // then sort by the factor\n  var factor = Math.abs(parseFloat(expFormat[0])); // [1..10)\n  /* istanbul ignore next */\n  if (neg) { // for negative reverse ordering\n    factor = 10 - factor;\n  }\n\n  var factorStr = factor.toFixed(20);\n\n  // strip zeros from the end\n  factorStr = factorStr.replace(/\\.?0+$/, '');\n\n  result += SEP + factorStr;\n\n  return result;\n}\n\n/*\n * Simple task queue to sequentialize actions. Assumes\n * callbacks will eventually fire (once).\n */\n\nfunction TaskQueue$2() {\n  this.promise = new PouchPromise$1(function (fulfill) {fulfill(); });\n}\nTaskQueue$2.prototype.add = function (promiseFactory) {\n  this.promise = this.promise.catch(function () {\n    // just recover\n  }).then(function () {\n    return promiseFactory();\n  });\n  return this.promise;\n};\nTaskQueue$2.prototype.finish = function () {\n  return this.promise;\n};\n\nfunction createView(opts) {\n  var sourceDB = opts.db;\n  var viewName = opts.viewName;\n  var mapFun = opts.map;\n  var reduceFun = opts.reduce;\n  var temporary = opts.temporary;\n\n  // the \"undefined\" part is for backwards compatibility\n  var viewSignature = mapFun.toString() + (reduceFun && reduceFun.toString()) +\n    'undefined';\n\n  var cachedViews;\n  if (!temporary) {\n    // cache this to ensure we don't try to update the same view twice\n    cachedViews = sourceDB._cachedViews = sourceDB._cachedViews || {};\n    if (cachedViews[viewSignature]) {\n      return cachedViews[viewSignature];\n    }\n  }\n\n  var promiseForView = sourceDB.info().then(function (info) {\n\n    var depDbName = info.db_name + '-mrview-' +\n      (temporary ? 'temp' : stringMd5(viewSignature));\n\n    // save the view name in the source db so it can be cleaned up if necessary\n    // (e.g. when the _design doc is deleted, remove all associated view data)\n    function diffFunction(doc) {\n      doc.views = doc.views || {};\n      var fullViewName = viewName;\n      if (fullViewName.indexOf('/') === -1) {\n        fullViewName = viewName + '/' + viewName;\n      }\n      var depDbs = doc.views[fullViewName] = doc.views[fullViewName] || {};\n      /* istanbul ignore if */\n      if (depDbs[depDbName]) {\n        return; // no update necessary\n      }\n      depDbs[depDbName] = true;\n      return doc;\n    }\n    return upsert(sourceDB, '_local/mrviews', diffFunction).then(function () {\n      return sourceDB.registerDependentDatabase(depDbName).then(function (res) {\n        var db = res.db;\n        db.auto_compaction = true;\n        var view = {\n          name: depDbName,\n          db: db,\n          sourceDB: sourceDB,\n          adapter: sourceDB.adapter,\n          mapFun: mapFun,\n          reduceFun: reduceFun\n        };\n        return view.db.get('_local/lastSeq').catch(function (err) {\n          /* istanbul ignore if */\n          if (err.status !== 404) {\n            throw err;\n          }\n        }).then(function (lastSeqDoc) {\n          view.seq = lastSeqDoc ? lastSeqDoc.seq : 0;\n          if (cachedViews) {\n            view.db.once('destroyed', function () {\n              delete cachedViews[viewSignature];\n            });\n          }\n          return view;\n        });\n      });\n    });\n  });\n\n  if (cachedViews) {\n    cachedViews[viewSignature] = promiseForView;\n  }\n  return promiseForView;\n}\n\nfunction QueryParseError(message) {\n  this.status = 400;\n  this.name = 'query_parse_error';\n  this.message = message;\n  this.error = true;\n  try {\n    Error.captureStackTrace(this, QueryParseError);\n  } catch (e) {}\n}\n\ninherits(QueryParseError, Error);\n\nfunction NotFoundError(message) {\n  this.status = 404;\n  this.name = 'not_found';\n  this.message = message;\n  this.error = true;\n  try {\n    Error.captureStackTrace(this, NotFoundError);\n  } catch (e) {}\n}\n\ninherits(NotFoundError, Error);\n\nfunction BuiltInError(message) {\n  this.status = 500;\n  this.name = 'invalid_value';\n  this.message = message;\n  this.error = true;\n  try {\n    Error.captureStackTrace(this, BuiltInError);\n  } catch (e) {}\n}\n\ninherits(BuiltInError, Error);\n\nfunction createBuiltInError(name) {\n  var message = 'builtin ' + name +\n    ' function requires map values to be numbers' +\n    ' or number arrays';\n  return new BuiltInError(message);\n}\n\nfunction sum(values) {\n  var result = 0;\n  for (var i = 0, len = values.length; i < len; i++) {\n    var num = values[i];\n    if (typeof num !== 'number') {\n      if (Array.isArray(num)) {\n        // lists of numbers are also allowed, sum them separately\n        result = typeof result === 'number' ? [result] : result;\n        for (var j = 0, jLen = num.length; j < jLen; j++) {\n          var jNum = num[j];\n          if (typeof jNum !== 'number') {\n            throw createBuiltInError('_sum');\n          } else if (typeof result[j] === 'undefined') {\n            result.push(jNum);\n          } else {\n            result[j] += jNum;\n          }\n        }\n      } else { // not array/number\n        throw createBuiltInError('_sum');\n      }\n    } else if (typeof result === 'number') {\n      result += num;\n    } else { // add number to array\n      result[0] += num;\n    }\n  }\n  return result;\n}\n\nvar log$2 = guardedConsole.bind(null, 'log');\nvar isArray = Array.isArray;\nvar toJSON = JSON.parse;\n\nfunction evalFunctionWithEval(func, emit) {\n  return scopedEval(\n    \"return (\" + func.replace(/;\\s*$/, \"\") + \");\",\n    {\n      emit: emit,\n      sum: sum,\n      log: log$2,\n      isArray: isArray,\n      toJSON: toJSON\n    }\n  );\n}\n\nfunction promisedCallback(promise, callback) {\n  if (callback) {\n    promise.then(function (res) {\n      nextTick(function () {\n        callback(null, res);\n      });\n    }, function (reason) {\n      nextTick(function () {\n        callback(reason);\n      });\n    });\n  }\n  return promise;\n}\n\nfunction callbackify(fun) {\n  return getArguments(function (args) {\n    var cb = args.pop();\n    var promise = fun.apply(this, args);\n    if (typeof cb === 'function') {\n      promisedCallback(promise, cb);\n    }\n    return promise;\n  });\n}\n\n// Promise finally util similar to Q.finally\nfunction fin(promise, finalPromiseFactory) {\n  return promise.then(function (res) {\n    return finalPromiseFactory().then(function () {\n      return res;\n    });\n  }, function (reason) {\n    return finalPromiseFactory().then(function () {\n      throw reason;\n    });\n  });\n}\n\nfunction sequentialize(queue, promiseFactory) {\n  return function () {\n    var args = arguments;\n    var that = this;\n    return queue.add(function () {\n      return promiseFactory.apply(that, args);\n    });\n  };\n}\n\n// uniq an array of strings, order not guaranteed\n// similar to underscore/lodash _.uniq\nfunction uniq(arr) {\n  var theSet = new ExportedSet(arr);\n  var result = new Array(theSet.size);\n  var index = -1;\n  theSet.forEach(function (value) {\n    result[++index] = value;\n  });\n  return result;\n}\n\nfunction mapToKeysArray(map) {\n  var result = new Array(map.size);\n  var index = -1;\n  map.forEach(function (value, key) {\n    result[++index] = key;\n  });\n  return result;\n}\n\nvar persistentQueues = {};\nvar tempViewQueue = new TaskQueue$2();\nvar CHANGES_BATCH_SIZE$1 = 50;\n\nfunction parseViewName(name) {\n  // can be either 'ddocname/viewname' or just 'viewname'\n  // (where the ddoc name is the same)\n  return name.indexOf('/') === -1 ? [name, name] : name.split('/');\n}\n\nfunction isGenOne(changes) {\n  // only return true if the current change is 1-\n  // and there are no other leafs\n  return changes.length === 1 && /^1-/.test(changes[0].rev);\n}\n\nfunction emitError(db, e) {\n  try {\n    db.emit('error', e);\n  } catch (err) {\n    guardedConsole('error',\n      'The user\\'s map/reduce function threw an uncaught error.\\n' +\n      'You can debug this error by doing:\\n' +\n      'myDatabase.on(\\'error\\', function (err) { debugger; });\\n' +\n      'Please double-check your map/reduce function.');\n    guardedConsole('error', e);\n  }\n}\nfunction tryMap(db, fun, doc) {\n  // emit an event if there was an error thrown by a map function.\n  // putting try/catches in a single function also avoids deoptimizations.\n  try {\n    fun(doc);\n  } catch (e) {\n    emitError(db, e);\n  }\n}\n\nfunction tryReduce(db, fun, keys, values, rereduce) {\n  // same as above, but returning the result or an error. there are two separate\n  // functions to avoid extra memory allocations since the tryCode() case is used\n  // for custom map functions (common) vs this function, which is only used for\n  // custom reduce functions (rare)\n  try {\n    return {output : fun(keys, values, rereduce)};\n  } catch (e) {\n    emitError(db, e);\n    return {error: e};\n  }\n}\n\nfunction sortByKeyThenValue(x, y) {\n  var keyCompare = collate(x.key, y.key);\n  return keyCompare !== 0 ? keyCompare : collate(x.value, y.value);\n}\n\nfunction sliceResults(results, limit, skip) {\n  skip = skip || 0;\n  if (typeof limit === 'number') {\n    return results.slice(skip, limit + skip);\n  } else if (skip > 0) {\n    return results.slice(skip);\n  }\n  return results;\n}\n\nfunction rowToDocId(row) {\n  var val = row.value;\n  // Users can explicitly specify a joined doc _id, or it\n  // defaults to the doc _id that emitted the key/value.\n  var docId = (val && typeof val === 'object' && val._id) || row.id;\n  return docId;\n}\n\nfunction readAttachmentsAsBlobOrBuffer$1(res) {\n  res.rows.forEach(function (row) {\n    var atts = row.doc && row.doc._attachments;\n    if (!atts) {\n      return;\n    }\n    Object.keys(atts).forEach(function (filename) {\n      var att = atts[filename];\n      atts[filename].data = b64ToBluffer(att.data, att.content_type);\n    });\n  });\n}\n\nfunction postprocessAttachments(opts) {\n  return function (res) {\n    if (opts.include_docs && opts.attachments && opts.binary) {\n      readAttachmentsAsBlobOrBuffer$1(res);\n    }\n    return res;\n  };\n}\n\nvar builtInReduce = {\n  _sum: function (keys, values) {\n    return sum(values);\n  },\n\n  _count: function (keys, values) {\n    return values.length;\n  },\n\n  _stats: function (keys, values) {\n    // no need to implement rereduce=true, because Pouch\n    // will never call it\n    function sumsqr(values) {\n      var _sumsqr = 0;\n      for (var i = 0, len = values.length; i < len; i++) {\n        var num = values[i];\n        _sumsqr += (num * num);\n      }\n      return _sumsqr;\n    }\n    return {\n      sum     : sum(values),\n      min     : Math.min.apply(null, values),\n      max     : Math.max.apply(null, values),\n      count   : values.length,\n      sumsqr : sumsqr(values)\n    };\n  }\n};\n\nfunction addHttpParam(paramName, opts, params, asJson) {\n  // add an http param from opts to params, optionally json-encoded\n  var val = opts[paramName];\n  if (typeof val !== 'undefined') {\n    if (asJson) {\n      val = encodeURIComponent(JSON.stringify(val));\n    }\n    params.push(paramName + '=' + val);\n  }\n}\n\nfunction coerceInteger(integerCandidate) {\n  if (typeof integerCandidate !== 'undefined') {\n    var asNumber = Number(integerCandidate);\n    // prevents e.g. '1foo' or '1.1' being coerced to 1\n    if (!isNaN(asNumber) && asNumber === parseInt(integerCandidate, 10)) {\n      return asNumber;\n    } else {\n      return integerCandidate;\n    }\n  }\n}\n\nfunction coerceOptions(opts) {\n  opts.group_level = coerceInteger(opts.group_level);\n  opts.limit = coerceInteger(opts.limit);\n  opts.skip = coerceInteger(opts.skip);\n  return opts;\n}\n\nfunction checkPositiveInteger(number) {\n  if (number) {\n    if (typeof number !== 'number') {\n      return  new QueryParseError('Invalid value for integer: \"' +\n      number + '\"');\n    }\n    if (number < 0) {\n      return new QueryParseError('Invalid value for positive integer: ' +\n        '\"' + number + '\"');\n    }\n  }\n}\n\nfunction checkQueryParseError(options, fun) {\n  var startkeyName = options.descending ? 'endkey' : 'startkey';\n  var endkeyName = options.descending ? 'startkey' : 'endkey';\n\n  if (typeof options[startkeyName] !== 'undefined' &&\n    typeof options[endkeyName] !== 'undefined' &&\n    collate(options[startkeyName], options[endkeyName]) > 0) {\n    throw new QueryParseError('No rows can match your key range, ' +\n    'reverse your start_key and end_key or set {descending : true}');\n  } else if (fun.reduce && options.reduce !== false) {\n    if (options.include_docs) {\n      throw new QueryParseError('{include_docs:true} is invalid for reduce');\n    } else if (options.keys && options.keys.length > 1 &&\n        !options.group && !options.group_level) {\n      throw new QueryParseError('Multi-key fetches for reduce views must use ' +\n      '{group: true}');\n    }\n  }\n  ['group_level', 'limit', 'skip'].forEach(function (optionName) {\n    var error = checkPositiveInteger(options[optionName]);\n    if (error) {\n      throw error;\n    }\n  });\n}\n\nfunction httpQuery(db, fun, opts) {\n  // List of parameters to add to the PUT request\n  var params = [];\n  var body;\n  var method = 'GET';\n\n  // If opts.reduce exists and is defined, then add it to the list\n  // of parameters.\n  // If reduce=false then the results are that of only the map function\n  // not the final result of map and reduce.\n  addHttpParam('reduce', opts, params);\n  addHttpParam('include_docs', opts, params);\n  addHttpParam('attachments', opts, params);\n  addHttpParam('limit', opts, params);\n  addHttpParam('descending', opts, params);\n  addHttpParam('group', opts, params);\n  addHttpParam('group_level', opts, params);\n  addHttpParam('skip', opts, params);\n  addHttpParam('stale', opts, params);\n  addHttpParam('conflicts', opts, params);\n  addHttpParam('startkey', opts, params, true);\n  addHttpParam('start_key', opts, params, true);\n  addHttpParam('endkey', opts, params, true);\n  addHttpParam('end_key', opts, params, true);\n  addHttpParam('inclusive_end', opts, params);\n  addHttpParam('key', opts, params, true);\n\n  // Format the list of parameters into a valid URI query string\n  params = params.join('&');\n  params = params === '' ? '' : '?' + params;\n\n  // If keys are supplied, issue a POST to circumvent GET query string limits\n  // see http://wiki.apache.org/couchdb/HTTP_view_API#Querying_Options\n  if (typeof opts.keys !== 'undefined') {\n    var MAX_URL_LENGTH = 2000;\n    // according to http://stackoverflow.com/a/417184/680742,\n    // the de facto URL length limit is 2000 characters\n\n    var keysAsString =\n      'keys=' + encodeURIComponent(JSON.stringify(opts.keys));\n    if (keysAsString.length + params.length + 1 <= MAX_URL_LENGTH) {\n      // If the keys are short enough, do a GET. we do this to work around\n      // Safari not understanding 304s on POSTs (see pouchdb/pouchdb#1239)\n      params += (params[0] === '?' ? '&' : '?') + keysAsString;\n    } else {\n      method = 'POST';\n      if (typeof fun === 'string') {\n        body = {keys: opts.keys};\n      } else { // fun is {map : mapfun}, so append to this\n        fun.keys = opts.keys;\n      }\n    }\n  }\n\n  // We are referencing a query defined in the design doc\n  if (typeof fun === 'string') {\n    var parts = parseViewName(fun);\n    return db.request({\n      method: method,\n      url: '_design/' + parts[0] + '/_view/' + parts[1] + params,\n      body: body\n    }).then(postprocessAttachments(opts));\n  }\n\n  // We are using a temporary view, terrible for performance, good for testing\n  body = body || {};\n  Object.keys(fun).forEach(function (key) {\n    if (Array.isArray(fun[key])) {\n      body[key] = fun[key];\n    } else {\n      body[key] = fun[key].toString();\n    }\n  });\n  return db.request({\n    method: 'POST',\n    url: '_temp_view' + params,\n    body: body\n  }).then(postprocessAttachments(opts));\n}\n\n// custom adapters can define their own api._query\n// and override the default behavior\n/* istanbul ignore next */\nfunction customQuery(db, fun, opts) {\n  return new PouchPromise$1(function (resolve, reject) {\n    db._query(fun, opts, function (err, res) {\n      if (err) {\n        return reject(err);\n      }\n      resolve(res);\n    });\n  });\n}\n\n// custom adapters can define their own api._viewCleanup\n// and override the default behavior\n/* istanbul ignore next */\nfunction customViewCleanup(db) {\n  return new PouchPromise$1(function (resolve, reject) {\n    db._viewCleanup(function (err, res) {\n      if (err) {\n        return reject(err);\n      }\n      resolve(res);\n    });\n  });\n}\n\nfunction defaultsTo(value) {\n  return function (reason) {\n    /* istanbul ignore else */\n    if (reason.status === 404) {\n      return value;\n    } else {\n      throw reason;\n    }\n  };\n}\n\n// returns a promise for a list of docs to update, based on the input docId.\n// the order doesn't matter, because post-3.2.0, bulkDocs\n// is an atomic operation in all three adapters.\nfunction getDocsToPersist(docId, view, docIdsToChangesAndEmits) {\n  var metaDocId = '_local/doc_' + docId;\n  var defaultMetaDoc = {_id: metaDocId, keys: []};\n  var docData = docIdsToChangesAndEmits.get(docId);\n  var indexableKeysToKeyValues = docData[0];\n  var changes = docData[1];\n\n  function getMetaDoc() {\n    if (isGenOne(changes)) {\n      // generation 1, so we can safely assume initial state\n      // for performance reasons (avoids unnecessary GETs)\n      return PouchPromise$1.resolve(defaultMetaDoc);\n    }\n    return view.db.get(metaDocId).catch(defaultsTo(defaultMetaDoc));\n  }\n\n  function getKeyValueDocs(metaDoc) {\n    if (!metaDoc.keys.length) {\n      // no keys, no need for a lookup\n      return PouchPromise$1.resolve({rows: []});\n    }\n    return view.db.allDocs({\n      keys: metaDoc.keys,\n      include_docs: true\n    });\n  }\n\n  function processKeyValueDocs(metaDoc, kvDocsRes) {\n    var kvDocs = [];\n    var oldKeys = new ExportedSet();\n\n    for (var i = 0, len = kvDocsRes.rows.length; i < len; i++) {\n      var row = kvDocsRes.rows[i];\n      var doc = row.doc;\n      if (!doc) { // deleted\n        continue;\n      }\n      kvDocs.push(doc);\n      oldKeys.add(doc._id);\n      doc._deleted = !indexableKeysToKeyValues.has(doc._id);\n      if (!doc._deleted) {\n        var keyValue = indexableKeysToKeyValues.get(doc._id);\n        if ('value' in keyValue) {\n          doc.value = keyValue.value;\n        }\n      }\n    }\n    var newKeys = mapToKeysArray(indexableKeysToKeyValues);\n    newKeys.forEach(function (key) {\n      if (!oldKeys.has(key)) {\n        // new doc\n        var kvDoc = {\n          _id: key\n        };\n        var keyValue = indexableKeysToKeyValues.get(key);\n        if ('value' in keyValue) {\n          kvDoc.value = keyValue.value;\n        }\n        kvDocs.push(kvDoc);\n      }\n    });\n    metaDoc.keys = uniq(newKeys.concat(metaDoc.keys));\n    kvDocs.push(metaDoc);\n\n    return kvDocs;\n  }\n\n  return getMetaDoc().then(function (metaDoc) {\n    return getKeyValueDocs(metaDoc).then(function (kvDocsRes) {\n      return processKeyValueDocs(metaDoc, kvDocsRes);\n    });\n  });\n}\n\n// updates all emitted key/value docs and metaDocs in the mrview database\n// for the given batch of documents from the source database\nfunction saveKeyValues(view, docIdsToChangesAndEmits, seq) {\n  var seqDocId = '_local/lastSeq';\n  return view.db.get(seqDocId)\n  .catch(defaultsTo({_id: seqDocId, seq: 0}))\n  .then(function (lastSeqDoc) {\n    var docIds = mapToKeysArray(docIdsToChangesAndEmits);\n    return PouchPromise$1.all(docIds.map(function (docId) {\n      return getDocsToPersist(docId, view, docIdsToChangesAndEmits);\n    })).then(function (listOfDocsToPersist) {\n      var docsToPersist = flatten(listOfDocsToPersist);\n      lastSeqDoc.seq = seq;\n      docsToPersist.push(lastSeqDoc);\n      // write all docs in a single operation, update the seq once\n      return view.db.bulkDocs({docs : docsToPersist});\n    });\n  });\n}\n\nfunction getQueue(view) {\n  var viewName = typeof view === 'string' ? view : view.name;\n  var queue = persistentQueues[viewName];\n  if (!queue) {\n    queue = persistentQueues[viewName] = new TaskQueue$2();\n  }\n  return queue;\n}\n\nfunction updateView(view) {\n  return sequentialize(getQueue(view), function () {\n    return updateViewInQueue(view);\n  })();\n}\n\nfunction updateViewInQueue(view) {\n  // bind the emit function once\n  var mapResults;\n  var doc;\n\n  function emit(key, value) {\n    var output = {id: doc._id, key: normalizeKey(key)};\n    // Don't explicitly store the value unless it's defined and non-null.\n    // This saves on storage space, because often people don't use it.\n    if (typeof value !== 'undefined' && value !== null) {\n      output.value = normalizeKey(value);\n    }\n    mapResults.push(output);\n  }\n\n  var mapFun;\n  // for temp_views one can use emit(doc, emit), see #38\n  if (typeof view.mapFun === \"function\" && view.mapFun.length === 2) {\n    var origMap = view.mapFun;\n    mapFun = function (doc) {\n      return origMap(doc, emit);\n    };\n  } else {\n    mapFun = evalFunctionWithEval(view.mapFun.toString(), emit);\n  }\n\n  var currentSeq = view.seq || 0;\n\n  function processChange(docIdsToChangesAndEmits, seq) {\n    return function () {\n      return saveKeyValues(view, docIdsToChangesAndEmits, seq);\n    };\n  }\n\n  var queue = new TaskQueue$2();\n\n  function processNextBatch() {\n    return view.sourceDB.changes({\n      conflicts: true,\n      include_docs: true,\n      style: 'all_docs',\n      since: currentSeq,\n      limit: CHANGES_BATCH_SIZE$1\n    }).then(processBatch);\n  }\n\n  function processBatch(response) {\n    var results = response.results;\n    if (!results.length) {\n      return;\n    }\n    var docIdsToChangesAndEmits = createDocIdsToChangesAndEmits(results);\n    queue.add(processChange(docIdsToChangesAndEmits, currentSeq));\n    if (results.length < CHANGES_BATCH_SIZE$1) {\n      return;\n    }\n    return processNextBatch();\n  }\n\n  function createDocIdsToChangesAndEmits(results) {\n    var docIdsToChangesAndEmits = new ExportedMap();\n    for (var i = 0, len = results.length; i < len; i++) {\n      var change = results[i];\n      if (change.doc._id[0] !== '_') {\n        mapResults = [];\n        doc = change.doc;\n\n        if (!doc._deleted) {\n          tryMap(view.sourceDB, mapFun, doc);\n        }\n        mapResults.sort(sortByKeyThenValue);\n\n        var indexableKeysToKeyValues = createIndexableKeysToKeyValues(mapResults);\n        docIdsToChangesAndEmits.set(change.doc._id, [\n          indexableKeysToKeyValues,\n          change.changes\n        ]);\n      }\n      currentSeq = change.seq;\n    }\n    return docIdsToChangesAndEmits;\n  }\n\n  function createIndexableKeysToKeyValues(mapResults) {\n    var indexableKeysToKeyValues = new ExportedMap();\n    var lastKey;\n    for (var i = 0, len = mapResults.length; i < len; i++) {\n      var emittedKeyValue = mapResults[i];\n      var complexKey = [emittedKeyValue.key, emittedKeyValue.id];\n      if (i > 0 && collate(emittedKeyValue.key, lastKey) === 0) {\n        complexKey.push(i); // dup key+id, so make it unique\n      }\n      indexableKeysToKeyValues.set(toIndexableString(complexKey), emittedKeyValue);\n      lastKey = emittedKeyValue.key;\n    }\n    return indexableKeysToKeyValues;\n  }\n\n  return processNextBatch().then(function () {\n    return queue.finish();\n  }).then(function () {\n    view.seq = currentSeq;\n  });\n}\n\nfunction reduceView(view, results, options) {\n  if (options.group_level === 0) {\n    delete options.group_level;\n  }\n\n  var shouldGroup = options.group || options.group_level;\n\n  var reduceFun;\n  if (builtInReduce[view.reduceFun]) {\n    reduceFun = builtInReduce[view.reduceFun];\n  } else {\n    reduceFun = evalFunctionWithEval(view.reduceFun.toString());\n  }\n\n  var groups = [];\n  var lvl = isNaN(options.group_level) ? Number.POSITIVE_INFINITY :\n    options.group_level;\n  results.forEach(function (e) {\n    var last = groups[groups.length - 1];\n    var groupKey = shouldGroup ? e.key : null;\n\n    // only set group_level for array keys\n    if (shouldGroup && Array.isArray(groupKey)) {\n      groupKey = groupKey.slice(0, lvl);\n    }\n\n    if (last && collate(last.groupKey, groupKey) === 0) {\n      last.keys.push([e.key, e.id]);\n      last.values.push(e.value);\n      return;\n    }\n    groups.push({\n      keys: [[e.key, e.id]],\n      values: [e.value],\n      groupKey: groupKey\n    });\n  });\n  results = [];\n  for (var i = 0, len = groups.length; i < len; i++) {\n    var e = groups[i];\n    var reduceTry = tryReduce(view.sourceDB, reduceFun, e.keys, e.values, false);\n    if (reduceTry.error && reduceTry.error instanceof BuiltInError) {\n      // CouchDB returns an error if a built-in errors out\n      throw reduceTry.error;\n    }\n    results.push({\n      // CouchDB just sets the value to null if a non-built-in errors out\n      value: reduceTry.error ? null : reduceTry.output,\n      key: e.groupKey\n    });\n  }\n  // no total_rows/offset when reducing\n  return {rows: sliceResults(results, options.limit, options.skip)};\n}\n\nfunction queryView(view, opts) {\n  return sequentialize(getQueue(view), function () {\n    return queryViewInQueue(view, opts);\n  })();\n}\n\nfunction queryViewInQueue(view, opts) {\n  var totalRows;\n  var shouldReduce = view.reduceFun && opts.reduce !== false;\n  var skip = opts.skip || 0;\n  if (typeof opts.keys !== 'undefined' && !opts.keys.length) {\n    // equivalent query\n    opts.limit = 0;\n    delete opts.keys;\n  }\n\n  function fetchFromView(viewOpts) {\n    viewOpts.include_docs = true;\n    return view.db.allDocs(viewOpts).then(function (res) {\n      totalRows = res.total_rows;\n      return res.rows.map(function (result) {\n\n        // implicit migration - in older versions of PouchDB,\n        // we explicitly stored the doc as {id: ..., key: ..., value: ...}\n        // this is tested in a migration test\n        /* istanbul ignore next */\n        if ('value' in result.doc && typeof result.doc.value === 'object' &&\n            result.doc.value !== null) {\n          var keys = Object.keys(result.doc.value).sort();\n          // this detection method is not perfect, but it's unlikely the user\n          // emitted a value which was an object with these 3 exact keys\n          var expectedKeys = ['id', 'key', 'value'];\n          if (!(keys < expectedKeys || keys > expectedKeys)) {\n            return result.doc.value;\n          }\n        }\n\n        var parsedKeyAndDocId = parseIndexableString(result.doc._id);\n        return {\n          key: parsedKeyAndDocId[0],\n          id: parsedKeyAndDocId[1],\n          value: ('value' in result.doc ? result.doc.value : null)\n        };\n      });\n    });\n  }\n\n  function onMapResultsReady(rows) {\n    var finalResults;\n    if (shouldReduce) {\n      finalResults = reduceView(view, rows, opts);\n    } else {\n      finalResults = {\n        total_rows: totalRows,\n        offset: skip,\n        rows: rows\n      };\n    }\n    if (opts.include_docs) {\n      var docIds = uniq(rows.map(rowToDocId));\n\n      return view.sourceDB.allDocs({\n        keys: docIds,\n        include_docs: true,\n        conflicts: opts.conflicts,\n        attachments: opts.attachments,\n        binary: opts.binary\n      }).then(function (allDocsRes) {\n        var docIdsToDocs = new ExportedMap();\n        allDocsRes.rows.forEach(function (row) {\n          docIdsToDocs.set(row.id, row.doc);\n        });\n        rows.forEach(function (row) {\n          var docId = rowToDocId(row);\n          var doc = docIdsToDocs.get(docId);\n          if (doc) {\n            row.doc = doc;\n          }\n        });\n        return finalResults;\n      });\n    } else {\n      return finalResults;\n    }\n  }\n\n  if (typeof opts.keys !== 'undefined') {\n    var keys = opts.keys;\n    var fetchPromises = keys.map(function (key) {\n      var viewOpts = {\n        startkey : toIndexableString([key]),\n        endkey   : toIndexableString([key, {}])\n      };\n      return fetchFromView(viewOpts);\n    });\n    return PouchPromise$1.all(fetchPromises).then(flatten).then(onMapResultsReady);\n  } else { // normal query, no 'keys'\n    var viewOpts = {\n      descending : opts.descending\n    };\n    if (opts.start_key) {\n        opts.startkey = opts.start_key;\n    }\n    if (opts.end_key) {\n        opts.endkey = opts.end_key;\n    }\n    if (typeof opts.startkey !== 'undefined') {\n      viewOpts.startkey = opts.descending ?\n        toIndexableString([opts.startkey, {}]) :\n        toIndexableString([opts.startkey]);\n    }\n    if (typeof opts.endkey !== 'undefined') {\n      var inclusiveEnd = opts.inclusive_end !== false;\n      if (opts.descending) {\n        inclusiveEnd = !inclusiveEnd;\n      }\n\n      viewOpts.endkey = toIndexableString(\n        inclusiveEnd ? [opts.endkey, {}] : [opts.endkey]);\n    }\n    if (typeof opts.key !== 'undefined') {\n      var keyStart = toIndexableString([opts.key]);\n      var keyEnd = toIndexableString([opts.key, {}]);\n      if (viewOpts.descending) {\n        viewOpts.endkey = keyStart;\n        viewOpts.startkey = keyEnd;\n      } else {\n        viewOpts.startkey = keyStart;\n        viewOpts.endkey = keyEnd;\n      }\n    }\n    if (!shouldReduce) {\n      if (typeof opts.limit === 'number') {\n        viewOpts.limit = opts.limit;\n      }\n      viewOpts.skip = skip;\n    }\n    return fetchFromView(viewOpts).then(onMapResultsReady);\n  }\n}\n\nfunction httpViewCleanup(db) {\n  return db.request({\n    method: 'POST',\n    url: '_view_cleanup'\n  });\n}\n\nfunction localViewCleanup(db) {\n  return db.get('_local/mrviews').then(function (metaDoc) {\n    var docsToViews = new ExportedMap();\n    Object.keys(metaDoc.views).forEach(function (fullViewName) {\n      var parts = parseViewName(fullViewName);\n      var designDocName = '_design/' + parts[0];\n      var viewName = parts[1];\n      var views = docsToViews.get(designDocName);\n      if (!views) {\n        views = new ExportedSet();\n        docsToViews.set(designDocName, views);\n      }\n      views.add(viewName);\n    });\n    var opts = {\n      keys : mapToKeysArray(docsToViews),\n      include_docs : true\n    };\n    return db.allDocs(opts).then(function (res) {\n      var viewsToStatus = {};\n      res.rows.forEach(function (row) {\n        var ddocName = row.key.substring(8); // cuts off '_design/'\n        docsToViews.get(row.key).forEach(function (viewName) {\n          var fullViewName = ddocName + '/' + viewName;\n          /* istanbul ignore if */\n          if (!metaDoc.views[fullViewName]) {\n            // new format, without slashes, to support PouchDB 2.2.0\n            // migration test in pouchdb's browser.migration.js verifies this\n            fullViewName = viewName;\n          }\n          var viewDBNames = Object.keys(metaDoc.views[fullViewName]);\n          // design doc deleted, or view function nonexistent\n          var statusIsGood = row.doc && row.doc.views &&\n            row.doc.views[viewName];\n          viewDBNames.forEach(function (viewDBName) {\n            viewsToStatus[viewDBName] =\n              viewsToStatus[viewDBName] || statusIsGood;\n          });\n        });\n      });\n      var dbsToDelete = Object.keys(viewsToStatus).filter(\n        function (viewDBName) { return !viewsToStatus[viewDBName]; });\n      var destroyPromises = dbsToDelete.map(function (viewDBName) {\n        return sequentialize(getQueue(viewDBName), function () {\n          return new db.constructor(viewDBName, db.__opts).destroy();\n        })();\n      });\n      return PouchPromise$1.all(destroyPromises).then(function () {\n        return {ok: true};\n      });\n    });\n  }, defaultsTo({ok: true}));\n}\n\nvar viewCleanup = callbackify(function () {\n  var db = this;\n  if (db.type() === 'http') {\n    return httpViewCleanup(db);\n  }\n  /* istanbul ignore next */\n  if (typeof db._viewCleanup === 'function') {\n    return customViewCleanup(db);\n  }\n  return localViewCleanup(db);\n});\n\nfunction queryPromised(db, fun, opts) {\n  if (db.type() === 'http') {\n    return httpQuery(db, fun, opts);\n  }\n\n  /* istanbul ignore next */\n  if (typeof db._query === 'function') {\n    return customQuery(db, fun, opts);\n  }\n\n  if (typeof fun !== 'string') {\n    // temp_view\n    checkQueryParseError(opts, fun);\n\n    var createViewOpts = {\n      db : db,\n      viewName : 'temp_view/temp_view',\n      map : fun.map,\n      reduce : fun.reduce,\n      temporary : true\n    };\n    tempViewQueue.add(function () {\n      return createView(createViewOpts).then(function (view) {\n        function cleanup() {\n          return view.db.destroy();\n        }\n        return fin(updateView(view).then(function () {\n          return queryView(view, opts);\n        }), cleanup);\n      });\n    });\n    return tempViewQueue.finish();\n  } else {\n    // persistent view\n    var fullViewName = fun;\n    var parts = parseViewName(fullViewName);\n    var designDocName = parts[0];\n    var viewName = parts[1];\n    return db.get('_design/' + designDocName).then(function (doc) {\n      var fun = doc.views && doc.views[viewName];\n\n      if (!fun || typeof fun.map !== 'string') {\n        throw new NotFoundError('ddoc ' + designDocName +\n        ' has no view named ' + viewName);\n      }\n      checkQueryParseError(opts, fun);\n\n      var createViewOpts = {\n        db : db,\n        viewName : fullViewName,\n        map : fun.map,\n        reduce : fun.reduce\n      };\n      return createView(createViewOpts).then(function (view) {\n        if (opts.stale === 'ok' || opts.stale === 'update_after') {\n          if (opts.stale === 'update_after') {\n            nextTick(function () {\n              updateView(view);\n            });\n          }\n          return queryView(view, opts);\n        } else { // stale not ok\n          return updateView(view).then(function () {\n            return queryView(view, opts);\n          });\n        }\n      });\n    });\n  }\n}\n\nvar query = function (fun, opts, callback) {\n  if (typeof opts === 'function') {\n    callback = opts;\n    opts = {};\n  }\n  opts = opts ? coerceOptions(opts) : {};\n\n  if (typeof fun === 'function') {\n    fun = {map : fun};\n  }\n\n  var db = this;\n  var promise = PouchPromise$1.resolve().then(function () {\n    return queryPromised(db, fun, opts);\n  });\n  promisedCallback(promise, callback);\n  return promise;\n};\n\n\nvar mapreduce = {\n  query: query,\n  viewCleanup: viewCleanup\n};\n\nfunction isGenOne$1(rev) {\n  return /^1-/.test(rev);\n}\n\nfunction fileHasChanged(localDoc, remoteDoc, filename) {\n  return !localDoc._attachments ||\n         !localDoc._attachments[filename] ||\n         localDoc._attachments[filename].digest !== remoteDoc._attachments[filename].digest;\n}\n\nfunction getDocAttachments(db, doc) {\n  var filenames = Object.keys(doc._attachments);\n  return PouchPromise$1.all(filenames.map(function (filename) {\n    return db.getAttachment(doc._id, filename, {rev: doc._rev});\n  }));\n}\n\nfunction getDocAttachmentsFromTargetOrSource(target, src, doc) {\n  var doCheckForLocalAttachments = src.type() === 'http' && target.type() !== 'http';\n  var filenames = Object.keys(doc._attachments);\n\n  if (!doCheckForLocalAttachments) {\n    return getDocAttachments(src, doc);\n  }\n\n  return target.get(doc._id).then(function (localDoc) {\n    return PouchPromise$1.all(filenames.map(function (filename) {\n      if (fileHasChanged(localDoc, doc, filename)) {\n        return src.getAttachment(doc._id, filename);\n      }\n\n      return target.getAttachment(localDoc._id, filename);\n    }));\n  }).catch(function (error) {\n    /* istanbul ignore if */\n    if (error.status !== 404) {\n      throw error;\n    }\n\n    return getDocAttachments(src, doc);\n  });\n}\n\nfunction createBulkGetOpts(diffs) {\n  var requests = [];\n  Object.keys(diffs).forEach(function (id) {\n    var missingRevs = diffs[id].missing;\n    missingRevs.forEach(function (missingRev) {\n      requests.push({\n        id: id,\n        rev: missingRev\n      });\n    });\n  });\n\n  return {\n    docs: requests,\n    revs: true,\n    latest: true\n  };\n}\n\n//\n// Fetch all the documents from the src as described in the \"diffs\",\n// which is a mapping of docs IDs to revisions. If the state ever\n// changes to \"cancelled\", then the returned promise will be rejected.\n// Else it will be resolved with a list of fetched documents.\n//\nfunction getDocs(src, target, diffs, state) {\n  diffs = clone(diffs); // we do not need to modify this\n\n  var resultDocs = [],\n      ok = true;\n\n  function getAllDocs() {\n\n    var bulkGetOpts = createBulkGetOpts(diffs);\n\n    if (!bulkGetOpts.docs.length) { // optimization: skip empty requests\n      return;\n    }\n\n    return src.bulkGet(bulkGetOpts).then(function (bulkGetResponse) {\n      /* istanbul ignore if */\n      if (state.cancelled) {\n        throw new Error('cancelled');\n      }\n      return PouchPromise$1.all(bulkGetResponse.results.map(function (bulkGetInfo) {\n        return PouchPromise$1.all(bulkGetInfo.docs.map(function (doc) {\n          var remoteDoc = doc.ok;\n\n          if (doc.error) {\n            // when AUTO_COMPACTION is set, docs can be returned which look\n            // like this: {\"missing\":\"1-7c3ac256b693c462af8442f992b83696\"}\n            ok = false;\n          }\n\n          if (!remoteDoc || !remoteDoc._attachments) {\n            return remoteDoc;\n          }\n\n          return getDocAttachmentsFromTargetOrSource(target, src, remoteDoc).then(function (attachments) {\n            var filenames = Object.keys(remoteDoc._attachments);\n            attachments.forEach(function (attachment, i) {\n              var att = remoteDoc._attachments[filenames[i]];\n              delete att.stub;\n              delete att.length;\n              att.data = attachment;\n            });\n\n            return remoteDoc;\n          });\n        }));\n      }))\n\n      .then(function (results) {\n        resultDocs = resultDocs.concat(flatten(results).filter(Boolean));\n      });\n    });\n  }\n\n  function hasAttachments(doc) {\n    return doc._attachments && Object.keys(doc._attachments).length > 0;\n  }\n\n  function hasConflicts(doc) {\n    return doc._conflicts && doc._conflicts.length > 0;\n  }\n\n  function fetchRevisionOneDocs(ids) {\n    // Optimization: fetch gen-1 docs and attachments in\n    // a single request using _all_docs\n    return src.allDocs({\n      keys: ids,\n      include_docs: true,\n      conflicts: true\n    }).then(function (res) {\n      if (state.cancelled) {\n        throw new Error('cancelled');\n      }\n      res.rows.forEach(function (row) {\n        if (row.deleted || !row.doc || !isGenOne$1(row.value.rev) ||\n            hasAttachments(row.doc) || hasConflicts(row.doc)) {\n          // if any of these conditions apply, we need to fetch using get()\n          return;\n        }\n\n        // strip _conflicts array to appease CSG (#5793)\n        /* istanbul ignore if */\n        if (row.doc._conflicts) {\n          delete row.doc._conflicts;\n        }\n\n        // the doc we got back from allDocs() is sufficient\n        resultDocs.push(row.doc);\n        delete diffs[row.id];\n      });\n    });\n  }\n\n  function getRevisionOneDocs() {\n    // filter out the generation 1 docs and get them\n    // leaving the non-generation one docs to be got otherwise\n    var ids = Object.keys(diffs).filter(function (id) {\n      var missing = diffs[id].missing;\n      return missing.length === 1 && isGenOne$1(missing[0]);\n    });\n    if (ids.length > 0) {\n      return fetchRevisionOneDocs(ids);\n    }\n  }\n\n  function returnResult() {\n    return { ok:ok, docs:resultDocs };\n  }\n\n  return PouchPromise$1.resolve()\n    .then(getRevisionOneDocs)\n    .then(getAllDocs)\n    .then(returnResult);\n}\n\nvar CHECKPOINT_VERSION = 1;\nvar REPLICATOR = \"pouchdb\";\n// This is an arbitrary number to limit the\n// amount of replication history we save in the checkpoint.\n// If we save too much, the checkpoing docs will become very big,\n// if we save fewer, we'll run a greater risk of having to\n// read all the changes from 0 when checkpoint PUTs fail\n// CouchDB 2.0 has a more involved history pruning,\n// but let's go for the simple version for now.\nvar CHECKPOINT_HISTORY_SIZE = 5;\nvar LOWEST_SEQ = 0;\n\nfunction updateCheckpoint(db, id, checkpoint, session, returnValue) {\n  return db.get(id).catch(function (err) {\n    if (err.status === 404) {\n      if (db.type() === 'http') {\n        explainError(\n          404, 'PouchDB is just checking if a remote checkpoint exists.'\n        );\n      }\n      return {\n        session_id: session,\n        _id: id,\n        history: [],\n        replicator: REPLICATOR,\n        version: CHECKPOINT_VERSION\n      };\n    }\n    throw err;\n  }).then(function (doc) {\n    if (returnValue.cancelled) {\n      return;\n    }\n\n    // if the checkpoint has not changed, do not update\n    if (doc.last_seq === checkpoint) {\n      return;\n    }\n\n    // Filter out current entry for this replication\n    doc.history = (doc.history || []).filter(function (item) {\n      return item.session_id !== session;\n    });\n\n    // Add the latest checkpoint to history\n    doc.history.unshift({\n      last_seq: checkpoint,\n      session_id: session\n    });\n\n    // Just take the last pieces in history, to\n    // avoid really big checkpoint docs.\n    // see comment on history size above\n    doc.history = doc.history.slice(0, CHECKPOINT_HISTORY_SIZE);\n\n    doc.version = CHECKPOINT_VERSION;\n    doc.replicator = REPLICATOR;\n\n    doc.session_id = session;\n    doc.last_seq = checkpoint;\n\n    return db.put(doc).catch(function (err) {\n      if (err.status === 409) {\n        // retry; someone is trying to write a checkpoint simultaneously\n        return updateCheckpoint(db, id, checkpoint, session, returnValue);\n      }\n      throw err;\n    });\n  });\n}\n\nfunction Checkpointer(src, target, id, returnValue) {\n  this.src = src;\n  this.target = target;\n  this.id = id;\n  this.returnValue = returnValue;\n}\n\nCheckpointer.prototype.writeCheckpoint = function (checkpoint, session) {\n  var self = this;\n  return this.updateTarget(checkpoint, session).then(function () {\n    return self.updateSource(checkpoint, session);\n  });\n};\n\nCheckpointer.prototype.updateTarget = function (checkpoint, session) {\n  return updateCheckpoint(this.target, this.id, checkpoint,\n    session, this.returnValue);\n};\n\nCheckpointer.prototype.updateSource = function (checkpoint, session) {\n  var self = this;\n  if (this.readOnlySource) {\n    return PouchPromise$1.resolve(true);\n  }\n  return updateCheckpoint(this.src, this.id, checkpoint,\n    session, this.returnValue)\n    .catch(function (err) {\n      if (isForbiddenError(err)) {\n        self.readOnlySource = true;\n        return true;\n      }\n      throw err;\n    });\n};\n\nvar comparisons = {\n  \"undefined\": function (targetDoc, sourceDoc) {\n    // This is the previous comparison function\n    if (collate(targetDoc.last_seq, sourceDoc.last_seq) === 0) {\n      return sourceDoc.last_seq;\n    }\n    /* istanbul ignore next */\n    return 0;\n  },\n  \"1\": function (targetDoc, sourceDoc) {\n    // This is the comparison function ported from CouchDB\n    return compareReplicationLogs(sourceDoc, targetDoc).last_seq;\n  }\n};\n\nCheckpointer.prototype.getCheckpoint = function () {\n  var self = this;\n  return self.target.get(self.id).then(function (targetDoc) {\n    if (self.readOnlySource) {\n      return PouchPromise$1.resolve(targetDoc.last_seq);\n    }\n\n    return self.src.get(self.id).then(function (sourceDoc) {\n      // Since we can't migrate an old version doc to a new one\n      // (no session id), we just go with the lowest seq in this case\n      /* istanbul ignore if */\n      if (targetDoc.version !== sourceDoc.version) {\n        return LOWEST_SEQ;\n      }\n\n      var version;\n      if (targetDoc.version) {\n        version = targetDoc.version.toString();\n      } else {\n        version = \"undefined\";\n      }\n\n      if (version in comparisons) {\n        return comparisons[version](targetDoc, sourceDoc);\n      }\n      /* istanbul ignore next */\n      return LOWEST_SEQ;\n    }, function (err) {\n      if (err.status === 404 && targetDoc.last_seq) {\n        return self.src.put({\n          _id: self.id,\n          last_seq: LOWEST_SEQ\n        }).then(function () {\n          return LOWEST_SEQ;\n        }, function (err) {\n          if (isForbiddenError(err)) {\n            self.readOnlySource = true;\n            return targetDoc.last_seq;\n          }\n          /* istanbul ignore next */\n          return LOWEST_SEQ;\n        });\n      }\n      throw err;\n    });\n  }).catch(function (err) {\n    if (err.status !== 404) {\n      throw err;\n    }\n    return LOWEST_SEQ;\n  });\n};\n// This checkpoint comparison is ported from CouchDBs source\n// they come from here:\n// https://github.com/apache/couchdb-couch-replicator/blob/master/src/couch_replicator.erl#L863-L906\n\nfunction compareReplicationLogs(srcDoc, tgtDoc) {\n  if (srcDoc.session_id === tgtDoc.session_id) {\n    return {\n      last_seq: srcDoc.last_seq,\n      history: srcDoc.history\n    };\n  }\n\n  return compareReplicationHistory(srcDoc.history, tgtDoc.history);\n}\n\nfunction compareReplicationHistory(sourceHistory, targetHistory) {\n  // the erlang loop via function arguments is not so easy to repeat in JS\n  // therefore, doing this as recursion\n  var S = sourceHistory[0];\n  var sourceRest = sourceHistory.slice(1);\n  var T = targetHistory[0];\n  var targetRest = targetHistory.slice(1);\n\n  if (!S || targetHistory.length === 0) {\n    return {\n      last_seq: LOWEST_SEQ,\n      history: []\n    };\n  }\n\n  var sourceId = S.session_id;\n  /* istanbul ignore if */\n  if (hasSessionId(sourceId, targetHistory)) {\n    return {\n      last_seq: S.last_seq,\n      history: sourceHistory\n    };\n  }\n\n  var targetId = T.session_id;\n  if (hasSessionId(targetId, sourceRest)) {\n    return {\n      last_seq: T.last_seq,\n      history: targetRest\n    };\n  }\n\n  return compareReplicationHistory(sourceRest, targetRest);\n}\n\nfunction hasSessionId(sessionId, history) {\n  var props = history[0];\n  var rest = history.slice(1);\n\n  if (!sessionId || history.length === 0) {\n    return false;\n  }\n\n  if (sessionId === props.session_id) {\n    return true;\n  }\n\n  return hasSessionId(sessionId, rest);\n}\n\nfunction isForbiddenError(err) {\n  return typeof err.status === 'number' && Math.floor(err.status / 100) === 4;\n}\n\nvar STARTING_BACK_OFF = 0;\n\nfunction backOff(opts, returnValue, error, callback) {\n  if (opts.retry === false) {\n    returnValue.emit('error', error);\n    returnValue.removeAllListeners();\n    return;\n  }\n  if (typeof opts.back_off_function !== 'function') {\n    opts.back_off_function = defaultBackOff;\n  }\n  returnValue.emit('requestError', error);\n  if (returnValue.state === 'active' || returnValue.state === 'pending') {\n    returnValue.emit('paused', error);\n    returnValue.state = 'stopped';\n    var backOffSet = function backoffTimeSet() {\n      opts.current_back_off = STARTING_BACK_OFF;\n    };\n    var removeBackOffSetter = function removeBackOffTimeSet() {\n      returnValue.removeListener('active', backOffSet);\n    };\n    returnValue.once('paused', removeBackOffSetter);\n    returnValue.once('active', backOffSet);\n  }\n\n  opts.current_back_off = opts.current_back_off || STARTING_BACK_OFF;\n  opts.current_back_off = opts.back_off_function(opts.current_back_off);\n  setTimeout(callback, opts.current_back_off);\n}\n\nfunction sortObjectPropertiesByKey(queryParams) {\n  return Object.keys(queryParams).sort(collate).reduce(function (result, key) {\n    result[key] = queryParams[key];\n    return result;\n  }, {});\n}\n\n// Generate a unique id particular to this replication.\n// Not guaranteed to align perfectly with CouchDB's rep ids.\nfunction generateReplicationId(src, target, opts) {\n  var docIds = opts.doc_ids ? opts.doc_ids.sort(collate) : '';\n  var filterFun = opts.filter ? opts.filter.toString() : '';\n  var queryParams = '';\n  var filterViewName =  '';\n\n  if (opts.filter && opts.query_params) {\n    queryParams = JSON.stringify(sortObjectPropertiesByKey(opts.query_params));\n  }\n\n  if (opts.filter && opts.filter === '_view') {\n    filterViewName = opts.view.toString();\n  }\n\n  return PouchPromise$1.all([src.id(), target.id()]).then(function (res) {\n    var queryData = res[0] + res[1] + filterFun + filterViewName +\n      queryParams + docIds;\n    return new PouchPromise$1(function (resolve) {\n      binaryMd5(queryData, resolve);\n    });\n  }).then(function (md5sum) {\n    // can't use straight-up md5 alphabet, because\n    // the char '/' is interpreted as being for attachments,\n    // and + is also not url-safe\n    md5sum = md5sum.replace(/\\//g, '.').replace(/\\+/g, '_');\n    return '_local/' + md5sum;\n  });\n}\n\nfunction replicate(src, target, opts, returnValue, result) {\n  var batches = [];               // list of batches to be processed\n  var currentBatch;               // the batch currently being processed\n  var pendingBatch = {\n    seq: 0,\n    changes: [],\n    docs: []\n  }; // next batch, not yet ready to be processed\n  var writingCheckpoint = false;  // true while checkpoint is being written\n  var changesCompleted = false;   // true when all changes received\n  var replicationCompleted = false; // true when replication has completed\n  var last_seq = 0;\n  var continuous = opts.continuous || opts.live || false;\n  var batch_size = opts.batch_size || 100;\n  var batches_limit = opts.batches_limit || 10;\n  var changesPending = false;     // true while src.changes is running\n  var doc_ids = opts.doc_ids;\n  var repId;\n  var checkpointer;\n  var changedDocs = [];\n  // Like couchdb, every replication gets a unique session id\n  var session = uuid();\n\n  result = result || {\n    ok: true,\n    start_time: new Date(),\n    docs_read: 0,\n    docs_written: 0,\n    doc_write_failures: 0,\n    errors: []\n  };\n\n  var changesOpts = {};\n  returnValue.ready(src, target);\n\n  function initCheckpointer() {\n    if (checkpointer) {\n      return PouchPromise$1.resolve();\n    }\n    return generateReplicationId(src, target, opts).then(function (res) {\n      repId = res;\n      checkpointer = new Checkpointer(src, target, repId, returnValue);\n    });\n  }\n\n  function writeDocs() {\n    changedDocs = [];\n\n    if (currentBatch.docs.length === 0) {\n      return;\n    }\n    var docs = currentBatch.docs;\n    var bulkOpts = {timeout: opts.timeout};\n    return target.bulkDocs({docs: docs, new_edits: false}, bulkOpts).then(function (res) {\n      /* istanbul ignore if */\n      if (returnValue.cancelled) {\n        completeReplication();\n        throw new Error('cancelled');\n      }\n\n      // `res` doesn't include full documents (which live in `docs`), so we create a map of \n      // (id -> error), and check for errors while iterating over `docs`\n      var errorsById = Object.create(null);\n      res.forEach(function (res) {\n        if (res.error) {\n          errorsById[res.id] = res;\n        }\n      });\n\n      var errorsNo = Object.keys(errorsById).length;\n      result.doc_write_failures += errorsNo;\n      result.docs_written += docs.length - errorsNo;\n\n      docs.forEach(function (doc) {\n        var error = errorsById[doc._id];\n        if (error) {\n          result.errors.push(error);\n          if (error.name === 'unauthorized' || error.name === 'forbidden') {\n            returnValue.emit('denied', clone(error));\n          } else {\n            throw error;\n          }\n        } else {\n          changedDocs.push(doc);\n        }\n      });\n\n    }, function (err) {\n      result.doc_write_failures += docs.length;\n      throw err;\n    });\n  }\n\n  function finishBatch() {\n    if (currentBatch.error) {\n      throw new Error('There was a problem getting docs.');\n    }\n    result.last_seq = last_seq = currentBatch.seq;\n    var outResult = clone(result);\n    if (changedDocs.length) {\n      outResult.docs = changedDocs;\n      returnValue.emit('change', outResult);\n    }\n    writingCheckpoint = true;\n    return checkpointer.writeCheckpoint(currentBatch.seq,\n        session).then(function () {\n      writingCheckpoint = false;\n      /* istanbul ignore if */\n      if (returnValue.cancelled) {\n        completeReplication();\n        throw new Error('cancelled');\n      }\n      currentBatch = undefined;\n      getChanges();\n    }).catch(function (err) {\n      onCheckpointError(err);\n      throw err;\n    });\n  }\n\n  function getDiffs() {\n    var diff = {};\n    currentBatch.changes.forEach(function (change) {\n      // Couchbase Sync Gateway emits these, but we can ignore them\n      /* istanbul ignore if */\n      if (change.id === \"_user/\") {\n        return;\n      }\n      diff[change.id] = change.changes.map(function (x) {\n        return x.rev;\n      });\n    });\n    return target.revsDiff(diff).then(function (diffs) {\n      /* istanbul ignore if */\n      if (returnValue.cancelled) {\n        completeReplication();\n        throw new Error('cancelled');\n      }\n      // currentBatch.diffs elements are deleted as the documents are written\n      currentBatch.diffs = diffs;\n    });\n  }\n\n  function getBatchDocs() {\n    return getDocs(src, target, currentBatch.diffs, returnValue).then(function (got) {\n      currentBatch.error = !got.ok;\n      got.docs.forEach(function (doc) {\n        delete currentBatch.diffs[doc._id];\n        result.docs_read++;\n        currentBatch.docs.push(doc);\n      });\n    });\n  }\n\n  function startNextBatch() {\n    if (returnValue.cancelled || currentBatch) {\n      return;\n    }\n    if (batches.length === 0) {\n      processPendingBatch(true);\n      return;\n    }\n    currentBatch = batches.shift();\n    getDiffs()\n      .then(getBatchDocs)\n      .then(writeDocs)\n      .then(finishBatch)\n      .then(startNextBatch)\n      .catch(function (err) {\n        abortReplication('batch processing terminated with error', err);\n      });\n  }\n\n\n  function processPendingBatch(immediate) {\n    if (pendingBatch.changes.length === 0) {\n      if (batches.length === 0 && !currentBatch) {\n        if ((continuous && changesOpts.live) || changesCompleted) {\n          returnValue.state = 'pending';\n          returnValue.emit('paused');\n        }\n        if (changesCompleted) {\n          completeReplication();\n        }\n      }\n      return;\n    }\n    if (\n      immediate ||\n      changesCompleted ||\n      pendingBatch.changes.length >= batch_size\n    ) {\n      batches.push(pendingBatch);\n      pendingBatch = {\n        seq: 0,\n        changes: [],\n        docs: []\n      };\n      if (returnValue.state === 'pending' || returnValue.state === 'stopped') {\n        returnValue.state = 'active';\n        returnValue.emit('active');\n      }\n      startNextBatch();\n    }\n  }\n\n\n  function abortReplication(reason, err) {\n    if (replicationCompleted) {\n      return;\n    }\n    if (!err.message) {\n      err.message = reason;\n    }\n    result.ok = false;\n    result.status = 'aborting';\n    batches = [];\n    pendingBatch = {\n      seq: 0,\n      changes: [],\n      docs: []\n    };\n    completeReplication(err);\n  }\n\n\n  function completeReplication(fatalError) {\n    if (replicationCompleted) {\n      return;\n    }\n    /* istanbul ignore if */\n    if (returnValue.cancelled) {\n      result.status = 'cancelled';\n      if (writingCheckpoint) {\n        return;\n      }\n    }\n    result.status = result.status || 'complete';\n    result.end_time = new Date();\n    result.last_seq = last_seq;\n    replicationCompleted = true;\n\n    if (fatalError) {\n      fatalError.result = result;\n\n      if (fatalError.name === 'unauthorized' || fatalError.name === 'forbidden') {\n        returnValue.emit('error', fatalError);\n        returnValue.removeAllListeners();\n      } else {\n        backOff(opts, returnValue, fatalError, function () {\n          replicate(src, target, opts, returnValue);\n        });\n      }\n    } else {\n      returnValue.emit('complete', result);\n      returnValue.removeAllListeners();\n    }\n  }\n\n\n  function onChange(change) {\n    /* istanbul ignore if */\n    if (returnValue.cancelled) {\n      return completeReplication();\n    }\n    var filter = filterChange(opts)(change);\n    if (!filter) {\n      return;\n    }\n    pendingBatch.seq = change.seq;\n    pendingBatch.changes.push(change);\n    processPendingBatch(batches.length === 0 && changesOpts.live);\n  }\n\n\n  function onChangesComplete(changes) {\n    changesPending = false;\n    /* istanbul ignore if */\n    if (returnValue.cancelled) {\n      return completeReplication();\n    }\n\n    // if no results were returned then we're done,\n    // else fetch more\n    if (changes.results.length > 0) {\n      changesOpts.since = changes.last_seq;\n      getChanges();\n      processPendingBatch(true);\n    } else {\n\n      var complete = function () {\n        if (continuous) {\n          changesOpts.live = true;\n          getChanges();\n        } else {\n          changesCompleted = true;\n        }\n        processPendingBatch(true);\n      };\n\n      // update the checkpoint so we start from the right seq next time\n      if (!currentBatch && changes.results.length === 0) {\n        writingCheckpoint = true;\n        checkpointer.writeCheckpoint(changes.last_seq,\n            session).then(function () {\n          writingCheckpoint = false;\n          result.last_seq = last_seq = changes.last_seq;\n          complete();\n        })\n        .catch(onCheckpointError);\n      } else {\n        complete();\n      }\n    }\n  }\n\n\n  function onChangesError(err) {\n    changesPending = false;\n    /* istanbul ignore if */\n    if (returnValue.cancelled) {\n      return completeReplication();\n    }\n    abortReplication('changes rejected', err);\n  }\n\n\n  function getChanges() {\n    if (!(\n      !changesPending &&\n      !changesCompleted &&\n      batches.length < batches_limit\n      )) {\n      return;\n    }\n    changesPending = true;\n    function abortChanges() {\n      changes.cancel();\n    }\n    function removeListener() {\n      returnValue.removeListener('cancel', abortChanges);\n    }\n\n    if (returnValue._changes) { // remove old changes() and listeners\n      returnValue.removeListener('cancel', returnValue._abortChanges);\n      returnValue._changes.cancel();\n    }\n    returnValue.once('cancel', abortChanges);\n\n    var changes = src.changes(changesOpts)\n      .on('change', onChange);\n    changes.then(removeListener, removeListener);\n    changes.then(onChangesComplete)\n      .catch(onChangesError);\n\n    if (opts.retry) {\n      // save for later so we can cancel if necessary\n      returnValue._changes = changes;\n      returnValue._abortChanges = abortChanges;\n    }\n  }\n\n\n  function startChanges() {\n    initCheckpointer().then(function () {\n      /* istanbul ignore if */\n      if (returnValue.cancelled) {\n        completeReplication();\n        return;\n      }\n      return checkpointer.getCheckpoint().then(function (checkpoint) {\n        last_seq = checkpoint;\n        changesOpts = {\n          since: last_seq,\n          limit: batch_size,\n          batch_size: batch_size,\n          style: 'all_docs',\n          doc_ids: doc_ids,\n          return_docs: true // required so we know when we're done\n        };\n        if (opts.filter) {\n          if (typeof opts.filter !== 'string') {\n            // required for the client-side filter in onChange\n            changesOpts.include_docs = true;\n          } else { // ddoc filter\n            changesOpts.filter = opts.filter;\n          }\n        }\n        if ('heartbeat' in opts) {\n          changesOpts.heartbeat = opts.heartbeat;\n        }\n        if ('timeout' in opts) {\n          changesOpts.timeout = opts.timeout;\n        }\n        if (opts.query_params) {\n          changesOpts.query_params = opts.query_params;\n        }\n        if (opts.view) {\n          changesOpts.view = opts.view;\n        }\n        getChanges();\n      });\n    }).catch(function (err) {\n      abortReplication('getCheckpoint rejected with ', err);\n    });\n  }\n\n  /* istanbul ignore next */\n  function onCheckpointError(err) {\n    writingCheckpoint = false;\n    abortReplication('writeCheckpoint completed with error', err);\n  }\n\n  /* istanbul ignore if */\n  if (returnValue.cancelled) { // cancelled immediately\n    completeReplication();\n    return;\n  }\n\n  if (!returnValue._addedListeners) {\n    returnValue.once('cancel', completeReplication);\n\n    if (typeof opts.complete === 'function') {\n      returnValue.once('error', opts.complete);\n      returnValue.once('complete', function (result) {\n        opts.complete(null, result);\n      });\n    }\n    returnValue._addedListeners = true;\n  }\n\n  if (typeof opts.since === 'undefined') {\n    startChanges();\n  } else {\n    initCheckpointer().then(function () {\n      writingCheckpoint = true;\n      return checkpointer.writeCheckpoint(opts.since, session);\n    }).then(function () {\n      writingCheckpoint = false;\n      /* istanbul ignore if */\n      if (returnValue.cancelled) {\n        completeReplication();\n        return;\n      }\n      last_seq = opts.since;\n      startChanges();\n    }).catch(onCheckpointError);\n  }\n}\n\n// We create a basic promise so the caller can cancel the replication possibly\n// before we have actually started listening to changes etc\ninherits(Replication, events.EventEmitter);\nfunction Replication() {\n  events.EventEmitter.call(this);\n  this.cancelled = false;\n  this.state = 'pending';\n  var self = this;\n  var promise = new PouchPromise$1(function (fulfill, reject) {\n    self.once('complete', fulfill);\n    self.once('error', reject);\n  });\n  self.then = function (resolve, reject) {\n    return promise.then(resolve, reject);\n  };\n  self.catch = function (reject) {\n    return promise.catch(reject);\n  };\n  // As we allow error handling via \"error\" event as well,\n  // put a stub in here so that rejecting never throws UnhandledError.\n  self.catch(function () {});\n}\n\nReplication.prototype.cancel = function () {\n  this.cancelled = true;\n  this.state = 'cancelled';\n  this.emit('cancel');\n};\n\nReplication.prototype.ready = function (src, target) {\n  var self = this;\n  if (self._readyCalled) {\n    return;\n  }\n  self._readyCalled = true;\n\n  function onDestroy() {\n    self.cancel();\n  }\n  src.once('destroyed', onDestroy);\n  target.once('destroyed', onDestroy);\n  function cleanup() {\n    src.removeListener('destroyed', onDestroy);\n    target.removeListener('destroyed', onDestroy);\n  }\n  self.once('complete', cleanup);\n};\n\nfunction toPouch(db, opts) {\n  var PouchConstructor = opts.PouchConstructor;\n  if (typeof db === 'string') {\n    return new PouchConstructor(db, opts);\n  } else {\n    return db;\n  }\n}\n\nfunction replicateWrapper(src, target, opts, callback) {\n\n  if (typeof opts === 'function') {\n    callback = opts;\n    opts = {};\n  }\n  if (typeof opts === 'undefined') {\n    opts = {};\n  }\n\n  if (opts.doc_ids && !Array.isArray(opts.doc_ids)) {\n    throw createError(BAD_REQUEST,\n                       \"`doc_ids` filter parameter is not a list.\");\n  }\n\n  opts.complete = callback;\n  opts = clone(opts);\n  opts.continuous = opts.continuous || opts.live;\n  opts.retry = ('retry' in opts) ? opts.retry : false;\n  /*jshint validthis:true */\n  opts.PouchConstructor = opts.PouchConstructor || this;\n  var replicateRet = new Replication(opts);\n  var srcPouch = toPouch(src, opts);\n  var targetPouch = toPouch(target, opts);\n  replicate(srcPouch, targetPouch, opts, replicateRet);\n  return replicateRet;\n}\n\ninherits(Sync, events.EventEmitter);\nfunction sync$1(src, target, opts, callback) {\n  if (typeof opts === 'function') {\n    callback = opts;\n    opts = {};\n  }\n  if (typeof opts === 'undefined') {\n    opts = {};\n  }\n  opts = clone(opts);\n  /*jshint validthis:true */\n  opts.PouchConstructor = opts.PouchConstructor || this;\n  src = toPouch(src, opts);\n  target = toPouch(target, opts);\n  return new Sync(src, target, opts, callback);\n}\n\nfunction Sync(src, target, opts, callback) {\n  var self = this;\n  this.canceled = false;\n\n  var optsPush = opts.push ? assign$1({}, opts, opts.push) : opts;\n  var optsPull = opts.pull ? assign$1({}, opts, opts.pull) : opts;\n\n  this.push = replicateWrapper(src, target, optsPush);\n  this.pull = replicateWrapper(target, src, optsPull);\n\n  this.pushPaused = true;\n  this.pullPaused = true;\n\n  function pullChange(change) {\n    self.emit('change', {\n      direction: 'pull',\n      change: change\n    });\n  }\n  function pushChange(change) {\n    self.emit('change', {\n      direction: 'push',\n      change: change\n    });\n  }\n  function pushDenied(doc) {\n    self.emit('denied', {\n      direction: 'push',\n      doc: doc\n    });\n  }\n  function pullDenied(doc) {\n    self.emit('denied', {\n      direction: 'pull',\n      doc: doc\n    });\n  }\n  function pushPaused() {\n    self.pushPaused = true;\n    /* istanbul ignore if */\n    if (self.pullPaused) {\n      self.emit('paused');\n    }\n  }\n  function pullPaused() {\n    self.pullPaused = true;\n    /* istanbul ignore if */\n    if (self.pushPaused) {\n      self.emit('paused');\n    }\n  }\n  function pushActive() {\n    self.pushPaused = false;\n    /* istanbul ignore if */\n    if (self.pullPaused) {\n      self.emit('active', {\n        direction: 'push'\n      });\n    }\n  }\n  function pullActive() {\n    self.pullPaused = false;\n    /* istanbul ignore if */\n    if (self.pushPaused) {\n      self.emit('active', {\n        direction: 'pull'\n      });\n    }\n  }\n\n  var removed = {};\n\n  function removeAll(type) { // type is 'push' or 'pull'\n    return function (event, func) {\n      var isChange = event === 'change' &&\n        (func === pullChange || func === pushChange);\n      var isDenied = event === 'denied' &&\n        (func === pullDenied || func === pushDenied);\n      var isPaused = event === 'paused' &&\n        (func === pullPaused || func === pushPaused);\n      var isActive = event === 'active' &&\n        (func === pullActive || func === pushActive);\n\n      if (isChange || isDenied || isPaused || isActive) {\n        if (!(event in removed)) {\n          removed[event] = {};\n        }\n        removed[event][type] = true;\n        if (Object.keys(removed[event]).length === 2) {\n          // both push and pull have asked to be removed\n          self.removeAllListeners(event);\n        }\n      }\n    };\n  }\n\n  if (opts.live) {\n    this.push.on('complete', self.pull.cancel.bind(self.pull));\n    this.pull.on('complete', self.push.cancel.bind(self.push));\n  }\n\n  function addOneListener(ee, event, listener) {\n    if (ee.listeners(event).indexOf(listener) == -1) {\n      ee.on(event, listener);\n    }\n  }\n\n  this.on('newListener', function (event) {\n    if (event === 'change') {\n      addOneListener(self.pull, 'change', pullChange);\n      addOneListener(self.push, 'change', pushChange);\n    } else if (event === 'denied') {\n      addOneListener(self.pull, 'denied', pullDenied);\n      addOneListener(self.push, 'denied', pushDenied);\n    } else if (event === 'active') {\n      addOneListener(self.pull, 'active', pullActive);\n      addOneListener(self.push, 'active', pushActive);\n    } else if (event === 'paused') {\n      addOneListener(self.pull, 'paused', pullPaused);\n      addOneListener(self.push, 'paused', pushPaused);\n    }\n  });\n\n  this.on('removeListener', function (event) {\n    if (event === 'change') {\n      self.pull.removeListener('change', pullChange);\n      self.push.removeListener('change', pushChange);\n    } else if (event === 'denied') {\n      self.pull.removeListener('denied', pullDenied);\n      self.push.removeListener('denied', pushDenied);\n    } else if (event === 'active') {\n      self.pull.removeListener('active', pullActive);\n      self.push.removeListener('active', pushActive);\n    } else if (event === 'paused') {\n      self.pull.removeListener('paused', pullPaused);\n      self.push.removeListener('paused', pushPaused);\n    }\n  });\n\n  this.pull.on('removeListener', removeAll('pull'));\n  this.push.on('removeListener', removeAll('push'));\n\n  var promise = PouchPromise$1.all([\n    this.push,\n    this.pull\n  ]).then(function (resp) {\n    var out = {\n      push: resp[0],\n      pull: resp[1]\n    };\n    self.emit('complete', out);\n    if (callback) {\n      callback(null, out);\n    }\n    self.removeAllListeners();\n    return out;\n  }, function (err) {\n    self.cancel();\n    if (callback) {\n      // if there's a callback, then the callback can receive\n      // the error event\n      callback(err);\n    } else {\n      // if there's no callback, then we're safe to emit an error\n      // event, which would otherwise throw an unhandled error\n      // due to 'error' being a special event in EventEmitters\n      self.emit('error', err);\n    }\n    self.removeAllListeners();\n    if (callback) {\n      // no sense throwing if we're already emitting an 'error' event\n      throw err;\n    }\n  });\n\n  this.then = function (success, err) {\n    return promise.then(success, err);\n  };\n\n  this.catch = function (err) {\n    return promise.catch(err);\n  };\n}\n\nSync.prototype.cancel = function () {\n  if (!this.canceled) {\n    this.canceled = true;\n    this.push.cancel();\n    this.pull.cancel();\n  }\n};\n\nfunction replication(PouchDB) {\n  PouchDB.replicate = replicateWrapper;\n  PouchDB.sync = sync$1;\n\n  Object.defineProperty(PouchDB.prototype, 'replicate', {\n    get: function () {\n      var self = this;\n      return {\n        from: function (other, opts, callback) {\n          return self.constructor.replicate(other, self, opts, callback);\n        },\n        to: function (other, opts, callback) {\n          return self.constructor.replicate(self, other, opts, callback);\n        }\n      };\n    }\n  });\n\n  PouchDB.prototype.sync = function (dbName, opts, callback) {\n    return this.constructor.sync(this, dbName, opts, callback);\n  };\n}\n\nPouchDB$5.plugin(IDBPouch)\n  .plugin(WebSqlPouch)\n  .plugin(HttpPouch$1)\n  .plugin(mapreduce)\n  .plugin(replication);\n\n// Pull from src because pouchdb-node/pouchdb-browser themselves\n// are aggressively optimized and jsnext:main would normally give us this\n// aggressive bundle.\n\nmodule.exports = PouchDB$5;\n\n\n\n//////////////////\n// WEBPACK FOOTER\n// ./~/pouchdb/lib/index-browser.js\n// module id = 90\n// module chunks = 0","'use strict';\nvar immediate = require('immediate');\n\n/* istanbul ignore next */\nfunction INTERNAL() {}\n\nvar handlers = {};\n\nvar REJECTED = ['REJECTED'];\nvar FULFILLED = ['FULFILLED'];\nvar PENDING = ['PENDING'];\n\nmodule.exports = Promise;\n\nfunction Promise(resolver) {\n  if (typeof resolver !== 'function') {\n    throw new TypeError('resolver must be a function');\n  }\n  this.state = PENDING;\n  this.queue = [];\n  this.outcome = void 0;\n  if (resolver !== INTERNAL) {\n    safelyResolveThenable(this, resolver);\n  }\n}\n\nPromise.prototype[\"catch\"] = function (onRejected) {\n  return this.then(null, onRejected);\n};\nPromise.prototype.then = function (onFulfilled, onRejected) {\n  if (typeof onFulfilled !== 'function' && this.state === FULFILLED ||\n    typeof onRejected !== 'function' && this.state === REJECTED) {\n    return this;\n  }\n  var promise = new this.constructor(INTERNAL);\n  if (this.state !== PENDING) {\n    var resolver = this.state === FULFILLED ? onFulfilled : onRejected;\n    unwrap(promise, resolver, this.outcome);\n  } else {\n    this.queue.push(new QueueItem(promise, onFulfilled, onRejected));\n  }\n\n  return promise;\n};\nfunction QueueItem(promise, onFulfilled, onRejected) {\n  this.promise = promise;\n  if (typeof onFulfilled === 'function') {\n    this.onFulfilled = onFulfilled;\n    this.callFulfilled = this.otherCallFulfilled;\n  }\n  if (typeof onRejected === 'function') {\n    this.onRejected = onRejected;\n    this.callRejected = this.otherCallRejected;\n  }\n}\nQueueItem.prototype.callFulfilled = function (value) {\n  handlers.resolve(this.promise, value);\n};\nQueueItem.prototype.otherCallFulfilled = function (value) {\n  unwrap(this.promise, this.onFulfilled, value);\n};\nQueueItem.prototype.callRejected = function (value) {\n  handlers.reject(this.promise, value);\n};\nQueueItem.prototype.otherCallRejected = function (value) {\n  unwrap(this.promise, this.onRejected, value);\n};\n\nfunction unwrap(promise, func, value) {\n  immediate(function () {\n    var returnValue;\n    try {\n      returnValue = func(value);\n    } catch (e) {\n      return handlers.reject(promise, e);\n    }\n    if (returnValue === promise) {\n      handlers.reject(promise, new TypeError('Cannot resolve promise with itself'));\n    } else {\n      handlers.resolve(promise, returnValue);\n    }\n  });\n}\n\nhandlers.resolve = function (self, value) {\n  var result = tryCatch(getThen, value);\n  if (result.status === 'error') {\n    return handlers.reject(self, result.value);\n  }\n  var thenable = result.value;\n\n  if (thenable) {\n    safelyResolveThenable(self, thenable);\n  } else {\n    self.state = FULFILLED;\n    self.outcome = value;\n    var i = -1;\n    var len = self.queue.length;\n    while (++i < len) {\n      self.queue[i].callFulfilled(value);\n    }\n  }\n  return self;\n};\nhandlers.reject = function (self, error) {\n  self.state = REJECTED;\n  self.outcome = error;\n  var i = -1;\n  var len = self.queue.length;\n  while (++i < len) {\n    self.queue[i].callRejected(error);\n  }\n  return self;\n};\n\nfunction getThen(obj) {\n  // Make sure we only access the accessor once as required by the spec\n  var then = obj && obj.then;\n  if (obj && typeof obj === 'object' && typeof then === 'function') {\n    return function appyThen() {\n      then.apply(obj, arguments);\n    };\n  }\n}\n\nfunction safelyResolveThenable(self, thenable) {\n  // Either fulfill, reject or reject with error\n  var called = false;\n  function onError(value) {\n    if (called) {\n      return;\n    }\n    called = true;\n    handlers.reject(self, value);\n  }\n\n  function onSuccess(value) {\n    if (called) {\n      return;\n    }\n    called = true;\n    handlers.resolve(self, value);\n  }\n\n  function tryToUnwrap() {\n    thenable(onSuccess, onError);\n  }\n\n  var result = tryCatch(tryToUnwrap);\n  if (result.status === 'error') {\n    onError(result.value);\n  }\n}\n\nfunction tryCatch(func, value) {\n  var out = {};\n  try {\n    out.value = func(value);\n    out.status = 'success';\n  } catch (e) {\n    out.status = 'error';\n    out.value = e;\n  }\n  return out;\n}\n\nPromise.resolve = resolve;\nfunction resolve(value) {\n  if (value instanceof this) {\n    return value;\n  }\n  return handlers.resolve(new this(INTERNAL), value);\n}\n\nPromise.reject = reject;\nfunction reject(reason) {\n  var promise = new this(INTERNAL);\n  return handlers.reject(promise, reason);\n}\n\nPromise.all = all;\nfunction all(iterable) {\n  var self = this;\n  if (Object.prototype.toString.call(iterable) !== '[object Array]') {\n    return this.reject(new TypeError('must be an array'));\n  }\n\n  var len = iterable.length;\n  var called = false;\n  if (!len) {\n    return this.resolve([]);\n  }\n\n  var values = new Array(len);\n  var resolved = 0;\n  var i = -1;\n  var promise = new this(INTERNAL);\n\n  while (++i < len) {\n    allResolver(iterable[i], i);\n  }\n  return promise;\n  function allResolver(value, i) {\n    self.resolve(value).then(resolveFromAll, function (error) {\n      if (!called) {\n        called = true;\n        handlers.reject(promise, error);\n      }\n    });\n    function resolveFromAll(outValue) {\n      values[i] = outValue;\n      if (++resolved === len && !called) {\n        called = true;\n        handlers.resolve(promise, values);\n      }\n    }\n  }\n}\n\nPromise.race = race;\nfunction race(iterable) {\n  var self = this;\n  if (Object.prototype.toString.call(iterable) !== '[object Array]') {\n    return this.reject(new TypeError('must be an array'));\n  }\n\n  var len = iterable.length;\n  var called = false;\n  if (!len) {\n    return this.resolve([]);\n  }\n\n  var i = -1;\n  var promise = new this(INTERNAL);\n\n  while (++i < len) {\n    resolver(iterable[i]);\n  }\n  return promise;\n  function resolver(value) {\n    self.resolve(value).then(function (response) {\n      if (!called) {\n        called = true;\n        handlers.resolve(promise, response);\n      }\n    }, function (error) {\n      if (!called) {\n        called = true;\n        handlers.reject(promise, error);\n      }\n    });\n  }\n}\n\n\n\n//////////////////\n// WEBPACK FOOTER\n// ./~/pouchdb/~/lie/lib/browser.js\n// module id = 91\n// module chunks = 0","// This method of obtaining a reference to the global object needs to be\n// kept identical to the way it is obtained in runtime.js\nvar g =\n  typeof global === \"object\" ? global :\n  typeof window === \"object\" ? window :\n  typeof self === \"object\" ? self : this;\n\n// Use `getOwnPropertyNames` because not all browsers support calling\n// `hasOwnProperty` on the global `self` object in a worker. See #183.\nvar hadRuntime = g.regeneratorRuntime &&\n  Object.getOwnPropertyNames(g).indexOf(\"regeneratorRuntime\") >= 0;\n\n// Save the old regeneratorRuntime in case it needs to be restored later.\nvar oldRuntime = hadRuntime && g.regeneratorRuntime;\n\n// Force reevalutation of runtime.js.\ng.regeneratorRuntime = undefined;\n\nmodule.exports = require(\"./runtime\");\n\nif (hadRuntime) {\n  // Restore the original runtime.\n  g.regeneratorRuntime = oldRuntime;\n} else {\n  // Remove the global property added by runtime.js.\n  try {\n    delete g.regeneratorRuntime;\n  } catch(e) {\n    g.regeneratorRuntime = undefined;\n  }\n}\n\n\n\n//////////////////\n// WEBPACK FOOTER\n// ./~/regenerator-runtime/runtime-module.js\n// module id = 92\n// module chunks = 0","/**\n * Copyright (c) 2014, Facebook, Inc.\n * All rights reserved.\n *\n * This source code is licensed under the BSD-style license found in the\n * https://raw.github.com/facebook/regenerator/master/LICENSE file. An\n * additional grant of patent rights can be found in the PATENTS file in\n * the same directory.\n */\n\n!(function(global) {\n  \"use strict\";\n\n  var Op = Object.prototype;\n  var hasOwn = Op.hasOwnProperty;\n  var undefined; // More compressible than void 0.\n  var $Symbol = typeof Symbol === \"function\" ? Symbol : {};\n  var iteratorSymbol = $Symbol.iterator || \"@@iterator\";\n  var toStringTagSymbol = $Symbol.toStringTag || \"@@toStringTag\";\n\n  var inModule = typeof module === \"object\";\n  var runtime = global.regeneratorRuntime;\n  if (runtime) {\n    if (inModule) {\n      // If regeneratorRuntime is defined globally and we're in a module,\n      // make the exports object identical to regeneratorRuntime.\n      module.exports = runtime;\n    }\n    // Don't bother evaluating the rest of this file if the runtime was\n    // already defined globally.\n    return;\n  }\n\n  // Define the runtime globally (as expected by generated code) as either\n  // module.exports (if we're in a module) or a new, empty object.\n  runtime = global.regeneratorRuntime = inModule ? module.exports : {};\n\n  function wrap(innerFn, outerFn, self, tryLocsList) {\n    // If outerFn provided and outerFn.prototype is a Generator, then outerFn.prototype instanceof Generator.\n    var protoGenerator = outerFn && outerFn.prototype instanceof Generator ? outerFn : Generator;\n    var generator = Object.create(protoGenerator.prototype);\n    var context = new Context(tryLocsList || []);\n\n    // The ._invoke method unifies the implementations of the .next,\n    // .throw, and .return methods.\n    generator._invoke = makeInvokeMethod(innerFn, self, context);\n\n    return generator;\n  }\n  runtime.wrap = wrap;\n\n  // Try/catch helper to minimize deoptimizations. Returns a completion\n  // record like context.tryEntries[i].completion. This interface could\n  // have been (and was previously) designed to take a closure to be\n  // invoked without arguments, but in all the cases we care about we\n  // already have an existing method we want to call, so there's no need\n  // to create a new function object. We can even get away with assuming\n  // the method takes exactly one argument, since that happens to be true\n  // in every case, so we don't have to touch the arguments object. The\n  // only additional allocation required is the completion record, which\n  // has a stable shape and so hopefully should be cheap to allocate.\n  function tryCatch(fn, obj, arg) {\n    try {\n      return { type: \"normal\", arg: fn.call(obj, arg) };\n    } catch (err) {\n      return { type: \"throw\", arg: err };\n    }\n  }\n\n  var GenStateSuspendedStart = \"suspendedStart\";\n  var GenStateSuspendedYield = \"suspendedYield\";\n  var GenStateExecuting = \"executing\";\n  var GenStateCompleted = \"completed\";\n\n  // Returning this object from the innerFn has the same effect as\n  // breaking out of the dispatch switch statement.\n  var ContinueSentinel = {};\n\n  // Dummy constructor functions that we use as the .constructor and\n  // .constructor.prototype properties for functions that return Generator\n  // objects. For full spec compliance, you may wish to configure your\n  // minifier not to mangle the names of these two functions.\n  function Generator() {}\n  function GeneratorFunction() {}\n  function GeneratorFunctionPrototype() {}\n\n  // This is a polyfill for %IteratorPrototype% for environments that\n  // don't natively support it.\n  var IteratorPrototype = {};\n  IteratorPrototype[iteratorSymbol] = function () {\n    return this;\n  };\n\n  var getProto = Object.getPrototypeOf;\n  var NativeIteratorPrototype = getProto && getProto(getProto(values([])));\n  if (NativeIteratorPrototype &&\n      NativeIteratorPrototype !== Op &&\n      hasOwn.call(NativeIteratorPrototype, iteratorSymbol)) {\n    // This environment has a native %IteratorPrototype%; use it instead\n    // of the polyfill.\n    IteratorPrototype = NativeIteratorPrototype;\n  }\n\n  var Gp = GeneratorFunctionPrototype.prototype =\n    Generator.prototype = Object.create(IteratorPrototype);\n  GeneratorFunction.prototype = Gp.constructor = GeneratorFunctionPrototype;\n  GeneratorFunctionPrototype.constructor = GeneratorFunction;\n  GeneratorFunctionPrototype[toStringTagSymbol] =\n    GeneratorFunction.displayName = \"GeneratorFunction\";\n\n  // Helper for defining the .next, .throw, and .return methods of the\n  // Iterator interface in terms of a single ._invoke method.\n  function defineIteratorMethods(prototype) {\n    [\"next\", \"throw\", \"return\"].forEach(function(method) {\n      prototype[method] = function(arg) {\n        return this._invoke(method, arg);\n      };\n    });\n  }\n\n  runtime.isGeneratorFunction = function(genFun) {\n    var ctor = typeof genFun === \"function\" && genFun.constructor;\n    return ctor\n      ? ctor === GeneratorFunction ||\n        // For the native GeneratorFunction constructor, the best we can\n        // do is to check its .name property.\n        (ctor.displayName || ctor.name) === \"GeneratorFunction\"\n      : false;\n  };\n\n  runtime.mark = function(genFun) {\n    if (Object.setPrototypeOf) {\n      Object.setPrototypeOf(genFun, GeneratorFunctionPrototype);\n    } else {\n      genFun.__proto__ = GeneratorFunctionPrototype;\n      if (!(toStringTagSymbol in genFun)) {\n        genFun[toStringTagSymbol] = \"GeneratorFunction\";\n      }\n    }\n    genFun.prototype = Object.create(Gp);\n    return genFun;\n  };\n\n  // Within the body of any async function, `await x` is transformed to\n  // `yield regeneratorRuntime.awrap(x)`, so that the runtime can test\n  // `hasOwn.call(value, \"__await\")` to determine if the yielded value is\n  // meant to be awaited.\n  runtime.awrap = function(arg) {\n    return { __await: arg };\n  };\n\n  function AsyncIterator(generator) {\n    function invoke(method, arg, resolve, reject) {\n      var record = tryCatch(generator[method], generator, arg);\n      if (record.type === \"throw\") {\n        reject(record.arg);\n      } else {\n        var result = record.arg;\n        var value = result.value;\n        if (value &&\n            typeof value === \"object\" &&\n            hasOwn.call(value, \"__await\")) {\n          return Promise.resolve(value.__await).then(function(value) {\n            invoke(\"next\", value, resolve, reject);\n          }, function(err) {\n            invoke(\"throw\", err, resolve, reject);\n          });\n        }\n\n        return Promise.resolve(value).then(function(unwrapped) {\n          // When a yielded Promise is resolved, its final value becomes\n          // the .value of the Promise<{value,done}> result for the\n          // current iteration. If the Promise is rejected, however, the\n          // result for this iteration will be rejected with the same\n          // reason. Note that rejections of yielded Promises are not\n          // thrown back into the generator function, as is the case\n          // when an awaited Promise is rejected. This difference in\n          // behavior between yield and await is important, because it\n          // allows the consumer to decide what to do with the yielded\n          // rejection (swallow it and continue, manually .throw it back\n          // into the generator, abandon iteration, whatever). With\n          // await, by contrast, there is no opportunity to examine the\n          // rejection reason outside the generator function, so the\n          // only option is to throw it from the await expression, and\n          // let the generator function handle the exception.\n          result.value = unwrapped;\n          resolve(result);\n        }, reject);\n      }\n    }\n\n    if (typeof process === \"object\" && process.domain) {\n      invoke = process.domain.bind(invoke);\n    }\n\n    var previousPromise;\n\n    function enqueue(method, arg) {\n      function callInvokeWithMethodAndArg() {\n        return new Promise(function(resolve, reject) {\n          invoke(method, arg, resolve, reject);\n        });\n      }\n\n      return previousPromise =\n        // If enqueue has been called before, then we want to wait until\n        // all previous Promises have been resolved before calling invoke,\n        // so that results are always delivered in the correct order. If\n        // enqueue has not been called before, then it is important to\n        // call invoke immediately, without waiting on a callback to fire,\n        // so that the async generator function has the opportunity to do\n        // any necessary setup in a predictable way. This predictability\n        // is why the Promise constructor synchronously invokes its\n        // executor callback, and why async functions synchronously\n        // execute code before the first await. Since we implement simple\n        // async functions in terms of async generators, it is especially\n        // important to get this right, even though it requires care.\n        previousPromise ? previousPromise.then(\n          callInvokeWithMethodAndArg,\n          // Avoid propagating failures to Promises returned by later\n          // invocations of the iterator.\n          callInvokeWithMethodAndArg\n        ) : callInvokeWithMethodAndArg();\n    }\n\n    // Define the unified helper method that is used to implement .next,\n    // .throw, and .return (see defineIteratorMethods).\n    this._invoke = enqueue;\n  }\n\n  defineIteratorMethods(AsyncIterator.prototype);\n  runtime.AsyncIterator = AsyncIterator;\n\n  // Note that simple async functions are implemented on top of\n  // AsyncIterator objects; they just return a Promise for the value of\n  // the final result produced by the iterator.\n  runtime.async = function(innerFn, outerFn, self, tryLocsList) {\n    var iter = new AsyncIterator(\n      wrap(innerFn, outerFn, self, tryLocsList)\n    );\n\n    return runtime.isGeneratorFunction(outerFn)\n      ? iter // If outerFn is a generator, return the full iterator.\n      : iter.next().then(function(result) {\n          return result.done ? result.value : iter.next();\n        });\n  };\n\n  function makeInvokeMethod(innerFn, self, context) {\n    var state = GenStateSuspendedStart;\n\n    return function invoke(method, arg) {\n      if (state === GenStateExecuting) {\n        throw new Error(\"Generator is already running\");\n      }\n\n      if (state === GenStateCompleted) {\n        if (method === \"throw\") {\n          throw arg;\n        }\n\n        // Be forgiving, per 25.3.3.3.3 of the spec:\n        // https://people.mozilla.org/~jorendorff/es6-draft.html#sec-generatorresume\n        return doneResult();\n      }\n\n      context.method = method;\n      context.arg = arg;\n\n      while (true) {\n        var delegate = context.delegate;\n        if (delegate) {\n          var delegateResult = maybeInvokeDelegate(delegate, context);\n          if (delegateResult) {\n            if (delegateResult === ContinueSentinel) continue;\n            return delegateResult;\n          }\n        }\n\n        if (context.method === \"next\") {\n          // Setting context._sent for legacy support of Babel's\n          // function.sent implementation.\n          context.sent = context._sent = context.arg;\n\n        } else if (context.method === \"throw\") {\n          if (state === GenStateSuspendedStart) {\n            state = GenStateCompleted;\n            throw context.arg;\n          }\n\n          context.dispatchException(context.arg);\n\n        } else if (context.method === \"return\") {\n          context.abrupt(\"return\", context.arg);\n        }\n\n        state = GenStateExecuting;\n\n        var record = tryCatch(innerFn, self, context);\n        if (record.type === \"normal\") {\n          // If an exception is thrown from innerFn, we leave state ===\n          // GenStateExecuting and loop back for another invocation.\n          state = context.done\n            ? GenStateCompleted\n            : GenStateSuspendedYield;\n\n          if (record.arg === ContinueSentinel) {\n            continue;\n          }\n\n          return {\n            value: record.arg,\n            done: context.done\n          };\n\n        } else if (record.type === \"throw\") {\n          state = GenStateCompleted;\n          // Dispatch the exception by looping back around to the\n          // context.dispatchException(context.arg) call above.\n          context.method = \"throw\";\n          context.arg = record.arg;\n        }\n      }\n    };\n  }\n\n  // Call delegate.iterator[context.method](context.arg) and handle the\n  // result, either by returning a { value, done } result from the\n  // delegate iterator, or by modifying context.method and context.arg,\n  // setting context.delegate to null, and returning the ContinueSentinel.\n  function maybeInvokeDelegate(delegate, context) {\n    var method = delegate.iterator[context.method];\n    if (method === undefined) {\n      // A .throw or .return when the delegate iterator has no .throw\n      // method always terminates the yield* loop.\n      context.delegate = null;\n\n      if (context.method === \"throw\") {\n        if (delegate.iterator.return) {\n          // If the delegate iterator has a return method, give it a\n          // chance to clean up.\n          context.method = \"return\";\n          context.arg = undefined;\n          maybeInvokeDelegate(delegate, context);\n\n          if (context.method === \"throw\") {\n            // If maybeInvokeDelegate(context) changed context.method from\n            // \"return\" to \"throw\", let that override the TypeError below.\n            return ContinueSentinel;\n          }\n        }\n\n        context.method = \"throw\";\n        context.arg = new TypeError(\n          \"The iterator does not provide a 'throw' method\");\n      }\n\n      return ContinueSentinel;\n    }\n\n    var record = tryCatch(method, delegate.iterator, context.arg);\n\n    if (record.type === \"throw\") {\n      context.method = \"throw\";\n      context.arg = record.arg;\n      context.delegate = null;\n      return ContinueSentinel;\n    }\n\n    var info = record.arg;\n\n    if (! info) {\n      context.method = \"throw\";\n      context.arg = new TypeError(\"iterator result is not an object\");\n      context.delegate = null;\n      return ContinueSentinel;\n    }\n\n    if (info.done) {\n      // Assign the result of the finished delegate to the temporary\n      // variable specified by delegate.resultName (see delegateYield).\n      context[delegate.resultName] = info.value;\n\n      // Resume execution at the desired location (see delegateYield).\n      context.next = delegate.nextLoc;\n\n      // If context.method was \"throw\" but the delegate handled the\n      // exception, let the outer generator proceed normally. If\n      // context.method was \"next\", forget context.arg since it has been\n      // \"consumed\" by the delegate iterator. If context.method was\n      // \"return\", allow the original .return call to continue in the\n      // outer generator.\n      if (context.method !== \"return\") {\n        context.method = \"next\";\n        context.arg = undefined;\n      }\n\n    } else {\n      // Re-yield the result returned by the delegate method.\n      return info;\n    }\n\n    // The delegate iterator is finished, so forget it and continue with\n    // the outer generator.\n    context.delegate = null;\n    return ContinueSentinel;\n  }\n\n  // Define Generator.prototype.{next,throw,return} in terms of the\n  // unified ._invoke helper method.\n  defineIteratorMethods(Gp);\n\n  Gp[toStringTagSymbol] = \"Generator\";\n\n  Gp.toString = function() {\n    return \"[object Generator]\";\n  };\n\n  function pushTryEntry(locs) {\n    var entry = { tryLoc: locs[0] };\n\n    if (1 in locs) {\n      entry.catchLoc = locs[1];\n    }\n\n    if (2 in locs) {\n      entry.finallyLoc = locs[2];\n      entry.afterLoc = locs[3];\n    }\n\n    this.tryEntries.push(entry);\n  }\n\n  function resetTryEntry(entry) {\n    var record = entry.completion || {};\n    record.type = \"normal\";\n    delete record.arg;\n    entry.completion = record;\n  }\n\n  function Context(tryLocsList) {\n    // The root entry object (effectively a try statement without a catch\n    // or a finally block) gives us a place to store values thrown from\n    // locations where there is no enclosing try statement.\n    this.tryEntries = [{ tryLoc: \"root\" }];\n    tryLocsList.forEach(pushTryEntry, this);\n    this.reset(true);\n  }\n\n  runtime.keys = function(object) {\n    var keys = [];\n    for (var key in object) {\n      keys.push(key);\n    }\n    keys.reverse();\n\n    // Rather than returning an object with a next method, we keep\n    // things simple and return the next function itself.\n    return function next() {\n      while (keys.length) {\n        var key = keys.pop();\n        if (key in object) {\n          next.value = key;\n          next.done = false;\n          return next;\n        }\n      }\n\n      // To avoid creating an additional object, we just hang the .value\n      // and .done properties off the next function object itself. This\n      // also ensures that the minifier will not anonymize the function.\n      next.done = true;\n      return next;\n    };\n  };\n\n  function values(iterable) {\n    if (iterable) {\n      var iteratorMethod = iterable[iteratorSymbol];\n      if (iteratorMethod) {\n        return iteratorMethod.call(iterable);\n      }\n\n      if (typeof iterable.next === \"function\") {\n        return iterable;\n      }\n\n      if (!isNaN(iterable.length)) {\n        var i = -1, next = function next() {\n          while (++i < iterable.length) {\n            if (hasOwn.call(iterable, i)) {\n              next.value = iterable[i];\n              next.done = false;\n              return next;\n            }\n          }\n\n          next.value = undefined;\n          next.done = true;\n\n          return next;\n        };\n\n        return next.next = next;\n      }\n    }\n\n    // Return an iterator with no values.\n    return { next: doneResult };\n  }\n  runtime.values = values;\n\n  function doneResult() {\n    return { value: undefined, done: true };\n  }\n\n  Context.prototype = {\n    constructor: Context,\n\n    reset: function(skipTempReset) {\n      this.prev = 0;\n      this.next = 0;\n      // Resetting context._sent for legacy support of Babel's\n      // function.sent implementation.\n      this.sent = this._sent = undefined;\n      this.done = false;\n      this.delegate = null;\n\n      this.method = \"next\";\n      this.arg = undefined;\n\n      this.tryEntries.forEach(resetTryEntry);\n\n      if (!skipTempReset) {\n        for (var name in this) {\n          // Not sure about the optimal order of these conditions:\n          if (name.charAt(0) === \"t\" &&\n              hasOwn.call(this, name) &&\n              !isNaN(+name.slice(1))) {\n            this[name] = undefined;\n          }\n        }\n      }\n    },\n\n    stop: function() {\n      this.done = true;\n\n      var rootEntry = this.tryEntries[0];\n      var rootRecord = rootEntry.completion;\n      if (rootRecord.type === \"throw\") {\n        throw rootRecord.arg;\n      }\n\n      return this.rval;\n    },\n\n    dispatchException: function(exception) {\n      if (this.done) {\n        throw exception;\n      }\n\n      var context = this;\n      function handle(loc, caught) {\n        record.type = \"throw\";\n        record.arg = exception;\n        context.next = loc;\n\n        if (caught) {\n          // If the dispatched exception was caught by a catch block,\n          // then let that catch block handle the exception normally.\n          context.method = \"next\";\n          context.arg = undefined;\n        }\n\n        return !! caught;\n      }\n\n      for (var i = this.tryEntries.length - 1; i >= 0; --i) {\n        var entry = this.tryEntries[i];\n        var record = entry.completion;\n\n        if (entry.tryLoc === \"root\") {\n          // Exception thrown outside of any try block that could handle\n          // it, so set the completion value of the entire function to\n          // throw the exception.\n          return handle(\"end\");\n        }\n\n        if (entry.tryLoc <= this.prev) {\n          var hasCatch = hasOwn.call(entry, \"catchLoc\");\n          var hasFinally = hasOwn.call(entry, \"finallyLoc\");\n\n          if (hasCatch && hasFinally) {\n            if (this.prev < entry.catchLoc) {\n              return handle(entry.catchLoc, true);\n            } else if (this.prev < entry.finallyLoc) {\n              return handle(entry.finallyLoc);\n            }\n\n          } else if (hasCatch) {\n            if (this.prev < entry.catchLoc) {\n              return handle(entry.catchLoc, true);\n            }\n\n          } else if (hasFinally) {\n            if (this.prev < entry.finallyLoc) {\n              return handle(entry.finallyLoc);\n            }\n\n          } else {\n            throw new Error(\"try statement without catch or finally\");\n          }\n        }\n      }\n    },\n\n    abrupt: function(type, arg) {\n      for (var i = this.tryEntries.length - 1; i >= 0; --i) {\n        var entry = this.tryEntries[i];\n        if (entry.tryLoc <= this.prev &&\n            hasOwn.call(entry, \"finallyLoc\") &&\n            this.prev < entry.finallyLoc) {\n          var finallyEntry = entry;\n          break;\n        }\n      }\n\n      if (finallyEntry &&\n          (type === \"break\" ||\n           type === \"continue\") &&\n          finallyEntry.tryLoc <= arg &&\n          arg <= finallyEntry.finallyLoc) {\n        // Ignore the finally entry if control is not jumping to a\n        // location outside the try/catch block.\n        finallyEntry = null;\n      }\n\n      var record = finallyEntry ? finallyEntry.completion : {};\n      record.type = type;\n      record.arg = arg;\n\n      if (finallyEntry) {\n        this.method = \"next\";\n        this.next = finallyEntry.finallyLoc;\n        return ContinueSentinel;\n      }\n\n      return this.complete(record);\n    },\n\n    complete: function(record, afterLoc) {\n      if (record.type === \"throw\") {\n        throw record.arg;\n      }\n\n      if (record.type === \"break\" ||\n          record.type === \"continue\") {\n        this.next = record.arg;\n      } else if (record.type === \"return\") {\n        this.rval = this.arg = record.arg;\n        this.method = \"return\";\n        this.next = \"end\";\n      } else if (record.type === \"normal\" && afterLoc) {\n        this.next = afterLoc;\n      }\n\n      return ContinueSentinel;\n    },\n\n    finish: function(finallyLoc) {\n      for (var i = this.tryEntries.length - 1; i >= 0; --i) {\n        var entry = this.tryEntries[i];\n        if (entry.finallyLoc === finallyLoc) {\n          this.complete(entry.completion, entry.afterLoc);\n          resetTryEntry(entry);\n          return ContinueSentinel;\n        }\n      }\n    },\n\n    \"catch\": function(tryLoc) {\n      for (var i = this.tryEntries.length - 1; i >= 0; --i) {\n        var entry = this.tryEntries[i];\n        if (entry.tryLoc === tryLoc) {\n          var record = entry.completion;\n          if (record.type === \"throw\") {\n            var thrown = record.arg;\n            resetTryEntry(entry);\n          }\n          return thrown;\n        }\n      }\n\n      // The context.catch method must only be called with a location\n      // argument that corresponds to a known catch block.\n      throw new Error(\"illegal catch attempt\");\n    },\n\n    delegateYield: function(iterable, resultName, nextLoc) {\n      this.delegate = {\n        iterator: values(iterable),\n        resultName: resultName,\n        nextLoc: nextLoc\n      };\n\n      if (this.method === \"next\") {\n        // Deliberately forget the last sent value so that we don't\n        // accidentally pass it on to the delegate.\n        this.arg = undefined;\n      }\n\n      return ContinueSentinel;\n    }\n  };\n})(\n  // Among the various tricks for obtaining a reference to the global\n  // object, this seems to be the most reliable technique that does not\n  // use indirect eval (which violates Content Security Policy).\n  typeof global === \"object\" ? global :\n  typeof window === \"object\" ? window :\n  typeof self === \"object\" ? self : this\n);\n\n\n\n//////////////////\n// WEBPACK FOOTER\n// ./~/regenerator-runtime/runtime.js\n// module id = 93\n// module chunks = 0","// Generated by CoffeeScript 1.9.2\n(function() {\n  var hasProp = {}.hasOwnProperty,\n    slice = [].slice;\n\n  module.exports = function(source, scope) {\n    var key, keys, value, values;\n    keys = [];\n    values = [];\n    for (key in scope) {\n      if (!hasProp.call(scope, key)) continue;\n      value = scope[key];\n      if (key === 'this') {\n        continue;\n      }\n      keys.push(key);\n      values.push(value);\n    }\n    return Function.apply(null, slice.call(keys).concat([source])).apply(scope[\"this\"], values);\n  };\n\n}).call(this);\n\n\n\n//////////////////\n// WEBPACK FOOTER\n// ./~/scope-eval/scope_eval.js\n// module id = 94\n// module chunks = 0","(function (factory) {\n    if (typeof exports === 'object') {\n        // Node/CommonJS\n        module.exports = factory();\n    } else if (typeof define === 'function' && define.amd) {\n        // AMD\n        define(factory);\n    } else {\n        // Browser globals (with support for web workers)\n        var glob;\n\n        try {\n            glob = window;\n        } catch (e) {\n            glob = self;\n        }\n\n        glob.SparkMD5 = factory();\n    }\n}(function (undefined) {\n\n    'use strict';\n\n    /*\n     * Fastest md5 implementation around (JKM md5).\n     * Credits: Joseph Myers\n     *\n     * @see http://www.myersdaily.org/joseph/javascript/md5-text.html\n     * @see http://jsperf.com/md5-shootout/7\n     */\n\n    /* this function is much faster,\n      so if possible we use it. Some IEs\n      are the only ones I know of that\n      need the idiotic second function,\n      generated by an if clause.  */\n    var add32 = function (a, b) {\n        return (a + b) & 0xFFFFFFFF;\n    },\n        hex_chr = ['0', '1', '2', '3', '4', '5', '6', '7', '8', '9', 'a', 'b', 'c', 'd', 'e', 'f'];\n\n\n    function cmn(q, a, b, x, s, t) {\n        a = add32(add32(a, q), add32(x, t));\n        return add32((a << s) | (a >>> (32 - s)), b);\n    }\n\n    function md5cycle(x, k) {\n        var a = x[0],\n            b = x[1],\n            c = x[2],\n            d = x[3];\n\n        a += (b & c | ~b & d) + k[0] - 680876936 | 0;\n        a  = (a << 7 | a >>> 25) + b | 0;\n        d += (a & b | ~a & c) + k[1] - 389564586 | 0;\n        d  = (d << 12 | d >>> 20) + a | 0;\n        c += (d & a | ~d & b) + k[2] + 606105819 | 0;\n        c  = (c << 17 | c >>> 15) + d | 0;\n        b += (c & d | ~c & a) + k[3] - 1044525330 | 0;\n        b  = (b << 22 | b >>> 10) + c | 0;\n        a += (b & c | ~b & d) + k[4] - 176418897 | 0;\n        a  = (a << 7 | a >>> 25) + b | 0;\n        d += (a & b | ~a & c) + k[5] + 1200080426 | 0;\n        d  = (d << 12 | d >>> 20) + a | 0;\n        c += (d & a | ~d & b) + k[6] - 1473231341 | 0;\n        c  = (c << 17 | c >>> 15) + d | 0;\n        b += (c & d | ~c & a) + k[7] - 45705983 | 0;\n        b  = (b << 22 | b >>> 10) + c | 0;\n        a += (b & c | ~b & d) + k[8] + 1770035416 | 0;\n        a  = (a << 7 | a >>> 25) + b | 0;\n        d += (a & b | ~a & c) + k[9] - 1958414417 | 0;\n        d  = (d << 12 | d >>> 20) + a | 0;\n        c += (d & a | ~d & b) + k[10] - 42063 | 0;\n        c  = (c << 17 | c >>> 15) + d | 0;\n        b += (c & d | ~c & a) + k[11] - 1990404162 | 0;\n        b  = (b << 22 | b >>> 10) + c | 0;\n        a += (b & c | ~b & d) + k[12] + 1804603682 | 0;\n        a  = (a << 7 | a >>> 25) + b | 0;\n        d += (a & b | ~a & c) + k[13] - 40341101 | 0;\n        d  = (d << 12 | d >>> 20) + a | 0;\n        c += (d & a | ~d & b) + k[14] - 1502002290 | 0;\n        c  = (c << 17 | c >>> 15) + d | 0;\n        b += (c & d | ~c & a) + k[15] + 1236535329 | 0;\n        b  = (b << 22 | b >>> 10) + c | 0;\n\n        a += (b & d | c & ~d) + k[1] - 165796510 | 0;\n        a  = (a << 5 | a >>> 27) + b | 0;\n        d += (a & c | b & ~c) + k[6] - 1069501632 | 0;\n        d  = (d << 9 | d >>> 23) + a | 0;\n        c += (d & b | a & ~b) + k[11] + 643717713 | 0;\n        c  = (c << 14 | c >>> 18) + d | 0;\n        b += (c & a | d & ~a) + k[0] - 373897302 | 0;\n        b  = (b << 20 | b >>> 12) + c | 0;\n        a += (b & d | c & ~d) + k[5] - 701558691 | 0;\n        a  = (a << 5 | a >>> 27) + b | 0;\n        d += (a & c | b & ~c) + k[10] + 38016083 | 0;\n        d  = (d << 9 | d >>> 23) + a | 0;\n        c += (d & b | a & ~b) + k[15] - 660478335 | 0;\n        c  = (c << 14 | c >>> 18) + d | 0;\n        b += (c & a | d & ~a) + k[4] - 405537848 | 0;\n        b  = (b << 20 | b >>> 12) + c | 0;\n        a += (b & d | c & ~d) + k[9] + 568446438 | 0;\n        a  = (a << 5 | a >>> 27) + b | 0;\n        d += (a & c | b & ~c) + k[14] - 1019803690 | 0;\n        d  = (d << 9 | d >>> 23) + a | 0;\n        c += (d & b | a & ~b) + k[3] - 187363961 | 0;\n        c  = (c << 14 | c >>> 18) + d | 0;\n        b += (c & a | d & ~a) + k[8] + 1163531501 | 0;\n        b  = (b << 20 | b >>> 12) + c | 0;\n        a += (b & d | c & ~d) + k[13] - 1444681467 | 0;\n        a  = (a << 5 | a >>> 27) + b | 0;\n        d += (a & c | b & ~c) + k[2] - 51403784 | 0;\n        d  = (d << 9 | d >>> 23) + a | 0;\n        c += (d & b | a & ~b) + k[7] + 1735328473 | 0;\n        c  = (c << 14 | c >>> 18) + d | 0;\n        b += (c & a | d & ~a) + k[12] - 1926607734 | 0;\n        b  = (b << 20 | b >>> 12) + c | 0;\n\n        a += (b ^ c ^ d) + k[5] - 378558 | 0;\n        a  = (a << 4 | a >>> 28) + b | 0;\n        d += (a ^ b ^ c) + k[8] - 2022574463 | 0;\n        d  = (d << 11 | d >>> 21) + a | 0;\n        c += (d ^ a ^ b) + k[11] + 1839030562 | 0;\n        c  = (c << 16 | c >>> 16) + d | 0;\n        b += (c ^ d ^ a) + k[14] - 35309556 | 0;\n        b  = (b << 23 | b >>> 9) + c | 0;\n        a += (b ^ c ^ d) + k[1] - 1530992060 | 0;\n        a  = (a << 4 | a >>> 28) + b | 0;\n        d += (a ^ b ^ c) + k[4] + 1272893353 | 0;\n        d  = (d << 11 | d >>> 21) + a | 0;\n        c += (d ^ a ^ b) + k[7] - 155497632 | 0;\n        c  = (c << 16 | c >>> 16) + d | 0;\n        b += (c ^ d ^ a) + k[10] - 1094730640 | 0;\n        b  = (b << 23 | b >>> 9) + c | 0;\n        a += (b ^ c ^ d) + k[13] + 681279174 | 0;\n        a  = (a << 4 | a >>> 28) + b | 0;\n        d += (a ^ b ^ c) + k[0] - 358537222 | 0;\n        d  = (d << 11 | d >>> 21) + a | 0;\n        c += (d ^ a ^ b) + k[3] - 722521979 | 0;\n        c  = (c << 16 | c >>> 16) + d | 0;\n        b += (c ^ d ^ a) + k[6] + 76029189 | 0;\n        b  = (b << 23 | b >>> 9) + c | 0;\n        a += (b ^ c ^ d) + k[9] - 640364487 | 0;\n        a  = (a << 4 | a >>> 28) + b | 0;\n        d += (a ^ b ^ c) + k[12] - 421815835 | 0;\n        d  = (d << 11 | d >>> 21) + a | 0;\n        c += (d ^ a ^ b) + k[15] + 530742520 | 0;\n        c  = (c << 16 | c >>> 16) + d | 0;\n        b += (c ^ d ^ a) + k[2] - 995338651 | 0;\n        b  = (b << 23 | b >>> 9) + c | 0;\n\n        a += (c ^ (b | ~d)) + k[0] - 198630844 | 0;\n        a  = (a << 6 | a >>> 26) + b | 0;\n        d += (b ^ (a | ~c)) + k[7] + 1126891415 | 0;\n        d  = (d << 10 | d >>> 22) + a | 0;\n        c += (a ^ (d | ~b)) + k[14] - 1416354905 | 0;\n        c  = (c << 15 | c >>> 17) + d | 0;\n        b += (d ^ (c | ~a)) + k[5] - 57434055 | 0;\n        b  = (b << 21 |b >>> 11) + c | 0;\n        a += (c ^ (b | ~d)) + k[12] + 1700485571 | 0;\n        a  = (a << 6 | a >>> 26) + b | 0;\n        d += (b ^ (a | ~c)) + k[3] - 1894986606 | 0;\n        d  = (d << 10 | d >>> 22) + a | 0;\n        c += (a ^ (d | ~b)) + k[10] - 1051523 | 0;\n        c  = (c << 15 | c >>> 17) + d | 0;\n        b += (d ^ (c | ~a)) + k[1] - 2054922799 | 0;\n        b  = (b << 21 |b >>> 11) + c | 0;\n        a += (c ^ (b | ~d)) + k[8] + 1873313359 | 0;\n        a  = (a << 6 | a >>> 26) + b | 0;\n        d += (b ^ (a | ~c)) + k[15] - 30611744 | 0;\n        d  = (d << 10 | d >>> 22) + a | 0;\n        c += (a ^ (d | ~b)) + k[6] - 1560198380 | 0;\n        c  = (c << 15 | c >>> 17) + d | 0;\n        b += (d ^ (c | ~a)) + k[13] + 1309151649 | 0;\n        b  = (b << 21 |b >>> 11) + c | 0;\n        a += (c ^ (b | ~d)) + k[4] - 145523070 | 0;\n        a  = (a << 6 | a >>> 26) + b | 0;\n        d += (b ^ (a | ~c)) + k[11] - 1120210379 | 0;\n        d  = (d << 10 | d >>> 22) + a | 0;\n        c += (a ^ (d | ~b)) + k[2] + 718787259 | 0;\n        c  = (c << 15 | c >>> 17) + d | 0;\n        b += (d ^ (c | ~a)) + k[9] - 343485551 | 0;\n        b  = (b << 21 | b >>> 11) + c | 0;\n\n        x[0] = a + x[0] | 0;\n        x[1] = b + x[1] | 0;\n        x[2] = c + x[2] | 0;\n        x[3] = d + x[3] | 0;\n    }\n\n    function md5blk(s) {\n        var md5blks = [],\n            i; /* Andy King said do it this way. */\n\n        for (i = 0; i < 64; i += 4) {\n            md5blks[i >> 2] = s.charCodeAt(i) + (s.charCodeAt(i + 1) << 8) + (s.charCodeAt(i + 2) << 16) + (s.charCodeAt(i + 3) << 24);\n        }\n        return md5blks;\n    }\n\n    function md5blk_array(a) {\n        var md5blks = [],\n            i; /* Andy King said do it this way. */\n\n        for (i = 0; i < 64; i += 4) {\n            md5blks[i >> 2] = a[i] + (a[i + 1] << 8) + (a[i + 2] << 16) + (a[i + 3] << 24);\n        }\n        return md5blks;\n    }\n\n    function md51(s) {\n        var n = s.length,\n            state = [1732584193, -271733879, -1732584194, 271733878],\n            i,\n            length,\n            tail,\n            tmp,\n            lo,\n            hi;\n\n        for (i = 64; i <= n; i += 64) {\n            md5cycle(state, md5blk(s.substring(i - 64, i)));\n        }\n        s = s.substring(i - 64);\n        length = s.length;\n        tail = [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0];\n        for (i = 0; i < length; i += 1) {\n            tail[i >> 2] |= s.charCodeAt(i) << ((i % 4) << 3);\n        }\n        tail[i >> 2] |= 0x80 << ((i % 4) << 3);\n        if (i > 55) {\n            md5cycle(state, tail);\n            for (i = 0; i < 16; i += 1) {\n                tail[i] = 0;\n            }\n        }\n\n        // Beware that the final length might not fit in 32 bits so we take care of that\n        tmp = n * 8;\n        tmp = tmp.toString(16).match(/(.*?)(.{0,8})$/);\n        lo = parseInt(tmp[2], 16);\n        hi = parseInt(tmp[1], 16) || 0;\n\n        tail[14] = lo;\n        tail[15] = hi;\n\n        md5cycle(state, tail);\n        return state;\n    }\n\n    function md51_array(a) {\n        var n = a.length,\n            state = [1732584193, -271733879, -1732584194, 271733878],\n            i,\n            length,\n            tail,\n            tmp,\n            lo,\n            hi;\n\n        for (i = 64; i <= n; i += 64) {\n            md5cycle(state, md5blk_array(a.subarray(i - 64, i)));\n        }\n\n        // Not sure if it is a bug, however IE10 will always produce a sub array of length 1\n        // containing the last element of the parent array if the sub array specified starts\n        // beyond the length of the parent array - weird.\n        // https://connect.microsoft.com/IE/feedback/details/771452/typed-array-subarray-issue\n        a = (i - 64) < n ? a.subarray(i - 64) : new Uint8Array(0);\n\n        length = a.length;\n        tail = [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0];\n        for (i = 0; i < length; i += 1) {\n            tail[i >> 2] |= a[i] << ((i % 4) << 3);\n        }\n\n        tail[i >> 2] |= 0x80 << ((i % 4) << 3);\n        if (i > 55) {\n            md5cycle(state, tail);\n            for (i = 0; i < 16; i += 1) {\n                tail[i] = 0;\n            }\n        }\n\n        // Beware that the final length might not fit in 32 bits so we take care of that\n        tmp = n * 8;\n        tmp = tmp.toString(16).match(/(.*?)(.{0,8})$/);\n        lo = parseInt(tmp[2], 16);\n        hi = parseInt(tmp[1], 16) || 0;\n\n        tail[14] = lo;\n        tail[15] = hi;\n\n        md5cycle(state, tail);\n\n        return state;\n    }\n\n    function rhex(n) {\n        var s = '',\n            j;\n        for (j = 0; j < 4; j += 1) {\n            s += hex_chr[(n >> (j * 8 + 4)) & 0x0F] + hex_chr[(n >> (j * 8)) & 0x0F];\n        }\n        return s;\n    }\n\n    function hex(x) {\n        var i;\n        for (i = 0; i < x.length; i += 1) {\n            x[i] = rhex(x[i]);\n        }\n        return x.join('');\n    }\n\n    // In some cases the fast add32 function cannot be used..\n    if (hex(md51('hello')) !== '5d41402abc4b2a76b9719d911017c592') {\n        add32 = function (x, y) {\n            var lsw = (x & 0xFFFF) + (y & 0xFFFF),\n                msw = (x >> 16) + (y >> 16) + (lsw >> 16);\n            return (msw << 16) | (lsw & 0xFFFF);\n        };\n    }\n\n    // ---------------------------------------------------\n\n    /**\n     * ArrayBuffer slice polyfill.\n     *\n     * @see https://github.com/ttaubert/node-arraybuffer-slice\n     */\n\n    if (typeof ArrayBuffer !== 'undefined' && !ArrayBuffer.prototype.slice) {\n        (function () {\n            function clamp(val, length) {\n                val = (val | 0) || 0;\n\n                if (val < 0) {\n                    return Math.max(val + length, 0);\n                }\n\n                return Math.min(val, length);\n            }\n\n            ArrayBuffer.prototype.slice = function (from, to) {\n                var length = this.byteLength,\n                    begin = clamp(from, length),\n                    end = length,\n                    num,\n                    target,\n                    targetArray,\n                    sourceArray;\n\n                if (to !== undefined) {\n                    end = clamp(to, length);\n                }\n\n                if (begin > end) {\n                    return new ArrayBuffer(0);\n                }\n\n                num = end - begin;\n                target = new ArrayBuffer(num);\n                targetArray = new Uint8Array(target);\n\n                sourceArray = new Uint8Array(this, begin, num);\n                targetArray.set(sourceArray);\n\n                return target;\n            };\n        })();\n    }\n\n    // ---------------------------------------------------\n\n    /**\n     * Helpers.\n     */\n\n    function toUtf8(str) {\n        if (/[\\u0080-\\uFFFF]/.test(str)) {\n            str = unescape(encodeURIComponent(str));\n        }\n\n        return str;\n    }\n\n    function utf8Str2ArrayBuffer(str, returnUInt8Array) {\n        var length = str.length,\n           buff = new ArrayBuffer(length),\n           arr = new Uint8Array(buff),\n           i;\n\n        for (i = 0; i < length; i += 1) {\n            arr[i] = str.charCodeAt(i);\n        }\n\n        return returnUInt8Array ? arr : buff;\n    }\n\n    function arrayBuffer2Utf8Str(buff) {\n        return String.fromCharCode.apply(null, new Uint8Array(buff));\n    }\n\n    function concatenateArrayBuffers(first, second, returnUInt8Array) {\n        var result = new Uint8Array(first.byteLength + second.byteLength);\n\n        result.set(new Uint8Array(first));\n        result.set(new Uint8Array(second), first.byteLength);\n\n        return returnUInt8Array ? result : result.buffer;\n    }\n\n    function hexToBinaryString(hex) {\n        var bytes = [],\n            length = hex.length,\n            x;\n\n        for (x = 0; x < length - 1; x += 2) {\n            bytes.push(parseInt(hex.substr(x, 2), 16));\n        }\n\n        return String.fromCharCode.apply(String, bytes);\n    }\n\n    // ---------------------------------------------------\n\n    /**\n     * SparkMD5 OOP implementation.\n     *\n     * Use this class to perform an incremental md5, otherwise use the\n     * static methods instead.\n     */\n\n    function SparkMD5() {\n        // call reset to init the instance\n        this.reset();\n    }\n\n    /**\n     * Appends a string.\n     * A conversion will be applied if an utf8 string is detected.\n     *\n     * @param {String} str The string to be appended\n     *\n     * @return {SparkMD5} The instance itself\n     */\n    SparkMD5.prototype.append = function (str) {\n        // Converts the string to utf8 bytes if necessary\n        // Then append as binary\n        this.appendBinary(toUtf8(str));\n\n        return this;\n    };\n\n    /**\n     * Appends a binary string.\n     *\n     * @param {String} contents The binary string to be appended\n     *\n     * @return {SparkMD5} The instance itself\n     */\n    SparkMD5.prototype.appendBinary = function (contents) {\n        this._buff += contents;\n        this._length += contents.length;\n\n        var length = this._buff.length,\n            i;\n\n        for (i = 64; i <= length; i += 64) {\n            md5cycle(this._hash, md5blk(this._buff.substring(i - 64, i)));\n        }\n\n        this._buff = this._buff.substring(i - 64);\n\n        return this;\n    };\n\n    /**\n     * Finishes the incremental computation, reseting the internal state and\n     * returning the result.\n     *\n     * @param {Boolean} raw True to get the raw string, false to get the hex string\n     *\n     * @return {String} The result\n     */\n    SparkMD5.prototype.end = function (raw) {\n        var buff = this._buff,\n            length = buff.length,\n            i,\n            tail = [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0],\n            ret;\n\n        for (i = 0; i < length; i += 1) {\n            tail[i >> 2] |= buff.charCodeAt(i) << ((i % 4) << 3);\n        }\n\n        this._finish(tail, length);\n        ret = hex(this._hash);\n\n        if (raw) {\n            ret = hexToBinaryString(ret);\n        }\n\n        this.reset();\n\n        return ret;\n    };\n\n    /**\n     * Resets the internal state of the computation.\n     *\n     * @return {SparkMD5} The instance itself\n     */\n    SparkMD5.prototype.reset = function () {\n        this._buff = '';\n        this._length = 0;\n        this._hash = [1732584193, -271733879, -1732584194, 271733878];\n\n        return this;\n    };\n\n    /**\n     * Gets the internal state of the computation.\n     *\n     * @return {Object} The state\n     */\n    SparkMD5.prototype.getState = function () {\n        return {\n            buff: this._buff,\n            length: this._length,\n            hash: this._hash\n        };\n    };\n\n    /**\n     * Gets the internal state of the computation.\n     *\n     * @param {Object} state The state\n     *\n     * @return {SparkMD5} The instance itself\n     */\n    SparkMD5.prototype.setState = function (state) {\n        this._buff = state.buff;\n        this._length = state.length;\n        this._hash = state.hash;\n\n        return this;\n    };\n\n    /**\n     * Releases memory used by the incremental buffer and other additional\n     * resources. If you plan to use the instance again, use reset instead.\n     */\n    SparkMD5.prototype.destroy = function () {\n        delete this._hash;\n        delete this._buff;\n        delete this._length;\n    };\n\n    /**\n     * Finish the final calculation based on the tail.\n     *\n     * @param {Array}  tail   The tail (will be modified)\n     * @param {Number} length The length of the remaining buffer\n     */\n    SparkMD5.prototype._finish = function (tail, length) {\n        var i = length,\n            tmp,\n            lo,\n            hi;\n\n        tail[i >> 2] |= 0x80 << ((i % 4) << 3);\n        if (i > 55) {\n            md5cycle(this._hash, tail);\n            for (i = 0; i < 16; i += 1) {\n                tail[i] = 0;\n            }\n        }\n\n        // Do the final computation based on the tail and length\n        // Beware that the final length may not fit in 32 bits so we take care of that\n        tmp = this._length * 8;\n        tmp = tmp.toString(16).match(/(.*?)(.{0,8})$/);\n        lo = parseInt(tmp[2], 16);\n        hi = parseInt(tmp[1], 16) || 0;\n\n        tail[14] = lo;\n        tail[15] = hi;\n        md5cycle(this._hash, tail);\n    };\n\n    /**\n     * Performs the md5 hash on a string.\n     * A conversion will be applied if utf8 string is detected.\n     *\n     * @param {String}  str The string\n     * @param {Boolean} raw True to get the raw string, false to get the hex string\n     *\n     * @return {String} The result\n     */\n    SparkMD5.hash = function (str, raw) {\n        // Converts the string to utf8 bytes if necessary\n        // Then compute it using the binary function\n        return SparkMD5.hashBinary(toUtf8(str), raw);\n    };\n\n    /**\n     * Performs the md5 hash on a binary string.\n     *\n     * @param {String}  content The binary string\n     * @param {Boolean} raw     True to get the raw string, false to get the hex string\n     *\n     * @return {String} The result\n     */\n    SparkMD5.hashBinary = function (content, raw) {\n        var hash = md51(content),\n            ret = hex(hash);\n\n        return raw ? hexToBinaryString(ret) : ret;\n    };\n\n    // ---------------------------------------------------\n\n    /**\n     * SparkMD5 OOP implementation for array buffers.\n     *\n     * Use this class to perform an incremental md5 ONLY for array buffers.\n     */\n    SparkMD5.ArrayBuffer = function () {\n        // call reset to init the instance\n        this.reset();\n    };\n\n    /**\n     * Appends an array buffer.\n     *\n     * @param {ArrayBuffer} arr The array to be appended\n     *\n     * @return {SparkMD5.ArrayBuffer} The instance itself\n     */\n    SparkMD5.ArrayBuffer.prototype.append = function (arr) {\n        var buff = concatenateArrayBuffers(this._buff.buffer, arr, true),\n            length = buff.length,\n            i;\n\n        this._length += arr.byteLength;\n\n        for (i = 64; i <= length; i += 64) {\n            md5cycle(this._hash, md5blk_array(buff.subarray(i - 64, i)));\n        }\n\n        this._buff = (i - 64) < length ? new Uint8Array(buff.buffer.slice(i - 64)) : new Uint8Array(0);\n\n        return this;\n    };\n\n    /**\n     * Finishes the incremental computation, reseting the internal state and\n     * returning the result.\n     *\n     * @param {Boolean} raw True to get the raw string, false to get the hex string\n     *\n     * @return {String} The result\n     */\n    SparkMD5.ArrayBuffer.prototype.end = function (raw) {\n        var buff = this._buff,\n            length = buff.length,\n            tail = [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0],\n            i,\n            ret;\n\n        for (i = 0; i < length; i += 1) {\n            tail[i >> 2] |= buff[i] << ((i % 4) << 3);\n        }\n\n        this._finish(tail, length);\n        ret = hex(this._hash);\n\n        if (raw) {\n            ret = hexToBinaryString(ret);\n        }\n\n        this.reset();\n\n        return ret;\n    };\n\n    /**\n     * Resets the internal state of the computation.\n     *\n     * @return {SparkMD5.ArrayBuffer} The instance itself\n     */\n    SparkMD5.ArrayBuffer.prototype.reset = function () {\n        this._buff = new Uint8Array(0);\n        this._length = 0;\n        this._hash = [1732584193, -271733879, -1732584194, 271733878];\n\n        return this;\n    };\n\n    /**\n     * Gets the internal state of the computation.\n     *\n     * @return {Object} The state\n     */\n    SparkMD5.ArrayBuffer.prototype.getState = function () {\n        var state = SparkMD5.prototype.getState.call(this);\n\n        // Convert buffer to a string\n        state.buff = arrayBuffer2Utf8Str(state.buff);\n\n        return state;\n    };\n\n    /**\n     * Gets the internal state of the computation.\n     *\n     * @param {Object} state The state\n     *\n     * @return {SparkMD5.ArrayBuffer} The instance itself\n     */\n    SparkMD5.ArrayBuffer.prototype.setState = function (state) {\n        // Convert string to buffer\n        state.buff = utf8Str2ArrayBuffer(state.buff, true);\n\n        return SparkMD5.prototype.setState.call(this, state);\n    };\n\n    SparkMD5.ArrayBuffer.prototype.destroy = SparkMD5.prototype.destroy;\n\n    SparkMD5.ArrayBuffer.prototype._finish = SparkMD5.prototype._finish;\n\n    /**\n     * Performs the md5 hash on an array buffer.\n     *\n     * @param {ArrayBuffer} arr The array buffer\n     * @param {Boolean}     raw True to get the raw string, false to get the hex one\n     *\n     * @return {String} The result\n     */\n    SparkMD5.ArrayBuffer.hash = function (arr, raw) {\n        var hash = md51_array(new Uint8Array(arr)),\n            ret = hex(hash);\n\n        return raw ? hexToBinaryString(ret) : ret;\n    };\n\n    return SparkMD5;\n}));\n\n\n\n//////////////////\n// WEBPACK FOOTER\n// ./~/spark-md5/spark-md5.js\n// module id = 95\n// module chunks = 0","'use strict';\n\n/**\n * Stringify/parse functions that don't operate\n * recursively, so they avoid call stack exceeded\n * errors.\n */\nexports.stringify = function stringify(input) {\n  var queue = [];\n  queue.push({obj: input});\n\n  var res = '';\n  var next, obj, prefix, val, i, arrayPrefix, keys, k, key, value, objPrefix;\n  while ((next = queue.pop())) {\n    obj = next.obj;\n    prefix = next.prefix || '';\n    val = next.val || '';\n    res += prefix;\n    if (val) {\n      res += val;\n    } else if (typeof obj !== 'object') {\n      res += typeof obj === 'undefined' ? null : JSON.stringify(obj);\n    } else if (obj === null) {\n      res += 'null';\n    } else if (Array.isArray(obj)) {\n      queue.push({val: ']'});\n      for (i = obj.length - 1; i >= 0; i--) {\n        arrayPrefix = i === 0 ? '' : ',';\n        queue.push({obj: obj[i], prefix: arrayPrefix});\n      }\n      queue.push({val: '['});\n    } else { // object\n      keys = [];\n      for (k in obj) {\n        if (obj.hasOwnProperty(k)) {\n          keys.push(k);\n        }\n      }\n      queue.push({val: '}'});\n      for (i = keys.length - 1; i >= 0; i--) {\n        key = keys[i];\n        value = obj[key];\n        objPrefix = (i > 0 ? ',' : '');\n        objPrefix += JSON.stringify(key) + ':';\n        queue.push({obj: value, prefix: objPrefix});\n      }\n      queue.push({val: '{'});\n    }\n  }\n  return res;\n};\n\n// Convenience function for the parse function.\n// This pop function is basically copied from\n// pouchCollate.parseIndexableString\nfunction pop(obj, stack, metaStack) {\n  var lastMetaElement = metaStack[metaStack.length - 1];\n  if (obj === lastMetaElement.element) {\n    // popping a meta-element, e.g. an object whose value is another object\n    metaStack.pop();\n    lastMetaElement = metaStack[metaStack.length - 1];\n  }\n  var element = lastMetaElement.element;\n  var lastElementIndex = lastMetaElement.index;\n  if (Array.isArray(element)) {\n    element.push(obj);\n  } else if (lastElementIndex === stack.length - 2) { // obj with key+value\n    var key = stack.pop();\n    element[key] = obj;\n  } else {\n    stack.push(obj); // obj with key only\n  }\n}\n\nexports.parse = function (str) {\n  var stack = [];\n  var metaStack = []; // stack for arrays and objects\n  var i = 0;\n  var collationIndex,parsedNum,numChar;\n  var parsedString,lastCh,numConsecutiveSlashes,ch;\n  var arrayElement, objElement;\n  while (true) {\n    collationIndex = str[i++];\n    if (collationIndex === '}' ||\n        collationIndex === ']' ||\n        typeof collationIndex === 'undefined') {\n      if (stack.length === 1) {\n        return stack.pop();\n      } else {\n        pop(stack.pop(), stack, metaStack);\n        continue;\n      }\n    }\n    switch (collationIndex) {\n      case ' ':\n      case '\\t':\n      case '\\n':\n      case ':':\n      case ',':\n        break;\n      case 'n':\n        i += 3; // 'ull'\n        pop(null, stack, metaStack);\n        break;\n      case 't':\n        i += 3; // 'rue'\n        pop(true, stack, metaStack);\n        break;\n      case 'f':\n        i += 4; // 'alse'\n        pop(false, stack, metaStack);\n        break;\n      case '0':\n      case '1':\n      case '2':\n      case '3':\n      case '4':\n      case '5':\n      case '6':\n      case '7':\n      case '8':\n      case '9':\n      case '-':\n        parsedNum = '';\n        i--;\n        while (true) {\n          numChar = str[i++];\n          if (/[\\d\\.\\-e\\+]/.test(numChar)) {\n            parsedNum += numChar;\n          } else {\n            i--;\n            break;\n          }\n        }\n        pop(parseFloat(parsedNum), stack, metaStack);\n        break;\n      case '\"':\n        parsedString = '';\n        lastCh = void 0;\n        numConsecutiveSlashes = 0;\n        while (true) {\n          ch = str[i++];\n          if (ch !== '\"' || (lastCh === '\\\\' &&\n              numConsecutiveSlashes % 2 === 1)) {\n            parsedString += ch;\n            lastCh = ch;\n            if (lastCh === '\\\\') {\n              numConsecutiveSlashes++;\n            } else {\n              numConsecutiveSlashes = 0;\n            }\n          } else {\n            break;\n          }\n        }\n        pop(JSON.parse('\"' + parsedString + '\"'), stack, metaStack);\n        break;\n      case '[':\n        arrayElement = { element: [], index: stack.length };\n        stack.push(arrayElement.element);\n        metaStack.push(arrayElement);\n        break;\n      case '{':\n        objElement = { element: {}, index: stack.length };\n        stack.push(objElement.element);\n        metaStack.push(objElement);\n        break;\n      default:\n        throw new Error(\n          'unexpectedly reached end of input: ' + collationIndex);\n    }\n  }\n};\n\n\n\n//////////////////\n// WEBPACK FOOTER\n// ./~/vuvuzela/index.js\n// module id = 96\n// module chunks = 0","(function(self) {\n  'use strict';\n\n  if (self.fetch) {\n    return\n  }\n\n  var support = {\n    searchParams: 'URLSearchParams' in self,\n    iterable: 'Symbol' in self && 'iterator' in Symbol,\n    blob: 'FileReader' in self && 'Blob' in self && (function() {\n      try {\n        new Blob()\n        return true\n      } catch(e) {\n        return false\n      }\n    })(),\n    formData: 'FormData' in self,\n    arrayBuffer: 'ArrayBuffer' in self\n  }\n\n  if (support.arrayBuffer) {\n    var viewClasses = [\n      '[object Int8Array]',\n      '[object Uint8Array]',\n      '[object Uint8ClampedArray]',\n      '[object Int16Array]',\n      '[object Uint16Array]',\n      '[object Int32Array]',\n      '[object Uint32Array]',\n      '[object Float32Array]',\n      '[object Float64Array]'\n    ]\n\n    var isDataView = function(obj) {\n      return obj && DataView.prototype.isPrototypeOf(obj)\n    }\n\n    var isArrayBufferView = ArrayBuffer.isView || function(obj) {\n      return obj && viewClasses.indexOf(Object.prototype.toString.call(obj)) > -1\n    }\n  }\n\n  function normalizeName(name) {\n    if (typeof name !== 'string') {\n      name = String(name)\n    }\n    if (/[^a-z0-9\\-#$%&'*+.\\^_`|~]/i.test(name)) {\n      throw new TypeError('Invalid character in header field name')\n    }\n    return name.toLowerCase()\n  }\n\n  function normalizeValue(value) {\n    if (typeof value !== 'string') {\n      value = String(value)\n    }\n    return value\n  }\n\n  // Build a destructive iterator for the value list\n  function iteratorFor(items) {\n    var iterator = {\n      next: function() {\n        var value = items.shift()\n        return {done: value === undefined, value: value}\n      }\n    }\n\n    if (support.iterable) {\n      iterator[Symbol.iterator] = function() {\n        return iterator\n      }\n    }\n\n    return iterator\n  }\n\n  function Headers(headers) {\n    this.map = {}\n\n    if (headers instanceof Headers) {\n      headers.forEach(function(value, name) {\n        this.append(name, value)\n      }, this)\n    } else if (Array.isArray(headers)) {\n      headers.forEach(function(header) {\n        this.append(header[0], header[1])\n      }, this)\n    } else if (headers) {\n      Object.getOwnPropertyNames(headers).forEach(function(name) {\n        this.append(name, headers[name])\n      }, this)\n    }\n  }\n\n  Headers.prototype.append = function(name, value) {\n    name = normalizeName(name)\n    value = normalizeValue(value)\n    var oldValue = this.map[name]\n    this.map[name] = oldValue ? oldValue+','+value : value\n  }\n\n  Headers.prototype['delete'] = function(name) {\n    delete this.map[normalizeName(name)]\n  }\n\n  Headers.prototype.get = function(name) {\n    name = normalizeName(name)\n    return this.has(name) ? this.map[name] : null\n  }\n\n  Headers.prototype.has = function(name) {\n    return this.map.hasOwnProperty(normalizeName(name))\n  }\n\n  Headers.prototype.set = function(name, value) {\n    this.map[normalizeName(name)] = normalizeValue(value)\n  }\n\n  Headers.prototype.forEach = function(callback, thisArg) {\n    for (var name in this.map) {\n      if (this.map.hasOwnProperty(name)) {\n        callback.call(thisArg, this.map[name], name, this)\n      }\n    }\n  }\n\n  Headers.prototype.keys = function() {\n    var items = []\n    this.forEach(function(value, name) { items.push(name) })\n    return iteratorFor(items)\n  }\n\n  Headers.prototype.values = function() {\n    var items = []\n    this.forEach(function(value) { items.push(value) })\n    return iteratorFor(items)\n  }\n\n  Headers.prototype.entries = function() {\n    var items = []\n    this.forEach(function(value, name) { items.push([name, value]) })\n    return iteratorFor(items)\n  }\n\n  if (support.iterable) {\n    Headers.prototype[Symbol.iterator] = Headers.prototype.entries\n  }\n\n  function consumed(body) {\n    if (body.bodyUsed) {\n      return Promise.reject(new TypeError('Already read'))\n    }\n    body.bodyUsed = true\n  }\n\n  function fileReaderReady(reader) {\n    return new Promise(function(resolve, reject) {\n      reader.onload = function() {\n        resolve(reader.result)\n      }\n      reader.onerror = function() {\n        reject(reader.error)\n      }\n    })\n  }\n\n  function readBlobAsArrayBuffer(blob) {\n    var reader = new FileReader()\n    var promise = fileReaderReady(reader)\n    reader.readAsArrayBuffer(blob)\n    return promise\n  }\n\n  function readBlobAsText(blob) {\n    var reader = new FileReader()\n    var promise = fileReaderReady(reader)\n    reader.readAsText(blob)\n    return promise\n  }\n\n  function readArrayBufferAsText(buf) {\n    var view = new Uint8Array(buf)\n    var chars = new Array(view.length)\n\n    for (var i = 0; i < view.length; i++) {\n      chars[i] = String.fromCharCode(view[i])\n    }\n    return chars.join('')\n  }\n\n  function bufferClone(buf) {\n    if (buf.slice) {\n      return buf.slice(0)\n    } else {\n      var view = new Uint8Array(buf.byteLength)\n      view.set(new Uint8Array(buf))\n      return view.buffer\n    }\n  }\n\n  function Body() {\n    this.bodyUsed = false\n\n    this._initBody = function(body) {\n      this._bodyInit = body\n      if (!body) {\n        this._bodyText = ''\n      } else if (typeof body === 'string') {\n        this._bodyText = body\n      } else if (support.blob && Blob.prototype.isPrototypeOf(body)) {\n        this._bodyBlob = body\n      } else if (support.formData && FormData.prototype.isPrototypeOf(body)) {\n        this._bodyFormData = body\n      } else if (support.searchParams && URLSearchParams.prototype.isPrototypeOf(body)) {\n        this._bodyText = body.toString()\n      } else if (support.arrayBuffer && support.blob && isDataView(body)) {\n        this._bodyArrayBuffer = bufferClone(body.buffer)\n        // IE 10-11 can't handle a DataView body.\n        this._bodyInit = new Blob([this._bodyArrayBuffer])\n      } else if (support.arrayBuffer && (ArrayBuffer.prototype.isPrototypeOf(body) || isArrayBufferView(body))) {\n        this._bodyArrayBuffer = bufferClone(body)\n      } else {\n        throw new Error('unsupported BodyInit type')\n      }\n\n      if (!this.headers.get('content-type')) {\n        if (typeof body === 'string') {\n          this.headers.set('content-type', 'text/plain;charset=UTF-8')\n        } else if (this._bodyBlob && this._bodyBlob.type) {\n          this.headers.set('content-type', this._bodyBlob.type)\n        } else if (support.searchParams && URLSearchParams.prototype.isPrototypeOf(body)) {\n          this.headers.set('content-type', 'application/x-www-form-urlencoded;charset=UTF-8')\n        }\n      }\n    }\n\n    if (support.blob) {\n      this.blob = function() {\n        var rejected = consumed(this)\n        if (rejected) {\n          return rejected\n        }\n\n        if (this._bodyBlob) {\n          return Promise.resolve(this._bodyBlob)\n        } else if (this._bodyArrayBuffer) {\n          return Promise.resolve(new Blob([this._bodyArrayBuffer]))\n        } else if (this._bodyFormData) {\n          throw new Error('could not read FormData body as blob')\n        } else {\n          return Promise.resolve(new Blob([this._bodyText]))\n        }\n      }\n\n      this.arrayBuffer = function() {\n        if (this._bodyArrayBuffer) {\n          return consumed(this) || Promise.resolve(this._bodyArrayBuffer)\n        } else {\n          return this.blob().then(readBlobAsArrayBuffer)\n        }\n      }\n    }\n\n    this.text = function() {\n      var rejected = consumed(this)\n      if (rejected) {\n        return rejected\n      }\n\n      if (this._bodyBlob) {\n        return readBlobAsText(this._bodyBlob)\n      } else if (this._bodyArrayBuffer) {\n        return Promise.resolve(readArrayBufferAsText(this._bodyArrayBuffer))\n      } else if (this._bodyFormData) {\n        throw new Error('could not read FormData body as text')\n      } else {\n        return Promise.resolve(this._bodyText)\n      }\n    }\n\n    if (support.formData) {\n      this.formData = function() {\n        return this.text().then(decode)\n      }\n    }\n\n    this.json = function() {\n      return this.text().then(JSON.parse)\n    }\n\n    return this\n  }\n\n  // HTTP methods whose capitalization should be normalized\n  var methods = ['DELETE', 'GET', 'HEAD', 'OPTIONS', 'POST', 'PUT']\n\n  function normalizeMethod(method) {\n    var upcased = method.toUpperCase()\n    return (methods.indexOf(upcased) > -1) ? upcased : method\n  }\n\n  function Request(input, options) {\n    options = options || {}\n    var body = options.body\n\n    if (input instanceof Request) {\n      if (input.bodyUsed) {\n        throw new TypeError('Already read')\n      }\n      this.url = input.url\n      this.credentials = input.credentials\n      if (!options.headers) {\n        this.headers = new Headers(input.headers)\n      }\n      this.method = input.method\n      this.mode = input.mode\n      if (!body && input._bodyInit != null) {\n        body = input._bodyInit\n        input.bodyUsed = true\n      }\n    } else {\n      this.url = String(input)\n    }\n\n    this.credentials = options.credentials || this.credentials || 'omit'\n    if (options.headers || !this.headers) {\n      this.headers = new Headers(options.headers)\n    }\n    this.method = normalizeMethod(options.method || this.method || 'GET')\n    this.mode = options.mode || this.mode || null\n    this.referrer = null\n\n    if ((this.method === 'GET' || this.method === 'HEAD') && body) {\n      throw new TypeError('Body not allowed for GET or HEAD requests')\n    }\n    this._initBody(body)\n  }\n\n  Request.prototype.clone = function() {\n    return new Request(this, { body: this._bodyInit })\n  }\n\n  function decode(body) {\n    var form = new FormData()\n    body.trim().split('&').forEach(function(bytes) {\n      if (bytes) {\n        var split = bytes.split('=')\n        var name = split.shift().replace(/\\+/g, ' ')\n        var value = split.join('=').replace(/\\+/g, ' ')\n        form.append(decodeURIComponent(name), decodeURIComponent(value))\n      }\n    })\n    return form\n  }\n\n  function parseHeaders(rawHeaders) {\n    var headers = new Headers()\n    rawHeaders.split(/\\r?\\n/).forEach(function(line) {\n      var parts = line.split(':')\n      var key = parts.shift().trim()\n      if (key) {\n        var value = parts.join(':').trim()\n        headers.append(key, value)\n      }\n    })\n    return headers\n  }\n\n  Body.call(Request.prototype)\n\n  function Response(bodyInit, options) {\n    if (!options) {\n      options = {}\n    }\n\n    this.type = 'default'\n    this.status = 'status' in options ? options.status : 200\n    this.ok = this.status >= 200 && this.status < 300\n    this.statusText = 'statusText' in options ? options.statusText : 'OK'\n    this.headers = new Headers(options.headers)\n    this.url = options.url || ''\n    this._initBody(bodyInit)\n  }\n\n  Body.call(Response.prototype)\n\n  Response.prototype.clone = function() {\n    return new Response(this._bodyInit, {\n      status: this.status,\n      statusText: this.statusText,\n      headers: new Headers(this.headers),\n      url: this.url\n    })\n  }\n\n  Response.error = function() {\n    var response = new Response(null, {status: 0, statusText: ''})\n    response.type = 'error'\n    return response\n  }\n\n  var redirectStatuses = [301, 302, 303, 307, 308]\n\n  Response.redirect = function(url, status) {\n    if (redirectStatuses.indexOf(status) === -1) {\n      throw new RangeError('Invalid status code')\n    }\n\n    return new Response(null, {status: status, headers: {location: url}})\n  }\n\n  self.Headers = Headers\n  self.Request = Request\n  self.Response = Response\n\n  self.fetch = function(input, init) {\n    return new Promise(function(resolve, reject) {\n      var request = new Request(input, init)\n      var xhr = new XMLHttpRequest()\n\n      xhr.onload = function() {\n        var options = {\n          status: xhr.status,\n          statusText: xhr.statusText,\n          headers: parseHeaders(xhr.getAllResponseHeaders() || '')\n        }\n        options.url = 'responseURL' in xhr ? xhr.responseURL : options.headers.get('X-Request-URL')\n        var body = 'response' in xhr ? xhr.response : xhr.responseText\n        resolve(new Response(body, options))\n      }\n\n      xhr.onerror = function() {\n        reject(new TypeError('Network request failed'))\n      }\n\n      xhr.ontimeout = function() {\n        reject(new TypeError('Network request failed'))\n      }\n\n      xhr.open(request.method, request.url, true)\n\n      if (request.credentials === 'include') {\n        xhr.withCredentials = true\n      }\n\n      if ('responseType' in xhr && support.blob) {\n        xhr.responseType = 'blob'\n      }\n\n      request.headers.forEach(function(value, name) {\n        xhr.setRequestHeader(name, value)\n      })\n\n      xhr.send(typeof request._bodyInit === 'undefined' ? null : request._bodyInit)\n    })\n  }\n  self.fetch.polyfill = true\n})(typeof self !== 'undefined' ? self : this);\n\n\n\n//////////////////\n// WEBPACK FOOTER\n// ./~/whatwg-fetch/fetch.js\n// module id = 97\n// module chunks = 0"],"sourceRoot":""}